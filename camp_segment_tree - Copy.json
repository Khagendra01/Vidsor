{
  "video": "camp.mp4",
  "fps": 30,
  "tracker": "bytetrack",
  "seconds": [
    {
      "second": 0,
      "time_range": [
        0,
        0.999
      ],
      "frame_range": [
        1,
        30
      ],
      "unified_description": "1-second scene where the main focus is on a man in a green shirt and sunglasses standing on a mountain",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:35",
        "processing_time": 10.08,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15,
          "frame_range": [
            11,
            15
          ],
          "description": "a man in a green shirt and sunglasses is standing on a mountain",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 3.57
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1,
            5
          ],
          "representative_frame": 1,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9507590532302856,
              "bbox": [
                204.27996826171875,
                28.640380859375,
                467.83856201171875,
                356.35443115234375
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6,
            10
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11,
            15
          ],
          "representative_frame": 11,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9539904594421387,
              "bbox": [
                200.9285888671875,
                28.712146759033203,
                464.7741394042969,
                356.6958312988281
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16,
            20
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            21,
            25
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9593721628189087,
              "bbox": [
                194.09121704101562,
                30.067119598388672,
                457.08636474609375,
                356.7889099121094
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            26,
            30
          ],
          "representative_frame": 26,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 0
    },
    {
      "second": 1,
      "time_range": [
        1,
        1.999
      ],
      "frame_range": [
        31,
        60
      ],
      "unified_description": "5-second descriptions are provided for free.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:36",
        "processing_time": 10.3,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 45,
          "frame_range": [
            41,
            45
          ],
          "description": "a man in a green shirt and hat is pointing at the camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 3.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            31,
            35
          ],
          "representative_frame": 31,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9604988694190979,
              "bbox": [
                185.72994995117188,
                30.24675178527832,
                449.0813903808594,
                356.6740417480469
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            36,
            40
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            41,
            45
          ],
          "representative_frame": 41,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9628799557685852,
              "bbox": [
                179.6627960205078,
                31.858909606933594,
                443.65155029296875,
                356.674072265625
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            46,
            50
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            51,
            55
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9547137022018433,
              "bbox": [
                191.21890258789062,
                30.82033920288086,
                458.150146484375,
                356.30987548828125
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            56,
            60
          ],
          "representative_frame": 56,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 0
    },
    {
      "second": 2,
      "time_range": [
        2,
        2.999
      ],
      "frame_range": [
        61,
        90
      ],
      "unified_description": "\n\nIn the image, there is a person wearing a green shirt and hat who is pointing at the camera. The field of view includes multiple objects simultaneously, which might be indicative of a POV camera perspective. Additionally, some technical details, such as possible motion blur or lens flare, can be observed in the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:35",
        "processing_time": 9.54,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 75,
          "frame_range": [
            71,
            75
          ],
          "description": "a man in a green shirt and hat pointing at the camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 3.38
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            61,
            65
          ],
          "representative_frame": 61,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9500173926353455,
              "bbox": [
                203.93826293945312,
                26.70396614074707,
                476.53582763671875,
                356.08660888671875
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            66,
            70
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            71,
            75
          ],
          "representative_frame": 71,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9538323283195496,
              "bbox": [
                209.8795166015625,
                23.710832595825195,
                487.2662658691406,
                356.1751708984375
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            76,
            80
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            81,
            85
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9561107754707336,
              "bbox": [
                224.47352600097656,
                26.760604858398438,
                500.51483154296875,
                356.1374206542969
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            86,
            90
          ],
          "representative_frame": 86,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 0
    },
    {
      "second": 3,
      "time_range": [
        3,
        3.999
      ],
      "frame_range": [
        91,
        120
      ],
      "unified_description": "1-second scene with a man in a helicopter flying over a mountain",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:39",
        "processing_time": 2.37,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 105,
          "frame_range": [
            101,
            105
          ],
          "description": "a man in a helicopter flying over a mountain",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.59
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            91,
            95
          ],
          "representative_frame": 91,
          "detections": [
            {
              "track_id": 1,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.47193643450737,
              "bbox": [
                194.7380828857422,
                31.609464645385742,
                490.82061767578125,
                354.4194030761719
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            96,
            100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            101,
            105
          ],
          "representative_frame": 101,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8430745601654053,
              "bbox": [
                0.0,
                165.96701049804688,
                234.9156494140625,
                357.66070556640625
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            106,
            110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            111,
            115
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8344135284423828,
              "bbox": [
                0.0,
                161.25543212890625,
                237.47085571289062,
                357.37652587890625
              ]
            },
            {
              "track_id": 4,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.36499059200286865,
              "bbox": [
                5.231254577636719,
                20.09417724609375,
                636.9119873046875,
                354.03887939453125
              ]
            }
          ],
          "unique_tracks": [
            3,
            4
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            116,
            120
          ],
          "representative_frame": 116,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 0
    },
    {
      "second": 4,
      "time_range": [
        4,
        4.999
      ],
      "frame_range": [
        121,
        150
      ],
      "unified_description": "1-second scene featuring a small plane sitting on the water, mounted camera providing wide-angle perspective, stable camera positioning, and various objects/people visible in frame.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:40",
        "processing_time": 2.92,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 135,
          "frame_range": [
            131,
            135
          ],
          "description": "a small plane is sitting on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.49
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            121,
            125
          ],
          "representative_frame": 121,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7873885631561279,
              "bbox": [
                2.467545747756958,
                158.8382568359375,
                248.50486755371094,
                357.0202331542969
              ]
            },
            {
              "track_id": 4,
              "class_id": 7,
              "class_name": "truck",
              "confidence": 0.5431358814239502,
              "bbox": [
                3.354332447052002,
                24.57671546936035,
                626.3038330078125,
                354.01153564453125
              ]
            }
          ],
          "unique_tracks": [
            3,
            4
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            126,
            130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            131,
            135
          ],
          "representative_frame": 131,
          "detections": [
            {
              "track_id": 4,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5294943451881409,
              "bbox": [
                5.591200351715088,
                6.318665504455566,
                640.0,
                345.8898010253906
              ]
            }
          ],
          "unique_tracks": [
            4
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            136,
            140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            141,
            145
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 4,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.8670928478240967,
              "bbox": [
                8.87352180480957,
                1.693039059638977,
                636.357177734375,
                333.63336181640625
              ]
            }
          ],
          "unique_tracks": [
            4
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            146,
            150
          ],
          "representative_frame": 146,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 1
    },
    {
      "second": 5,
      "time_range": [
        5,
        5.999
      ],
      "frame_range": [
        151,
        180
      ],
      "unified_description": "2d scene from a first-person perspective camera view with several objects present in the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:40",
        "processing_time": 3.32,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 165,
          "frame_range": [
            161,
            165
          ],
          "description": "a man is standing near a tent by the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.38
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            151,
            155
          ],
          "representative_frame": 151,
          "detections": [
            {
              "track_id": 4,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.8478488326072693,
              "bbox": [
                40.14228820800781,
                0.08027173578739166,
                603.4263916015625,
                295.53369140625
              ]
            }
          ],
          "unique_tracks": [
            4
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            156,
            160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            161,
            165
          ],
          "representative_frame": 161,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.931973934173584,
              "bbox": [
                0.0,
                10.13897705078125,
                363.3157043457031,
                354.19805908203125
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            166,
            170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            171,
            175
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.829245924949646,
              "bbox": [
                0.0,
                0.0,
                378.255615234375,
                354.0686340332031
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            176,
            180
          ],
          "representative_frame": 176,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 1
    },
    {
      "second": 6,
      "time_range": [
        6,
        6.999
      ],
      "frame_range": [
        181,
        210
      ],
      "unified_description": "4k Wide Angle Shot of a Man in the Woods",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:42",
        "processing_time": 2.34,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 195,
          "frame_range": [
            191,
            195
          ],
          "description": "a man is standing next to a tree",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.88
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            181,
            185
          ],
          "representative_frame": 181,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8930047750473022,
              "bbox": [
                0.0,
                0.0,
                420.9224853515625,
                353.85809326171875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            186,
            190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            191,
            195
          ],
          "representative_frame": 191,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9282649755477905,
              "bbox": [
                323.32574462890625,
                82.76326751708984,
                578.5562133789062,
                356.781494140625
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            196,
            200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            201,
            205
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 6,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9323602318763733,
              "bbox": [
                4.4222846031188965,
                79.98775482177734,
                178.65444946289062,
                297.514892578125
              ]
            },
            {
              "track_id": 7,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8692275881767273,
              "bbox": [
                120.25582122802734,
                78.73434448242188,
                241.56735229492188,
                221.86155700683594
              ]
            },
            {
              "track_id": 9,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.36055564880371094,
              "bbox": [
                591.116455078125,
                193.38723754882812,
                608.5519409179688,
                229.3829345703125
              ]
            },
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9152858853340149,
              "bbox": [
                330.4203186035156,
                96.2899169921875,
                578.4588012695312,
                356.8045959472656
              ]
            }
          ],
          "unique_tracks": [
            6,
            7,
            9,
            1
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            206,
            210
          ],
          "representative_frame": 206,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 1
    },
    {
      "second": 7,
      "time_range": [
        7,
        7.999
      ],
      "frame_range": [
        211,
        240
      ],
      "unified_description": "2 men are having lunch together in this image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:43",
        "processing_time": 2.26,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 225,
          "frame_range": [
            221,
            225
          ],
          "description": "two people sitting on the ground eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.24
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            211,
            215
          ],
          "representative_frame": 211,
          "detections": [
            {
              "track_id": 6,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9271562099456787,
              "bbox": [
                4.738406658172607,
                80.32447052001953,
                178.5801544189453,
                297.34912109375
              ]
            },
            {
              "track_id": 7,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8400675654411316,
              "bbox": [
                119.3870620727539,
                77.89501953125,
                242.1838836669922,
                222.84059143066406
              ]
            },
            {
              "track_id": 9,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3400264084339142,
              "bbox": [
                591.0966186523438,
                193.36166381835938,
                608.554443359375,
                229.4056396484375
              ]
            },
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9291509389877319,
              "bbox": [
                326.6929626464844,
                95.57341003417969,
                579.859619140625,
                356.73126220703125
              ]
            }
          ],
          "unique_tracks": [
            6,
            7,
            9,
            1
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            216,
            220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            221,
            225
          ],
          "representative_frame": 221,
          "detections": [
            {
              "track_id": 6,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9247143268585205,
              "bbox": [
                4.3079962730407715,
                80.0662841796875,
                178.9336395263672,
                298.0809326171875
              ]
            },
            {
              "track_id": 7,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8589786887168884,
              "bbox": [
                119.35272216796875,
                77.64167785644531,
                242.0414581298828,
                222.49232482910156
              ]
            },
            {
              "track_id": 9,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3422187268733978,
              "bbox": [
                591.098876953125,
                193.37351989746094,
                608.5467529296875,
                229.4010772705078
              ]
            },
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9265065789222717,
              "bbox": [
                323.67669677734375,
                100.79772186279297,
                577.2544555664062,
                356.7384033203125
              ]
            },
            {
              "track_id": 11,
              "class_id": 34,
              "class_name": "baseball bat",
              "confidence": 0.3225689232349396,
              "bbox": [
                486.1221008300781,
                109.23503875732422,
                639.2018432617188,
                161.22732543945312
              ]
            }
          ],
          "unique_tracks": [
            6,
            7,
            9,
            1,
            11
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            226,
            230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            231,
            235
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            236,
            240
          ],
          "representative_frame": 236,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 1
    },
    {
      "second": 8,
      "time_range": [
        8,
        8.999
      ],
      "frame_range": [
        241,
        270
      ],
      "unified_description": "\nIn this scene there is a man standing by the water with a fishing rod in his hand. He appears to be focused on his activity. The camera capturing this moment is mounted on a backpack, providing a first-person perspective of the scene. There are two boats visible on the lake which adds context and interest to the image. The overall setting seems to be outdoors by a body of water, possibly in a recreational or fishing environment.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:45",
        "processing_time": 4.05,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 255,
          "frame_range": [
            251,
            255
          ],
          "description": "a man fishing on a lake with two boats",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            241,
            245
          ],
          "representative_frame": 241,
          "detections": [
            {
              "track_id": 12,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9111188054084778,
              "bbox": [
                234.63186645507812,
                117.04703521728516,
                303.3243713378906,
                322.637451171875
              ]
            },
            {
              "track_id": 13,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8304157853126526,
              "bbox": [
                0.0,
                259.26287841796875,
                230.623046875,
                343.9941711425781
              ]
            },
            {
              "track_id": 14,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.751838743686676,
              "bbox": [
                413.3829040527344,
                242.48324584960938,
                584.4465942382812,
                321.5242919921875
              ]
            }
          ],
          "unique_tracks": [
            12,
            13,
            14
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            246,
            250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            251,
            255
          ],
          "representative_frame": 251,
          "detections": [
            {
              "track_id": 12,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9150422811508179,
              "bbox": [
                233.34942626953125,
                117.66963958740234,
                301.96075439453125,
                322.6609802246094
              ]
            },
            {
              "track_id": 13,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8250353336334229,
              "bbox": [
                0.0,
                259.2254943847656,
                230.84445190429688,
                344.1025085449219
              ]
            },
            {
              "track_id": 14,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7433767318725586,
              "bbox": [
                413.5086669921875,
                242.47808837890625,
                584.4810791015625,
                321.4820861816406
              ]
            }
          ],
          "unique_tracks": [
            12,
            13,
            14
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            256,
            260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            261,
            265
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 12,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.91446852684021,
              "bbox": [
                230.76446533203125,
                117.9176254272461,
                299.6139221191406,
                322.5917663574219
              ]
            },
            {
              "track_id": 13,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8414720296859741,
              "bbox": [
                0.0,
                258.9443054199219,
                231.16094970703125,
                344.0950012207031
              ]
            },
            {
              "track_id": 14,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7516250014305115,
              "bbox": [
                414.1439514160156,
                242.90655517578125,
                584.0535888671875,
                321.4108581542969
              ]
            }
          ],
          "unique_tracks": [
            12,
            13,
            14
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            266,
            270
          ],
          "representative_frame": 266,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 2
    },
    {
      "second": 9,
      "time_range": [
        9,
        9.999
      ],
      "frame_range": [
        271,
        300
      ],
      "unified_description": "1-second scene that features a man holdinging a fish in his hand",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:46",
        "processing_time": 3.39,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 285,
          "frame_range": [
            281,
            285
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            271,
            275
          ],
          "representative_frame": 271,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6290048956871033,
              "bbox": [
                344.145751953125,
                10.357288360595703,
                640.0,
                336.541748046875
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            276,
            280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            281,
            285
          ],
          "representative_frame": 281,
          "detections": [
            {
              "track_id": 15,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.7643557786941528,
              "bbox": [
                87.25816345214844,
                111.0964126586914,
                442.3265380859375,
                258.9237365722656
              ]
            },
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8466410636901855,
              "bbox": [
                345.1493835449219,
                2.3944804668426514,
                640.0,
                342.50445556640625
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7455866932868958,
              "bbox": [
                118.17118835449219,
                0.0,
                363.2675476074219,
                195.37974548339844
              ]
            }
          ],
          "unique_tracks": [
            15,
            1,
            3
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            286,
            290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            291,
            295
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 15,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.8417583107948303,
              "bbox": [
                90.37540435791016,
                112.01891326904297,
                421.9374694824219,
                250.15145874023438
              ]
            },
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7874661684036255,
              "bbox": [
                338.8258361816406,
                0.0,
                640.0,
                346.666259765625
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7460663914680481,
              "bbox": [
                119.09014129638672,
                0.0,
                350.3685607910156,
                185.9444122314453
              ]
            }
          ],
          "unique_tracks": [
            15,
            1,
            3
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            296,
            300
          ],
          "representative_frame": 296,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 2
    },
    {
      "second": 10,
      "time_range": [
        10,
        10.999
      ],
      "frame_range": [
        301,
        330
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:46",
        "processing_time": 2.12,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 315,
          "frame_range": [
            311,
            315
          ],
          "description": "a young boy holding a fish on a rock",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            301,
            305
          ],
          "representative_frame": 301,
          "detections": [
            {
              "track_id": 15,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8303283452987671,
              "bbox": [
                0.0,
                35.35582733154297,
                640.0,
                336.470458984375
              ]
            }
          ],
          "unique_tracks": [
            15
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            306,
            310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            311,
            315
          ],
          "representative_frame": 311,
          "detections": [
            {
              "track_id": 17,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.6782817840576172,
              "bbox": [
                171.94107055664062,
                244.53268432617188,
                520.3787841796875,
                346.28485107421875
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8581926822662354,
              "bbox": [
                111.85317993164062,
                8.231097221374512,
                487.92681884765625,
                332.3021240234375
              ]
            }
          ],
          "unique_tracks": [
            17,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            316,
            320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            321,
            325
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 17,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.5650207996368408,
              "bbox": [
                182.94747924804688,
                256.0105895996094,
                517.5365600585938,
                353.7800598144531
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8131354451179504,
              "bbox": [
                129.02310180664062,
                5.861510276794434,
                519.8340454101562,
                358.677001953125
              ]
            }
          ],
          "unique_tracks": [
            17,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            326,
            330
          ],
          "representative_frame": 326,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 2
    },
    {
      "second": 11,
      "time_range": [
        11,
        11.999
      ],
      "frame_range": [
        331,
        360
      ],
      "unified_description": "1-second scene with a man holding a fish in his hands",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:50",
        "processing_time": 2.34,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 345,
          "frame_range": [
            341,
            345
          ],
          "description": "a man holding a fish in his hands",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.12
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            331,
            335
          ],
          "representative_frame": 331,
          "detections": [
            {
              "track_id": 13,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7444362044334412,
              "bbox": [
                0.0,
                183.04299926757812,
                292.6763000488281,
                356.3812561035156
              ]
            }
          ],
          "unique_tracks": [
            13
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            336,
            340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            341,
            345
          ],
          "representative_frame": 341,
          "detections": [
            {
              "track_id": 18,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8482088446617126,
              "bbox": [
                177.2501220703125,
                138.13565063476562,
                539.3565673828125,
                231.2949981689453
              ]
            },
            {
              "track_id": 20,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.445970356464386,
              "bbox": [
                120.88544464111328,
                1.0379120111465454,
                458.90582275390625,
                149.32647705078125
              ]
            },
            {
              "track_id": 6,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7161080241203308,
              "bbox": [
                0.5282527208328247,
                183.80845642089844,
                139.0198516845703,
                356.6011657714844
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4823489487171173,
              "bbox": [
                124.54611206054688,
                4.630040168762207,
                494.0894470214844,
                343.1195983886719
              ]
            }
          ],
          "unique_tracks": [
            18,
            20,
            6,
            3
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            346,
            350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            351,
            355
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            356,
            360
          ],
          "representative_frame": 356,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 2
    },
    {
      "second": 12,
      "time_range": [
        12,
        12.999
      ],
      "frame_range": [
        361,
        390
      ],
      "unified_description": "2 people are walking up a hill, and there is a lake in the background.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:52",
        "processing_time": 2.93,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 375,
          "frame_range": [
            371,
            375
          ],
          "description": "two people walking up a hill with a lake in the background",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            361,
            365
          ],
          "representative_frame": 361,
          "detections": [
            {
              "track_id": 21,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8674055337905884,
              "bbox": [
                274.6982727050781,
                135.482421875,
                326.3636169433594,
                243.0889892578125
              ]
            }
          ],
          "unique_tracks": [
            21
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            366,
            370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            371,
            375
          ],
          "representative_frame": 371,
          "detections": [
            {
              "track_id": 21,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8479529619216919,
              "bbox": [
                290.9670104980469,
                136.4116973876953,
                344.7263488769531,
                249.2429656982422
              ]
            }
          ],
          "unique_tracks": [
            21
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            376,
            380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            381,
            385
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9571301341056824,
              "bbox": [
                211.9161834716797,
                5.777378082275391,
                604.2592163085938,
                356.8426818847656
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            386,
            390
          ],
          "representative_frame": 386,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 3
    },
    {
      "second": 13,
      "time_range": [
        13,
        13.999
      ],
      "frame_range": [
        391,
        420
      ],
      "unified_description": "\n- Video has a wide-angle perspective, capturing a lot of the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:51",
        "processing_time": 2.61,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 405,
          "frame_range": [
            401,
            405
          ],
          "description": "a man in a boat on a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.25
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            391,
            395
          ],
          "representative_frame": 391,
          "detections": [
            {
              "track_id": 25,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8015137910842896,
              "bbox": [
                90.29822540283203,
                161.04348754882812,
                195.7443084716797,
                189.76095581054688
              ]
            },
            {
              "track_id": 26,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6737478375434875,
              "bbox": [
                155.45335388183594,
                143.25021362304688,
                176.78054809570312,
                169.69638061523438
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9418284296989441,
              "bbox": [
                224.48934936523438,
                4.061923027038574,
                624.959228515625,
                358.54296875
              ]
            }
          ],
          "unique_tracks": [
            25,
            26,
            3
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            396,
            400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            401,
            405
          ],
          "representative_frame": 401,
          "detections": [
            {
              "track_id": 25,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8141570091247559,
              "bbox": [
                94.73973846435547,
                160.93006896972656,
                198.24746704101562,
                189.1554412841797
              ]
            },
            {
              "track_id": 26,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6967717409133911,
              "bbox": [
                156.38836669921875,
                142.89794921875,
                178.22039794921875,
                169.87428283691406
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9407411813735962,
              "bbox": [
                238.7548828125,
                3.326655149459839,
                640.0,
                358.72900390625
              ]
            }
          ],
          "unique_tracks": [
            25,
            26,
            3
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            406,
            410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            411,
            415
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9003905057907104,
              "bbox": [
                178.743896484375,
                3.7526447772979736,
                561.3082275390625,
                358.7680969238281
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            416,
            420
          ],
          "representative_frame": 416,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 3
    },
    {
      "second": 14,
      "time_range": [
        14,
        14.999
      ],
      "frame_range": [
        421,
        450
      ],
      "unified_description": "1-second scene featuring a man in a hat sitting in a barrel",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:54",
        "processing_time": 2.38,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 435,
          "frame_range": [
            431,
            435
          ],
          "description": "a man in a hat is sitting in a barrel",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            421,
            425
          ],
          "representative_frame": 421,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.92197185754776,
              "bbox": [
                173.3914031982422,
                3.138709306716919,
                539.2730712890625,
                358.98431396484375
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            426,
            430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            431,
            435
          ],
          "representative_frame": 431,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.933417797088623,
              "bbox": [
                186.55673217773438,
                2.768325090408325,
                535.2510375976562,
                358.3570861816406
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            436,
            440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            441,
            445
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.923451840877533,
              "bbox": [
                162.53793334960938,
                2.8503153324127197,
                503.1936950683594,
                358.2141418457031
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            446,
            450
          ],
          "representative_frame": 446,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 3
    },
    {
      "second": 15,
      "time_range": [
        15,
        15.999
      ],
      "frame_range": [
        451,
        480
      ],
      "unified_description": "\nFirst-person video that includes a man standing in front of a wooden cabin. The camera is mounted on a tripod, providing stable footage. There are also several other objects visible within the scene, which can be seen in the image descriptions above.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:56",
        "processing_time": 3.04,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 465,
          "frame_range": [
            461,
            465
          ],
          "description": "a man standing in front of a wooden cabin",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.12
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            451,
            455
          ],
          "representative_frame": 451,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8693680763244629,
              "bbox": [
                188.39634704589844,
                6.034997463226318,
                489.5587463378906,
                343.0153503417969
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            456,
            460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            461,
            465
          ],
          "representative_frame": 461,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9088011384010315,
              "bbox": [
                189.1995086669922,
                3.500164747238159,
                471.4242248535156,
                338.1645812988281
              ]
            },
            {
              "track_id": 30,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.44643038511276245,
              "bbox": [
                495.47314453125,
                147.68080139160156,
                540.1699829101562,
                173.1026153564453
              ]
            }
          ],
          "unique_tracks": [
            3,
            30
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            466,
            470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            471,
            475
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9186460375785828,
              "bbox": [
                188.37322998046875,
                2.6713833808898926,
                454.659423828125,
                336.5171813964844
              ]
            },
            {
              "track_id": 30,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3647236227989197,
              "bbox": [
                497.0612487792969,
                149.71730041503906,
                538.7732543945312,
                173.3939208984375
              ]
            }
          ],
          "unique_tracks": [
            3,
            30
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            476,
            480
          ],
          "representative_frame": 476,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 3
    },
    {
      "second": 16,
      "time_range": [
        16,
        16.999
      ],
      "frame_range": [
        481,
        510
      ],
      "unified_description": "\n\n1. The camera was stable while recording this footage.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:57",
        "processing_time": 3.17,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 495,
          "frame_range": [
            491,
            495
          ],
          "description": "a man is sitting in a chair outside",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.85
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            481,
            485
          ],
          "representative_frame": 481,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8871590495109558,
              "bbox": [
                200.7762908935547,
                21.67636489868164,
                439.8064880371094,
                334.477294921875
              ]
            },
            {
              "track_id": 30,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4400121569633484,
              "bbox": [
                495.9029541015625,
                148.59420776367188,
                539.7811889648438,
                173.48133850097656
              ]
            }
          ],
          "unique_tracks": [
            3,
            30
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            486,
            490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            491,
            495
          ],
          "representative_frame": 491,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7757158279418945,
              "bbox": [
                221.53392028808594,
                67.23560333251953,
                413.34796142578125,
                321.53045654296875
              ]
            },
            {
              "track_id": 30,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.34263381361961365,
              "bbox": [
                496.2203063964844,
                149.9191436767578,
                538.0302734375,
                173.55677795410156
              ]
            }
          ],
          "unique_tracks": [
            3,
            30
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            496,
            500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            501,
            505
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7885887622833252,
              "bbox": [
                240.23910522460938,
                103.81822967529297,
                395.664794921875,
                308.4963073730469
              ]
            },
            {
              "track_id": 30,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2701997458934784,
              "bbox": [
                499.3487854003906,
                153.359375,
                535.307861328125,
                173.4190216064453
              ]
            }
          ],
          "unique_tracks": [
            3,
            30
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            506,
            510
          ],
          "representative_frame": 506,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 4
    },
    {
      "second": 17,
      "time_range": [
        17,
        17.999
      ],
      "frame_range": [
        511,
        540
      ],
      "unified_description": "\nI'll try to analyze the image descriptions and object detections summary provided and give a detailed response.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:12:58",
        "processing_time": 2.75,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 525,
          "frame_range": [
            521,
            525
          ],
          "description": "a man sitting on a chair in front of a building",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.27
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            511,
            515
          ],
          "representative_frame": 511,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8524378538131714,
              "bbox": [
                238.87091064453125,
                88.288330078125,
                399.85693359375,
                302.2279968261719
              ]
            },
            {
              "track_id": 30,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.24693694710731506,
              "bbox": [
                498.84844970703125,
                153.158447265625,
                535.3453979492188,
                173.32174682617188
              ]
            },
            {
              "track_id": 38,
              "class_id": 56,
              "class_name": "chair",
              "confidence": 0.37760233879089355,
              "bbox": [
                87.51709747314453,
                151.34776306152344,
                185.6719970703125,
                304.9002685546875
              ]
            }
          ],
          "unique_tracks": [
            3,
            30,
            38
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            516,
            520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            521,
            525
          ],
          "representative_frame": 521,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8379719853401184,
              "bbox": [
                227.46083068847656,
                83.86406707763672,
                409.6244201660156,
                331.02508544921875
              ]
            },
            {
              "track_id": 30,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.28783661127090454,
              "bbox": [
                498.8332214355469,
                152.7891387939453,
                536.0499877929688,
                173.1571044921875
              ]
            },
            {
              "track_id": 38,
              "class_id": 56,
              "class_name": "chair",
              "confidence": 0.3350902199745178,
              "bbox": [
                87.8659439086914,
                151.82127380371094,
                185.64942932128906,
                304.7488098144531
              ]
            },
            {
              "track_id": 39,
              "class_id": 56,
              "class_name": "chair",
              "confidence": 0.3479427993297577,
              "bbox": [
                385.1808776855469,
                2.740344285964966,
                558.3450927734375,
                355.0648498535156
              ]
            }
          ],
          "unique_tracks": [
            3,
            30,
            38,
            39
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            526,
            530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            531,
            535
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            536,
            540
          ],
          "representative_frame": 536,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 4
    },
    {
      "second": 18,
      "time_range": [
        18,
        18.999
      ],
      "frame_range": [
        541,
        570
      ],
      "unified_description": "30 fps camera capturing outdoor scene on a sunny day.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:01",
        "processing_time": 2.39,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 555,
          "frame_range": [
            551,
            555
          ],
          "description": "a large axe is stuck into a tree stump",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.4
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            541,
            545
          ],
          "representative_frame": 541,
          "detections": [
            {
              "track_id": 41,
              "class_id": 10,
              "class_name": "fire hydrant",
              "confidence": 0.34705090522766113,
              "bbox": [
                77.93897247314453,
                53.57273483276367,
                610.8735961914062,
                354.2466125488281
              ]
            }
          ],
          "unique_tracks": [
            41
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            546,
            550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            551,
            555
          ],
          "representative_frame": 551,
          "detections": [
            {
              "track_id": 41,
              "class_id": 13,
              "class_name": "bench",
              "confidence": 0.34419217705726624,
              "bbox": [
                49.495662689208984,
                54.902915954589844,
                580.1690673828125,
                353.39666748046875
              ]
            }
          ],
          "unique_tracks": [
            41
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            556,
            560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            561,
            565
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            566,
            570
          ],
          "representative_frame": 566,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 4
    },
    {
      "second": 19,
      "time_range": [
        19,
        19.999
      ],
      "frame_range": [
        571,
        600
      ],
      "unified_description": "1-second scene with 6 groups containing object data such as colors, positions, movements, etc.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:02",
        "processing_time": 2.64,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 585,
          "frame_range": [
            581,
            585
          ],
          "description": "a axe is stuck into a tree stump",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.58
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            571,
            575
          ],
          "representative_frame": 571,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            576,
            580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            581,
            585
          ],
          "representative_frame": 581,
          "detections": [
            {
              "track_id": 3,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.7303178906440735,
              "bbox": [
                232.18661499023438,
                76.84481048583984,
                402.96356201171875,
                298.4319152832031
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            586,
            590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            591,
            595
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.36373913288116455,
              "bbox": [
                229.68482971191406,
                74.96784210205078,
                405.6263122558594,
                295.4705505371094
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            596,
            600
          ],
          "representative_frame": 596,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 4
    },
    {
      "second": 20,
      "time_range": [
        20,
        20.999
      ],
      "frame_range": [
        601,
        630
      ],
      "unified_description": "1-second scene with a knife on top of a tree stump",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:02",
        "processing_time": 2.62,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 615,
          "frame_range": [
            611,
            615
          ],
          "description": "a knife is on top of a tree stump",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.9
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            601,
            605
          ],
          "representative_frame": 601,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.4220951795578003,
              "bbox": [
                229.9632568359375,
                74.50051879882812,
                405.5723571777344,
                287.173095703125
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            606,
            610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            611,
            615
          ],
          "representative_frame": 611,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.5173249244689941,
              "bbox": [
                230.40785217285156,
                74.1837387084961,
                405.8936462402344,
                279.9039001464844
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            616,
            620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            621,
            625
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.4418213665485382,
              "bbox": [
                228.93280029296875,
                74.04158782958984,
                408.0507507324219,
                278.71435546875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            626,
            630
          ],
          "representative_frame": 626,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 5
    },
    {
      "second": 21,
      "time_range": [
        21,
        21.999
      ],
      "frame_range": [
        631,
        660
      ],
      "unified_description": "1 second video with objects detected including the logo for the new logo",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:04",
        "processing_time": 2.32,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 645,
          "frame_range": [
            641,
            645
          ],
          "description": "the logo for the new logo",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.82
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            631,
            635
          ],
          "representative_frame": 631,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.3371151089668274,
              "bbox": [
                226.37522888183594,
                73.76626586914062,
                410.3453063964844,
                279.9217224121094
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            636,
            640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            641,
            645
          ],
          "representative_frame": 641,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.5020081996917725,
              "bbox": [
                223.80850219726562,
                73.850830078125,
                412.9742736816406,
                282.76055908203125
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            646,
            650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            651,
            655
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.4738010764122009,
              "bbox": [
                222.24342346191406,
                73.86904907226562,
                414.5700378417969,
                283.55902099609375
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            656,
            660
          ],
          "representative_frame": 656,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 5
    },
    {
      "second": 22,
      "time_range": [
        22,
        22.999
      ],
      "frame_range": [
        661,
        690
      ],
      "unified_description": "\nThere is an unsteady camera position which may cause some motion blur in the final product. The camera is panning a subject while also capturing other objects and people in the field of view.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:06",
        "processing_time": 2.84,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 675,
          "frame_range": [
            671,
            675
          ],
          "description": "the logo for the new logo",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.12
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            661,
            665
          ],
          "representative_frame": 661,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.4738010764122009,
              "bbox": [
                220.99807739257812,
                73.86750030517578,
                415.8253479003906,
                283.9198303222656
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            666,
            670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            671,
            675
          ],
          "representative_frame": 671,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.7880275845527649,
              "bbox": [
                223.6882781982422,
                73.69390106201172,
                413.45428466796875,
                274.84442138671875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            676,
            680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            681,
            685
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            686,
            690
          ],
          "representative_frame": 686,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 5
    },
    {
      "second": 23,
      "time_range": [
        23,
        23.999
      ],
      "frame_range": [
        691,
        720
      ],
      "unified_description": "3rd person perspective camera mounted on top of a vehicle, capturing the road ahead as the car drives forward.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:07",
        "processing_time": 3.01,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 705,
          "frame_range": [
            701,
            705
          ],
          "description": "a man driving a car on a road",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.17
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            691,
            695
          ],
          "representative_frame": 691,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            696,
            700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            701,
            705
          ],
          "representative_frame": 701,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            706,
            710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            711,
            715
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            716,
            720
          ],
          "representative_frame": 716,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 5
    },
    {
      "second": 24,
      "time_range": [
        24,
        24.999
      ],
      "frame_range": [
        721,
        750
      ],
      "unified_description": "1-second scene featuring a man in a car with a child inside, captured using either a wide-angle or fisheye lens, resulting in some distortion. The camera was likely mounted on a tripod, giving a stable view.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:09",
        "processing_time": 3.31,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 735,
          "frame_range": [
            731,
            735
          ],
          "description": "a man in a car with a child inside",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            721,
            725
          ],
          "representative_frame": 721,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5361323952674866,
              "bbox": [
                1.7283062934875488,
                0.0,
                639.0068969726562,
                355.7532653808594
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            726,
            730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            731,
            735
          ],
          "representative_frame": 731,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.668205738067627,
              "bbox": [
                3.3491687774658203,
                1.5994490385055542,
                637.8045043945312,
                355.74481201171875
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8908608555793762,
              "bbox": [
                132.87954711914062,
                68.30899810791016,
                401.94036865234375,
                350.9401550292969
              ]
            }
          ],
          "unique_tracks": [
            48,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            736,
            740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            741,
            745
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6371522545814514,
              "bbox": [
                3.642571210861206,
                1.200789213180542,
                637.4706420898438,
                354.995849609375
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9161389470100403,
              "bbox": [
                137.62042236328125,
                45.39576721191406,
                440.6848449707031,
                356.720947265625
              ]
            }
          ],
          "unique_tracks": [
            48,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            746,
            750
          ],
          "representative_frame": 746,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 6
    },
    {
      "second": 25,
      "time_range": [
        25,
        25.999
      ],
      "frame_range": [
        751,
        780
      ],
      "unified_description": "\nBased on these image descriptions and object detections, provide a first draft description of this 1-second scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:11",
        "processing_time": 2.53,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 765,
          "frame_range": [
            761,
            765
          ],
          "description": "a man in a black jacket and hat is sitting in a car",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.06
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            751,
            755
          ],
          "representative_frame": 751,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.4150708317756653,
              "bbox": [
                100.39016723632812,
                2.505370855331421,
                640.0,
                354.4175720214844
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9048471450805664,
              "bbox": [
                114.0639877319336,
                18.1608829498291,
                452.50732421875,
                359.5174865722656
              ]
            }
          ],
          "unique_tracks": [
            48,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            756,
            760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            761,
            765
          ],
          "representative_frame": 761,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.934381902217865,
              "bbox": [
                120.8203353881836,
                5.561675548553467,
                453.2113342285156,
                359.4986267089844
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            766,
            770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            771,
            775
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9386749863624573,
              "bbox": [
                131.72007751464844,
                0.3407890796661377,
                450.5264892578125,
                355.9888916015625
              ]
            },
            {
              "track_id": 60,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6706032156944275,
              "bbox": [
                94.05941772460938,
                55.44511795043945,
                113.0194091796875,
                71.58521270751953
              ]
            },
            {
              "track_id": 61,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5133658647537231,
              "bbox": [
                118.87480163574219,
                52.88211441040039,
                139.66920471191406,
                68.05957794189453
              ]
            },
            {
              "track_id": 65,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.46981433033943176,
              "bbox": [
                284.2461853027344,
                194.27967834472656,
                433.0501708984375,
                352.6500549316406
              ]
            }
          ],
          "unique_tracks": [
            3,
            60,
            61,
            65
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            776,
            780
          ],
          "representative_frame": 776,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 6
    },
    {
      "second": 26,
      "time_range": [
        26,
        26.999
      ],
      "frame_range": [
        781,
        810
      ],
      "unified_description": "1-second scene that features a man walking down the street with a bag",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:11",
        "processing_time": 2.67,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 795,
          "frame_range": [
            791,
            795
          ],
          "description": "a man walking down the street with a bag",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.72
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            781,
            785
          ],
          "representative_frame": 781,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9283356666564941,
              "bbox": [
                145.59022521972656,
                0.0,
                450.6273498535156,
                352.9218444824219
              ]
            },
            {
              "track_id": 60,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6596017479896545,
              "bbox": [
                90.57091522216797,
                58.95198059082031,
                108.48828125,
                74.08747863769531
              ]
            },
            {
              "track_id": 61,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.56939297914505,
              "bbox": [
                115.72232055664062,
                53.03430938720703,
                139.1595458984375,
                69.97315216064453
              ]
            },
            {
              "track_id": 65,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.634682834148407,
              "bbox": [
                299.6012268066406,
                190.01156616210938,
                454.3472900390625,
                355.0867919921875
              ]
            },
            {
              "track_id": 68,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6619961261749268,
              "bbox": [
                9.11666488647461,
                70.63339233398438,
                30.359798431396484,
                88.8972396850586
              ]
            },
            {
              "track_id": 69,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.674278199672699,
              "bbox": [
                61.54948806762695,
                61.78109359741211,
                86.17050170898438,
                79.06307983398438
              ]
            },
            {
              "track_id": 71,
              "class_id": 13,
              "class_name": "bench",
              "confidence": 0.490220844745636,
              "bbox": [
                472.89251708984375,
                95.30583190917969,
                640.0,
                292.7455139160156
              ]
            }
          ],
          "unique_tracks": [
            3,
            60,
            61,
            65,
            68,
            69,
            71
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            786,
            790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            791,
            795
          ],
          "representative_frame": 791,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9449130296707153,
              "bbox": [
                157.0575714111328,
                6.993293285369873,
                448.01336669921875,
                357.0520935058594
              ]
            },
            {
              "track_id": 60,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6823520064353943,
              "bbox": [
                82.06362915039062,
                60.10684585571289,
                103.0902328491211,
                77.66513061523438
              ]
            },
            {
              "track_id": 65,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.4126829206943512,
              "bbox": [
                303.995361328125,
                195.63450622558594,
                453.5994567871094,
                355.38824462890625
              ]
            },
            {
              "track_id": 71,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.15302139520645142,
              "bbox": [
                436.8477478027344,
                38.848140716552734,
                640.0,
                315.5296630859375
              ]
            },
            {
              "track_id": 78,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.5953928828239441,
              "bbox": [
                199.9081268310547,
                143.66114807128906,
                279.33331298828125,
                259.2653503417969
              ]
            }
          ],
          "unique_tracks": [
            3,
            60,
            65,
            71,
            78
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            796,
            800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            801,
            805
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9338885545730591,
              "bbox": [
                146.1367645263672,
                13.502362251281738,
                400.49749755859375,
                334.9223937988281
              ]
            },
            {
              "track_id": 38,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8640209436416626,
              "bbox": [
                83.96177673339844,
                80.1750259399414,
                212.78952026367188,
                299.527587890625
              ]
            },
            {
              "track_id": 48,
              "class_id": 7,
              "class_name": "truck",
              "confidence": 0.4843319356441498,
              "bbox": [
                159.4651641845703,
                1.6919254064559937,
                640.0,
                351.7928771972656
              ]
            }
          ],
          "unique_tracks": [
            3,
            38,
            48
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            806,
            810
          ],
          "representative_frame": 806,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 6
    },
    {
      "second": 27,
      "time_range": [
        27,
        27.999
      ],
      "frame_range": [
        811,
        840
      ],
      "unified_description": "30 FPS camera capturing the scene for 1 second",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:12",
        "processing_time": 2.44,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 825,
          "frame_range": [
            821,
            825
          ],
          "description": "a man is getting off the boat and getting off",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.72
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            811,
            815
          ],
          "representative_frame": 811,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9060192704200745,
              "bbox": [
                172.67324829101562,
                18.569948196411133,
                411.0365295410156,
                328.6295471191406
              ]
            },
            {
              "track_id": 86,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8031141757965088,
              "bbox": [
                396.82183837890625,
                0.6285034418106079,
                492.34979248046875,
                143.03598022460938
              ]
            },
            {
              "track_id": 38,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7323946356773376,
              "bbox": [
                72.97857666015625,
                83.37869262695312,
                201.0489501953125,
                310.2547302246094
              ]
            }
          ],
          "unique_tracks": [
            3,
            86,
            38
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            816,
            820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            821,
            825
          ],
          "representative_frame": 821,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8702690005302429,
              "bbox": [
                187.86065673828125,
                22.000181198120117,
                417.9136657714844,
                330.20513916015625
              ]
            },
            {
              "track_id": 86,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8310878276824951,
              "bbox": [
                384.3182373046875,
                1.4211361408233643,
                484.00067138671875,
                150.0093994140625
              ]
            },
            {
              "track_id": 38,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8776016235351562,
              "bbox": [
                58.43954849243164,
                88.04810333251953,
                187.26702880859375,
                316.2081298828125
              ]
            },
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.516939103603363,
              "bbox": [
                50.71964645385742,
                0.7708845138549805,
                631.7314453125,
                338.7986145019531
              ]
            }
          ],
          "unique_tracks": [
            3,
            86,
            38,
            48
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            826,
            830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            831,
            835
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 38,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9424980878829956,
              "bbox": [
                43.04193878173828,
                127.51924896240234,
                179.5804901123047,
                343.0180969238281
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9508558511734009,
              "bbox": [
                119.03192138671875,
                27.619976043701172,
                640.0,
                350.4071350097656
              ]
            }
          ],
          "unique_tracks": [
            38,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            836,
            840
          ],
          "representative_frame": 836,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 6
    },
    {
      "second": 28,
      "time_range": [
        28,
        28.999
      ],
      "frame_range": [
        841,
        870
      ],
      "unified_description": "1-second scene including a person working on a car and a tripod-mounted camera capturing the action.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:15",
        "processing_time": 2.55,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 855,
          "frame_range": [
            851,
            855
          ],
          "description": "a man in a black jacket and hat is fixing a car",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.16
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            841,
            845
          ],
          "representative_frame": 841,
          "detections": [
            {
              "track_id": 38,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.827157199382782,
              "bbox": [
                84.46376037597656,
                162.09722900390625,
                198.41696166992188,
                353.2633972167969
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9153852462768555,
              "bbox": [
                109.2424545288086,
                9.687538146972656,
                640.0,
                353.833740234375
              ]
            }
          ],
          "unique_tracks": [
            38,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            846,
            850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            851,
            855
          ],
          "representative_frame": 851,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8914344906806946,
              "bbox": [
                112.83139038085938,
                3.7557578086853027,
                640.0,
                354.5275573730469
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            856,
            860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            861,
            865
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9392359256744385,
              "bbox": [
                109.31672668457031,
                1.3611606359481812,
                640.0,
                354.145263671875
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            866,
            870
          ],
          "representative_frame": 866,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 7
    },
    {
      "second": 29,
      "time_range": [
        29,
        29.999
      ],
      "frame_range": [
        871,
        900
      ],
      "unified_description": "\n\nThe image depicts an outdoor scene featuring a person riding on top of a helicopter. The camera is mounted on the side of the helicopter, capturing the pilot's perspective as they fly through the sky. In addition to the main subject, multiple other objects can be seen in the background, giving the viewer a sense of depth and context for the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:17",
        "processing_time": 4.35,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 885,
          "frame_range": [
            881,
            885
          ],
          "description": "a man in a helicopter with a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.74
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            871,
            875
          ],
          "representative_frame": 871,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8885224461555481,
              "bbox": [
                101.22441864013672,
                1.6924222707748413,
                640.0,
                355.65576171875
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            876,
            880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            881,
            885
          ],
          "representative_frame": 881,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9158449172973633,
              "bbox": [
                209.93768310546875,
                3.290266275405884,
                481.4488830566406,
                353.5797119140625
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            886,
            890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            891,
            895
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9296180009841919,
              "bbox": [
                197.08132934570312,
                0.9266600012779236,
                479.072265625,
                355.56524658203125
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            896,
            900
          ],
          "representative_frame": 896,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 7
    },
    {
      "second": 30,
      "time_range": [
        30,
        30.999
      ],
      "frame_range": [
        901,
        930
      ],
      "unified_description": "10-second scene including a man in a boat on a river with additional people and objects.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:18",
        "processing_time": 4.54,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 915,
          "frame_range": [
            911,
            915
          ],
          "description": "a man in a boat is driving down the river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.41
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            901,
            905
          ],
          "representative_frame": 901,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9167084097862244,
              "bbox": [
                173.7749786376953,
                0.6344751715660095,
                462.9635009765625,
                356.41326904296875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            906,
            910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            911,
            915
          ],
          "representative_frame": 911,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9266306757926941,
              "bbox": [
                117.78829193115234,
                25.059602737426758,
                405.00054931640625,
                356.99298095703125
              ]
            },
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.4672582149505615,
              "bbox": [
                45.828826904296875,
                0.12883207201957703,
                612.1990966796875,
                358.8778381347656
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            916,
            920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            921,
            925
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.932878315448761,
              "bbox": [
                87.39833068847656,
                33.4404411315918,
                380.7978820800781,
                357.14544677734375
              ]
            },
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.2802688181400299,
              "bbox": [
                37.692298889160156,
                0.006107895635068417,
                610.2054443359375,
                357.6490478515625
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            926,
            930
          ],
          "representative_frame": 926,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 7
    },
    {
      "second": 31,
      "time_range": [
        31,
        31.999
      ],
      "frame_range": [
        931,
        960
      ],
      "unified_description": "\n\nIn the image, there are several objects and people present. There is a boat in the water near a house, which appears to be the main focus of the scene. A person can also be seen standing near the water. In addition, there are six groups of people in the picture, who seem to be engaged in various activities around the scene. \n\nFrom a technical standpoint, the image displays an overall stable camera perspective and a wide-angle view capturing most of the action in the scene. The camera positioning is also notably steady, which allows for better appreciation of the content within the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:21",
        "processing_time": 4.5,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 945,
          "frame_range": [
            941,
            945
          ],
          "description": "a boat is in the water near a house",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.19
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            931,
            935
          ],
          "representative_frame": 931,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9381016492843628,
              "bbox": [
                74.5602035522461,
                43.67771530151367,
                370.2759094238281,
                357.2982177734375
              ]
            },
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.4720124900341034,
              "bbox": [
                32.90250778198242,
                0.11531289666891098,
                611.4443359375,
                357.2621765136719
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            936,
            940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            941,
            945
          ],
          "representative_frame": 941,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            946,
            950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            951,
            955
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 98,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.4834085702896118,
              "bbox": [
                0.0,
                154.6630859375,
                305.7347412109375,
                356.6422424316406
              ]
            }
          ],
          "unique_tracks": [
            98
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            956,
            960
          ],
          "representative_frame": 956,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 7
    },
    {
      "second": 32,
      "time_range": [
        32,
        32.999
      ],
      "frame_range": [
        961,
        990
      ],
      "unified_description": "\n\n1. Content Description - What is happening in the scene:\n   - Objects, people, actions, and location",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:22",
        "processing_time": 3.03,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 975,
          "frame_range": [
            971,
            975
          ],
          "description": "a boat is seen from the inside of a boat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.59
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            961,
            965
          ],
          "representative_frame": 961,
          "detections": [
            {
              "track_id": 98,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.3332473933696747,
              "bbox": [
                0.0,
                143.4626007080078,
                308.6209411621094,
                356.62725830078125
              ]
            }
          ],
          "unique_tracks": [
            98
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            966,
            970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            971,
            975
          ],
          "representative_frame": 971,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            976,
            980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            981,
            985
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.766850471496582,
              "bbox": [
                29.810867309570312,
                0.6032494902610779,
                612.0947875976562,
                355.1989440917969
              ]
            },
            {
              "track_id": 98,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8595413565635681,
              "bbox": [
                0.0,
                116.57970428466797,
                305.1280822753906,
                357.4620361328125
              ]
            }
          ],
          "unique_tracks": [
            48,
            98
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            986,
            990
          ],
          "representative_frame": 986,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 8
    },
    {
      "second": 33,
      "time_range": [
        33,
        33.999
      ],
      "frame_range": [
        991,
        1020
      ],
      "unified_description": "1 second video with a man in a boat, various objects and people visible, shot with wide-angle lens, stable camera positioning, and no technical artifacts.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:23",
        "processing_time": 3.7,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1005,
          "frame_range": [
            1001,
            1005
          ],
          "description": "a man in a boat with a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.28
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            991,
            995
          ],
          "representative_frame": 991,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.5626766681671143,
              "bbox": [
                39.473079681396484,
                0.8910201191902161,
                622.5177612304688,
                353.84478759765625
              ]
            },
            {
              "track_id": 98,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8841067552566528,
              "bbox": [
                0.0,
                105.11524963378906,
                305.03094482421875,
                357.2315368652344
              ]
            }
          ],
          "unique_tracks": [
            48,
            98
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            996,
            1000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1001,
            1005
          ],
          "representative_frame": 1001,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.592369794845581,
              "bbox": [
                31.42171859741211,
                0.3194715082645416,
                621.2943725585938,
                354.42816162109375
              ]
            },
            {
              "track_id": 98,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.514421284198761,
              "bbox": [
                0.0,
                95.71366119384766,
                307.3730773925781,
                357.53582763671875
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.42377811670303345,
              "bbox": [
                69.52680969238281,
                96.58651733398438,
                342.0187683105469,
                357.86822509765625
              ]
            }
          ],
          "unique_tracks": [
            48,
            98,
            3
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            1006,
            1010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1011,
            1015
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.3662808835506439,
              "bbox": [
                23.776174545288086,
                0.42814701795578003,
                621.1045532226562,
                356.11151123046875
              ]
            },
            {
              "track_id": 98,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7698674201965332,
              "bbox": [
                0.0,
                88.66758728027344,
                301.9595031738281,
                357.4642639160156
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.49235057830810547,
              "bbox": [
                60.82086944580078,
                99.48299407958984,
                350.7794494628906,
                358.5273132324219
              ]
            }
          ],
          "unique_tracks": [
            48,
            98,
            3
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            1016,
            1020
          ],
          "representative_frame": 1016,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 8
    },
    {
      "second": 34,
      "time_range": [
        34,
        34.999
      ],
      "frame_range": [
        1021,
        1050
      ],
      "unified_description": "30 second video with multiple objects",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:25",
        "processing_time": 2.21,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1035,
          "frame_range": [
            1031,
            1035
          ],
          "description": "a man in a helicopter flying over a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.37
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1021,
            1025
          ],
          "representative_frame": 1021,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.5164409279823303,
              "bbox": [
                19.868118286132812,
                0.9014606475830078,
                620.4977416992188,
                355.7303161621094
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8586081266403198,
              "bbox": [
                62.59945297241211,
                133.7034149169922,
                336.6865234375,
                358.6729431152344
              ]
            }
          ],
          "unique_tracks": [
            48,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1026,
            1030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1031,
            1035
          ],
          "representative_frame": 1031,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.3202051520347595,
              "bbox": [
                16.874223709106445,
                0.7966554164886475,
                621.9468994140625,
                355.7550354003906
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8582004308700562,
              "bbox": [
                66.9483642578125,
                160.7610626220703,
                329.2913513183594,
                358.7542724609375
              ]
            }
          ],
          "unique_tracks": [
            48,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1036,
            1040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1041,
            1045
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.3014465570449829,
              "bbox": [
                15.405102729797363,
                1.222306489944458,
                623.4153442382812,
                355.7214050292969
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8429576754570007,
              "bbox": [
                61.649662017822266,
                164.92901611328125,
                334.30828857421875,
                358.6414794921875
              ]
            }
          ],
          "unique_tracks": [
            48,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1046,
            1050
          ],
          "representative_frame": 1046,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 8
    },
    {
      "second": 35,
      "time_range": [
        35,
        35.999
      ],
      "frame_range": [
        1051,
        1080
      ],
      "unified_description": "1-second scene, content description, camera perspective, field of view, lens characteristics, production style, lighting, frame composition, and any technical artifacts.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:26",
        "processing_time": 2.69,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1065,
          "frame_range": [
            1061,
            1065
          ],
          "description": "a view of a lake from a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.46
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1051,
            1055
          ],
          "representative_frame": 1051,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.27592402696609497,
              "bbox": [
                14.006561279296875,
                1.0126320123672485,
                624.67724609375,
                355.18359375
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8524879813194275,
              "bbox": [
                54.07356262207031,
                162.42481994628906,
                342.9205017089844,
                358.5458984375
              ]
            }
          ],
          "unique_tracks": [
            48,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1056,
            1060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1061,
            1065
          ],
          "representative_frame": 1061,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.6146875023841858,
              "bbox": [
                66.29114532470703,
                76.82581329345703,
                570.31689453125,
                353.5520935058594
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1066,
            1070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1071,
            1075
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.5474815964698792,
              "bbox": [
                46.19620132446289,
                58.97629165649414,
                589.814453125,
                353.027587890625
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1076,
            1080
          ],
          "representative_frame": 1076,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 8
    },
    {
      "second": 36,
      "time_range": [
        36,
        36.999
      ],
      "frame_range": [
        1081,
        1110
      ],
      "unified_description": "\n\n1. Content Description - What is happening in the scene:\n   - A small plane flying over a lake\n   - This could be part of a travel vlog or a recreational activity like skydiving\n   - The camera angle suggests the person is capturing their own perspective as they experience this moment\n\n2. Camera Perspective and Technical Details:\n   - Handheld camera, mounted on a body harness\n   - Wide-angle lens, capturing the plane and lake in the same frame\n   - No signs of motion blur, fisheye effect, or other technical artifacts indicate that the camera is stable and properly focused on the subjects",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:29",
        "processing_time": 5.37,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1095,
          "frame_range": [
            1091,
            1095
          ],
          "description": "a small plane flying over a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.78
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1081,
            1085
          ],
          "representative_frame": 1081,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.5629032850265503,
              "bbox": [
                58.71556091308594,
                80.40958404541016,
                579.9160766601562,
                354.18023681640625
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1086,
            1090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1091,
            1095
          ],
          "representative_frame": 1091,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            1096,
            1100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1101,
            1105
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8985850811004639,
              "bbox": [
                0.0,
                21.137800216674805,
                541.4817504882812,
                355.64813232421875
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1106,
            1110
          ],
          "representative_frame": 1106,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 9
    },
    {
      "second": 37,
      "time_range": [
        37,
        37.999
      ],
      "frame_range": [
        1111,
        1140
      ],
      "unified_description": "\nAn image description for a video of a young boy in a helicopter looking out the window would be helpful.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:30",
        "processing_time": 4.16,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1125,
          "frame_range": [
            1121,
            1125
          ],
          "description": "a young boy in a helicopter looking out the window",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1111,
            1115
          ],
          "representative_frame": 1111,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9227280020713806,
              "bbox": [
                0.0,
                7.687073230743408,
                526.6025390625,
                356.51263427734375
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1116,
            1120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1121,
            1125
          ],
          "representative_frame": 1121,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9215964674949646,
              "bbox": [
                0.0,
                2.3380813598632812,
                516.6975708007812,
                356.5648193359375
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1126,
            1130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1131,
            1135
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.753856897354126,
              "bbox": [
                9.38759708404541,
                55.49750900268555,
                546.1123657226562,
                356.9874572753906
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1136,
            1140
          ],
          "representative_frame": 1136,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 9
    },
    {
      "second": 38,
      "time_range": [
        38,
        38.999
      ],
      "frame_range": [
        1141,
        1170
      ],
      "unified_description": "\nThe image descriptions and object detections will be used to create an accurate summary of the scene in no time!",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:30",
        "processing_time": 3.13,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1155,
          "frame_range": [
            1151,
            1155
          ],
          "description": "a helicopter flying over a lake with a cloudy sky",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.15
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1141,
            1145
          ],
          "representative_frame": 1141,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.3512002229690552,
              "bbox": [
                61.01176452636719,
                93.76773071289062,
                551.1857299804688,
                356.88507080078125
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1146,
            1150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1151,
            1155
          ],
          "representative_frame": 1151,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.44739195704460144,
              "bbox": [
                72.76004791259766,
                108.74668884277344,
                552.6333618164062,
                356.5766296386719
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1156,
            1160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1161,
            1165
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.6170142292976379,
              "bbox": [
                59.67535400390625,
                95.68132019042969,
                574.2568359375,
                355.6833190917969
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1166,
            1170
          ],
          "representative_frame": 1166,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 9
    },
    {
      "second": 39,
      "time_range": [
        39,
        39.999
      ],
      "frame_range": [
        1171,
        1200
      ],
      "unified_description": "\n\n1st person perspective camera view of a skate park with people doing tricks on their skateboards. The video shows the skater's point of view as they maneuver through the park.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:33",
        "processing_time": 2.86,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1185,
          "frame_range": [
            1181,
            1185
          ],
          "description": "a view from the cockpit of a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.21
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1171,
            1175
          ],
          "representative_frame": 1171,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            1176,
            1180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1181,
            1185
          ],
          "representative_frame": 1181,
          "detections": [
            {
              "track_id": 110,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.41690513491630554,
              "bbox": [
                292.8946838378906,
                0.555041491985321,
                637.0494995117188,
                352.37982177734375
              ]
            }
          ],
          "unique_tracks": [
            110
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1186,
            1190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1191,
            1195
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 110,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.3636914789676666,
              "bbox": [
                292.40972900390625,
                0.6154557466506958,
                637.025146484375,
                352.8892822265625
              ]
            }
          ],
          "unique_tracks": [
            110
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1196,
            1200
          ],
          "representative_frame": 1196,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 9
    },
    {
      "second": 40,
      "time_range": [
        40,
        40.999
      ],
      "frame_range": [
        1201,
        1230
      ],
      "unified_description": "2013",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:34",
        "processing_time": 2.2,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1215,
          "frame_range": [
            1211,
            1215
          ],
          "description": "a view from the cockpit of a plane flying over a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1201,
            1205
          ],
          "representative_frame": 1201,
          "detections": [
            {
              "track_id": 110,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.19763493537902832,
              "bbox": [
                292.353515625,
                0.4169052243232727,
                637.7105712890625,
                353.3702087402344
              ]
            }
          ],
          "unique_tracks": [
            110
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1206,
            1210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1211,
            1215
          ],
          "representative_frame": 1211,
          "detections": [
            {
              "track_id": 110,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.16479744017124176,
              "bbox": [
                294.2779235839844,
                0.6184127330780029,
                638.2315063476562,
                352.0445556640625
              ]
            }
          ],
          "unique_tracks": [
            110
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1216,
            1220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1221,
            1225
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            1226,
            1230
          ],
          "representative_frame": 1226,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 10
    },
    {
      "second": 41,
      "time_range": [
        41,
        41.999
      ],
      "frame_range": [
        1231,
        1260
      ],
      "unified_description": "1-second scene featuring two boys in a plane's cockpit, shot with a wide-angle lens that captures some distortion.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:34",
        "processing_time": 2.85,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1245,
          "frame_range": [
            1241,
            1245
          ],
          "description": "two boys are sitting in the cockpit of a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.25
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1231,
            1235
          ],
          "representative_frame": 1231,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            1236,
            1240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1241,
            1245
          ],
          "representative_frame": 1241,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9222798943519592,
              "bbox": [
                0.0,
                116.2364501953125,
                275.8341979980469,
                357.1285705566406
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9311953186988831,
              "bbox": [
                92.98684692382812,
                91.79736328125,
                568.1839599609375,
                357.4235534667969
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1246,
            1250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1251,
            1255
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9162003993988037,
              "bbox": [
                0.0,
                116.398193359375,
                264.5340270996094,
                357.01055908203125
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9334086775779724,
              "bbox": [
                114.43146514892578,
                92.68306732177734,
                548.6998901367188,
                357.2239990234375
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1256,
            1260
          ],
          "representative_frame": 1256,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 10
    },
    {
      "second": 42,
      "time_range": [
        42,
        42.999
      ],
      "frame_range": [
        1261,
        1290
      ],
      "unified_description": "3D VR Video with a first person perspective. Two boys are sitting in the cockpit of a plane. The camera is stable and the lighting is natural outdoor lighting.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:37",
        "processing_time": 2.68,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1275,
          "frame_range": [
            1271,
            1275
          ],
          "description": "two boys are sitting in the cockpit of a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.16
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1261,
            1265
          ],
          "representative_frame": 1261,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9165599942207336,
              "bbox": [
                0.0,
                117.05638122558594,
                256.6601867675781,
                356.7946472167969
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9363710284233093,
              "bbox": [
                130.09332275390625,
                93.17987823486328,
                532.2091064453125,
                357.2131652832031
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1266,
            1270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1271,
            1275
          ],
          "representative_frame": 1271,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9262441396713257,
              "bbox": [
                0.0,
                115.7444076538086,
                246.1365203857422,
                356.74127197265625
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9312430024147034,
              "bbox": [
                143.14122009277344,
                93.23787689208984,
                519.3408813476562,
                357.1678771972656
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1276,
            1280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1281,
            1285
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9199704527854919,
              "bbox": [
                0.0,
                114.14825439453125,
                246.91700744628906,
                356.81158447265625
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9329484701156616,
              "bbox": [
                153.3035888671875,
                92.64021301269531,
                508.6097412109375,
                357.017578125
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1286,
            1290
          ],
          "representative_frame": 1286,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 10
    },
    {
      "second": 43,
      "time_range": [
        43,
        43.999
      ],
      "frame_range": [
        1291,
        1320
      ],
      "unified_description": "1-second scene that includes objects, people, actions, and location as well as camera perspective, field of view, video production style, and lighting conditions.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:38",
        "processing_time": 2.93,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1305,
          "frame_range": [
            1301,
            1305
          ],
          "description": "a view from the cockpit of a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.39
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1291,
            1295
          ],
          "representative_frame": 1291,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            1296,
            1300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1301,
            1305
          ],
          "representative_frame": 1301,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            1306,
            1310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1311,
            1315
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            1316,
            1320
          ],
          "representative_frame": 1316,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 10
    },
    {
      "second": 44,
      "time_range": [
        44,
        44.999
      ],
      "frame_range": [
        1321,
        1350
      ],
      "unified_description": "1-second scene featuring two men in a helicopter with headphones on",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:38",
        "processing_time": 3.02,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1335,
          "frame_range": [
            1331,
            1335
          ],
          "description": "two men in a helicopter with headphones on",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.94
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1321,
            1325
          ],
          "representative_frame": 1321,
          "detections": [
            {
              "track_id": 110,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9192209243774414,
              "bbox": [
                417.2012939453125,
                92.56139373779297,
                640.0,
                356.3014831542969
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8764417171478271,
              "bbox": [
                14.442312240600586,
                10.900217056274414,
                465.940185546875,
                355.82281494140625
              ]
            }
          ],
          "unique_tracks": [
            110,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1326,
            1330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1331,
            1335
          ],
          "representative_frame": 1331,
          "detections": [
            {
              "track_id": 112,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5043954849243164,
              "bbox": [
                340.8994445800781,
                137.22189331054688,
                424.2740173339844,
                248.43580627441406
              ]
            },
            {
              "track_id": 113,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3878227770328522,
              "bbox": [
                344.1882019042969,
                137.01950073242188,
                429.16375732421875,
                319.9988708496094
              ]
            },
            {
              "track_id": 110,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9163551926612854,
              "bbox": [
                423.7154541015625,
                94.80290222167969,
                640.0,
                356.2933044433594
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9029721617698669,
              "bbox": [
                12.980942726135254,
                1.772546410560608,
                463.076171875,
                355.464599609375
              ]
            }
          ],
          "unique_tracks": [
            112,
            113,
            110,
            48
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            1336,
            1340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1341,
            1345
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 112,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6710883378982544,
              "bbox": [
                336.7621154785156,
                136.35154724121094,
                424.4539489746094,
                253.2394561767578
              ]
            },
            {
              "track_id": 113,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.16370724141597748,
              "bbox": [
                338.6665344238281,
                137.0579071044922,
                429.51025390625,
                332.5461730957031
              ]
            },
            {
              "track_id": 110,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9220518469810486,
              "bbox": [
                426.4121398925781,
                94.60320281982422,
                640.0,
                356.31201171875
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9170253872871399,
              "bbox": [
                31.525888442993164,
                6.236546039581299,
                462.2674865722656,
                355.4123229980469
              ]
            }
          ],
          "unique_tracks": [
            112,
            113,
            110,
            48
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            1346,
            1350
          ],
          "representative_frame": 1346,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 11
    },
    {
      "second": 45,
      "time_range": [
        45,
        45.999
      ],
      "frame_range": [
        1351,
        1380
      ],
      "unified_description": "4 VIDEOS - No",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:40",
        "processing_time": 2.2,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1365,
          "frame_range": [
            1361,
            1365
          ],
          "description": "a view of a mountain range from a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.02
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1351,
            1355
          ],
          "representative_frame": 1351,
          "detections": [
            {
              "track_id": 112,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.49658113718032837,
              "bbox": [
                342.1280822753906,
                137.4637451171875,
                427.38763427734375,
                251.5376739501953
              ]
            },
            {
              "track_id": 113,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.14951294660568237,
              "bbox": [
                342.6637268066406,
                136.7882843017578,
                432.2254943847656,
                329.7121887207031
              ]
            },
            {
              "track_id": 110,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9331485629081726,
              "bbox": [
                420.6048278808594,
                93.5047836303711,
                640.0,
                356.8887023925781
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9172343611717224,
              "bbox": [
                40.411773681640625,
                1.744468092918396,
                463.7960205078125,
                355.4056701660156
              ]
            },
            {
              "track_id": 114,
              "class_id": 56,
              "class_name": "chair",
              "confidence": 0.4107033908367157,
              "bbox": [
                418.57696533203125,
                188.97328186035156,
                515.5496215820312,
                352.77239990234375
              ]
            }
          ],
          "unique_tracks": [
            112,
            113,
            110,
            48,
            114
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            1356,
            1360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1361,
            1365
          ],
          "representative_frame": 1361,
          "detections": [
            {
              "track_id": 3,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.41937923431396484,
              "bbox": [
                0.0,
                122.24920654296875,
                244.607177734375,
                356.48590087890625
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1366,
            1370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1371,
            1375
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.6339063048362732,
              "bbox": [
                18.27069664001465,
                183.6302490234375,
                219.60891723632812,
                356.525634765625
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1376,
            1380
          ],
          "representative_frame": 1376,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 11
    },
    {
      "second": 46,
      "time_range": [
        46,
        46.999
      ],
      "frame_range": [
        1381,
        1410
      ],
      "unified_description": "\n\n1. Content Description - What is happening in the scene:\n   - A plane flying above mountains and clouds\n   - The sky is clear and blue\n   - No people or objects are visible within the frame\n\n2. Camera Perspective and Technical Details:\n   - First-person perspective: The camera is mounted on a person's head, capturing their point of view as they travel by train through the landscape\n   - Field of view: The camera captures a wide field of view, including the person's surroundings and the scenery as it moves along its route\n\n3. Video Production Style and Characteristics:\n   - Documentary style: The footage is intended to capture a real-world scene without any additional elements or effects added in post-production",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:44",
        "processing_time": 4.98,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1395,
          "frame_range": [
            1391,
            1395
          ],
          "description": "a view from a plane of mountains and clouds",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.42
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1381,
            1385
          ],
          "representative_frame": 1381,
          "detections": [
            {
              "track_id": 3,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.7297350168228149,
              "bbox": [
                0.0,
                93.86195373535156,
                266.9787902832031,
                355.5594787597656
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1386,
            1390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1391,
            1395
          ],
          "representative_frame": 1391,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            1396,
            1400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1401,
            1405
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5099807977676392,
              "bbox": [
                0.0,
                92.57064056396484,
                255.88975524902344,
                355.0616149902344
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1406,
            1410
          ],
          "representative_frame": 1406,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 11
    },
    {
      "second": 47,
      "time_range": [
        47,
        47.999
      ],
      "frame_range": [
        1411,
        1440
      ],
      "unified_description": "3D model of a person in a flying object with textured onto it, mounted on a camera and recording footage from that perspective.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:45",
        "processing_time": 5.36,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1425,
          "frame_range": [
            1421,
            1425
          ],
          "description": "a person flying a small plane over a mountain",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.34
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1411,
            1415
          ],
          "representative_frame": 1411,
          "detections": [
            {
              "track_id": 3,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5152395367622375,
              "bbox": [
                0.0,
                133.23231506347656,
                233.85330200195312,
                355.2611083984375
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1416,
            1420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1421,
            1425
          ],
          "representative_frame": 1421,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            1426,
            1430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1431,
            1435
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            1436,
            1440
          ],
          "representative_frame": 1436,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 11
    },
    {
      "second": 48,
      "time_range": [
        48,
        48.999
      ],
      "frame_range": [
        1441,
        1470
      ],
      "unified_description": "\n\nThe image captures a picturesque mountain landscape. The beautiful outdoor setting makes it an ideal location for adventure seekers and nature lovers. A series of mountains can be seen in the distance, giving the scene a sense of scale and depth. The camera is stable, allowing for clear visibility of the terrain. The helicopter view provides a unique perspective on this breathtaking scenery.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:47",
        "processing_time": 6.05,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1455,
          "frame_range": [
            1451,
            1455
          ],
          "description": "a view of the mountains from a helicopter",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.01
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1441,
            1445
          ],
          "representative_frame": 1441,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            1446,
            1450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1451,
            1455
          ],
          "representative_frame": 1451,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            1456,
            1460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1461,
            1465
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8041397333145142,
              "bbox": [
                10.794692993164062,
                167.18621826171875,
                220.63255310058594,
                356.5886535644531
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1466,
            1470
          ],
          "representative_frame": 1466,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 12
    },
    {
      "second": 49,
      "time_range": [
        49,
        49.999
      ],
      "frame_range": [
        1471,
        1500
      ],
      "unified_description": "\n\nA man in a helicopter is flying over a beautiful snowy mountain range. The camera perspective provides a stunning view of the landscape below. In the image, there are several interesting objects and people that catch the viewer's attention.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:49",
        "processing_time": 3.13,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1485,
          "frame_range": [
            1481,
            1485
          ],
          "description": "a man in a helicopter flying over a mountain range",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.35
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1471,
            1475
          ],
          "representative_frame": 1471,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7743139266967773,
              "bbox": [
                8.116621017456055,
                164.71157836914062,
                223.4063262939453,
                357.06982421875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1476,
            1480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1481,
            1485
          ],
          "representative_frame": 1481,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6361581087112427,
              "bbox": [
                7.244763374328613,
                154.86355590820312,
                235.39974975585938,
                356.99786376953125
              ]
            },
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.5360214710235596,
              "bbox": [
                83.12989044189453,
                1.7215226888656616,
                548.2005004882812,
                354.775390625
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1486,
            1490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1491,
            1495
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            1496,
            1500
          ],
          "representative_frame": 1496,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 12
    },
    {
      "second": 50,
      "time_range": [
        50,
        50.999
      ],
      "frame_range": [
        1501,
        1530
      ],
      "unified_description": "\nAn unsteady camera mounted on a backpack captures an action-packed scene of a plane flying over a mountain range. The video is shot in wide-angle perspective, emphasizing the vastness of the landscape as well as the motion of the camera.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:50",
        "processing_time": 3.39,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1515,
          "frame_range": [
            1511,
            1515
          ],
          "description": "a view from the cockpit of a plane flying over a mountain range",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.78
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1501,
            1505
          ],
          "representative_frame": 1501,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            1506,
            1510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1511,
            1515
          ],
          "representative_frame": 1511,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            1516,
            1520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1521,
            1525
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            1526,
            1530
          ],
          "representative_frame": 1526,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 12
    },
    {
      "second": 51,
      "time_range": [
        51,
        51.999
      ],
      "frame_range": [
        1531,
        1560
      ],
      "unified_description": "3rd person perspective with wide-angle lens capturing a man in red jacket sitting in a plane. The camera is mounted on a tripod.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:51",
        "processing_time": 2.91,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1545,
          "frame_range": [
            1541,
            1545
          ],
          "description": "a man in a red jacket sitting in a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.02
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1531,
            1535
          ],
          "representative_frame": 1531,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9128912687301636,
              "bbox": [
                34.535057067871094,
                56.675140380859375,
                425.00604248046875,
                354.9708251953125
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1536,
            1540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1541,
            1545
          ],
          "representative_frame": 1541,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9326964020729065,
              "bbox": [
                29.793556213378906,
                56.890541076660156,
                417.3328552246094,
                355.4065856933594
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1546,
            1550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1551,
            1555
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9084623456001282,
              "bbox": [
                30.30622100830078,
                58.11406707763672,
                414.5068359375,
                355.4123840332031
              ]
            },
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.3616137206554413,
              "bbox": [
                1.711875319480896,
                0.724285900592804,
                636.4650268554688,
                354.99810791015625
              ]
            }
          ],
          "unique_tracks": [
            48,
            121
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1556,
            1560
          ],
          "representative_frame": 1556,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 12
    },
    {
      "second": 52,
      "time_range": [
        52,
        52.999
      ],
      "frame_range": [
        1561,
        1590
      ],
      "unified_description": "20 seconds of video with aerial view, natural outdoor lighting",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:52",
        "processing_time": 2.32,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1575,
          "frame_range": [
            1571,
            1575
          ],
          "description": "a view from the cockpit of a plane flying over a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.25
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1561,
            1565
          ],
          "representative_frame": 1561,
          "detections": [
            {
              "track_id": 3,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.7641370892524719,
              "bbox": [
                68.38529205322266,
                182.20022583007812,
                296.83538818359375,
                357.7548828125
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1566,
            1570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1571,
            1575
          ],
          "representative_frame": 1571,
          "detections": [
            {
              "track_id": 3,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5515680909156799,
              "bbox": [
                60.563690185546875,
                184.94573974609375,
                306.8101501464844,
                357.45263671875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1576,
            1580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1581,
            1585
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.4477342665195465,
              "bbox": [
                52.98480224609375,
                185.54623413085938,
                314.8492126464844,
                357.53814697265625
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1586,
            1590
          ],
          "representative_frame": 1586,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 13
    },
    {
      "second": 53,
      "time_range": [
        53,
        53.999
      ],
      "frame_range": [
        1591,
        1620
      ],
      "unified_description": "1-second scene including a lake and airplane",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:54",
        "processing_time": 2.26,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1605,
          "frame_range": [
            1601,
            1605
          ],
          "description": "a view of a lake from a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1591,
            1595
          ],
          "representative_frame": 1591,
          "detections": [
            {
              "track_id": 3,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.5683962106704712,
              "bbox": [
                39.93559265136719,
                195.75331115722656,
                294.900634765625,
                356.5185546875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1596,
            1600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1601,
            1605
          ],
          "representative_frame": 1601,
          "detections": [
            {
              "track_id": 3,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.22840572893619537,
              "bbox": [
                30.68511199951172,
                195.9065399169922,
                292.258056640625,
                356.3437805175781
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1606,
            1610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1611,
            1615
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.14609722793102264,
              "bbox": [
                26.927858352661133,
                195.0997772216797,
                296.4219970703125,
                356.3738708496094
              ]
            },
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.418343722820282,
              "bbox": [
                55.46068572998047,
                62.78260803222656,
                584.7555541992188,
                353.894775390625
              ]
            }
          ],
          "unique_tracks": [
            3,
            121
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1616,
            1620
          ],
          "representative_frame": 1616,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 13
    },
    {
      "second": 54,
      "time_range": [
        54,
        54.999
      ],
      "frame_range": [
        1621,
        1650
      ],
      "unified_description": "\n\nContent Description:\nA plane flying above water with mountains in the background\n\nTechnical Details:\nPOV camera perspective, tripod-mounted, wide-angle lens, stable camera positioning",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:55",
        "processing_time": 2.98,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1635,
          "frame_range": [
            1631,
            1635
          ],
          "description": "a plane flying over a lake with mountains in the background",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.84
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1621,
            1625
          ],
          "representative_frame": 1621,
          "detections": [
            {
              "track_id": 3,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.5319925546646118,
              "bbox": [
                23.870302200317383,
                195.02940368652344,
                299.036865234375,
                356.3641357421875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1626,
            1630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1631,
            1635
          ],
          "representative_frame": 1631,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            1636,
            1640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1641,
            1645
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.34259098768234253,
              "bbox": [
                72.42491912841797,
                90.52935028076172,
                568.767822265625,
                355.9801025390625
              ]
            }
          ],
          "unique_tracks": [
            121
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1646,
            1650
          ],
          "representative_frame": 1646,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 13
    },
    {
      "second": 55,
      "time_range": [
        55,
        55.999
      ],
      "frame_range": [
        1651,
        1680
      ],
      "unified_description": "10-second scene from first-person perspective camera, mounted on helmet. Field of view is wide-angle, showing a plane flying over a lake with mountains in the background.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:56",
        "processing_time": 2.93,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1665,
          "frame_range": [
            1661,
            1665
          ],
          "description": "a plane flying over a lake with mountains in the background",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1651,
            1655
          ],
          "representative_frame": 1651,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.32329121232032776,
              "bbox": [
                69.59049987792969,
                94.31462097167969,
                571.68115234375,
                355.769287109375
              ]
            }
          ],
          "unique_tracks": [
            121
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1656,
            1660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1661,
            1665
          ],
          "representative_frame": 1661,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.4359983503818512,
              "bbox": [
                12.205412864685059,
                30.75732421875,
                630.958984375,
                354.88165283203125
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8975052237510681,
              "bbox": [
                0.0,
                3.0978105068206787,
                412.4405212402344,
                355.9831848144531
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1666,
            1670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1671,
            1675
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5712747573852539,
              "bbox": [
                0.0,
                10.012201309204102,
                640.0,
                356.6912536621094
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9098714590072632,
              "bbox": [
                0.0,
                1.2954285144805908,
                407.68682861328125,
                356.0461730957031
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1676,
            1680
          ],
          "representative_frame": 1676,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 13
    },
    {
      "second": 56,
      "time_range": [
        56,
        56.999
      ],
      "frame_range": [
        1681,
        1710
      ],
      "unified_description": "360-degree video of a man on a boat in the water",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:57",
        "processing_time": 2.47,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1695,
          "frame_range": [
            1691,
            1695
          ],
          "description": "a man in a helicopter flying over a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.82
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1681,
            1685
          ],
          "representative_frame": 1681,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5304250717163086,
              "bbox": [
                0.0,
                0.9780318140983582,
                640.0,
                355.1016845703125
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8931311368942261,
              "bbox": [
                0.0,
                0.05703241378068924,
                402.8431396484375,
                356.2828369140625
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1686,
            1690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1691,
            1695
          ],
          "representative_frame": 1691,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6831372976303101,
              "bbox": [
                0.0,
                0.0,
                640.0,
                357.83197021484375
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8968839049339294,
              "bbox": [
                0.0,
                1.0944640636444092,
                388.2347412109375,
                356.10888671875
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1696,
            1700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1701,
            1705
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6843818426132202,
              "bbox": [
                0.0,
                0.0,
                640.0,
                358.4370422363281
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6122840642929077,
              "bbox": [
                0.0,
                4.378411769866943,
                350.7844543457031,
                356.5342102050781
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1706,
            1710
          ],
          "representative_frame": 1706,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 14
    },
    {
      "second": 57,
      "time_range": [
        57,
        57.999
      ],
      "frame_range": [
        1711,
        1740
      ],
      "unified_description": "\nI'll try to give you detailed descriptions of what is happening in the scene (content description) and the camera's perspective, positioning, movement, and other technical details (camera perspective, field of view, etc.).",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:13:59",
        "processing_time": 2.93,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1725,
          "frame_range": [
            1721,
            1725
          ],
          "description": "a man in a boat is driving through the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.92
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1711,
            1715
          ],
          "representative_frame": 1711,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5599175691604614,
              "bbox": [
                0.0,
                0.0,
                640.0,
                357.8301696777344
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8221911191940308,
              "bbox": [
                0.0,
                4.14647102355957,
                292.3579406738281,
                356.1755676269531
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1716,
            1720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1721,
            1725
          ],
          "representative_frame": 1721,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.7387955188751221,
              "bbox": [
                0.0,
                0.0,
                640.0,
                357.4888610839844
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8013911247253418,
              "bbox": [
                0.0,
                2.4920060634613037,
                268.0464782714844,
                356.30401611328125
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1726,
            1730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1731,
            1735
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.37393587827682495,
              "bbox": [
                0.0,
                0.0,
                640.0,
                359.1510925292969
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8755959868431091,
              "bbox": [
                6.433385848999023,
                21.71407127380371,
                349.4649963378906,
                356.1229248046875
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1736,
            1740
          ],
          "representative_frame": 1736,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 14
    },
    {
      "second": 58,
      "time_range": [
        58,
        58.999
      ],
      "frame_range": [
        1741,
        1770
      ],
      "unified_description": "\nBased on the image descriptions, the primary focus of the video is a man driving a boat on a river. The camera perspective appears to be first-person, capturing the driver's viewpoint. The scene includes objects such as boats, people, and the surrounding natural environment. There may also be other secondary elements present in the video, but the main subject remains the person driving the boat on the water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:01",
        "processing_time": 3.97,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1755,
          "frame_range": [
            1751,
            1755
          ],
          "description": "a man driving a boat on a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.71
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1741,
            1745
          ],
          "representative_frame": 1741,
          "detections": [
            {
              "track_id": 121,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.3480805456638336,
              "bbox": [
                0.0,
                0.0,
                640.0,
                357.5541687011719
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8369372487068176,
              "bbox": [
                39.82158660888672,
                29.022722244262695,
                387.4574890136719,
                355.8851318359375
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1746,
            1750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1751,
            1755
          ],
          "representative_frame": 1751,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.41212183237075806,
              "bbox": [
                0.0,
                0.0,
                640.0,
                357.69720458984375
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.813713014125824,
              "bbox": [
                54.88113784790039,
                31.816152572631836,
                409.0594177246094,
                356.5003662109375
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1756,
            1760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1761,
            1765
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6882051229476929,
              "bbox": [
                0.0,
                0.0,
                640.0,
                357.72479248046875
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8257938623428345,
              "bbox": [
                61.6785888671875,
                34.05045700073242,
                421.20306396484375,
                357.2504577636719
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1766,
            1770
          ],
          "representative_frame": 1766,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 14
    },
    {
      "second": 59,
      "time_range": [
        59,
        59.999
      ],
      "frame_range": [
        1771,
        1800
      ],
      "unified_description": "1-second scene including a man in a helicopter cockpit and various other objects. The camera perspective is first person and it is mounted on a backpack. The image captures an action-packed moment with multiple interesting elements.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:02",
        "processing_time": 4.45,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1785,
          "frame_range": [
            1781,
            1785
          ],
          "description": "a man in a helicopter cockpit is seen",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.6
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1771,
            1775
          ],
          "representative_frame": 1771,
          "detections": [
            {
              "track_id": 121,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.32933294773101807,
              "bbox": [
                0.0,
                0.0,
                640.0,
                355.4688415527344
              ]
            },
            {
              "track_id": 48,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.44227513670921326,
              "bbox": [
                71.35173797607422,
                62.060970306396484,
                405.237548828125,
                355.5450744628906
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1776,
            1780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1781,
            1785
          ],
          "representative_frame": 1781,
          "detections": [
            {
              "track_id": 121,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.23559793829917908,
              "bbox": [
                0.0,
                0.0,
                640.0,
                355.029296875
              ]
            },
            {
              "track_id": 48,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.6845037937164307,
              "bbox": [
                80.79144287109375,
                82.53164672851562,
                395.60321044921875,
                355.8221435546875
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1786,
            1790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1791,
            1795
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.5150527954101562,
              "bbox": [
                0.0,
                0.0,
                640.0,
                355.4632263183594
              ]
            },
            {
              "track_id": 48,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.6483159065246582,
              "bbox": [
                87.00277709960938,
                86.59201049804688,
                395.13018798828125,
                356.2709655761719
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1796,
            1800
          ],
          "representative_frame": 1796,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 14
    },
    {
      "second": 60,
      "time_range": [
        60,
        60.999
      ],
      "frame_range": [
        1801,
        1830
      ],
      "unified_description": "\nBased on these image descriptions and object detections, provide a unified detailed description of this 1-second scene. Include:\n\n1. Content Description - What is happening in the scene:\n   - Objects, people, actions, and location ( wide-angle, panoramic, etc.)\n   - Camera perspective (POV), positioning (mounted, body-mounted, tripod, etc.)\n   - Field of view (wide-angle, fisheye, telephoto compression), lens characteristics (lens flare, distortion, etc.)\n\n2. Video Production Style and Characteristics:\n   - Action camera (GoPro-style), documentary, narrative, test footage, etc.\n   - Lighting (natural outdoor lighting, indoor lighting, low light, etc.)",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:05",
        "processing_time": 5.46,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1815,
          "frame_range": [
            1811,
            1815
          ],
          "description": "a man in a gray jacket is standing next to a helicopter",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.18
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1801,
            1805
          ],
          "representative_frame": 1801,
          "detections": [
            {
              "track_id": 121,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9180534482002258,
              "bbox": [
                0.0,
                0.0,
                587.6270141601562,
                355.94378662109375
              ]
            }
          ],
          "unique_tracks": [
            121
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1806,
            1810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1811,
            1815
          ],
          "representative_frame": 1811,
          "detections": [
            {
              "track_id": 121,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9088388681411743,
              "bbox": [
                0.0,
                0.0,
                565.3617553710938,
                356.2378234863281
              ]
            }
          ],
          "unique_tracks": [
            121
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1816,
            1820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1821,
            1825
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9305567741394043,
              "bbox": [
                0.0,
                0.0,
                551.4478759765625,
                354.95428466796875
              ]
            }
          ],
          "unique_tracks": [
            121
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1826,
            1830
          ],
          "representative_frame": 1826,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 15
    },
    {
      "second": 61,
      "time_range": [
        61,
        61.999
      ],
      "frame_range": [
        1831,
        1860
      ],
      "unified_description": "3D Wide-angle lens on a camera capturing a scene with a man standing next to a small plane.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:06",
        "processing_time": 4.47,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1845,
          "frame_range": [
            1841,
            1845
          ],
          "description": "a man standing next to a small plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.89
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1831,
            1835
          ],
          "representative_frame": 1831,
          "detections": [
            {
              "track_id": 121,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9257261157035828,
              "bbox": [
                0.0,
                0.0,
                557.80029296875,
                355.4994201660156
              ]
            }
          ],
          "unique_tracks": [
            121
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1836,
            1840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1841,
            1845
          ],
          "representative_frame": 1841,
          "detections": [
            {
              "track_id": 121,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9214940071105957,
              "bbox": [
                48.059715270996094,
                0.0,
                611.2232055664062,
                356.077880859375
              ]
            }
          ],
          "unique_tracks": [
            121
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1846,
            1850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1851,
            1855
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9004103541374207,
              "bbox": [
                94.85189056396484,
                0.0,
                633.7464599609375,
                355.4883117675781
              ]
            },
            {
              "track_id": 128,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8642022609710693,
              "bbox": [
                519.1221313476562,
                192.46951293945312,
                632.4073486328125,
                356.2220153808594
              ]
            },
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.500272274017334,
              "bbox": [
                46.808719635009766,
                42.988746643066406,
                588.9891967773438,
                304.3181457519531
              ]
            }
          ],
          "unique_tracks": [
            121,
            128,
            130
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            1856,
            1860
          ],
          "representative_frame": 1856,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 15
    },
    {
      "second": 62,
      "time_range": [
        62,
        62.999
      ],
      "frame_range": [
        1861,
        1890
      ],
      "unified_description": "1-second scene featuring a man in a hat standing next to a small plane. The camera was positioned on a tripod, capturing the scene with a wide-angle lens that produced some distortion.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:07",
        "processing_time": 4.26,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1875,
          "frame_range": [
            1871,
            1875
          ],
          "description": "a man in a hat is standing next to a small plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.11
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1861,
            1865
          ],
          "representative_frame": 1861,
          "detections": [
            {
              "track_id": 121,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8979006409645081,
              "bbox": [
                100.58441162109375,
                0.0,
                622.3289184570312,
                356.1247253417969
              ]
            },
            {
              "track_id": 128,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.877699613571167,
              "bbox": [
                515.0408935546875,
                173.70494079589844,
                637.681640625,
                351.4117431640625
              ]
            },
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.30328747630119324,
              "bbox": [
                67.2309341430664,
                50.779937744140625,
                564.1061401367188,
                288.8639831542969
              ]
            }
          ],
          "unique_tracks": [
            121,
            128,
            130
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            1866,
            1870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1871,
            1875
          ],
          "representative_frame": 1871,
          "detections": [
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6040440797805786,
              "bbox": [
                217.2530517578125,
                167.39427185058594,
                467.57171630859375,
                356.7561950683594
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1876,
            1880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1881,
            1885
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 132,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8131746649742126,
              "bbox": [
                457.86553955078125,
                90.7493667602539,
                498.9342041015625,
                237.4746856689453
              ]
            },
            {
              "track_id": 133,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.747818648815155,
              "bbox": [
                386.780029296875,
                117.98299407958984,
                442.63751220703125,
                269.6085205078125
              ]
            },
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8636714816093445,
              "bbox": [
                225.323486328125,
                181.04257202148438,
                483.30584716796875,
                356.5353088378906
              ]
            },
            {
              "track_id": 121,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5083884596824646,
              "bbox": [
                131.54290771484375,
                4.703818321228027,
                510.57891845703125,
                236.8939971923828
              ]
            }
          ],
          "unique_tracks": [
            132,
            133,
            48,
            121
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            1886,
            1890
          ],
          "representative_frame": 1886,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 15
    },
    {
      "second": 63,
      "time_range": [
        63,
        63.999
      ],
      "frame_range": [
        1891,
        1920
      ],
      "unified_description": "3rd person perspective, camera mounted on helmet, stabilizer used, focusing on main subject, background consists of blurry trees and sky, no technical artifacts visible",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:10",
        "processing_time": 2.69,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1905,
          "frame_range": [
            1901,
            1905
          ],
          "description": "a man in a canoe is getting ready to go into the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1891,
            1895
          ],
          "representative_frame": 1891,
          "detections": [
            {
              "track_id": 132,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.811413586139679,
              "bbox": [
                459.2018737792969,
                89.3643569946289,
                500.730224609375,
                237.1105499267578
              ]
            },
            {
              "track_id": 133,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7424004077911377,
              "bbox": [
                363.52734375,
                118.89751434326172,
                423.9377746582031,
                282.8595275878906
              ]
            },
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8219082951545715,
              "bbox": [
                211.04132080078125,
                179.67376708984375,
                492.84539794921875,
                357.0745544433594
              ]
            },
            {
              "track_id": 121,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.19659925997257233,
              "bbox": [
                137.842041015625,
                4.248417377471924,
                502.40130615234375,
                208.05767822265625
              ]
            }
          ],
          "unique_tracks": [
            132,
            133,
            48,
            121
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            1896,
            1900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1901,
            1905
          ],
          "representative_frame": 1901,
          "detections": [
            {
              "track_id": 132,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7679026126861572,
              "bbox": [
                459.9647521972656,
                90.38105773925781,
                502.73583984375,
                241.93902587890625
              ]
            },
            {
              "track_id": 133,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.816788375377655,
              "bbox": [
                328.3223571777344,
                124.17068481445312,
                392.37603759765625,
                297.5743713378906
              ]
            },
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6739115118980408,
              "bbox": [
                206.26980590820312,
                180.81605529785156,
                502.8556823730469,
                356.8876953125
              ]
            },
            {
              "track_id": 121,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.21520115435123444,
              "bbox": [
                123.90472412109375,
                2.666564464569092,
                504.87677001953125,
                201.22927856445312
              ]
            },
            {
              "track_id": 137,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6594936847686768,
              "bbox": [
                389.4112243652344,
                68.14448547363281,
                451.25592041015625,
                188.56997680664062
              ]
            }
          ],
          "unique_tracks": [
            132,
            133,
            48,
            121,
            137
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            1906,
            1910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1911,
            1915
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 133,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7527011632919312,
              "bbox": [
                330.3174743652344,
                109.80906677246094,
                389.6829833984375,
                268.37261962890625
              ]
            },
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7971479892730713,
              "bbox": [
                195.5067596435547,
                197.09481811523438,
                449.0273742675781,
                345.2774963378906
              ]
            }
          ],
          "unique_tracks": [
            133,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1916,
            1920
          ],
          "representative_frame": 1916,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 15
    },
    {
      "second": 64,
      "time_range": [
        64,
        64.999
      ],
      "frame_range": [
        1921,
        1950
      ],
      "unified_description": "3rd person's perspective with a fisheye lens capturing a man standing on the shore of a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:11",
        "processing_time": 2.72,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1935,
          "frame_range": [
            1931,
            1935
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.72
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1921,
            1925
          ],
          "representative_frame": 1921,
          "detections": [
            {
              "track_id": 133,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8038236498832703,
              "bbox": [
                313.21405029296875,
                96.7351303100586,
                372.5220947265625,
                255.86656188964844
              ]
            },
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7544324398040771,
              "bbox": [
                189.26089477539062,
                202.32626342773438,
                429.27874755859375,
                340.80010986328125
              ]
            },
            {
              "track_id": 141,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7536445260047913,
              "bbox": [
                355.9966125488281,
                96.11700439453125,
                418.5552978515625,
                225.63369750976562
              ]
            },
            {
              "track_id": 121,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.46349403262138367,
              "bbox": [
                134.53036499023438,
                3.323387622833252,
                502.1375427246094,
                177.45108032226562
              ]
            }
          ],
          "unique_tracks": [
            133,
            48,
            141,
            121
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            1926,
            1930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1931,
            1935
          ],
          "representative_frame": 1931,
          "detections": [
            {
              "track_id": 133,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.815609872341156,
              "bbox": [
                293.0438537597656,
                90.77571868896484,
                356.2856140136719,
                260.904541015625
              ]
            },
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8366308212280273,
              "bbox": [
                185.80673217773438,
                203.73829650878906,
                423.8319091796875,
                339.56512451171875
              ]
            },
            {
              "track_id": 141,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7960394620895386,
              "bbox": [
                356.70709228515625,
                96.18099975585938,
                420.98602294921875,
                230.08644104003906
              ]
            }
          ],
          "unique_tracks": [
            133,
            48,
            141
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            1936,
            1940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1941,
            1945
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8712595701217651,
              "bbox": [
                8.30463981628418,
                113.55229949951172,
                328.4906921386719,
                357.11138916015625
              ]
            },
            {
              "track_id": 130,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6066520810127258,
              "bbox": [
                74.54702758789062,
                0.3135709762573242,
                640.0,
                351.6548767089844
              ]
            }
          ],
          "unique_tracks": [
            3,
            130
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1946,
            1950
          ],
          "representative_frame": 1946,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 16
    },
    {
      "second": 65,
      "time_range": [
        65,
        65.999
      ],
      "frame_range": [
        1951,
        1980
      ],
      "unified_description": "2 men on a small speedboat in the water, one at the front and the other towards the back of the boat",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:11",
        "processing_time": 3.12,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1965,
          "frame_range": [
            1961,
            1965
          ],
          "description": "a man is getting off the boat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.86
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1951,
            1955
          ],
          "representative_frame": 1951,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8886952996253967,
              "bbox": [
                35.912784576416016,
                113.07443237304688,
                302.60302734375,
                356.7803039550781
              ]
            },
            {
              "track_id": 130,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7281893491744995,
              "bbox": [
                87.27653503417969,
                0.0,
                640.0,
                355.5985107421875
              ]
            }
          ],
          "unique_tracks": [
            3,
            130
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1956,
            1960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1961,
            1965
          ],
          "representative_frame": 1961,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8806496262550354,
              "bbox": [
                59.41250991821289,
                114.56770324707031,
                297.20184326171875,
                356.7399597167969
              ]
            },
            {
              "track_id": 130,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6560624241828918,
              "bbox": [
                20.94083595275879,
                0.0,
                640.0,
                358.2740478515625
              ]
            },
            {
              "track_id": 133,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.56175297498703,
              "bbox": [
                243.19776916503906,
                137.3643341064453,
                289.7925109863281,
                250.46376037597656
              ]
            }
          ],
          "unique_tracks": [
            3,
            130,
            133
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            1966,
            1970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1971,
            1975
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5714382529258728,
              "bbox": [
                86.26166534423828,
                114.5246810913086,
                317.56768798828125,
                356.1006164550781
              ]
            },
            {
              "track_id": 130,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5274325013160706,
              "bbox": [
                0.0,
                0.0,
                640.0,
                358.25360107421875
              ]
            }
          ],
          "unique_tracks": [
            3,
            130
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1976,
            1980
          ],
          "representative_frame": 1976,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 16
    },
    {
      "second": 66,
      "time_range": [
        66,
        66.999
      ],
      "frame_range": [
        1981,
        2010
      ],
      "unified_description": "1-second scene showing a man stepping off an airplane on the tarmac. There is also a handbag visible in the image. The camera perspective suggests it might be a first-person or POV camera, providing an immersive experience for viewers.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:14",
        "processing_time": 3.07,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1995,
          "frame_range": [
            1991,
            1995
          ],
          "description": "a man is getting off the plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.0
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1981,
            1985
          ],
          "representative_frame": 1981,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.69224613904953,
              "bbox": [
                91.72920989990234,
                117.39354705810547,
                311.58563232421875,
                355.2597961425781
              ]
            },
            {
              "track_id": 130,
              "class_id": 7,
              "class_name": "truck",
              "confidence": 0.4111415445804596,
              "bbox": [
                0.0,
                0.0,
                640.0,
                359.9459533691406
              ]
            },
            {
              "track_id": 153,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.3741980195045471,
              "bbox": [
                219.64031982421875,
                146.72964477539062,
                312.7154235839844,
                245.8067626953125
              ]
            }
          ],
          "unique_tracks": [
            3,
            130,
            153
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            1986,
            1990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1991,
            1995
          ],
          "representative_frame": 1991,
          "detections": [
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.4043748676776886,
              "bbox": [
                13.991518020629883,
                33.72380828857422,
                636.0939331054688,
                357.78045654296875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1996,
            2000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2001,
            2005
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.41043201088905334,
              "bbox": [
                26.658803939819336,
                51.71859359741211,
                619.2644653320312,
                356.6171875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2006,
            2010
          ],
          "representative_frame": 2006,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 16
    },
    {
      "second": 67,
      "time_range": [
        67,
        67.999
      ],
      "frame_range": [
        2011,
        2040
      ],
      "unified_description": "30 second video showing a small airplane on water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:15",
        "processing_time": 2.42,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2025,
          "frame_range": [
            2021,
            2025
          ],
          "description": "a small plane is sitting on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.48
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2011,
            2015
          ],
          "representative_frame": 2011,
          "detections": [
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.3982805013656616,
              "bbox": [
                30.236989974975586,
                59.642696380615234,
                613.3746948242188,
                356.1400451660156
              ]
            },
            {
              "track_id": 158,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.3148951232433319,
              "bbox": [
                9.881368637084961,
                67.2349624633789,
                633.492431640625,
                241.36724853515625
              ]
            }
          ],
          "unique_tracks": [
            130,
            158
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2016,
            2020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2021,
            2025
          ],
          "representative_frame": 2021,
          "detections": [
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.2857315242290497,
              "bbox": [
                36.139095306396484,
                64.72673034667969,
                611.2516479492188,
                353.6015930175781
              ]
            },
            {
              "track_id": 158,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.3578837215900421,
              "bbox": [
                15.591707229614258,
                70.24768829345703,
                629.6786499023438,
                241.602294921875
              ]
            }
          ],
          "unique_tracks": [
            130,
            158
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2026,
            2030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2031,
            2035
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 158,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.4789198040962219,
              "bbox": [
                6.712647438049316,
                68.03528594970703,
                636.6856079101562,
                243.8211669921875
              ]
            }
          ],
          "unique_tracks": [
            158
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2036,
            2040
          ],
          "representative_frame": 2036,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 16
    },
    {
      "second": 68,
      "time_range": [
        68,
        68.999
      ],
      "frame_range": [
        2041,
        2070
      ],
      "unified_description": "3D model of a small airplane.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:15",
        "processing_time": 2.52,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2055,
          "frame_range": [
            2051,
            2055
          ],
          "description": "a small plane is sitting on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2041,
            2045
          ],
          "representative_frame": 2041,
          "detections": [
            {
              "track_id": 158,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.47987091541290283,
              "bbox": [
                9.822996139526367,
                70.21369171142578,
                633.0535278320312,
                243.94419860839844
              ]
            }
          ],
          "unique_tracks": [
            158
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2046,
            2050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2051,
            2055
          ],
          "representative_frame": 2051,
          "detections": [
            {
              "track_id": 158,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.3774492144584656,
              "bbox": [
                0.0,
                36.45241928100586,
                640.0,
                244.78875732421875
              ]
            }
          ],
          "unique_tracks": [
            158
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2056,
            2060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2061,
            2065
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 158,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.534654974937439,
              "bbox": [
                0.0,
                15.329360008239746,
                640.0,
                250.2880401611328
              ]
            }
          ],
          "unique_tracks": [
            158
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2066,
            2070
          ],
          "representative_frame": 2066,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 17
    },
    {
      "second": 69,
      "time_range": [
        69,
        69.999
      ],
      "frame_range": [
        2071,
        2100
      ],
      "unified_description": "3-second scene including an airplane sitting on the water, with people nearby.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:18",
        "processing_time": 2.39,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2085,
          "frame_range": [
            2081,
            2085
          ],
          "description": "a small plane is sitting on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.34
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2071,
            2075
          ],
          "representative_frame": 2071,
          "detections": [
            {
              "track_id": 158,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5101149678230286,
              "bbox": [
                0.0,
                1.9225397109985352,
                640.0,
                237.02029418945312
              ]
            }
          ],
          "unique_tracks": [
            158
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2076,
            2080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2081,
            2085
          ],
          "representative_frame": 2081,
          "detections": [
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.8640574812889099,
              "bbox": [
                0.0,
                5.0422539710998535,
                640.0,
                343.2922058105469
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2086,
            2090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2091,
            2095
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.9059922695159912,
              "bbox": [
                1.8890973329544067,
                1.7238601446151733,
                639.4844360351562,
                322.9095153808594
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2096,
            2100
          ],
          "representative_frame": 2096,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 17
    },
    {
      "second": 70,
      "time_range": [
        70,
        70.999
      ],
      "frame_range": [
        2101,
        2130
      ],
      "unified_description": "\n\nA man is standing near a body of water wearing a backpack while holding his arm out to the side. He appears to be looking at something in the distance as he stands on the shore. The camera capturing this scene seems to be mounted on a tripod, providing a stable perspective. The image shows an outdoor setting with natural lighting, and there are no technical artifacts visible in the picture.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:20",
        "processing_time": 3.77,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2115,
          "frame_range": [
            2111,
            2115
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.65
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2101,
            2105
          ],
          "representative_frame": 2101,
          "detections": [
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.7743924856185913,
              "bbox": [
                22.318403244018555,
                0.0,
                600.6951904296875,
                285.95196533203125
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2106,
            2110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2111,
            2115
          ],
          "representative_frame": 2111,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9436278343200684,
              "bbox": [
                176.67913818359375,
                48.64300537109375,
                640.0,
                333.1921691894531
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2116,
            2120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2121,
            2125
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9443424344062805,
              "bbox": [
                241.0924835205078,
                65.50399017333984,
                640.0,
                349.2739562988281
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2126,
            2130
          ],
          "representative_frame": 2126,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 17
    },
    {
      "second": 71,
      "time_range": [
        71,
        71.999
      ],
      "frame_range": [
        2131,
        2160
      ],
      "unified_description": "1-second scene including a man standing on a rock near a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:20",
        "processing_time": 4.16,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2145,
          "frame_range": [
            2141,
            2145
          ],
          "description": "a man standing on a rock near a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.4
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2131,
            2135
          ],
          "representative_frame": 2131,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9474409222602844,
              "bbox": [
                272.5150146484375,
                71.66314697265625,
                640.0,
                355.1110534667969
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2136,
            2140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2141,
            2145
          ],
          "representative_frame": 2141,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9501105546951294,
              "bbox": [
                291.42303466796875,
                73.57957458496094,
                640.0,
                357.0924987792969
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2146,
            2150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2151,
            2155
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9437077641487122,
              "bbox": [
                305.5888977050781,
                75.01495361328125,
                640.0,
                357.6251525878906
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2156,
            2160
          ],
          "representative_frame": 2156,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 17
    },
    {
      "second": 72,
      "time_range": [
        72,
        72.999
      ],
      "frame_range": [
        2161,
        2190
      ],
      "unified_description": "1-second scene featuring a man in red raincoats standing on a rock near a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:21",
        "processing_time": 2.58,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2175,
          "frame_range": [
            2171,
            2175
          ],
          "description": "a man in red raincoats standing on a rock near a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.15
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2161,
            2165
          ],
          "representative_frame": 2161,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9290874600410461,
              "bbox": [
                279.41796875,
                56.174198150634766,
                640.0,
                357.76324462890625
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2166,
            2170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2171,
            2175
          ],
          "representative_frame": 2171,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9451223015785217,
              "bbox": [
                279.6341857910156,
                46.42384719848633,
                640.0,
                357.7940368652344
              ]
            },
            {
              "track_id": 159,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.836891233921051,
              "bbox": [
                555.847412109375,
                192.6768798828125,
                636.0310668945312,
                358.0928039550781
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9184622764587402,
              "bbox": [
                36.981300354003906,
                216.1944122314453,
                262.2841491699219,
                358.7255859375
              ]
            }
          ],
          "unique_tracks": [
            130,
            159,
            48
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            2176,
            2180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2181,
            2185
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9370725750923157,
              "bbox": [
                298.1621398925781,
                45.07318878173828,
                640.0,
                357.7508239746094
              ]
            },
            {
              "track_id": 159,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8208936452865601,
              "bbox": [
                569.8671264648438,
                210.61160278320312,
                640.0,
                358.2608642578125
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9155217409133911,
              "bbox": [
                79.11206817626953,
                226.13414001464844,
                274.95208740234375,
                359.29852294921875
              ]
            }
          ],
          "unique_tracks": [
            130,
            159,
            48
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            2186,
            2190
          ],
          "representative_frame": 2186,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 18
    },
    {
      "second": 73,
      "time_range": [
        73,
        73.999
      ],
      "frame_range": [
        2191,
        2220
      ],
      "unified_description": "1 second video of three people near the shoreline. Shot with a fisheye lens creating a wide-angle perspective, focusing on the subjects rather than the background. The camera is positioned at approximately waist height, capturing the scene as the subjects move around the shore.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:25",
        "processing_time": 3.09,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2205,
          "frame_range": [
            2201,
            2205
          ],
          "description": "a man and two children are standing near the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.47
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2191,
            2195
          ],
          "representative_frame": 2191,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9459744095802307,
              "bbox": [
                306.1728820800781,
                44.19963455200195,
                640.0,
                357.6835632324219
              ]
            },
            {
              "track_id": 159,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8395221829414368,
              "bbox": [
                577.4476318359375,
                212.13487243652344,
                640.0,
                357.6352233886719
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9284921288490295,
              "bbox": [
                87.78831481933594,
                221.5241241455078,
                281.13665771484375,
                359.2192077636719
              ]
            }
          ],
          "unique_tracks": [
            130,
            159,
            48
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            2196,
            2200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2201,
            2205
          ],
          "representative_frame": 2201,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.943558931350708,
              "bbox": [
                317.0716247558594,
                48.37803268432617,
                640.0,
                357.3912658691406
              ]
            },
            {
              "track_id": 159,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8098440170288086,
              "bbox": [
                578.3553466796875,
                213.75753784179688,
                640.0,
                357.940673828125
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9255026578903198,
              "bbox": [
                104.35200500488281,
                220.42494201660156,
                290.6184387207031,
                359.12481689453125
              ]
            }
          ],
          "unique_tracks": [
            130,
            159,
            48
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            2206,
            2210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2211,
            2215
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9430294632911682,
              "bbox": [
                334.5859069824219,
                48.85354995727539,
                640.0,
                357.3084716796875
              ]
            },
            {
              "track_id": 159,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7982245683670044,
              "bbox": [
                581.1873168945312,
                216.1580047607422,
                640.0,
                358.0632019042969
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9146209359169006,
              "bbox": [
                120.1544189453125,
                216.47894287109375,
                301.8125305175781,
                359.2085266113281
              ]
            }
          ],
          "unique_tracks": [
            130,
            159,
            48
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            2216,
            2220
          ],
          "representative_frame": 2216,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 18
    },
    {
      "second": 74,
      "time_range": [
        74,
        74.999
      ],
      "frame_range": [
        2221,
        2250
      ],
      "unified_description": "45 seconds of video showing a man wearing a backpack standing on the shore of a lake with two handheld cameras capturing the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:25",
        "processing_time": 3.52,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2235,
          "frame_range": [
            2231,
            2235
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.41
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2221,
            2225
          ],
          "representative_frame": 2221,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9312692284584045,
              "bbox": [
                331.5435791015625,
                62.35675811767578,
                629.5634155273438,
                356.94342041015625
              ]
            },
            {
              "track_id": 159,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8966338038444519,
              "bbox": [
                584.8174438476562,
                169.5578155517578,
                640.0,
                298.1982116699219
              ]
            }
          ],
          "unique_tracks": [
            130,
            159
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2226,
            2230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2231,
            2235
          ],
          "representative_frame": 2231,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9074275493621826,
              "bbox": [
                353.89752197265625,
                65.70699310302734,
                637.71630859375,
                356.365966796875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2236,
            2240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2241,
            2245
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9336799383163452,
              "bbox": [
                374.54693603515625,
                64.27496337890625,
                640.0,
                356.3008728027344
              ]
            },
            {
              "track_id": 141,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8526765704154968,
              "bbox": [
                373.5523376464844,
                144.80780029296875,
                421.602783203125,
                250.9613494873047
              ]
            }
          ],
          "unique_tracks": [
            130,
            141
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            2246,
            2250
          ],
          "representative_frame": 2246,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 18
    },
    {
      "second": 75,
      "time_range": [
        75,
        75.999
      ],
      "frame_range": [
        2251,
        2280
      ],
      "unified_description": "1-second scene that includes a man standing on a rocky shore next to a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:26",
        "processing_time": 3.47,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2265,
          "frame_range": [
            2261,
            2265
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.89
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2251,
            2255
          ],
          "representative_frame": 2251,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9270318150520325,
              "bbox": [
                381.8365783691406,
                64.03545379638672,
                640.0,
                356.02008056640625
              ]
            },
            {
              "track_id": 163,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8348928093910217,
              "bbox": [
                336.2560119628906,
                148.6891326904297,
                371.0802001953125,
                257.58782958984375
              ]
            }
          ],
          "unique_tracks": [
            130,
            163
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2256,
            2260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2261,
            2265
          ],
          "representative_frame": 2261,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.935015857219696,
              "bbox": [
                386.4687194824219,
                68.45509338378906,
                640.0,
                356.44281005859375
              ]
            },
            {
              "track_id": 164,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7625415325164795,
              "bbox": [
                307.95684814453125,
                150.18099975585938,
                343.0332336425781,
                262.0874328613281
              ]
            }
          ],
          "unique_tracks": [
            130,
            164
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2266,
            2270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2271,
            2275
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.936265766620636,
              "bbox": [
                387.6820373535156,
                69.64028930664062,
                634.1973266601562,
                356.6624450683594
              ]
            },
            {
              "track_id": 164,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8922810554504395,
              "bbox": [
                292.157958984375,
                148.1251678466797,
                328.7057189941406,
                264.2711181640625
              ]
            }
          ],
          "unique_tracks": [
            130,
            164
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            2276,
            2280
          ],
          "representative_frame": 2276,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 18
    },
    {
      "second": 76,
      "time_range": [
        76,
        76.999
      ],
      "frame_range": [
        2281,
        2310
      ],
      "unified_description": " The image descriptions will be used to generate a text-based summary of the scene. Please provide include as many details as possible for a more accurate description.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:29",
        "processing_time": 2.62,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2295,
          "frame_range": [
            2291,
            2295
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.46
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2281,
            2285
          ],
          "representative_frame": 2281,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9279900789260864,
              "bbox": [
                395.6746826171875,
                74.5311279296875,
                631.9458618164062,
                356.33367919921875
              ]
            },
            {
              "track_id": 164,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8501365780830383,
              "bbox": [
                294.91571044921875,
                155.10040283203125,
                327.3211975097656,
                258.11767578125
              ]
            },
            {
              "track_id": 153,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.79984050989151,
              "bbox": [
                237.2975311279297,
                150.66969299316406,
                337.26556396484375,
                276.0630187988281
              ]
            }
          ],
          "unique_tracks": [
            130,
            164,
            153
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            2286,
            2290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2291,
            2295
          ],
          "representative_frame": 2291,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9332036972045898,
              "bbox": [
                403.8307800292969,
                79.4061508178711,
                631.4349365234375,
                356.4385681152344
              ]
            },
            {
              "track_id": 164,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8605124354362488,
              "bbox": [
                279.35882568359375,
                158.15675354003906,
                311.830810546875,
                261.0487060546875
              ]
            },
            {
              "track_id": 153,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8520857691764832,
              "bbox": [
                226.71009826660156,
                154.38241577148438,
                319.5551452636719,
                283.5971374511719
              ]
            }
          ],
          "unique_tracks": [
            130,
            164,
            153
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            2296,
            2300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2301,
            2305
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9239043593406677,
              "bbox": [
                399.5970458984375,
                76.26287841796875,
                624.7879028320312,
                356.634521484375
              ]
            },
            {
              "track_id": 164,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.877282440662384,
              "bbox": [
                266.01837158203125,
                156.7931671142578,
                299.10809326171875,
                261.3094482421875
              ]
            },
            {
              "track_id": 153,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9058433175086975,
              "bbox": [
                205.6160430908203,
                155.28985595703125,
                294.0165710449219,
                290.60394287109375
              ]
            }
          ],
          "unique_tracks": [
            130,
            164,
            153
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            2306,
            2310
          ],
          "representative_frame": 2306,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 19
    },
    {
      "second": 77,
      "time_range": [
        77,
        77.999
      ],
      "frame_range": [
        2311,
        2340
      ],
      "unified_description": "\nPlease provide beach scene, and include details like lighting conditions, camera movement or stabilization, and any other relevant technical details.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:30",
        "processing_time": 2.65,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2325,
          "frame_range": [
            2321,
            2325
          ],
          "description": "a man and a little girl are standing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.69
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2311,
            2315
          ],
          "representative_frame": 2311,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9310140609741211,
              "bbox": [
                379.52435302734375,
                72.35098266601562,
                603.7888793945312,
                356.7894592285156
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8600950837135315,
              "bbox": [
                144.95802307128906,
                234.91738891601562,
                300.2633056640625,
                358.78759765625
              ]
            }
          ],
          "unique_tracks": [
            130,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2316,
            2320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2321,
            2325
          ],
          "representative_frame": 2321,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9202433228492737,
              "bbox": [
                383.6749267578125,
                73.42646026611328,
                603.5533447265625,
                356.5672607421875
              ]
            },
            {
              "track_id": 168,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9443598389625549,
              "bbox": [
                300.8970947265625,
                190.14781188964844,
                388.93719482421875,
                358.56158447265625
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.24378542602062225,
              "bbox": [
                155.38900756835938,
                266.3939208984375,
                279.2841491699219,
                358.8216552734375
              ]
            }
          ],
          "unique_tracks": [
            130,
            168,
            48
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            2326,
            2330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2331,
            2335
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9171761870384216,
              "bbox": [
                386.24932861328125,
                78.96247100830078,
                598.8711547851562,
                356.5586242675781
              ]
            },
            {
              "track_id": 168,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9393736720085144,
              "bbox": [
                294.3547668457031,
                190.32313537597656,
                382.0198059082031,
                358.6701965332031
              ]
            }
          ],
          "unique_tracks": [
            130,
            168
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            2336,
            2340
          ],
          "representative_frame": 2336,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 19
    },
    {
      "second": 78,
      "time_range": [
        78,
        78.999
      ],
      "frame_range": [
        2341,
        2370
      ],
      "unified_description": "4K 30 FPS camera recording a man and a little girl standing on the shore of a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:30",
        "processing_time": 2.95,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2355,
          "frame_range": [
            2351,
            2355
          ],
          "description": "a man and a little girl are standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.49
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2341,
            2345
          ],
          "representative_frame": 2341,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9273861050605774,
              "bbox": [
                385.908935546875,
                85.47413635253906,
                591.3582763671875,
                356.4824523925781
              ]
            },
            {
              "track_id": 168,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9235483407974243,
              "bbox": [
                305.2403564453125,
                193.32510375976562,
                390.9612731933594,
                358.7190246582031
              ]
            }
          ],
          "unique_tracks": [
            130,
            168
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2346,
            2350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2351,
            2355
          ],
          "representative_frame": 2351,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9350325465202332,
              "bbox": [
                376.4366760253906,
                90.09698486328125,
                576.42138671875,
                356.71258544921875
              ]
            },
            {
              "track_id": 168,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9204655885696411,
              "bbox": [
                317.381591796875,
                193.28457641601562,
                402.53564453125,
                358.6380310058594
              ]
            }
          ],
          "unique_tracks": [
            130,
            168
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2356,
            2360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2361,
            2365
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9244393110275269,
              "bbox": [
                354.385009765625,
                93.27763366699219,
                550.5554809570312,
                356.9371032714844
              ]
            },
            {
              "track_id": 168,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8888822793960571,
              "bbox": [
                317.9443359375,
                197.91659545898438,
                399.8896484375,
                357.88775634765625
              ]
            }
          ],
          "unique_tracks": [
            130,
            168
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            2366,
            2370
          ],
          "representative_frame": 2366,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 19
    },
    {
      "second": 79,
      "time_range": [
        79,
        79.999
      ],
      "frame_range": [
        2371,
        2400
      ],
      "unified_description": "1-second scene where a man stands on the shore of a lake, with a wide-angle distorted perspective, showing natural outdoor lighting",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:32",
        "processing_time": 2.63,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2385,
          "frame_range": [
            2381,
            2385
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2371,
            2375
          ],
          "representative_frame": 2371,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.884158730506897,
              "bbox": [
                337.9773254394531,
                92.29322814941406,
                533.163330078125,
                357.2174072265625
              ]
            },
            {
              "track_id": 168,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8589947819709778,
              "bbox": [
                315.1000671386719,
                202.00025939941406,
                393.97125244140625,
                356.9880065917969
              ]
            }
          ],
          "unique_tracks": [
            130,
            168
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2376,
            2380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2381,
            2385
          ],
          "representative_frame": 2381,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.887614369392395,
              "bbox": [
                331.00762939453125,
                92.1407699584961,
                524.8900756835938,
                357.1265869140625
              ]
            },
            {
              "track_id": 168,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6064786911010742,
              "bbox": [
                322.2725830078125,
                204.34837341308594,
                395.76434326171875,
                349.9927062988281
              ]
            }
          ],
          "unique_tracks": [
            130,
            168
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2386,
            2390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2391,
            2395
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9048250913619995,
              "bbox": [
                327.0128173828125,
                92.12805938720703,
                519.554931640625,
                356.5379638671875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2396,
            2400
          ],
          "representative_frame": 2396,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 19
    },
    {
      "second": 80,
      "time_range": [
        80,
        80.999
      ],
      "frame_range": [
        2401,
        2430
      ],
      "unified_description": "1-second scene that includes a man standing on a rocky shore next to a body of water",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:34",
        "processing_time": 2.44,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2415,
          "frame_range": [
            2411,
            2415
          ],
          "description": "a man standing on a rocky shore next to a body of water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.6
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2401,
            2405
          ],
          "representative_frame": 2401,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.952565610408783,
              "bbox": [
                282.8898620605469,
                50.76057815551758,
                501.98492431640625,
                356.3726501464844
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2406,
            2410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2411,
            2415
          ],
          "representative_frame": 2411,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.949283242225647,
              "bbox": [
                266.42095947265625,
                34.868282318115234,
                493.615478515625,
                356.2581787109375
              ]
            },
            {
              "track_id": 170,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8035388588905334,
              "bbox": [
                527.0003051757812,
                189.65060424804688,
                549.0473022460938,
                255.51986694335938
              ]
            }
          ],
          "unique_tracks": [
            130,
            170
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2416,
            2420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2421,
            2425
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9481241703033447,
              "bbox": [
                264.1548156738281,
                29.153759002685547,
                493.78131103515625,
                356.20123291015625
              ]
            },
            {
              "track_id": 170,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7952952980995178,
              "bbox": [
                528.04833984375,
                189.59915161132812,
                549.9049682617188,
                254.9589385986328
              ]
            }
          ],
          "unique_tracks": [
            130,
            170
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            2426,
            2430
          ],
          "representative_frame": 2426,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 20
    },
    {
      "second": 81,
      "time_range": [
        81,
        81.999
      ],
      "frame_range": [
        2431,
        2460
      ],
      "unified_description": "36 seconds remaining",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:34",
        "processing_time": 2.28,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2445,
          "frame_range": [
            2441,
            2445
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.33
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2431,
            2435
          ],
          "representative_frame": 2431,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9524813294410706,
              "bbox": [
                258.1348571777344,
                33.9041862487793,
                486.3974609375,
                356.71380615234375
              ]
            },
            {
              "track_id": 170,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8393930792808533,
              "bbox": [
                530.9749145507812,
                189.16429138183594,
                552.6739501953125,
                254.09877014160156
              ]
            }
          ],
          "unique_tracks": [
            130,
            170
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2436,
            2440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2441,
            2445
          ],
          "representative_frame": 2441,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            2446,
            2450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2451,
            2455
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            2456,
            2460
          ],
          "representative_frame": 2456,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 20
    },
    {
      "second": 82,
      "time_range": [
        82,
        82.999
      ],
      "frame_range": [
        2461,
        2490
      ],
      "unified_description": "5",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:35",
        "processing_time": 2.11,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2475,
          "frame_range": [
            2471,
            2475
          ],
          "description": "a map of the alaska region",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.5
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2461,
            2465
          ],
          "representative_frame": 2461,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            2466,
            2470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2471,
            2475
          ],
          "representative_frame": 2471,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            2476,
            2480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2481,
            2485
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            2486,
            2490
          ],
          "representative_frame": 2486,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 20
    },
    {
      "second": 83,
      "time_range": [
        83,
        83.999
      ],
      "frame_range": [
        2491,
        2520
      ],
      "unified_description": "\nBased on what I can see in the image descriptions and object detections, the scene is outdoors with a man standing on the shore of a lake. The camera perspective seems to be first-person, capturing the surrounding environment. The lighting appears to be natural outdoor lighting, and there are no technical artifacts visible in the image descriptions provided.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:40",
        "processing_time": 3.36,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2505,
          "frame_range": [
            2501,
            2505
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.46
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2491,
            2495
          ],
          "representative_frame": 2491,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            2496,
            2500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2501,
            2505
          ],
          "representative_frame": 2501,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9439659118652344,
              "bbox": [
                278.8406066894531,
                39.39213562011719,
                500.5555114746094,
                356.8114318847656
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2506,
            2510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2511,
            2515
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9428735971450806,
              "bbox": [
                284.5472412109375,
                40.71253204345703,
                503.2138366699219,
                356.72100830078125
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2516,
            2520
          ],
          "representative_frame": 2516,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 20
    },
    {
      "second": 84,
      "time_range": [
        84,
        84.999
      ],
      "frame_range": [
        2521,
        2550
      ],
      "unified_description": "1-second scene with a man standing on the shore of a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:40",
        "processing_time": 3.79,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2535,
          "frame_range": [
            2531,
            2535
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.29
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2521,
            2525
          ],
          "representative_frame": 2521,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9429008364677429,
              "bbox": [
                286.972412109375,
                40.864559173583984,
                503.7838439941406,
                356.5174255371094
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2526,
            2530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2531,
            2535
          ],
          "representative_frame": 2531,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9438028931617737,
              "bbox": [
                287.9102783203125,
                41.38943862915039,
                502.70086669921875,
                356.3175964355469
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2536,
            2540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2541,
            2545
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9396802186965942,
              "bbox": [
                288.27423095703125,
                42.00704574584961,
                501.8891296386719,
                356.3016357421875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2546,
            2550
          ],
          "representative_frame": 2546,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 21
    },
    {
      "second": 85,
      "time_range": [
        85,
        85.999
      ],
      "frame_range": [
        2551,
        2580
      ],
      "unified_description": "\n\nIn this image, there is a man standing by a body of water, likely at the shore of a lake. The camera perspective appears to be first-person, capturing the entire scene in the frame. There are two other people present near the water's edge. Several objects can be seen throughout the scene, including three bottles placed on the ground, two backpacks lying nearby, and a bench located further back from the water's edge. Overall, this image depicts a casual outdoor gathering with friends, where they might be enjoying a day by the lake.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:43",
        "processing_time": 6.14,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2565,
          "frame_range": [
            2561,
            2565
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.84
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2551,
            2555
          ],
          "representative_frame": 2551,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9414775371551514,
              "bbox": [
                288.79083251953125,
                41.540157318115234,
                501.9705505371094,
                356.4786071777344
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2556,
            2560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2561,
            2565
          ],
          "representative_frame": 2561,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9439215064048767,
              "bbox": [
                292.7452392578125,
                41.197872161865234,
                504.984619140625,
                356.5434875488281
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2566,
            2570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2571,
            2575
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9451601505279541,
              "bbox": [
                290.29443359375,
                39.91962814331055,
                502.31219482421875,
                356.9493408203125
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2576,
            2580
          ],
          "representative_frame": 2576,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 21
    },
    {
      "second": 86,
      "time_range": [
        86,
        86.999
      ],
      "frame_range": [
        2581,
        2610
      ],
      "unified_description": "1-second scene featuring a man standing on the shore of a lake. The camera is mounted on a tripod, capturing the scene with a wide-angle lens.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:44",
        "processing_time": 2.76,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2595,
          "frame_range": [
            2591,
            2595
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.58
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2581,
            2585
          ],
          "representative_frame": 2581,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9423187375068665,
              "bbox": [
                275.4644470214844,
                41.883052825927734,
                485.61199951171875,
                356.8184814453125
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2586,
            2590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2591,
            2595
          ],
          "representative_frame": 2591,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9423162937164307,
              "bbox": [
                265.31866455078125,
                44.98966598510742,
                473.5073547363281,
                356.6658935546875
              ]
            },
            {
              "track_id": 175,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8198567032814026,
              "bbox": [
                455.8743896484375,
                187.1865692138672,
                476.9428405761719,
                244.99740600585938
              ]
            }
          ],
          "unique_tracks": [
            130,
            175
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2596,
            2600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2601,
            2605
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9471852779388428,
              "bbox": [
                274.3519287109375,
                47.91636276245117,
                480.3682556152344,
                356.66015625
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2606,
            2610
          ],
          "representative_frame": 2606,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 21
    },
    {
      "second": 87,
      "time_range": [
        87,
        87.999
      ],
      "frame_range": [
        2611,
        2640
      ],
      "unified_description": "4 people are seen near the water and a backpack is identified in the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:44",
        "processing_time": 2.86,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2625,
          "frame_range": [
            2621,
            2625
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.54
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2611,
            2615
          ],
          "representative_frame": 2611,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9407297968864441,
              "bbox": [
                295.24127197265625,
                49.52449035644531,
                499.18402099609375,
                356.56591796875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2616,
            2620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2621,
            2625
          ],
          "representative_frame": 2621,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9463698267936707,
              "bbox": [
                309.4011535644531,
                51.652503967285156,
                510.5166015625,
                356.619873046875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2626,
            2630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2631,
            2635
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9416394233703613,
              "bbox": [
                308.9540710449219,
                51.96748352050781,
                508.9042053222656,
                356.8873596191406
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2636,
            2640
          ],
          "representative_frame": 2636,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 21
    },
    {
      "second": 88,
      "time_range": [
        88,
        88.999
      ],
      "frame_range": [
        2641,
        2670
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:46",
        "processing_time": 2.08,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2655,
          "frame_range": [
            2651,
            2655
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.81
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2641,
            2645
          ],
          "representative_frame": 2641,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9462761282920837,
              "bbox": [
                301.2552185058594,
                48.95583724975586,
                501.5476379394531,
                356.9953308105469
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2646,
            2650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2651,
            2655
          ],
          "representative_frame": 2651,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9403504729270935,
              "bbox": [
                288.45306396484375,
                45.13502883911133,
                489.5146484375,
                356.69549560546875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2656,
            2660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2661,
            2665
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9458233714103699,
              "bbox": [
                277.703369140625,
                44.240455627441406,
                477.89276123046875,
                356.7667236328125
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2666,
            2670
          ],
          "representative_frame": 2666,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 22
    },
    {
      "second": 89,
      "time_range": [
        89,
        89.999
      ],
      "frame_range": [
        2671,
        2700
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:48",
        "processing_time": 2.11,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2685,
          "frame_range": [
            2681,
            2685
          ],
          "description": "a man standing on a beach next to a body of water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.6
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2671,
            2675
          ],
          "representative_frame": 2671,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.94392991065979,
              "bbox": [
                272.4151916503906,
                44.600589752197266,
                471.7386169433594,
                356.5924377441406
              ]
            },
            {
              "track_id": 170,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7960841059684753,
              "bbox": [
                550.73828125,
                179.70086669921875,
                572.9982299804688,
                243.81338500976562
              ]
            }
          ],
          "unique_tracks": [
            130,
            170
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2676,
            2680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2681,
            2685
          ],
          "representative_frame": 2681,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9433876872062683,
              "bbox": [
                271.78582763671875,
                44.47267150878906,
                470.5565185546875,
                356.7580871582031
              ]
            },
            {
              "track_id": 190,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7660399675369263,
              "bbox": [
                518.0407104492188,
                180.68003845214844,
                539.8373413085938,
                244.41595458984375
              ]
            },
            {
              "track_id": 170,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8073617219924927,
              "bbox": [
                552.9932250976562,
                178.4834747314453,
                576.4255981445312,
                243.3760986328125
              ]
            }
          ],
          "unique_tracks": [
            130,
            190,
            170
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            2686,
            2690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2691,
            2695
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9347882866859436,
              "bbox": [
                267.9111022949219,
                46.11720275878906,
                466.21337890625,
                356.66046142578125
              ]
            },
            {
              "track_id": 190,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8174219727516174,
              "bbox": [
                515.4849853515625,
                178.46412658691406,
                536.6875610351562,
                240.46669006347656
              ]
            },
            {
              "track_id": 170,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.720287024974823,
              "bbox": [
                548.0975952148438,
                176.29795837402344,
                571.5392456054688,
                241.1327362060547
              ]
            }
          ],
          "unique_tracks": [
            130,
            190,
            170
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            2696,
            2700
          ],
          "representative_frame": 2696,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 22
    },
    {
      "second": 90,
      "time_range": [
        90,
        90.999
      ],
      "frame_range": [
        2701,
        2730
      ],
      "unified_description": "1-second scene showing a man standing on the shore of a lake with a GoPro-style action camera recording the event.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:49",
        "processing_time": 2.84,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2715,
          "frame_range": [
            2711,
            2715
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.4
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2701,
            2705
          ],
          "representative_frame": 2701,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9471218585968018,
              "bbox": [
                274.85308837890625,
                47.985042572021484,
                472.2230529785156,
                356.2577209472656
              ]
            },
            {
              "track_id": 190,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8127703070640564,
              "bbox": [
                520.0621337890625,
                173.46316528320312,
                541.5530395507812,
                236.27244567871094
              ]
            }
          ],
          "unique_tracks": [
            130,
            190
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2706,
            2710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2711,
            2715
          ],
          "representative_frame": 2711,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9511908292770386,
              "bbox": [
                207.77720642089844,
                32.5689582824707,
                421.0672607421875,
                356.261474609375
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2716,
            2720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2721,
            2725
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9508533477783203,
              "bbox": [
                192.02493286132812,
                29.471879959106445,
                412.44647216796875,
                356.53466796875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2726,
            2730
          ],
          "representative_frame": 2726,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 22
    },
    {
      "second": 91,
      "time_range": [
        91,
        91.999
      ],
      "frame_range": [
        2731,
        2760
      ],
      "unified_description": "1-second scene featuring a man standing on a rock near a lake with a camera mounted on his body. The image also includes an overhead view of the area surrounding the man.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:50",
        "processing_time": 3.34,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2745,
          "frame_range": [
            2741,
            2745
          ],
          "description": "a man standing on a rock near a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.81
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2731,
            2735
          ],
          "representative_frame": 2731,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9521914720535278,
              "bbox": [
                189.42367553710938,
                24.20206069946289,
                416.77813720703125,
                356.0707092285156
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2736,
            2740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2741,
            2745
          ],
          "representative_frame": 2741,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9512898325920105,
              "bbox": [
                187.549560546875,
                21.99509620666504,
                419.7589111328125,
                355.85272216796875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2746,
            2750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2751,
            2755
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9426975250244141,
              "bbox": [
                181.95745849609375,
                23.517322540283203,
                417.50738525390625,
                355.7815856933594
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2756,
            2760
          ],
          "representative_frame": 2756,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 22
    },
    {
      "second": 92,
      "time_range": [
        92,
        92.999
      ],
      "frame_range": [
        2761,
        2790
      ],
      "unified_description": "30 seconds remaining",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:51",
        "processing_time": 2.15,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2775,
          "frame_range": [
            2771,
            2775
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.58
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2761,
            2765
          ],
          "representative_frame": 2761,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9441957473754883,
              "bbox": [
                179.11849975585938,
                23.41716766357422,
                418.700927734375,
                355.82916259765625
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2766,
            2770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2771,
            2775
          ],
          "representative_frame": 2771,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9472317099571228,
              "bbox": [
                183.81629943847656,
                25.908720016479492,
                425.25958251953125,
                355.8593444824219
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2776,
            2780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2781,
            2785
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9493350982666016,
              "bbox": [
                185.47962951660156,
                27.14237403869629,
                428.8451232910156,
                355.77569580078125
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2786,
            2790
          ],
          "representative_frame": 2786,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 23
    },
    {
      "second": 93,
      "time_range": [
        93,
        93.999
      ],
      "frame_range": [
        2791,
        2820
      ],
      "unified_description": "\nThese details will help provide better context for viewers and improve search engine optimization.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:53",
        "processing_time": 2.35,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2805,
          "frame_range": [
            2801,
            2805
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.61
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2791,
            2795
          ],
          "representative_frame": 2791,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9405276775360107,
              "bbox": [
                178.08804321289062,
                32.666046142578125,
                421.7842712402344,
                356.06866455078125
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2796,
            2800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2801,
            2805
          ],
          "representative_frame": 2801,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9432894587516785,
              "bbox": [
                157.59310913085938,
                36.39222717285156,
                403.0924072265625,
                356.5212097167969
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2806,
            2810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2811,
            2815
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9514726400375366,
              "bbox": [
                157.5053253173828,
                38.16984176635742,
                404.68914794921875,
                356.5151062011719
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2816,
            2820
          ],
          "representative_frame": 2816,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 23
    },
    {
      "second": 94,
      "time_range": [
        94,
        94.999
      ],
      "frame_range": [
        2821,
        2850
      ],
      "unified_description": "3rd person perspective, stable camera, wide-angle distortion, action camera style, outdoor setting, natural lighting.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:54",
        "processing_time": 2.71,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2835,
          "frame_range": [
            2831,
            2835
          ],
          "description": "a man standing on a rocky shore next to a body of water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.12
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2821,
            2825
          ],
          "representative_frame": 2821,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9496263861656189,
              "bbox": [
                180.77255249023438,
                39.163841247558594,
                428.6736145019531,
                356.0163269042969
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2826,
            2830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2831,
            2835
          ],
          "representative_frame": 2831,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9512262940406799,
              "bbox": [
                182.59596252441406,
                38.852996826171875,
                432.4936828613281,
                355.63104248046875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2836,
            2840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2841,
            2845
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9503269195556641,
              "bbox": [
                179.82278442382812,
                35.73623275756836,
                434.73516845703125,
                355.6295166015625
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2846,
            2850
          ],
          "representative_frame": 2846,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 23
    },
    {
      "second": 95,
      "time_range": [
        95,
        95.999
      ],
      "frame_range": [
        2851,
        2880
      ],
      "unified_description": "1-second scene featuring a man standing on the shore of a lake, surrounded by six other groups.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:55",
        "processing_time": 2.51,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2865,
          "frame_range": [
            2861,
            2865
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2851,
            2855
          ],
          "representative_frame": 2851,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9479320645332336,
              "bbox": [
                175.84197998046875,
                33.150150299072266,
                435.1330871582031,
                356.1820983886719
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2856,
            2860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2861,
            2865
          ],
          "representative_frame": 2861,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.951962947845459,
              "bbox": [
                176.72467041015625,
                29.8330020904541,
                440.20501708984375,
                356.76702880859375
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2866,
            2870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2871,
            2875
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            2876,
            2880
          ],
          "representative_frame": 2876,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 23
    },
    {
      "second": 96,
      "time_range": [
        96,
        96.999
      ],
      "frame_range": [
        2881,
        2910
      ],
      "unified_description": "2 men walking by water? Yes",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:56",
        "processing_time": 2.21,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2895,
          "frame_range": [
            2891,
            2895
          ],
          "description": "two people are walking along the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2881,
            2885
          ],
          "representative_frame": 2881,
          "detections": [
            {
              "track_id": 196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9209455847740173,
              "bbox": [
                108.04907989501953,
                73.92840576171875,
                205.3084716796875,
                352.01422119140625
              ]
            },
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7724496126174927,
              "bbox": [
                378.20587158203125,
                154.72303771972656,
                563.4324951171875,
                357.6860046386719
              ]
            },
            {
              "track_id": 198,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.8916462659835815,
              "bbox": [
                483.388671875,
                149.537841796875,
                604.4182739257812,
                357.2457275390625
              ]
            }
          ],
          "unique_tracks": [
            196,
            197,
            198
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            2886,
            2890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2891,
            2895
          ],
          "representative_frame": 2891,
          "detections": [
            {
              "track_id": 196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7656845450401306,
              "bbox": [
                70.37262725830078,
                106.63217163085938,
                159.62794494628906,
                356.8730773925781
              ]
            },
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7491766810417175,
              "bbox": [
                372.2357177734375,
                153.08938598632812,
                556.9939575195312,
                357.17950439453125
              ]
            },
            {
              "track_id": 198,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.9037652611732483,
              "bbox": [
                483.3848876953125,
                144.67947387695312,
                606.4270629882812,
                356.1960144042969
              ]
            }
          ],
          "unique_tracks": [
            196,
            197,
            198
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            2896,
            2900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2901,
            2905
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8015248775482178,
              "bbox": [
                31.762224197387695,
                134.39158630371094,
                113.03011322021484,
                357.7889099121094
              ]
            },
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.533810555934906,
              "bbox": [
                363.04388427734375,
                149.13192749023438,
                549.1803588867188,
                356.76165771484375
              ]
            },
            {
              "track_id": 198,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.8464273810386658,
              "bbox": [
                476.48724365234375,
                140.7520294189453,
                600.5044555664062,
                354.607666015625
              ]
            }
          ],
          "unique_tracks": [
            196,
            197,
            198
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            2906,
            2910
          ],
          "representative_frame": 2906,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 24
    },
    {
      "second": 97,
      "time_range": [
        97,
        97.999
      ],
      "frame_range": [
        2911,
        2940
      ],
      "unified_description": "2 people walking in the woods by a river, with a backpack",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:57",
        "processing_time": 2.41,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2925,
          "frame_range": [
            2921,
            2925
          ],
          "description": "two people walking along a river with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.72
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2911,
            2915
          ],
          "representative_frame": 2911,
          "detections": [
            {
              "track_id": 196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8819084167480469,
              "bbox": [
                36.00891876220703,
                62.82490921020508,
                144.6608428955078,
                357.0195617675781
              ]
            },
            {
              "track_id": 198,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8763406872749329,
              "bbox": [
                462.0740051269531,
                68.62051391601562,
                616.95654296875,
                340.1676330566406
              ]
            }
          ],
          "unique_tracks": [
            196,
            198
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2916,
            2920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2921,
            2925
          ],
          "representative_frame": 2921,
          "detections": [
            {
              "track_id": 196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7083407044410706,
              "bbox": [
                64.54134368896484,
                50.75423812866211,
                165.64010620117188,
                317.8323669433594
              ]
            },
            {
              "track_id": 198,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7020279765129089,
              "bbox": [
                458.847900390625,
                62.2592658996582,
                616.926025390625,
                345.5323486328125
              ]
            },
            {
              "track_id": 203,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5608465671539307,
              "bbox": [
                558.2188720703125,
                109.50895690917969,
                639.7665405273438,
                242.65733337402344
              ]
            }
          ],
          "unique_tracks": [
            196,
            198,
            203
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            2926,
            2930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2931,
            2935
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 198,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8116335272789001,
              "bbox": [
                462.4561462402344,
                48.74937057495117,
                620.4205932617188,
                336.6717224121094
              ]
            },
            {
              "track_id": 203,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.645013153553009,
              "bbox": [
                564.1211547851562,
                93.43331146240234,
                640.0,
                224.122314453125
              ]
            }
          ],
          "unique_tracks": [
            198,
            203
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            2936,
            2940
          ],
          "representative_frame": 2936,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 24
    },
    {
      "second": 98,
      "time_range": [
        98,
        98.999
      ],
      "frame_range": [
        2941,
        2970
      ],
      "unified_description": "3D WIDE ANGLE SHOT OF TWO PEOPLE WALKING BY A RIVER.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:58",
        "processing_time": 2.55,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2955,
          "frame_range": [
            2951,
            2955
          ],
          "description": "two people walking along a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.47
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2941,
            2945
          ],
          "representative_frame": 2941,
          "detections": [
            {
              "track_id": 198,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9124985933303833,
              "bbox": [
                469.374755859375,
                47.967803955078125,
                618.0953369140625,
                324.5593566894531
              ]
            },
            {
              "track_id": 203,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7378026843070984,
              "bbox": [
                572.1953125,
                96.91104888916016,
                640.0,
                220.69447326660156
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8044452667236328,
              "bbox": [
                148.0146484375,
                34.240333557128906,
                248.59844970703125,
                295.8963317871094
              ]
            }
          ],
          "unique_tracks": [
            198,
            203,
            207
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            2946,
            2950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2951,
            2955
          ],
          "representative_frame": 2951,
          "detections": [
            {
              "track_id": 198,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.766238808631897,
              "bbox": [
                460.7267761230469,
                33.409000396728516,
                605.0588989257812,
                303.6358337402344
              ]
            },
            {
              "track_id": 203,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.8037058711051941,
              "bbox": [
                545.7606201171875,
                58.09382247924805,
                640.0,
                221.67987060546875
              ]
            }
          ],
          "unique_tracks": [
            198,
            203
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2956,
            2960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2961,
            2965
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 198,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5655851364135742,
              "bbox": [
                445.91070556640625,
                19.98142433166504,
                591.188720703125,
                300.4842834472656
              ]
            },
            {
              "track_id": 203,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7254670858383179,
              "bbox": [
                532.0440673828125,
                47.57102584838867,
                640.0,
                226.4420928955078
              ]
            }
          ],
          "unique_tracks": [
            198,
            203
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            2966,
            2970
          ],
          "representative_frame": 2966,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 24
    },
    {
      "second": 99,
      "time_range": [
        99,
        99.999
      ],
      "frame_range": [
        2971,
        3000
      ],
      "unified_description": "4th person to provide an image description for this scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:14:59",
        "processing_time": 2.29,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2985,
          "frame_range": [
            2981,
            2985
          ],
          "description": "a man walking through the woods with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.76
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2971,
            2975
          ],
          "representative_frame": 2971,
          "detections": [
            {
              "track_id": 198,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7080119252204895,
              "bbox": [
                412.53851318359375,
                12.59598159790039,
                554.0448608398438,
                294.4808349609375
              ]
            }
          ],
          "unique_tracks": [
            198
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2976,
            2980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2981,
            2985
          ],
          "representative_frame": 2981,
          "detections": [
            {
              "track_id": 198,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7729028463363647,
              "bbox": [
                410.0887145996094,
                23.47715187072754,
                509.2920837402344,
                217.7559814453125
              ]
            },
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8743106722831726,
              "bbox": [
                302.62451171875,
                20.360227584838867,
                504.6943054199219,
                257.68511962890625
              ]
            }
          ],
          "unique_tracks": [
            198,
            197
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2986,
            2990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2991,
            2995
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8462839722633362,
              "bbox": [
                280.62847900390625,
                11.92641830444336,
                458.2644958496094,
                232.75669860839844
              ]
            }
          ],
          "unique_tracks": [
            197
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2996,
            3000
          ],
          "representative_frame": 2996,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 24
    },
    {
      "second": 100,
      "time_range": [
        100,
        100.999
      ],
      "frame_range": [
        3001,
        3030
      ],
      "unified_description": "2 men in a forest with trees in the background",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:00",
        "processing_time": 2.34,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3015,
          "frame_range": [
            3011,
            3015
          ],
          "description": "a person walking through the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.54
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3001,
            3005
          ],
          "representative_frame": 3001,
          "detections": [
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8692699670791626,
              "bbox": [
                261.62725830078125,
                16.428388595581055,
                418.171630859375,
                220.6094970703125
              ]
            }
          ],
          "unique_tracks": [
            197
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3006,
            3010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3011,
            3015
          ],
          "representative_frame": 3011,
          "detections": [
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8580992817878723,
              "bbox": [
                242.3047332763672,
                12.632452964782715,
                377.7116394042969,
                196.22874450683594
              ]
            }
          ],
          "unique_tracks": [
            197
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3016,
            3020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3021,
            3025
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8595330715179443,
              "bbox": [
                225.67013549804688,
                12.366527557373047,
                340.9614562988281,
                171.2939453125
              ]
            }
          ],
          "unique_tracks": [
            197
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3026,
            3030
          ],
          "representative_frame": 3026,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 25
    },
    {
      "second": 101,
      "time_range": [
        101,
        101.999
      ],
      "frame_range": [
        3031,
        3060
      ],
      "unified_description": "1-second scene with 3 main objects: a man in a red jacket is walking through the woods (content description), camera positioned on tripod (technicial details), and video style being action camera ( GoPro-style) ( additional details ).",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:01",
        "processing_time": 3.03,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3045,
          "frame_range": [
            3041,
            3045
          ],
          "description": "a man in a red jacket is walking through the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.73
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3031,
            3035
          ],
          "representative_frame": 3031,
          "detections": [
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7424910068511963,
              "bbox": [
                207.2628173828125,
                7.091735363006592,
                318.4478759765625,
                164.17784118652344
              ]
            }
          ],
          "unique_tracks": [
            197
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3036,
            3040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3041,
            3045
          ],
          "representative_frame": 3041,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8532754182815552,
              "bbox": [
                197.95428466796875,
                39.8304443359375,
                391.9630126953125,
                282.8007507324219
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3046,
            3050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3051,
            3055
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9347096681594849,
              "bbox": [
                422.4796447753906,
                15.80194091796875,
                558.5269165039062,
                357.3227844238281
              ]
            },
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.438507616519928,
              "bbox": [
                205.8130645751953,
                66.02536010742188,
                400.21282958984375,
                302.6325378417969
              ]
            }
          ],
          "unique_tracks": [
            218,
            130
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3056,
            3060
          ],
          "representative_frame": 3056,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 25
    },
    {
      "second": 102,
      "time_range": [
        102,
        102.999
      ],
      "frame_range": [
        3061,
        3090
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:02",
        "processing_time": 2.12,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3075,
          "frame_range": [
            3071,
            3075
          ],
          "description": "two men in red jackets are walking through the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.0
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3061,
            3065
          ],
          "representative_frame": 3061,
          "detections": [
            {
              "track_id": 218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9264512062072754,
              "bbox": [
                472.9166259765625,
                4.111672878265381,
                613.7216796875,
                356.7039794921875
              ]
            },
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7799413800239563,
              "bbox": [
                199.53440856933594,
                65.71089935302734,
                394.91162109375,
                319.840576171875
              ]
            },
            {
              "track_id": 220,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7536598443984985,
              "bbox": [
                314.9925231933594,
                94.71705627441406,
                412.68695068359375,
                264.8417053222656
              ]
            }
          ],
          "unique_tracks": [
            218,
            130,
            220
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3066,
            3070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3071,
            3075
          ],
          "representative_frame": 3071,
          "detections": [
            {
              "track_id": 218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9122398495674133,
              "bbox": [
                513.9298095703125,
                0.0,
                640.0,
                356.0217590332031
              ]
            },
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7362146377563477,
              "bbox": [
                214.8498077392578,
                56.92259979248047,
                411.9329528808594,
                327.9312744140625
              ]
            }
          ],
          "unique_tracks": [
            218,
            130
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3076,
            3080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3081,
            3085
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9162073135375977,
              "bbox": [
                233.8638916015625,
                50.43668746948242,
                422.1150817871094,
                322.8162841796875
              ]
            },
            {
              "track_id": 224,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.6922544836997986,
              "bbox": [
                454.80609130859375,
                235.35452270507812,
                552.88671875,
                347.912109375
              ]
            }
          ],
          "unique_tracks": [
            130,
            224
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3086,
            3090
          ],
          "representative_frame": 3086,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 25
    },
    {
      "second": 103,
      "time_range": [
        103,
        103.999
      ],
      "frame_range": [
        3091,
        3120
      ],
      "unified_description": "3D Camera Perspective: POV, Handheld, Wide-angle distortion, Fisheye effect, Telephoto compression, Tremble",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:03",
        "processing_time": 2.77,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3105,
          "frame_range": [
            3101,
            3105
          ],
          "description": "a man in a red jacket is walking up a hill",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.93
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3091,
            3095
          ],
          "representative_frame": 3091,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9033286571502686,
              "bbox": [
                233.54530334472656,
                49.843231201171875,
                423.9801025390625,
                325.9751892089844
              ]
            },
            {
              "track_id": 224,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7553817629814148,
              "bbox": [
                478.30584716796875,
                254.71688842773438,
                566.6777954101562,
                355.9379577636719
              ]
            }
          ],
          "unique_tracks": [
            130,
            224
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3096,
            3100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3101,
            3105
          ],
          "representative_frame": 3101,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9001418948173523,
              "bbox": [
                264.3531188964844,
                43.59831237792969,
                454.56988525390625,
                329.23388671875
              ]
            },
            {
              "track_id": 224,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7827298641204834,
              "bbox": [
                527.3632202148438,
                280.11083984375,
                597.4022216796875,
                359.520751953125
              ]
            }
          ],
          "unique_tracks": [
            130,
            224
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3106,
            3110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3111,
            3115
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9154114127159119,
              "bbox": [
                327.0849914550781,
                33.98585891723633,
                523.90478515625,
                345.1706237792969
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3116,
            3120
          ],
          "representative_frame": 3116,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 25
    },
    {
      "second": 104,
      "time_range": [
        104,
        104.999
      ],
      "frame_range": [
        3121,
        3150
      ],
      "unified_description": "1-second scene featuring a man walking in a wooded area with a backpack on his back. The camera captures an action camera perspective providing a first hand experience for the viewer.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:05",
        "processing_time": 2.76,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3135,
          "frame_range": [
            3131,
            3135
          ],
          "description": "a man is walking through the woods with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.86
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3121,
            3125
          ],
          "representative_frame": 3121,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8740720152854919,
              "bbox": [
                271.6236572265625,
                8.202432632446289,
                407.4631042480469,
                248.04330444335938
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3126,
            3130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3131,
            3135
          ],
          "representative_frame": 3131,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.809426486492157,
              "bbox": [
                265.36273193359375,
                2.273960828781128,
                396.599609375,
                236.52215576171875
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3136,
            3140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3141,
            3145
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7813968658447266,
              "bbox": [
                261.291015625,
                2.279064178466797,
                400.2000732421875,
                257.181884765625
              ]
            },
            {
              "track_id": 230,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4866982400417328,
              "bbox": [
                242.19711303710938,
                174.66078186035156,
                288.7125244140625,
                216.2892608642578
              ]
            }
          ],
          "unique_tracks": [
            220,
            230
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3146,
            3150
          ],
          "representative_frame": 3146,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 26
    },
    {
      "second": 105,
      "time_range": [
        105,
        105.999
      ],
      "frame_range": [
        3151,
        3180
      ],
      "unified_description": "\nIn this scene, there is a man with a backpack who is standing in a wooded area. The camera perspective appears to be first-person, suggesting that it may have been mounted on the man's body. The image has a wide field of view, capturing the surrounding environment. There are several other objects and people nearby, including birds flying around. Additionally, the presence of a tripod indicates that the camera was likely set up for steady shots in various settings.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:07",
        "processing_time": 4.16,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3165,
          "frame_range": [
            3161,
            3165
          ],
          "description": "a man is standing in the woods with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3151,
            3155
          ],
          "representative_frame": 3151,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8903627395629883,
              "bbox": [
                267.7049255371094,
                11.5460786819458,
                404.4369812011719,
                266.3008728027344
              ]
            },
            {
              "track_id": 230,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5962164402008057,
              "bbox": [
                241.37042236328125,
                173.85830688476562,
                290.33502197265625,
                217.74905395507812
              ]
            }
          ],
          "unique_tracks": [
            220,
            230
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3156,
            3160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3161,
            3165
          ],
          "representative_frame": 3161,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.76705002784729,
              "bbox": [
                269.5240173339844,
                14.559654235839844,
                402.2982177734375,
                266.2096862792969
              ]
            },
            {
              "track_id": 230,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5202887654304504,
              "bbox": [
                240.93511962890625,
                173.49562072753906,
                290.7741394042969,
                218.28469848632812
              ]
            }
          ],
          "unique_tracks": [
            220,
            230
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3166,
            3170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3171,
            3175
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7968211770057678,
              "bbox": [
                273.3418273925781,
                20.0999755859375,
                397.27099609375,
                256.1324462890625
              ]
            },
            {
              "track_id": 230,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.521270751953125,
              "bbox": [
                240.78216552734375,
                173.39352416992188,
                290.7953796386719,
                218.48439025878906
              ]
            }
          ],
          "unique_tracks": [
            220,
            230
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3176,
            3180
          ],
          "representative_frame": 3176,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 26
    },
    {
      "second": 106,
      "time_range": [
        106,
        106.999
      ],
      "frame_range": [
        3181,
        3210
      ],
      "unified_description": "3D WALKING MOTION BlurRY IN A HALLWAY WITH A BACK Pack ON A BODY Mounted CAMERA",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:08",
        "processing_time": 4.07,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3195,
          "frame_range": [
            3191,
            3195
          ],
          "description": "a man standing next to a tree with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.71
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3181,
            3185
          ],
          "representative_frame": 3181,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.887338399887085,
              "bbox": [
                258.8253479003906,
                35.938541412353516,
                392.19940185546875,
                296.2153625488281
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3186,
            3190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3191,
            3195
          ],
          "representative_frame": 3191,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9113285541534424,
              "bbox": [
                247.56565856933594,
                41.95199203491211,
                381.9920349121094,
                311.0115966796875
              ]
            },
            {
              "track_id": 234,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7515401244163513,
              "bbox": [
                369.0485534667969,
                250.52622985839844,
                497.7257385253906,
                319.70562744140625
              ]
            },
            {
              "track_id": 236,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.31894218921661377,
              "bbox": [
                140.26678466796875,
                233.5201416015625,
                205.2462158203125,
                276.79736328125
              ]
            }
          ],
          "unique_tracks": [
            220,
            234,
            236
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            3196,
            3200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3201,
            3205
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.914757490158081,
              "bbox": [
                250.3546600341797,
                45.59724807739258,
                381.5445556640625,
                316.3835754394531
              ]
            },
            {
              "track_id": 234,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7562969326972961,
              "bbox": [
                368.8638916015625,
                250.38702392578125,
                497.4632873535156,
                319.50537109375
              ]
            },
            {
              "track_id": 236,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.34873631596565247,
              "bbox": [
                140.07272338867188,
                233.39480590820312,
                204.8787841796875,
                276.5416259765625
              ]
            }
          ],
          "unique_tracks": [
            220,
            234,
            236
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            3206,
            3210
          ],
          "representative_frame": 3206,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 26
    },
    {
      "second": 107,
      "time_range": [
        107,
        107.999
      ],
      "frame_range": [
        3211,
        3240
      ],
      "unified_description": "2 people and a tent can be seen outdoors. The camera is stable and captures motion well.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:09",
        "processing_time": 2.64,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3225,
          "frame_range": [
            3221,
            3225
          ],
          "description": "two men are standing near a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.08
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3211,
            3215
          ],
          "representative_frame": 3211,
          "detections": [
            {
              "track_id": 236,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5331587195396423,
              "bbox": [
                148.10731506347656,
                234.16607666015625,
                211.8468017578125,
                276.9703369140625
              ]
            }
          ],
          "unique_tracks": [
            236
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3216,
            3220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3221,
            3225
          ],
          "representative_frame": 3221,
          "detections": [
            {
              "track_id": 239,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.76036137342453,
              "bbox": [
                127.21435546875,
                109.86152648925781,
                178.8011016845703,
                281.7719421386719
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.789924681186676,
              "bbox": [
                400.6712951660156,
                59.50923538208008,
                495.79840087890625,
                304.35498046875
              ]
            }
          ],
          "unique_tracks": [
            239,
            240
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3226,
            3230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3231,
            3235
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 239,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.816783607006073,
              "bbox": [
                127.58280944824219,
                110.38636779785156,
                178.82508850097656,
                280.8325500488281
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.29874345660209656,
              "bbox": [
                393.816162109375,
                55.41912078857422,
                490.3904724121094,
                303.13763427734375
              ]
            }
          ],
          "unique_tracks": [
            239,
            240
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3236,
            3240
          ],
          "representative_frame": 3236,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 26
    },
    {
      "second": 108,
      "time_range": [
        108,
        108.999
      ],
      "frame_range": [
        3241,
        3270
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:10",
        "processing_time": 2.1,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3255,
          "frame_range": [
            3251,
            3255
          ],
          "description": "a man is standing next to a large bird",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.97
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3241,
            3245
          ],
          "representative_frame": 3241,
          "detections": [
            {
              "track_id": 239,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6205352544784546,
              "bbox": [
                125.94295501708984,
                110.93013763427734,
                177.38336181640625,
                281.802490234375
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.482158899307251,
              "bbox": [
                386.7191162109375,
                50.88663101196289,
                485.2877197265625,
                303.4134826660156
              ]
            }
          ],
          "unique_tracks": [
            239,
            240
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3246,
            3250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3251,
            3255
          ],
          "representative_frame": 3251,
          "detections": [
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.890302300453186,
              "bbox": [
                162.86410522460938,
                95.6572265625,
                250.05809020996094,
                330.0453186035156
              ]
            },
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8863058090209961,
              "bbox": [
                269.3840637207031,
                71.01887512207031,
                406.0184020996094,
                352.8106994628906
              ]
            }
          ],
          "unique_tracks": [
            207,
            220
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3256,
            3260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3261,
            3265
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.910316526889801,
              "bbox": [
                158.904052734375,
                91.8427734375,
                245.10777282714844,
                330.5334167480469
              ]
            },
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8897581696510315,
              "bbox": [
                267.7035217285156,
                38.190040588378906,
                420.159423828125,
                356.8695068359375
              ]
            }
          ],
          "unique_tracks": [
            207,
            220
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3266,
            3270
          ],
          "representative_frame": 3266,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 27
    },
    {
      "second": 109,
      "time_range": [
        109,
        109.999
      ],
      "frame_range": [
        3271,
        3300
      ],
      "unified_description": "1-second scene including a man and a dog walking in the woods. The camera perspective is first-person, with the camera positioned on the person's shoulder. It appears to be an action camera setup, capturing the movement and activity during this moment.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:13",
        "processing_time": 3.04,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3285,
          "frame_range": [
            3281,
            3285
          ],
          "description": "a man is walking through the woods with a dog",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.28
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3271,
            3275
          ],
          "representative_frame": 3271,
          "detections": [
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9160047173500061,
              "bbox": [
                158.18812561035156,
                86.45738220214844,
                245.4730224609375,
                337.6411437988281
              ]
            },
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.936369776725769,
              "bbox": [
                270.372802734375,
                14.369260787963867,
                433.5110168457031,
                358.2921447753906
              ]
            }
          ],
          "unique_tracks": [
            207,
            220
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3276,
            3280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3281,
            3285
          ],
          "representative_frame": 3281,
          "detections": [
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9210827946662903,
              "bbox": [
                404.82427978515625,
                3.4427802562713623,
                542.7554321289062,
                353.7319030761719
              ]
            }
          ],
          "unique_tracks": [
            240
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3286,
            3290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3291,
            3295
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 244,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9110872149467468,
              "bbox": [
                0.0,
                61.44858932495117,
                73.79920959472656,
                356.47113037109375
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.939130961894989,
              "bbox": [
                408.17950439453125,
                0.0,
                551.3556518554688,
                358.5274658203125
              ]
            }
          ],
          "unique_tracks": [
            244,
            240
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3296,
            3300
          ],
          "representative_frame": 3296,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 27
    },
    {
      "second": 110,
      "time_range": [
        110,
        110.999
      ],
      "frame_range": [
        3301,
        3330
      ],
      "unified_description": "2 men in orange jackets are working on a tree",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:13",
        "processing_time": 2.94,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3315,
          "frame_range": [
            3311,
            3315
          ],
          "description": "two men in orange jackets are working on a tree",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.1
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3301,
            3305
          ],
          "representative_frame": 3301,
          "detections": [
            {
              "track_id": 244,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.916176974773407,
              "bbox": [
                0.0,
                61.48332977294922,
                72.49020385742188,
                356.6615905761719
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9313207268714905,
              "bbox": [
                410.98028564453125,
                0.0,
                557.2242431640625,
                360.0
              ]
            },
            {
              "track_id": 220,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.6205413937568665,
              "bbox": [
                298.5830078125,
                38.70241928100586,
                418.93951416015625,
                274.97564697265625
              ]
            }
          ],
          "unique_tracks": [
            244,
            240,
            220
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3306,
            3310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3311,
            3315
          ],
          "representative_frame": 3311,
          "detections": [
            {
              "track_id": 244,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9284384846687317,
              "bbox": [
                1.1873527765274048,
                59.38633728027344,
                77.08741760253906,
                356.4584655761719
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.927944004535675,
              "bbox": [
                411.47564697265625,
                0.0,
                559.5760498046875,
                360.0
              ]
            },
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9306328296661377,
              "bbox": [
                265.9989318847656,
                26.640846252441406,
                424.3960876464844,
                331.1106262207031
              ]
            }
          ],
          "unique_tracks": [
            244,
            240,
            220
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            3316,
            3320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3321,
            3325
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8806374669075012,
              "bbox": [
                163.59495544433594,
                42.18137741088867,
                350.4924621582031,
                346.95562744140625
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3326,
            3330
          ],
          "representative_frame": 3326,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 27
    },
    {
      "second": 111,
      "time_range": [
        111,
        111.999
      ],
      "frame_range": [
        3331,
        3360
      ],
      "unified_description": "\nA man in a black jacket is standing under a tree",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:14",
        "processing_time": 2.42,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3345,
          "frame_range": [
            3341,
            3345
          ],
          "description": "a man in a black jacket is standing under a tree",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.8
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3331,
            3335
          ],
          "representative_frame": 3331,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8456403613090515,
              "bbox": [
                115.5755844116211,
                91.70647430419922,
                301.8954162597656,
                353.8127746582031
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3336,
            3340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3341,
            3345
          ],
          "representative_frame": 3341,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9257598519325256,
              "bbox": [
                89.54183959960938,
                119.88523864746094,
                279.66876220703125,
                356.82659912109375
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3346,
            3350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3351,
            3355
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8467649221420288,
              "bbox": [
                72.8763427734375,
                120.03034210205078,
                280.53790283203125,
                357.514892578125
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3356,
            3360
          ],
          "representative_frame": 3356,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 27
    },
    {
      "second": 112,
      "time_range": [
        112,
        112.999
      ],
      "frame_range": [
        3361,
        3390
      ],
      "unified_description": "3rd person perspective showing a man holding an umbrella in the rain.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:16",
        "processing_time": 2.38,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3375,
          "frame_range": [
            3371,
            3375
          ],
          "description": "a man is holding a large umbrella",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.47
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3361,
            3365
          ],
          "representative_frame": 3361,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.906500518321991,
              "bbox": [
                56.558921813964844,
                82.9299545288086,
                308.12432861328125,
                357.0196228027344
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3366,
            3370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3371,
            3375
          ],
          "representative_frame": 3371,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8591503500938416,
              "bbox": [
                79.0479736328125,
                119.13861846923828,
                310.80712890625,
                357.4967041015625
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3376,
            3380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3381,
            3385
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7029392719268799,
              "bbox": [
                485.3880615234375,
                0.37520307302474976,
                589.491943359375,
                221.5888214111328
              ]
            }
          ],
          "unique_tracks": [
            240
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3386,
            3390
          ],
          "representative_frame": 3386,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 28
    },
    {
      "second": 113,
      "time_range": [
        113,
        113.999
      ],
      "frame_range": [
        3391,
        3420
      ],
      "unified_description": "2 people are standing next to each other, one with a backpack on.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:17",
        "processing_time": 2.47,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3405,
          "frame_range": [
            3401,
            3405
          ],
          "description": "a man and two children sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3391,
            3395
          ],
          "representative_frame": 3391,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.830260694026947,
              "bbox": [
                276.31103515625,
                50.7619743347168,
                379.47320556640625,
                202.96444702148438
              ]
            }
          ],
          "unique_tracks": [
            252
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3396,
            3400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3401,
            3405
          ],
          "representative_frame": 3401,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7841440439224243,
              "bbox": [
                275.85107421875,
                54.661231994628906,
                373.6770324707031,
                199.12014770507812
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8555861115455627,
              "bbox": [
                155.44654846191406,
                34.861289978027344,
                254.5568084716797,
                261.8323974609375
              ]
            }
          ],
          "unique_tracks": [
            252,
            207
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3406,
            3410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3411,
            3415
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8748890161514282,
              "bbox": [
                298.4391784667969,
                35.03989791870117,
                396.677490234375,
                177.1627655029297
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.840717613697052,
              "bbox": [
                183.20938110351562,
                111.95309448242188,
                245.78709411621094,
                228.73788452148438
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7919060587882996,
              "bbox": [
                461.5072937011719,
                44.59536361694336,
                593.2957153320312,
                310.53118896484375
              ]
            }
          ],
          "unique_tracks": [
            252,
            207,
            240
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            3416,
            3420
          ],
          "representative_frame": 3416,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 28
    },
    {
      "second": 114,
      "time_range": [
        114,
        114.999
      ],
      "frame_range": [
        3421,
        3450
      ],
      "unified_description": "1-second scene with a group of people sitting in a tent, camera perspective is first person, stable camera positioning, wide-angle distortion visible, action camera (GoPro-style) recording, natural outdoor lighting, etc.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:18",
        "processing_time": 3.45,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3435,
          "frame_range": [
            3431,
            3435
          ],
          "description": "a group of people sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.39
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3421,
            3425
          ],
          "representative_frame": 3421,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5189257860183716,
              "bbox": [
                294.3004150390625,
                28.661006927490234,
                414.4319152832031,
                200.48541259765625
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8699878454208374,
              "bbox": [
                193.11158752441406,
                138.9480743408203,
                248.0699462890625,
                232.07192993164062
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8266035318374634,
              "bbox": [
                455.1492919921875,
                49.32957077026367,
                595.2860107421875,
                322.4792175292969
              ]
            }
          ],
          "unique_tracks": [
            252,
            207,
            240
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3426,
            3430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3431,
            3435
          ],
          "representative_frame": 3431,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7828999161720276,
              "bbox": [
                293.0413513183594,
                26.501022338867188,
                421.7384033203125,
                208.17013549804688
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8714296817779541,
              "bbox": [
                191.4461212158203,
                144.1764678955078,
                255.98065185546875,
                248.7794952392578
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.79911208152771,
              "bbox": [
                453.12554931640625,
                50.79317092895508,
                597.60400390625,
                326.8709411621094
              ]
            }
          ],
          "unique_tracks": [
            252,
            207,
            240
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            3436,
            3440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3441,
            3445
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.848476767539978,
              "bbox": [
                287.9058532714844,
                25.859819412231445,
                429.4829406738281,
                224.14369201660156
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7869232296943665,
              "bbox": [
                170.88348388671875,
                146.2611083984375,
                262.1499938964844,
                292.6221923828125
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.41465169191360474,
              "bbox": [
                450.2636413574219,
                51.075965881347656,
                598.3847045898438,
                328.24359130859375
              ]
            }
          ],
          "unique_tracks": [
            252,
            207,
            240
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            3446,
            3450
          ],
          "representative_frame": 3446,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 28
    },
    {
      "second": 115,
      "time_range": [
        115,
        115.999
      ],
      "frame_range": [
        3451,
        3480
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:19",
        "processing_time": 2.08,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3465,
          "frame_range": [
            3461,
            3465
          ],
          "description": "a group of people sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.94
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3451,
            3455
          ],
          "representative_frame": 3451,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8556743860244751,
              "bbox": [
                291.81256103515625,
                21.505897521972656,
                433.362548828125,
                218.5648651123047
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5287957787513733,
              "bbox": [
                148.31201171875,
                151.9098358154297,
                258.73431396484375,
                308.3234558105469
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8817865252494812,
              "bbox": [
                436.49285888671875,
                57.08999252319336,
                592.7506103515625,
                348.0771179199219
              ]
            }
          ],
          "unique_tracks": [
            252,
            207,
            240
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3456,
            3460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3461,
            3465
          ],
          "representative_frame": 3461,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8632764220237732,
              "bbox": [
                299.3743591308594,
                16.247827529907227,
                436.6549377441406,
                204.56678771972656
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6496531963348389,
              "bbox": [
                119.05847930908203,
                154.99867248535156,
                249.31927490234375,
                317.48468017578125
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7963442206382751,
              "bbox": [
                444.5582275390625,
                57.26596450805664,
                597.3534545898438,
                340.1495056152344
              ]
            }
          ],
          "unique_tracks": [
            252,
            207,
            240
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            3466,
            3470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3471,
            3475
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7185339331626892,
              "bbox": [
                274.1478576660156,
                14.466197967529297,
                447.251220703125,
                252.42855834960938
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8648219704627991,
              "bbox": [
                444.15948486328125,
                56.745662689208984,
                595.1130981445312,
                330.3428955078125
              ]
            }
          ],
          "unique_tracks": [
            252,
            240
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3476,
            3480
          ],
          "representative_frame": 3476,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 28
    },
    {
      "second": 116,
      "time_range": [
        116,
        116.999
      ],
      "frame_range": [
        3481,
        3510
      ],
      "unified_description": "1-second scene including a man in a hat standing in the woods",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:21",
        "processing_time": 2.34,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3495,
          "frame_range": [
            3491,
            3495
          ],
          "description": "a man in a hat is standing in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.14
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3481,
            3485
          ],
          "representative_frame": 3481,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5972378253936768,
              "bbox": [
                291.4361267089844,
                12.148508071899414,
                446.6207275390625,
                223.98648071289062
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7675110101699829,
              "bbox": [
                447.5360107421875,
                56.63409423828125,
                600.9124755859375,
                330.5978088378906
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6811829805374146,
              "bbox": [
                180.46424865722656,
                152.89370727539062,
                290.9908752441406,
                290.7926940917969
              ]
            }
          ],
          "unique_tracks": [
            252,
            240,
            263
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3486,
            3490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3491,
            3495
          ],
          "representative_frame": 3491,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            3496,
            3500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3501,
            3505
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6944353580474854,
              "bbox": [
                93.7602767944336,
                0.546844482421875,
                459.3074645996094,
                353.9249267578125
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3506,
            3510
          ],
          "representative_frame": 3506,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 29
    },
    {
      "second": 117,
      "time_range": [
        117,
        117.999
      ],
      "frame_range": [
        3511,
        3540
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:21",
        "processing_time": 2.12,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3525,
          "frame_range": [
            3521,
            3525
          ],
          "description": "a man is putting a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.69
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3511,
            3515
          ],
          "representative_frame": 3511,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9398477077484131,
              "bbox": [
                89.00664520263672,
                2.4565505981445312,
                454.2682800292969,
                354.5942077636719
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3516,
            3520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3521,
            3525
          ],
          "representative_frame": 3521,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7396438121795654,
              "bbox": [
                102.2410659790039,
                2.005584239959717,
                473.390380859375,
                355.6563415527344
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3526,
            3530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3531,
            3535
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4641384482383728,
              "bbox": [
                97.58834075927734,
                0.5937514305114746,
                476.17437744140625,
                354.2817077636719
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3536,
            3540
          ],
          "representative_frame": 3536,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 29
    },
    {
      "second": 118,
      "time_range": [
        118,
        118.999
      ],
      "frame_range": [
        3541,
        3570
      ],
      "unified_description": "1-second scene showing a man in a rain suit standing next to a tent. The camera is mounted on a tripod, using a wide-angle lens to capture the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:23",
        "processing_time": 2.78,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3555,
          "frame_range": [
            3551,
            3555
          ],
          "description": "a man in a rain suit standing next to a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.78
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3541,
            3545
          ],
          "representative_frame": 3541,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9215824007987976,
              "bbox": [
                137.70516967773438,
                0.21979433298110962,
                496.7915954589844,
                345.339599609375
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8764322996139526,
              "bbox": [
                144.60264587402344,
                120.91742706298828,
                293.7840270996094,
                309.21368408203125
              ]
            }
          ],
          "unique_tracks": [
            267,
            263
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3546,
            3550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3551,
            3555
          ],
          "representative_frame": 3551,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9122290015220642,
              "bbox": [
                158.1002197265625,
                0.5992540717124939,
                502.1361389160156,
                342.46685791015625
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.885309100151062,
              "bbox": [
                149.90098571777344,
                105.5445327758789,
                308.184814453125,
                312.0494384765625
              ]
            }
          ],
          "unique_tracks": [
            267,
            263
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3556,
            3560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3561,
            3565
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9220811128616333,
              "bbox": [
                177.3651580810547,
                0.3007894456386566,
                509.03216552734375,
                341.4822082519531
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9080408811569214,
              "bbox": [
                145.7598419189453,
                89.12598419189453,
                311.9149475097656,
                312.93890380859375
              ]
            }
          ],
          "unique_tracks": [
            267,
            263
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3566,
            3570
          ],
          "representative_frame": 3566,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 29
    },
    {
      "second": 119,
      "time_range": [
        119,
        119.999
      ],
      "frame_range": [
        3571,
        3600
      ],
      "unified_description": "\nPlease provide Camp of Instructions",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:24",
        "processing_time": 2.21,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3585,
          "frame_range": [
            3581,
            3585
          ],
          "description": "a man in a red rain suit standing next to a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.13
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3571,
            3575
          ],
          "representative_frame": 3571,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9211535453796387,
              "bbox": [
                181.9883270263672,
                0.05077271908521652,
                500.5995178222656,
                341.33294677734375
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.898541271686554,
              "bbox": [
                138.88955688476562,
                74.84490966796875,
                309.42926025390625,
                312.6844177246094
              ]
            }
          ],
          "unique_tracks": [
            267,
            263
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3576,
            3580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3581,
            3585
          ],
          "representative_frame": 3581,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5721912980079651,
              "bbox": [
                192.08750915527344,
                0.41206470131874084,
                512.4476318359375,
                351.4593811035156
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8320372700691223,
              "bbox": [
                143.411865234375,
                64.93997192382812,
                311.2098083496094,
                308.4684753417969
              ]
            }
          ],
          "unique_tracks": [
            267,
            263
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3586,
            3590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3591,
            3595
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8139034509658813,
              "bbox": [
                173.52316284179688,
                0.11112038791179657,
                486.6436767578125,
                355.2525634765625
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8253172039985657,
              "bbox": [
                148.00442504882812,
                61.89105987548828,
                310.044189453125,
                306.6105651855469
              ]
            },
            {
              "track_id": 271,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.831418514251709,
              "bbox": [
                396.40521240234375,
                79.58860778808594,
                434.31732177734375,
                290.6396484375
              ]
            }
          ],
          "unique_tracks": [
            267,
            263,
            271
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            3596,
            3600
          ],
          "representative_frame": 3596,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 29
    },
    {
      "second": 120,
      "time_range": [
        120,
        120.999
      ],
      "frame_range": [
        3601,
        3630
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:25",
        "processing_time": 2.11,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3615,
          "frame_range": [
            3611,
            3615
          ],
          "description": "a man in a red jacket and black pants standing next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.2
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3601,
            3605
          ],
          "representative_frame": 3601,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9040698409080505,
              "bbox": [
                163.61732482910156,
                0.0009621985373087227,
                468.6544189453125,
                356.32110595703125
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7646893262863159,
              "bbox": [
                155.67486572265625,
                73.64421844482422,
                303.95977783203125,
                305.4424743652344
              ]
            },
            {
              "track_id": 271,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8908631801605225,
              "bbox": [
                400.2363586425781,
                73.29615020751953,
                439.783935546875,
                291.5119934082031
              ]
            }
          ],
          "unique_tracks": [
            267,
            263,
            271
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3606,
            3610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3611,
            3615
          ],
          "representative_frame": 3611,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7614779472351074,
              "bbox": [
                165.265380859375,
                0.4002474248409271,
                461.1772155761719,
                357.0859069824219
              ]
            },
            {
              "track_id": 271,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.904147744178772,
              "bbox": [
                418.06146240234375,
                69.47820281982422,
                460.0798034667969,
                295.15277099609375
              ]
            }
          ],
          "unique_tracks": [
            267,
            271
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3616,
            3620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3621,
            3625
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            3626,
            3630
          ],
          "representative_frame": 3626,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 30
    },
    {
      "second": 121,
      "time_range": [
        121,
        121.999
      ],
      "frame_range": [
        3631,
        3660
      ],
      "unified_description": "\n\n1st second of a person's day as they walk along the shoreline, wearing a red jacket. The camera is mounted on their shoulder, capturing their movements as they explore the riverside area. There are also six other people in various positions throughout the scene, although they are not the main focus of the image. The primary subject remains the person in the red jacket, and their actions and surroundings are recorded in detail.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:27",
        "processing_time": 3.67,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3645,
          "frame_range": [
            3641,
            3645
          ],
          "description": "a person in red jacket walking along the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.7
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3631,
            3635
          ],
          "representative_frame": 3631,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            3636,
            3640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3641,
            3645
          ],
          "representative_frame": 3641,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            3646,
            3650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3651,
            3655
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 276,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8829826712608337,
              "bbox": [
                552.254638671875,
                197.98818969726562,
                597.5117797851562,
                316.0326843261719
              ]
            }
          ],
          "unique_tracks": [
            276
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3656,
            3660
          ],
          "representative_frame": 3656,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 30
    },
    {
      "second": 122,
      "time_range": [
        122,
        122.999
      ],
      "frame_range": [
        3661,
        3690
      ],
      "unified_description": "1-second scene with a person in red standing on rocks. Also features an object with the shape of a bottle.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:28",
        "processing_time": 3.15,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3675,
          "frame_range": [
            3671,
            3675
          ],
          "description": "a person in red clothes standing on a rocky shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3661,
            3665
          ],
          "representative_frame": 3661,
          "detections": [
            {
              "track_id": 276,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8545997738838196,
              "bbox": [
                565.0084228515625,
                196.00921630859375,
                609.2446899414062,
                311.5843505859375
              ]
            }
          ],
          "unique_tracks": [
            276
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3666,
            3670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3671,
            3675
          ],
          "representative_frame": 3671,
          "detections": [
            {
              "track_id": 276,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7579959630966187,
              "bbox": [
                575.6484375,
                191.90380859375,
                619.5733642578125,
                307.6937561035156
              ]
            }
          ],
          "unique_tracks": [
            276
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3676,
            3680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3681,
            3685
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 276,
              "class_id": 10,
              "class_name": "fire hydrant",
              "confidence": 0.7772905826568604,
              "bbox": [
                581.7394409179688,
                189.11105346679688,
                626.0833129882812,
                306.9093322753906
              ]
            }
          ],
          "unique_tracks": [
            276
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3686,
            3690
          ],
          "representative_frame": 3686,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 30
    },
    {
      "second": 123,
      "time_range": [
        123,
        123.999
      ],
      "frame_range": [
        3691,
        3720
      ],
      "unified_description": "1-second scene featuring a man near water with mountains in the distance, shot using action camera.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:29",
        "processing_time": 3.15,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3705,
          "frame_range": [
            3701,
            3705
          ],
          "description": "a person walking along a lake with mountains in the background",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3691,
            3695
          ],
          "representative_frame": 3691,
          "detections": [
            {
              "track_id": 276,
              "class_id": 10,
              "class_name": "fire hydrant",
              "confidence": 0.8149906396865845,
              "bbox": [
                585.6935424804688,
                190.08628845214844,
                629.0830078125,
                305.5992126464844
              ]
            }
          ],
          "unique_tracks": [
            276
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3696,
            3700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3701,
            3705
          ],
          "representative_frame": 3701,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            3706,
            3710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3711,
            3715
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 278,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7512038946151733,
              "bbox": [
                561.9268798828125,
                154.4962615966797,
                587.0379638671875,
                220.54161071777344
              ]
            }
          ],
          "unique_tracks": [
            278
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3716,
            3720
          ],
          "representative_frame": 3716,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 30
    },
    {
      "second": 124,
      "time_range": [
        124,
        124.999
      ],
      "frame_range": [
        3721,
        3750
      ],
      "unified_description": "3rd person perspective, POV, camera positioned on top of a person's head, field of view covers most of scene, no distortion, action camera style, outdoor setting with water body and mountain in background, stable camera positioning, well lit, clear frame composition",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:32",
        "processing_time": 3.07,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3735,
          "frame_range": [
            3731,
            3735
          ],
          "description": "a person walking along a lake with mountains in the background",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3721,
            3725
          ],
          "representative_frame": 3721,
          "detections": [
            {
              "track_id": 278,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7703260183334351,
              "bbox": [
                559.8180541992188,
                152.8216094970703,
                585.2260131835938,
                219.72132873535156
              ]
            }
          ],
          "unique_tracks": [
            278
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3726,
            3730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3731,
            3735
          ],
          "representative_frame": 3731,
          "detections": [
            {
              "track_id": 278,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7729820609092712,
              "bbox": [
                558.7317504882812,
                152.01345825195312,
                584.4120483398438,
                219.75706481933594
              ]
            }
          ],
          "unique_tracks": [
            278
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3736,
            3740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3741,
            3745
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9210354685783386,
              "bbox": [
                117.45537567138672,
                0.7366932034492493,
                319.8447570800781,
                317.6894226074219
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3746,
            3750
          ],
          "representative_frame": 3746,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 31
    },
    {
      "second": 125,
      "time_range": [
        125,
        125.999
      ],
      "frame_range": [
        3751,
        3780
      ],
      "unified_description": "1 second video with a POV camera perspective showing a person in an orange jacket and a tent",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:33",
        "processing_time": 2.76,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3765,
          "frame_range": [
            3761,
            3765
          ],
          "description": "a person in an orange jacket is standing near a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.83
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3751,
            3755
          ],
          "representative_frame": 3751,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9191197156906128,
              "bbox": [
                165.12554931640625,
                23.991003036499023,
                404.37847900390625,
                319.63983154296875
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3756,
            3760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3761,
            3765
          ],
          "representative_frame": 3761,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8590918779373169,
              "bbox": [
                210.3111572265625,
                59.5807991027832,
                417.80181884765625,
                313.3562316894531
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3766,
            3770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3771,
            3775
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9064251184463501,
              "bbox": [
                226.0743865966797,
                76.56267547607422,
                422.82586669921875,
                313.3888244628906
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3776,
            3780
          ],
          "representative_frame": 3776,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 31
    },
    {
      "second": 126,
      "time_range": [
        126,
        126.999
      ],
      "frame_range": [
        3781,
        3810
      ],
      "unified_description": "1-second scene including a man in a red raincoat holding a fishing rod and a group of people standing around outside.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:33",
        "processing_time": 3.36,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3795,
          "frame_range": [
            3791,
            3795
          ],
          "description": "a man in a red raincoat holding a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.4
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3781,
            3785
          ],
          "representative_frame": 3781,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8522056341171265,
              "bbox": [
                233.4984130859375,
                75.81134796142578,
                426.449462890625,
                304.1158752441406
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3786,
            3790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3791,
            3795
          ],
          "representative_frame": 3791,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9239524602890015,
              "bbox": [
                147.79502868652344,
                0.0,
                366.7275390625,
                349.7167663574219
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3796,
            3800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3801,
            3805
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9414013624191284,
              "bbox": [
                119.45958709716797,
                0.0,
                343.2064514160156,
                352.51885986328125
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3806,
            3810
          ],
          "representative_frame": 3806,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 31
    },
    {
      "second": 127,
      "time_range": [
        127,
        127.999
      ],
      "frame_range": [
        3811,
        3840
      ],
      "unified_description": "1-second scene showing a person walking with a small child. The surrounding environment is also captured in the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:36",
        "processing_time": 2.5,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3825,
          "frame_range": [
            3821,
            3825
          ],
          "description": "a man in a red suit is holding a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.67
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3811,
            3815
          ],
          "representative_frame": 3811,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9397888779640198,
              "bbox": [
                90.59207916259766,
                0.0,
                320.7160949707031,
                354.7749938964844
              ]
            },
            {
              "track_id": 281,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5897716283798218,
              "bbox": [
                14.13266658782959,
                3.370593309402466,
                78.35966491699219,
                106.71493530273438
              ]
            }
          ],
          "unique_tracks": [
            263,
            281
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3816,
            3820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3821,
            3825
          ],
          "representative_frame": 3821,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8679614663124084,
              "bbox": [
                104.25006866455078,
                3.204742431640625,
                327.5244140625,
                355.2072448730469
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3826,
            3830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3831,
            3835
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9243423342704773,
              "bbox": [
                206.77915954589844,
                132.92666625976562,
                397.7207336425781,
                347.4817199707031
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3836,
            3840
          ],
          "representative_frame": 3836,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 31
    },
    {
      "second": 128,
      "time_range": [
        128,
        128.999
      ],
      "frame_range": [
        3841,
        3870
      ],
      "unified_description": "1-second scene that includes a man kneeling on a trail with a tent, and other outdoor elements.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:37",
        "processing_time": 2.67,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3855,
          "frame_range": [
            3851,
            3855
          ],
          "description": "a man kneeling on a trail with a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.65
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3841,
            3845
          ],
          "representative_frame": 3841,
          "detections": [
            {
              "track_id": 284,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.47634559869766235,
              "bbox": [
                85.19857025146484,
                155.14491271972656,
                280.9656982421875,
                285.20361328125
              ]
            },
            {
              "track_id": 285,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4605056643486023,
              "bbox": [
                16.01636505126953,
                234.04014587402344,
                71.30549621582031,
                281.0043029785156
              ]
            },
            {
              "track_id": 286,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4092094898223877,
              "bbox": [
                148.78598022460938,
                311.79638671875,
                181.947021484375,
                352.7572937011719
              ]
            },
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9208215475082397,
              "bbox": [
                201.72267150878906,
                137.58709716796875,
                403.1380310058594,
                350.9912414550781
              ]
            }
          ],
          "unique_tracks": [
            284,
            285,
            286,
            267
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            3846,
            3850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3851,
            3855
          ],
          "representative_frame": 3851,
          "detections": [
            {
              "track_id": 284,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.5039286017417908,
              "bbox": [
                104.80691528320312,
                154.92626953125,
                264.5828857421875,
                260.37957763671875
              ]
            },
            {
              "track_id": 285,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.49681052565574646,
              "bbox": [
                17.208032608032227,
                234.78846740722656,
                71.55355072021484,
                280.9568176269531
              ]
            },
            {
              "track_id": 286,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.28776076436042786,
              "bbox": [
                148.8736572265625,
                311.7747802734375,
                181.93698120117188,
                352.619384765625
              ]
            },
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9268589019775391,
              "bbox": [
                201.6426544189453,
                139.72763061523438,
                412.2584228515625,
                352.3917236328125
              ]
            }
          ],
          "unique_tracks": [
            284,
            285,
            286,
            267
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            3856,
            3860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3861,
            3865
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 284,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.394092321395874,
              "bbox": [
                94.05780029296875,
                154.92141723632812,
                272.8049011230469,
                272.653076171875
              ]
            },
            {
              "track_id": 285,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.44527468085289,
              "bbox": [
                17.68712615966797,
                235.10586547851562,
                71.60930633544922,
                280.91986083984375
              ]
            },
            {
              "track_id": 286,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2971270680427551,
              "bbox": [
                148.4531707763672,
                311.7378234863281,
                181.76138305664062,
                352.8908386230469
              ]
            },
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8860067129135132,
              "bbox": [
                217.97120666503906,
                141.8557891845703,
                429.95697021484375,
                352.176513671875
              ]
            }
          ],
          "unique_tracks": [
            284,
            285,
            286,
            267
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            3866,
            3870
          ],
          "representative_frame": 3866,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 32
    },
    {
      "second": 129,
      "time_range": [
        129,
        129.999
      ],
      "frame_range": [
        3871,
        3900
      ],
      "unified_description": "30-second description and object detection summary for a video that features a man in a raincoat sitting on the ground.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:38",
        "processing_time": 3.1,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3885,
          "frame_range": [
            3881,
            3885
          ],
          "description": "a man in a raincoat is sitting on the ground",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.21
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3871,
            3875
          ],
          "representative_frame": 3871,
          "detections": [
            {
              "track_id": 284,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.4663860499858856,
              "bbox": [
                94.28135681152344,
                155.60462951660156,
                273.8116455078125,
                273.69879150390625
              ]
            },
            {
              "track_id": 285,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.21636982262134552,
              "bbox": [
                17.66950225830078,
                235.7194366455078,
                71.83189392089844,
                281.7498779296875
              ]
            },
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7466035485267639,
              "bbox": [
                238.08505249023438,
                140.64300537109375,
                448.49237060546875,
                350.67852783203125
              ]
            }
          ],
          "unique_tracks": [
            284,
            285,
            267
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3876,
            3880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3881,
            3885
          ],
          "representative_frame": 3881,
          "detections": [
            {
              "track_id": 284,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.15915492177009583,
              "bbox": [
                93.84870147705078,
                155.5462646484375,
                274.62103271484375,
                274.2528076171875
              ]
            },
            {
              "track_id": 285,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.21591965854167938,
              "bbox": [
                15.871758460998535,
                235.37159729003906,
                71.44573974609375,
                282.5693664550781
              ]
            },
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6196988224983215,
              "bbox": [
                245.709716796875,
                140.0030517578125,
                454.60626220703125,
                349.65704345703125
              ]
            },
            {
              "track_id": 288,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9294126629829407,
              "bbox": [
                448.4509582519531,
                20.016870498657227,
                568.9406127929688,
                357.0301513671875
              ]
            }
          ],
          "unique_tracks": [
            284,
            285,
            267,
            288
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            3886,
            3890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3891,
            3895
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 284,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.18991149961948395,
              "bbox": [
                92.34513092041016,
                155.72999572753906,
                275.9184875488281,
                276.2392883300781
              ]
            },
            {
              "track_id": 285,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.17743781208992004,
              "bbox": [
                16.433609008789062,
                235.71896362304688,
                71.28902435302734,
                282.2642822265625
              ]
            },
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7603909373283386,
              "bbox": [
                248.1461944580078,
                139.45010375976562,
                456.7845458984375,
                349.9248962402344
              ]
            },
            {
              "track_id": 288,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9274353981018066,
              "bbox": [
                449.0870666503906,
                19.293685913085938,
                569.7992553710938,
                356.966552734375
              ]
            }
          ],
          "unique_tracks": [
            284,
            285,
            267,
            288
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            3896,
            3900
          ],
          "representative_frame": 3896,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 32
    },
    {
      "second": 130,
      "time_range": [
        130,
        130.999
      ],
      "frame_range": [
        3901,
        3930
      ],
      "unified_description": "1 second left to right",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:40",
        "processing_time": 2.18,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3915,
          "frame_range": [
            3911,
            3915
          ],
          "description": "a man and a child are fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.33
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3901,
            3905
          ],
          "representative_frame": 3901,
          "detections": [
            {
              "track_id": 284,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.36138564348220825,
              "bbox": [
                93.14584350585938,
                155.81678771972656,
                275.1715087890625,
                275.0836181640625
              ]
            },
            {
              "track_id": 285,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.20954281091690063,
              "bbox": [
                17.41349220275879,
                236.037841796875,
                71.4136962890625,
                281.8436279296875
              ]
            },
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7487442493438721,
              "bbox": [
                249.0355224609375,
                139.01051330566406,
                457.00384521484375,
                349.80230712890625
              ]
            },
            {
              "track_id": 288,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9276703000068665,
              "bbox": [
                449.58258056640625,
                18.748586654663086,
                570.4299926757812,
                356.92291259765625
              ]
            }
          ],
          "unique_tracks": [
            284,
            285,
            267,
            288
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            3906,
            3910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3911,
            3915
          ],
          "representative_frame": 3911,
          "detections": [
            {
              "track_id": 267,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.8555405139923096,
              "bbox": [
                271.65216064453125,
                156.54087829589844,
                482.4960632324219,
                354.4132995605469
              ]
            },
            {
              "track_id": 288,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9160124063491821,
              "bbox": [
                427.9867858886719,
                5.046103477478027,
                513.1635131835938,
                228.32669067382812
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.918298602104187,
              "bbox": [
                56.73206329345703,
                1.5559217929840088,
                273.4300231933594,
                303.5324401855469
              ]
            }
          ],
          "unique_tracks": [
            267,
            288,
            263
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            3916,
            3920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3921,
            3925
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 267,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.8324699401855469,
              "bbox": [
                276.4409484863281,
                162.8548583984375,
                495.48724365234375,
                355.8115234375
              ]
            },
            {
              "track_id": 288,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9224461317062378,
              "bbox": [
                419.4749755859375,
                0.5820472240447998,
                495.2762451171875,
                185.64678955078125
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9373006224632263,
              "bbox": [
                45.17530822753906,
                1.461925745010376,
                277.3657531738281,
                300.909423828125
              ]
            }
          ],
          "unique_tracks": [
            267,
            288,
            263
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            3926,
            3930
          ],
          "representative_frame": 3926,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 32
    },
    {
      "second": 131,
      "time_range": [
        131,
        131.999
      ],
      "frame_range": [
        3931,
        3960
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:41",
        "processing_time": 2.1,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3945,
          "frame_range": [
            3941,
            3945
          ],
          "description": "a man and a child are fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3931,
            3935
          ],
          "representative_frame": 3931,
          "detections": [
            {
              "track_id": 267,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.8232827186584473,
              "bbox": [
                274.5673828125,
                165.1013946533203,
                503.2452087402344,
                356.1445617675781
              ]
            },
            {
              "track_id": 288,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9196203947067261,
              "bbox": [
                415.79620361328125,
                0.0,
                494.6133728027344,
                178.73768615722656
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9396750330924988,
              "bbox": [
                39.43749237060547,
                1.3295612335205078,
                285.4447021484375,
                300.6626281738281
              ]
            }
          ],
          "unique_tracks": [
            267,
            288,
            263
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3936,
            3940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3941,
            3945
          ],
          "representative_frame": 3941,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8674430251121521,
              "bbox": [
                80.44036865234375,
                0.9506572484970093,
                364.0397033691406,
                336.21148681640625
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3946,
            3950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3951,
            3955
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.939605176448822,
              "bbox": [
                69.96310424804688,
                0.5726470351219177,
                369.99853515625,
                349.1933288574219
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3956,
            3960
          ],
          "representative_frame": 3956,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 32
    },
    {
      "second": 132,
      "time_range": [
        132,
        132.999
      ],
      "frame_range": [
        3961,
        3990
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:41",
        "processing_time": 2.12,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3975,
          "frame_range": [
            3971,
            3975
          ],
          "description": "a man in a raincoat is holding a blue bottle",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.37
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3961,
            3965
          ],
          "representative_frame": 3961,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9337807297706604,
              "bbox": [
                64.80403137207031,
                0.33668404817581177,
                377.8264465332031,
                354.381591796875
              ]
            },
            {
              "track_id": 291,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8572908639907837,
              "bbox": [
                502.07745361328125,
                129.78927612304688,
                527.3197021484375,
                225.9468994140625
              ]
            }
          ],
          "unique_tracks": [
            263,
            291
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3966,
            3970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3971,
            3975
          ],
          "representative_frame": 3971,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9329207539558411,
              "bbox": [
                164.6983184814453,
                13.946122169494629,
                437.4096984863281,
                336.1076965332031
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3976,
            3980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3981,
            3985
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9324756860733032,
              "bbox": [
                204.9334259033203,
                19.564817428588867,
                455.85772705078125,
                328.8355712890625
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3986,
            3990
          ],
          "representative_frame": 3986,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 33
    },
    {
      "second": 133,
      "time_range": [
        133,
        133.999
      ],
      "frame_range": [
        3991,
        4020
      ],
      "unified_description": "\n\nIn this scene, there is a man standing in the water, wearing an ankle bracelet. He has a fishing pole in his hand, and he appears to be catching fish. The camera is positioned overhead, recording the activity with some distortion, possibly due to wide-angle lens characteristics or camera movement. \n\nIn addition to the main subject, there are several other objects visible in the image, including a bottle near the man, as well as three backpacks located on the ground nearby. The presence of these backpacks suggests that this might be an outdoor adventure or camping trip.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:45",
        "processing_time": 4.28,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4005,
          "frame_range": [
            4001,
            4005
          ],
          "description": "a man standing in the water with a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3991,
            3995
          ],
          "representative_frame": 3991,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.908667266368866,
              "bbox": [
                217.3486785888672,
                27.62584114074707,
                444.37261962890625,
                325.6298522949219
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3996,
            4000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4001,
            4005
          ],
          "representative_frame": 4001,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9179757833480835,
              "bbox": [
                218.056640625,
                37.952327728271484,
                421.3387756347656,
                323.0021057128906
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4006,
            4010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4011,
            4015
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9123133420944214,
              "bbox": [
                215.9710693359375,
                44.40370559692383,
                401.2050476074219,
                319.0133056640625
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4016,
            4020
          ],
          "representative_frame": 4016,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 33
    },
    {
      "second": 134,
      "time_range": [
        134,
        134.999
      ],
      "frame_range": [
        4021,
        4050
      ],
      "unified_description": "3rd person perspective camera with a wide angle lens capturing the scene of a man standing in the water near a mountain lake.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:46",
        "processing_time": 3.11,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4035,
          "frame_range": [
            4031,
            4035
          ],
          "description": "a man standing in the water near a mountain lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.29
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4021,
            4025
          ],
          "representative_frame": 4021,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9170299172401428,
              "bbox": [
                218.5652618408203,
                46.494293212890625,
                389.0827331542969,
                312.0735168457031
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4026,
            4030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4031,
            4035
          ],
          "representative_frame": 4031,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.920879602432251,
              "bbox": [
                223.52597045898438,
                29.3050537109375,
                399.34173583984375,
                316.33538818359375
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4036,
            4040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4041,
            4045
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.923750638961792,
              "bbox": [
                226.94039916992188,
                23.44733238220215,
                400.3505859375,
                319.667236328125
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4046,
            4050
          ],
          "representative_frame": 4046,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 33
    },
    {
      "second": 135,
      "time_range": [
        135,
        135.999
      ],
      "frame_range": [
        4051,
        4080
      ],
      "unified_description": "\nIn this scene, there is one person who appears to be standing on a rock in some water. The camera perspective seems to be from the person's point of view, suggesting that it may be a first-person shoot. The image also contains various objects such as backpack and handbag floating around, giving some context to the environment. Since there are multiple objects detected, it could either be an outdoor adventure or possibly an indoor scene with objects scattered around.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:48",
        "processing_time": 5.11,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4065,
          "frame_range": [
            4061,
            4065
          ],
          "description": "a man standing on a rock in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.18
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4051,
            4055
          ],
          "representative_frame": 4051,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9267103672027588,
              "bbox": [
                226.40237426757812,
                19.5357723236084,
                398.72650146484375,
                326.63580322265625
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4056,
            4060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4061,
            4065
          ],
          "representative_frame": 4061,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9183721542358398,
              "bbox": [
                227.26560974121094,
                16.893590927124023,
                394.1890869140625,
                326.5847473144531
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4066,
            4070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4071,
            4075
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9281783103942871,
              "bbox": [
                214.2215576171875,
                13.999114990234375,
                379.33880615234375,
                328.68994140625
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4076,
            4080
          ],
          "representative_frame": 4076,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 33
    },
    {
      "second": 136,
      "time_range": [
        136,
        136.999
      ],
      "frame_range": [
        4081,
        4110
      ],
      "unified_description": "1-second scene with a man fishing in a lake. The camera perspective is first-person. The camera is stable and mounted on a backpack. The lens characteristics show signs of wide-angle distortion.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:49",
        "processing_time": 3.2,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4095,
          "frame_range": [
            4091,
            4095
          ],
          "description": "a man fishing in a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.71
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4081,
            4085
          ],
          "representative_frame": 4081,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9100279808044434,
              "bbox": [
                193.02056884765625,
                8.195027351379395,
                359.560791015625,
                326.27264404296875
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4086,
            4090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4091,
            4095
          ],
          "representative_frame": 4091,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9241730570793152,
              "bbox": [
                167.77928161621094,
                2.8041419982910156,
                339.109619140625,
                329.1983947753906
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4096,
            4100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4101,
            4105
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9349157214164734,
              "bbox": [
                135.9355926513672,
                0.46839049458503723,
                320.3051452636719,
                342.6177978515625
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4106,
            4110
          ],
          "representative_frame": 4106,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 34
    },
    {
      "second": 137,
      "time_range": [
        137,
        137.999
      ],
      "frame_range": [
        4111,
        4140
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:49",
        "processing_time": 2.15,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4125,
          "frame_range": [
            4121,
            4125
          ],
          "description": "a man is fishing in the water with a red fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.09
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4111,
            4115
          ],
          "representative_frame": 4111,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8914709687232971,
              "bbox": [
                99.37251281738281,
                0.0,
                295.49896240234375,
                349.327392578125
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4116,
            4120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4121,
            4125
          ],
          "representative_frame": 4121,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9278166890144348,
              "bbox": [
                87.39044189453125,
                0.0,
                297.0467529296875,
                354.9071960449219
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4126,
            4130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4131,
            4135
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9434413909912109,
              "bbox": [
                84.06859588623047,
                0.0,
                310.2976989746094,
                356.3312683105469
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4136,
            4140
          ],
          "representative_frame": 4136,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 34
    },
    {
      "second": 138,
      "time_range": [
        138,
        138.999
      ],
      "frame_range": [
        4141,
        4170
      ],
      "unified_description": "1-second scene featuring a man standing in water near a lake. Technical details include camera perspective, stability, lens characteristics, and overall production style.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:51",
        "processing_time": 2.66,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4155,
          "frame_range": [
            4151,
            4155
          ],
          "description": "a man is standing in the water near a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.07
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4141,
            4145
          ],
          "representative_frame": 4141,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9470335245132446,
              "bbox": [
                146.17330932617188,
                0.0,
                382.7840270996094,
                356.6968994140625
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4146,
            4150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4151,
            4155
          ],
          "representative_frame": 4151,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9456887245178223,
              "bbox": [
                200.81065368652344,
                0.0,
                442.5738220214844,
                357.7358093261719
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4156,
            4160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4161,
            4165
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8400540351867676,
              "bbox": [
                263.119873046875,
                0.0,
                521.5897827148438,
                356.15667724609375
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4166,
            4170
          ],
          "representative_frame": 4166,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 34
    },
    {
      "second": 139,
      "time_range": [
        139,
        139.999
      ],
      "frame_range": [
        4171,
        4200
      ],
      "unified_description": "54 seconds of footage showing people, landscape, and weather conditions.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:53",
        "processing_time": 2.34,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4185,
          "frame_range": [
            4181,
            4185
          ],
          "description": "a person in red raincoat fishing on a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.63
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4171,
            4175
          ],
          "representative_frame": 4171,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.789762556552887,
              "bbox": [
                340.4327087402344,
                0.0,
                598.962646484375,
                354.0995788574219
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4176,
            4180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4181,
            4185
          ],
          "representative_frame": 4181,
          "detections": [
            {
              "track_id": 298,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9412792325019836,
              "bbox": [
                40.61436462402344,
                56.351646423339844,
                139.0257110595703,
                356.2978820800781
              ]
            }
          ],
          "unique_tracks": [
            298
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4186,
            4190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4191,
            4195
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 298,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9292574524879456,
              "bbox": [
                27.29482650756836,
                114.67074584960938,
                107.82888793945312,
                357.0223693847656
              ]
            }
          ],
          "unique_tracks": [
            298
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4196,
            4200
          ],
          "representative_frame": 4196,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 34
    },
    {
      "second": 140,
      "time_range": [
        140,
        140.999
      ],
      "frame_range": [
        4201,
        4230
      ],
      "unified_description": "1-second scene where a man is standing on a boat casting a fishing line in a lake with some objects around him which include bottle, backpack, chair and a cell phone.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:54",
        "processing_time": 3.31,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4215,
          "frame_range": [
            4211,
            4215
          ],
          "description": "a man fishing on a lake with a small boat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.54
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4201,
            4205
          ],
          "representative_frame": 4201,
          "detections": [
            {
              "track_id": 298,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9196736216545105,
              "bbox": [
                30.97791862487793,
                134.1464385986328,
                106.95972442626953,
                357.1019592285156
              ]
            }
          ],
          "unique_tracks": [
            298
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4206,
            4210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4211,
            4215
          ],
          "representative_frame": 4211,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            4216,
            4220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4221,
            4225
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8865914344787598,
              "bbox": [
                332.1776123046875,
                59.939796447753906,
                437.73486328125,
                283.7725524902344
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4226,
            4230
          ],
          "representative_frame": 4226,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 35
    },
    {
      "second": 141,
      "time_range": [
        141,
        141.999
      ],
      "frame_range": [
        4231,
        4260
      ],
      "unified_description": "10-second scene with a young boy fishing on the shore of a lake at dawn. The scene includes the boy, his fishing pole, a nearby tree, and small details like a bird in the distance. The camera is positioned close to the boy's head, giving an immersive first-person perspective of the fishing experience.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:56",
        "processing_time": 3.46,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4245,
          "frame_range": [
            4241,
            4245
          ],
          "description": "a young boy fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.8
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4231,
            4235
          ],
          "representative_frame": 4231,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8770541548728943,
              "bbox": [
                347.6111145019531,
                62.19424057006836,
                448.5191650390625,
                276.0837097167969
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4236,
            4240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4241,
            4245
          ],
          "representative_frame": 4241,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8901546001434326,
              "bbox": [
                368.7629699707031,
                69.94515228271484,
                465.3848571777344,
                274.1275939941406
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4246,
            4250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4251,
            4255
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9063456654548645,
              "bbox": [
                386.151611328125,
                70.5520248413086,
                481.65362548828125,
                271.8453369140625
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4256,
            4260
          ],
          "representative_frame": 4256,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 35
    },
    {
      "second": 142,
      "time_range": [
        142,
        142.999
      ],
      "frame_range": [
        4261,
        4290
      ],
      "unified_description": "1-second scene featuring a young child holding a fishing pole near a body of water. The video is slightly shaky, indicating it may have been taken with a handheld camera or from a moving perspective.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:57",
        "processing_time": 3.15,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4275,
          "frame_range": [
            4271,
            4275
          ],
          "description": "a little boy fishing on the river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.88
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4261,
            4265
          ],
          "representative_frame": 4261,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9420864582061768,
              "bbox": [
                395.2187194824219,
                67.64002227783203,
                490.9107666015625,
                265.77880859375
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4266,
            4270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4271,
            4275
          ],
          "representative_frame": 4271,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.922636866569519,
              "bbox": [
                409.1127624511719,
                62.831642150878906,
                508.4542236328125,
                265.3794250488281
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4276,
            4280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4281,
            4285
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9300698637962341,
              "bbox": [
                422.143798828125,
                57.88496780395508,
                523.9860229492188,
                263.1670837402344
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4286,
            4290
          ],
          "representative_frame": 4286,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 35
    },
    {
      "second": 143,
      "time_range": [
        143,
        143.999
      ],
      "frame_range": [
        4291,
        4320
      ],
      "unified_description": "3D camera perspective with image stabilization. The camera is mounted on a person's head who is wearing a red jacket. The camera captures a scene taking place near a lake where another man stands with a fishing rod in hand. The background is blurred, making the main subject in focus.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:58",
        "processing_time": 3.57,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4305,
          "frame_range": [
            4301,
            4305
          ],
          "description": "a man in red jacket fishing on a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4291,
            4295
          ],
          "representative_frame": 4291,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9064003229141235,
              "bbox": [
                439.2178649902344,
                51.250064849853516,
                540.202392578125,
                255.2964324951172
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4296,
            4300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4301,
            4305
          ],
          "representative_frame": 4301,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9156732559204102,
              "bbox": [
                451.9591064453125,
                40.789302825927734,
                554.9269409179688,
                249.174072265625
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4306,
            4310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4311,
            4315
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8982585072517395,
              "bbox": [
                470.8917236328125,
                32.275699615478516,
                573.7933959960938,
                244.32228088378906
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4316,
            4320
          ],
          "representative_frame": 4316,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 35
    },
    {
      "second": 144,
      "time_range": [
        144,
        144.999
      ],
      "frame_range": [
        4321,
        4350
      ],
      "unified_description": "1 second video of outdoors scene with a man in red fishing. The camera is mounted on a body harness.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:15:59",
        "processing_time": 2.61,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4335,
          "frame_range": [
            4331,
            4335
          ],
          "description": "a man in red jacket fishing on a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.97
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4321,
            4325
          ],
          "representative_frame": 4321,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9221512675285339,
              "bbox": [
                473.6224670410156,
                23.9945011138916,
                572.72314453125,
                230.83682250976562
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4326,
            4330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4331,
            4335
          ],
          "representative_frame": 4331,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8714593648910522,
              "bbox": [
                463.9439697265625,
                11.809684753417969,
                560.5751953125,
                216.76451110839844
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4336,
            4340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4341,
            4345
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            4346,
            4350
          ],
          "representative_frame": 4346,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 36
    },
    {
      "second": 145,
      "time_range": [
        145,
        145.999
      ],
      "frame_range": [
        4351,
        4380
      ],
      "unified_description": "1-second scene including a man fishing in the water with a small fish, shot using camera perspective, field of view, lens characteristics, and video production style",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:01",
        "processing_time": 2.7,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4365,
          "frame_range": [
            4361,
            4365
          ],
          "description": "a man is fishing in the water with a small fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.13
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4351,
            4355
          ],
          "representative_frame": 4351,
          "detections": [
            {
              "track_id": 303,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.888228714466095,
              "bbox": [
                429.3377990722656,
                0.0,
                501.9226379394531,
                187.99301147460938
              ]
            }
          ],
          "unique_tracks": [
            303
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4356,
            4360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4361,
            4365
          ],
          "representative_frame": 4361,
          "detections": [
            {
              "track_id": 303,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9133565425872803,
              "bbox": [
                427.6697692871094,
                0.10157407075166702,
                495.0918884277344,
                174.6377410888672
              ]
            }
          ],
          "unique_tracks": [
            303
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4366,
            4370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4371,
            4375
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 303,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8918793797492981,
              "bbox": [
                422.38232421875,
                0.459198921918869,
                484.2999572753906,
                159.8180389404297
              ]
            },
            {
              "track_id": 306,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7163785696029663,
              "bbox": [
                393.25335693359375,
                151.18846130371094,
                640.0,
                313.19024658203125
              ]
            }
          ],
          "unique_tracks": [
            303,
            306
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4376,
            4380
          ],
          "representative_frame": 4376,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 36
    },
    {
      "second": 146,
      "time_range": [
        146,
        146.999
      ],
      "frame_range": [
        4381,
        4410
      ],
      "unified_description": "\nThe image depicts a calm outdoor scene with no signs of people or significant activity. The primary focus is on the small black dog walking near the center of the frame. The camera's perspective and positioning, as well as its movement and stability, suggest that it may be mounted on a backpack or tripod for a more stable view while capturing the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:03",
        "processing_time": 3.64,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4395,
          "frame_range": [
            4391,
            4395
          ],
          "description": "a small black dog is walking on the ground",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4381,
            4385
          ],
          "representative_frame": 4381,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            4386,
            4390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4391,
            4395
          ],
          "representative_frame": 4391,
          "detections": [
            {
              "track_id": 307,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.48331955075263977,
              "bbox": [
                304.3439025878906,
                324.91131591796875,
                368.4895935058594,
                359.0875549316406
              ]
            }
          ],
          "unique_tracks": [
            307
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4396,
            4400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4401,
            4405
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 307,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.20916417241096497,
              "bbox": [
                316.1864929199219,
                325.103271484375,
                380.3106689453125,
                359.1342468261719
              ]
            }
          ],
          "unique_tracks": [
            307
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4406,
            4410
          ],
          "representative_frame": 4406,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 36
    },
    {
      "second": 147,
      "time_range": [
        147,
        147.999
      ],
      "frame_range": [
        4411,
        4440
      ],
      "unified_description": "30 seconds of video with a dog in view.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:03",
        "processing_time": 3.16,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4425,
          "frame_range": [
            4421,
            4425
          ],
          "description": "a small dog is walking on the ground",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.62
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4411,
            4415
          ],
          "representative_frame": 4411,
          "detections": [
            {
              "track_id": 307,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46176329255104065,
              "bbox": [
                316.5909423828125,
                318.5804138183594,
                393.49078369140625,
                359.3419494628906
              ]
            }
          ],
          "unique_tracks": [
            307
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4416,
            4420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4421,
            4425
          ],
          "representative_frame": 4421,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            4426,
            4430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4431,
            4435
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            4436,
            4440
          ],
          "representative_frame": 4436,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 36
    },
    {
      "second": 148,
      "time_range": [
        148,
        148.999
      ],
      "frame_range": [
        4441,
        4470
      ],
      "unified_description": "365 words, 24 images",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:04",
        "processing_time": 2.32,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4455,
          "frame_range": [
            4451,
            4455
          ],
          "description": "a bird is standing on the ground near a road",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.13
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4441,
            4445
          ],
          "representative_frame": 4441,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            4446,
            4450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4451,
            4455
          ],
          "representative_frame": 4451,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            4456,
            4460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4461,
            4465
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            4466,
            4470
          ],
          "representative_frame": 4466,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 37
    },
    {
      "second": 149,
      "time_range": [
        149,
        149.999
      ],
      "frame_range": [
        4471,
        4500
      ],
      "unified_description": "30-second video with various scenes, including a person holding a bottle",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:07",
        "processing_time": 2.36,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4485,
          "frame_range": [
            4481,
            4485
          ],
          "description": "a person is holding a bottle in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.52
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4471,
            4475
          ],
          "representative_frame": 4471,
          "detections": [
            {
              "track_id": 311,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4566049873828888,
              "bbox": [
                312.5059814453125,
                280.42181396484375,
                481.5094299316406,
                357.58551025390625
              ]
            }
          ],
          "unique_tracks": [
            311
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4476,
            4480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4481,
            4485
          ],
          "representative_frame": 4481,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            4486,
            4490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4491,
            4495
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 10,
              "class_name": "fire hydrant",
              "confidence": 0.8182810544967651,
              "bbox": [
                162.6947479248047,
                129.90281677246094,
                340.6569519042969,
                327.3556213378906
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4496,
            4500
          ],
          "representative_frame": 4496,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 37
    },
    {
      "second": 150,
      "time_range": [
        150,
        150.999
      ],
      "frame_range": [
        4501,
        4530
      ],
      "unified_description": "3D model of a little boy at the shore of a river, captured with a shaky camera",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:07",
        "processing_time": 2.6,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4515,
          "frame_range": [
            4511,
            4515
          ],
          "description": "a little boy is standing on the shore of a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.75
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4501,
            4505
          ],
          "representative_frame": 4501,
          "detections": [
            {
              "track_id": 312,
              "class_id": 10,
              "class_name": "fire hydrant",
              "confidence": 0.6393530964851379,
              "bbox": [
                175.61376953125,
                144.9830780029297,
                343.1524353027344,
                330.3402099609375
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4506,
            4510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4511,
            4515
          ],
          "representative_frame": 4511,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8926174640655518,
              "bbox": [
                148.91851806640625,
                92.37730407714844,
                335.39251708984375,
                299.8992919921875
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4516,
            4520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4521,
            4525
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9296920895576477,
              "bbox": [
                118.90109252929688,
                19.640031814575195,
                367.3115234375,
                299.5069274902344
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4526,
            4530
          ],
          "representative_frame": 4526,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 37
    },
    {
      "second": 151,
      "time_range": [
        151,
        151.999
      ],
      "frame_range": [
        4531,
        4560
      ],
      "unified_description": "\n\nIn the image, there is a man wearing a red jacket who is fishing in a river. The camera is positioned above and slightly behind him, capturing his activity from a bird's eye perspective. The scene takes place outdoors, with the surrounding area visible in the frame. In addition to the man and the river, various other objects are also captured in the image, contributing to a lively and engaging visual experience.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:09",
        "processing_time": 4.45,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4545,
          "frame_range": [
            4541,
            4545
          ],
          "description": "a man in a red jacket is fishing",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.9
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4531,
            4535
          ],
          "representative_frame": 4531,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9392074346542358,
              "bbox": [
                53.853755950927734,
                0.0,
                336.7944030761719,
                312.21881103515625
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4536,
            4540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4541,
            4545
          ],
          "representative_frame": 4541,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8808006644248962,
              "bbox": [
                26.68848991394043,
                0.0,
                318.3622131347656,
                311.60400390625
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4546,
            4550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4551,
            4555
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8737634420394897,
              "bbox": [
                8.837708473205566,
                0.0,
                300.14349365234375,
                307.7331848144531
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4556,
            4560
          ],
          "representative_frame": 4556,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 37
    },
    {
      "second": 152,
      "time_range": [
        152,
        152.999
      ],
      "frame_range": [
        4561,
        4590
      ],
      "unified_description": "3D scene with a person in an orange jacket holding a fishing rod. The camera is positioned overhead, providing a wide-angle view of the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:11",
        "processing_time": 2.68,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4575,
          "frame_range": [
            4571,
            4575
          ],
          "description": "a man in an orange jacket is holding a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.33
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4561,
            4565
          ],
          "representative_frame": 4561,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8596010208129883,
              "bbox": [
                9.271576881408691,
                0.0,
                318.08966064453125,
                326.9610900878906
              ]
            },
            {
              "track_id": 315,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.6094241142272949,
              "bbox": [
                542.5086669921875,
                218.04832458496094,
                640.0,
                354.0495910644531
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4566,
            4570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4571,
            4575
          ],
          "representative_frame": 4571,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8875506520271301,
              "bbox": [
                0.7186834812164307,
                0.0,
                324.70697021484375,
                343.907958984375
              ]
            },
            {
              "track_id": 315,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5661569833755493,
              "bbox": [
                533.8858642578125,
                200.3057098388672,
                640.0,
                356.5206298828125
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4576,
            4580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4581,
            4585
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4095940887928009,
              "bbox": [
                2.913428544998169,
                0.0,
                302.15789794921875,
                314.900390625
              ]
            },
            {
              "track_id": 315,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.24045465886592865,
              "bbox": [
                525.4176635742188,
                184.27902221679688,
                640.0,
                357.0458984375
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4586,
            4590
          ],
          "representative_frame": 4586,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 38
    },
    {
      "second": 153,
      "time_range": [
        153,
        153.999
      ],
      "frame_range": [
        4591,
        4620
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:11",
        "processing_time": 2.11,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4605,
          "frame_range": [
            4601,
            4605
          ],
          "description": "a man in a red jacket is holding a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.42
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4591,
            4595
          ],
          "representative_frame": 4591,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4125855267047882,
              "bbox": [
                3.227276086807251,
                0.0,
                278.6756896972656,
                288.9560241699219
              ]
            },
            {
              "track_id": 315,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8111610412597656,
              "bbox": [
                514.6787109375,
                171.1211700439453,
                640.0,
                357.6986999511719
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4596,
            4600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4601,
            4605
          ],
          "representative_frame": 4601,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4477510154247284,
              "bbox": [
                0.0,
                0.0,
                271.5699462890625,
                288.28460693359375
              ]
            },
            {
              "track_id": 315,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8857772350311279,
              "bbox": [
                504.56268310546875,
                159.02261352539062,
                640.0,
                358.1815490722656
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4606,
            4610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4611,
            4615
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.845524787902832,
              "bbox": [
                0.0,
                2.69170880317688,
                276.5010070800781,
                320.63623046875
              ]
            },
            {
              "track_id": 315,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8893605470657349,
              "bbox": [
                497.12164306640625,
                150.48220825195312,
                640.0,
                357.8010559082031
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4616,
            4620
          ],
          "representative_frame": 4616,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 38
    },
    {
      "second": 154,
      "time_range": [
        154,
        154.999
      ],
      "frame_range": [
        4621,
        4650
      ],
      "unified_description": "3D camera positioning, wide-angle lens, stable camera position, action camera mounting, etc.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:13",
        "processing_time": 2.46,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4635,
          "frame_range": [
            4631,
            4635
          ],
          "description": "a man in a red jacket is fishing",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.68
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4621,
            4625
          ],
          "representative_frame": 4621,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9203968048095703,
              "bbox": [
                0.0,
                23.293014526367188,
                280.9141540527344,
                343.24249267578125
              ]
            },
            {
              "track_id": 315,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.7662994265556335,
              "bbox": [
                493.13824462890625,
                146.63710021972656,
                640.0,
                358.2980041503906
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4626,
            4630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4631,
            4635
          ],
          "representative_frame": 4631,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9379542469978333,
              "bbox": [
                0.0,
                6.06247615814209,
                267.03900146484375,
                352.3517150878906
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4636,
            4640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4641,
            4645
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8760069012641907,
              "bbox": [
                0.0,
                0.0,
                246.08058166503906,
                355.167724609375
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4646,
            4650
          ],
          "representative_frame": 4646,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 38
    },
    {
      "second": 155,
      "time_range": [
        155,
        155.999
      ],
      "frame_range": [
        4651,
        4680
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:14",
        "processing_time": 2.09,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4665,
          "frame_range": [
            4661,
            4665
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.04
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4651,
            4655
          ],
          "representative_frame": 4651,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            4656,
            4660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4661,
            4665
          ],
          "representative_frame": 4661,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5789675116539001,
              "bbox": [
                288.51666259765625,
                2.0318970680236816,
                640.0,
                297.2168273925781
              ]
            },
            {
              "track_id": 320,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8168693780899048,
              "bbox": [
                511.926513671875,
                6.2679290771484375,
                640.0,
                141.49156188964844
              ]
            }
          ],
          "unique_tracks": [
            319,
            320
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4666,
            4670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4671,
            4675
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.42330893874168396,
              "bbox": [
                319.08740234375,
                0.5110228657722473,
                640.0,
                271.5677795410156
              ]
            },
            {
              "track_id": 320,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7936788201332092,
              "bbox": [
                513.8333129882812,
                1.901511549949646,
                640.0,
                139.65174865722656
              ]
            }
          ],
          "unique_tracks": [
            319,
            320
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4676,
            4680
          ],
          "representative_frame": 4676,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 38
    },
    {
      "second": 156,
      "time_range": [
        156,
        156.999
      ],
      "frame_range": [
        4681,
        4710
      ],
      "unified_description": "\nPlease provide angled view, as well as straight-on views, to give a complete understanding of the scene being captured in the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:15",
        "processing_time": 2.83,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4695,
          "frame_range": [
            4691,
            4695
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4681,
            4685
          ],
          "representative_frame": 4681,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7909078001976013,
              "bbox": [
                318.03607177734375,
                0.5182351469993591,
                640.0,
                301.025634765625
              ]
            },
            {
              "track_id": 320,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7306848168373108,
              "bbox": [
                521.615478515625,
                8.604674339294434,
                640.0,
                149.17550659179688
              ]
            }
          ],
          "unique_tracks": [
            319,
            320
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4686,
            4690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4691,
            4695
          ],
          "representative_frame": 4691,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6605784893035889,
              "bbox": [
                327.0694580078125,
                14.075570106506348,
                640.0,
                309.19891357421875
              ]
            },
            {
              "track_id": 320,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7220056056976318,
              "bbox": [
                525.4408569335938,
                24.755014419555664,
                640.0,
                163.06346130371094
              ]
            }
          ],
          "unique_tracks": [
            319,
            320
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4696,
            4700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4701,
            4705
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 320,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8223918080329895,
              "bbox": [
                528.3626708984375,
                41.40770721435547,
                640.0,
                171.1859893798828
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8913098573684692,
              "bbox": [
                0.0,
                0.0,
                190.69566345214844,
                353.6866455078125
              ]
            }
          ],
          "unique_tracks": [
            320,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4706,
            4710
          ],
          "representative_frame": 4706,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 39
    },
    {
      "second": 157,
      "time_range": [
        157,
        157.999
      ],
      "frame_range": [
        4711,
        4740
      ],
      "unified_description": "\n\nThe image depicts a young boy holding a fish while standing on a rock. The scene is set outdoors with several other objects present in the background. There are three more people in various locations throughout the scene, possibly indicating an event or gathering. A backpack can be seen placed nearby, suggesting that it might belong to one of the individuals in the area.\n\nThe camera perspective appears to be a POV (first-person) view, capturing the scene from the boy's point of view as he holds the fish. The camera is stable, and there are no signs of motion blur or other technical artifacts. Overall, the image portrays a moment of outdoor adventure and camaraderie among the people present.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:18",
        "processing_time": 4.82,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4725,
          "frame_range": [
            4721,
            4725
          ],
          "description": "a young boy holding a fish while standing on a rock",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4711,
            4715
          ],
          "representative_frame": 4711,
          "detections": [
            {
              "track_id": 320,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3923282027244568,
              "bbox": [
                540.8836059570312,
                49.5606689453125,
                640.0,
                170.89797973632812
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8478654623031616,
              "bbox": [
                0.0,
                0.638555109500885,
                189.28416442871094,
                353.5643615722656
              ]
            },
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5474868416786194,
              "bbox": [
                340.67950439453125,
                38.697696685791016,
                640.0,
                331.22998046875
              ]
            }
          ],
          "unique_tracks": [
            320,
            312,
            319
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            4716,
            4720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4721,
            4725
          ],
          "representative_frame": 4721,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8460029363632202,
              "bbox": [
                0.0,
                7.5406107902526855,
                184.90223693847656,
                353.4988708496094
              ]
            },
            {
              "track_id": 315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.554185152053833,
              "bbox": [
                441.028564453125,
                57.15785217285156,
                640.0,
                329.4996643066406
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4726,
            4730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4731,
            4735
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7803180813789368,
              "bbox": [
                0.0,
                36.866668701171875,
                180.2200469970703,
                353.7883605957031
              ]
            },
            {
              "track_id": 315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8045141100883484,
              "bbox": [
                449.4284362792969,
                60.03998565673828,
                640.0,
                327.4786376953125
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4736,
            4740
          ],
          "representative_frame": 4736,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 39
    },
    {
      "second": 158,
      "time_range": [
        158,
        158.999
      ],
      "frame_range": [
        4741,
        4770
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:18",
        "processing_time": 3.62,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4755,
          "frame_range": [
            4751,
            4755
          ],
          "description": "a young boy is holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.93
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4741,
            4745
          ],
          "representative_frame": 4741,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7623041272163391,
              "bbox": [
                0.0,
                52.41299057006836,
                205.73416137695312,
                354.4271545410156
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4746,
            4750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4751,
            4755
          ],
          "representative_frame": 4751,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8516412973403931,
              "bbox": [
                29.00789451599121,
                52.52294158935547,
                245.29440307617188,
                354.2013854980469
              ]
            },
            {
              "track_id": 315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.36167076230049133,
              "bbox": [
                467.0254211425781,
                83.80436706542969,
                640.0,
                341.599609375
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4756,
            4760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4761,
            4765
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9273594617843628,
              "bbox": [
                75.641357421875,
                46.90336608886719,
                306.292724609375,
                354.6307373046875
              ]
            },
            {
              "track_id": 315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.14855177700519562,
              "bbox": [
                481.7049560546875,
                94.2965087890625,
                640.0,
                329.0397644042969
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4766,
            4770
          ],
          "representative_frame": 4766,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 39
    },
    {
      "second": 159,
      "time_range": [
        159,
        159.999
      ],
      "frame_range": [
        4771,
        4800
      ],
      "unified_description": "30 second camera mounted on a backpack recording video.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:19",
        "processing_time": 3.05,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4785,
          "frame_range": [
            4781,
            4785
          ],
          "description": "a young boy holding a fish while another looks on",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.9
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4771,
            4775
          ],
          "representative_frame": 4771,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9345875978469849,
              "bbox": [
                119.10761260986328,
                42.464454650878906,
                368.2901916503906,
                354.8338928222656
              ]
            },
            {
              "track_id": 315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5594966411590576,
              "bbox": [
                470.98187255859375,
                108.97759246826172,
                638.2896118164062,
                346.2293395996094
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4776,
            4780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4781,
            4785
          ],
          "representative_frame": 4781,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8848044276237488,
              "bbox": [
                148.10595703125,
                32.628150939941406,
                429.2641296386719,
                355.0283508300781
              ]
            },
            {
              "track_id": 315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.18933901190757751,
              "bbox": [
                478.75531005859375,
                117.14830780029297,
                640.0,
                352.09423828125
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4786,
            4790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4791,
            4795
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.930401086807251,
              "bbox": [
                125.04756927490234,
                24.316307067871094,
                435.3075866699219,
                354.9537658691406
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4796,
            4800
          ],
          "representative_frame": 4796,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 39
    },
    {
      "second": 160,
      "time_range": [
        160,
        160.999
      ],
      "frame_range": [
        4801,
        4830
      ],
      "unified_description": "3D model, Blender, Unity, OpenGL, Direct3D, Mesh, Camera movement",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:23",
        "processing_time": 2.49,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4815,
          "frame_range": [
            4811,
            4815
          ],
          "description": "a young boy is holding a fish in his hands",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.21
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4801,
            4805
          ],
          "representative_frame": 4801,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8786701560020447,
              "bbox": [
                87.52788543701172,
                41.314064025878906,
                387.44476318359375,
                353.9051513671875
              ]
            },
            {
              "track_id": 315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8437597751617432,
              "bbox": [
                500.96099853515625,
                151.8039093017578,
                616.6842041015625,
                303.8447265625
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4806,
            4810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4811,
            4815
          ],
          "representative_frame": 4811,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9509128332138062,
              "bbox": [
                32.877803802490234,
                13.946446418762207,
                358.93505859375,
                353.8651428222656
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4816,
            4820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4821,
            4825
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9328352808952332,
              "bbox": [
                42.78407287597656,
                88.74918365478516,
                310.2909240722656,
                354.2375793457031
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4826,
            4830
          ],
          "representative_frame": 4826,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 40
    },
    {
      "second": 161,
      "time_range": [
        161,
        161.999
      ],
      "frame_range": [
        4831,
        4860
      ],
      "unified_description": "1-second scene including a man standing on a rock in the woods",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:23",
        "processing_time": 2.83,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4845,
          "frame_range": [
            4841,
            4845
          ],
          "description": "a man is standing on a rock in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.22
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4831,
            4835
          ],
          "representative_frame": 4831,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            4836,
            4840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4841,
            4845
          ],
          "representative_frame": 4841,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            4846,
            4850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4851,
            4855
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 330,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8933636546134949,
              "bbox": [
                13.843061447143555,
                182.64483642578125,
                92.2089614868164,
                356.5507507324219
              ]
            }
          ],
          "unique_tracks": [
            330
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4856,
            4860
          ],
          "representative_frame": 4856,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 40
    },
    {
      "second": 162,
      "time_range": [
        162,
        162.999
      ],
      "frame_range": [
        4861,
        4890
      ],
      "unified_description": "1-second scene showing a young child playing with a toy in an outdoor setting. The camera's perspective is from the boy's point of view, capturing the action and surrounding environment.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:25",
        "processing_time": 3.78,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4875,
          "frame_range": [
            4871,
            4875
          ],
          "description": "a little boy in a red shirt is playing with a toy",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.08
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4861,
            4865
          ],
          "representative_frame": 4861,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8993358016014099,
              "bbox": [
                317.6246032714844,
                113.3757095336914,
                600.8434448242188,
                355.1620788574219
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4866,
            4870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4871,
            4875
          ],
          "representative_frame": 4871,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.926656186580658,
              "bbox": [
                390.1656494140625,
                173.73268127441406,
                612.6911010742188,
                357.1202697753906
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4876,
            4880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4881,
            4885
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7860571146011353,
              "bbox": [
                416.59765625,
                170.09521484375,
                640.0,
                357.60650634765625
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4886,
            4890
          ],
          "representative_frame": 4886,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 40
    },
    {
      "second": 163,
      "time_range": [
        163,
        163.999
      ],
      "frame_range": [
        4891,
        4920
      ],
      "unified_description": "20 minutes of battery life, 4k resolution, HDR, GPS enabled, accelerometer, gyroscope, barometer",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:28",
        "processing_time": 2.58,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4905,
          "frame_range": [
            4901,
            4905
          ],
          "description": "a man in a red jacket is standing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.51
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4891,
            4895
          ],
          "representative_frame": 4891,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4740697741508484,
              "bbox": [
                418.6505126953125,
                161.9189453125,
                640.0,
                357.6028747558594
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4896,
            4900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4901,
            4905
          ],
          "representative_frame": 4901,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9276478290557861,
              "bbox": [
                348.17193603515625,
                156.23338317871094,
                578.1008911132812,
                356.4931640625
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4906,
            4910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4911,
            4915
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9232717752456665,
              "bbox": [
                247.22555541992188,
                123.41206359863281,
                506.7452697753906,
                355.3744201660156
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4916,
            4920
          ],
          "representative_frame": 4916,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 40
    },
    {
      "second": 164,
      "time_range": [
        164,
        164.999
      ],
      "frame_range": [
        4921,
        4950
      ],
      "unified_description": "1-second scene featuring a little boy playing with a toy on the beach - content descriptions and object detections summary based on image descriptions provided.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:29",
        "processing_time": 3.23,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4935,
          "frame_range": [
            4931,
            4935
          ],
          "description": "a little boy is playing with a toy on the beach",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.3
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4921,
            4925
          ],
          "representative_frame": 4921,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9115676879882812,
              "bbox": [
                176.22927856445312,
                117.66719055175781,
                431.97308349609375,
                351.73260498046875
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4926,
            4930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4931,
            4935
          ],
          "representative_frame": 4931,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8882397413253784,
              "bbox": [
                75.6298828125,
                113.19013977050781,
                311.860595703125,
                352.6136474609375
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4936,
            4940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4941,
            4945
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9151659607887268,
              "bbox": [
                141.01414489746094,
                85.99337005615234,
                373.5735168457031,
                308.9243469238281
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4946,
            4950
          ],
          "representative_frame": 4946,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 41
    },
    {
      "second": 165,
      "time_range": [
        165,
        165.999
      ],
      "frame_range": [
        4951,
        4980
      ],
      "unified_description": "\n\nFirst-person view of someone walking around inside. The camera perspective is from the person's point of view, resulting in a subjective experience for the viewer. The field of view is relatively narrow compared to a wide-angle lens, focusing on the baby in the red suit and the toy he is playing with. No technical artifacts are visible in this image description.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:31",
        "processing_time": 5.0,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4965,
          "frame_range": [
            4961,
            4965
          ],
          "description": "a baby in a red suit is playing with a toy",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.45
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4951,
            4955
          ],
          "representative_frame": 4951,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8829693794250488,
              "bbox": [
                435.6434326171875,
                180.76531982421875,
                528.2238159179688,
                310.7308349609375
              ]
            },
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.924800455570221,
              "bbox": [
                134.8405303955078,
                78.82254028320312,
                355.6300354003906,
                299.3954162597656
              ]
            }
          ],
          "unique_tracks": [
            335,
            319
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4956,
            4960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4961,
            4965
          ],
          "representative_frame": 4961,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8925555944442749,
              "bbox": [
                430.519287109375,
                181.3338623046875,
                523.4252319335938,
                311.756591796875
              ]
            },
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9183207154273987,
              "bbox": [
                131.64703369140625,
                80.56382751464844,
                341.24676513671875,
                297.6235656738281
              ]
            }
          ],
          "unique_tracks": [
            335,
            319
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4966,
            4970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4971,
            4975
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.9105227589607239,
              "bbox": [
                436.6992492675781,
                185.24034118652344,
                527.5872192382812,
                312.9039611816406
              ]
            },
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8298460841178894,
              "bbox": [
                127.16133880615234,
                81.89787292480469,
                327.02349853515625,
                296.4176025390625
              ]
            }
          ],
          "unique_tracks": [
            335,
            319
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4976,
            4980
          ],
          "representative_frame": 4976,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 41
    },
    {
      "second": 166,
      "time_range": [
        166,
        166.999
      ],
      "frame_range": [
        4981,
        5010
      ],
      "unified_description": "1-second scene - A young boy in a red suit is playing with a toy.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:32",
        "processing_time": 2.4,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4995,
          "frame_range": [
            4991,
            4995
          ],
          "description": "a young boy in a red suit is playing with a toy",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.78
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4981,
            4985
          ],
          "representative_frame": 4981,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.9075855612754822,
              "bbox": [
                448.1309509277344,
                186.8720245361328,
                538.5866088867188,
                314.1083679199219
              ]
            },
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9188287854194641,
              "bbox": [
                132.6003875732422,
                81.3159408569336,
                328.706298828125,
                299.1451721191406
              ]
            }
          ],
          "unique_tracks": [
            335,
            319
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4986,
            4990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4991,
            4995
          ],
          "representative_frame": 4991,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.9106636047363281,
              "bbox": [
                455.83270263671875,
                192.37265014648438,
                550.42138671875,
                325.9068298339844
              ]
            },
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7848377227783203,
              "bbox": [
                139.80616760253906,
                83.08729553222656,
                341.3787841796875,
                310.60162353515625
              ]
            }
          ],
          "unique_tracks": [
            335,
            319
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4996,
            5000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5001,
            5005
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8312718868255615,
              "bbox": [
                469.3564147949219,
                203.64768981933594,
                569.7420654296875,
                345.985595703125
              ]
            },
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9223653078079224,
              "bbox": [
                132.14584350585938,
                93.05060577392578,
                339.2665100097656,
                333.21124267578125
              ]
            }
          ],
          "unique_tracks": [
            335,
            319
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5006,
            5010
          ],
          "representative_frame": 5006,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 41
    },
    {
      "second": 167,
      "time_range": [
        167,
        167.999
      ],
      "frame_range": [
        5011,
        5040
      ],
      "unified_description": "\nFor example: The scene takes place at an outdoor pool where a child is playing with a toy in the water. The camera capturing this moment has a wide-angle lens which results in some distortion around the edges of the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:34",
        "processing_time": 2.97,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5025,
          "frame_range": [
            5021,
            5025
          ],
          "description": "a little boy is playing with a toy in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.86
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5011,
            5015
          ],
          "representative_frame": 5011,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8835859894752502,
              "bbox": [
                482.97772216796875,
                214.30621337890625,
                583.4566650390625,
                357.07745361328125
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9204436540603638,
              "bbox": [
                122.48300170898438,
                117.99468994140625,
                346.93133544921875,
                358.1656188964844
              ]
            }
          ],
          "unique_tracks": [
            335,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5016,
            5020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5021,
            5025
          ],
          "representative_frame": 5021,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8357574939727783,
              "bbox": [
                485.26739501953125,
                218.7717742919922,
                584.9319458007812,
                360.0
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9141672253608704,
              "bbox": [
                133.8037109375,
                128.09814453125,
                344.93255615234375,
                357.23199462890625
              ]
            }
          ],
          "unique_tracks": [
            335,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5026,
            5030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5031,
            5035
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8614785075187683,
              "bbox": [
                476.5721740722656,
                213.8830108642578,
                576.9844970703125,
                358.6987609863281
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8965955376625061,
              "bbox": [
                149.1288299560547,
                151.8852081298828,
                339.7721862792969,
                357.2054138183594
              ]
            }
          ],
          "unique_tracks": [
            335,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5036,
            5040
          ],
          "representative_frame": 5036,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 41
    },
    {
      "second": 168,
      "time_range": [
        168,
        168.999
      ],
      "frame_range": [
        5041,
        5070
      ],
      "unified_description": "1-second scene that includes a boy fishing in red, various objects, people, actions and location details",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:34",
        "processing_time": 2.71,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5055,
          "frame_range": [
            5051,
            5055
          ],
          "description": "a young boy in a red jacket is fishing",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.67
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5041,
            5045
          ],
          "representative_frame": 5041,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.7737190127372742,
              "bbox": [
                471.0116882324219,
                203.15936279296875,
                568.8346557617188,
                346.686279296875
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9256290793418884,
              "bbox": [
                157.49844360351562,
                113.62548065185547,
                384.79815673828125,
                356.7939758300781
              ]
            }
          ],
          "unique_tracks": [
            335,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5046,
            5050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5051,
            5055
          ],
          "representative_frame": 5051,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            5056,
            5060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5061,
            5065
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8867955803871155,
              "bbox": [
                70.53390502929688,
                28.54171371459961,
                253.83871459960938,
                254.57766723632812
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9018373489379883,
              "bbox": [
                137.0054931640625,
                44.36376953125,
                355.6602478027344,
                298.191650390625
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5066,
            5070
          ],
          "representative_frame": 5066,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 42
    },
    {
      "second": 169,
      "time_range": [
        169,
        169.999
      ],
      "frame_range": [
        5071,
        5100
      ],
      "unified_description": "1-second scene - A man and a child fishing near a lake at dusk with a GoPro camera mounted on a backpack capturing the action.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:36",
        "processing_time": 3.0,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5085,
          "frame_range": [
            5081,
            5085
          ],
          "description": "a man and a child fishing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.7
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5071,
            5075
          ],
          "representative_frame": 5071,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9034910202026367,
              "bbox": [
                37.63624954223633,
                10.100027084350586,
                235.33694458007812,
                268.8561706542969
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.874995768070221,
              "bbox": [
                120.30886840820312,
                31.610645294189453,
                336.44122314453125,
                299.093505859375
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5076,
            5080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5081,
            5085
          ],
          "representative_frame": 5081,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.92645663022995,
              "bbox": [
                0.8910603523254395,
                6.002739906311035,
                212.18359375,
                296.8083190917969
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9058399796485901,
              "bbox": [
                108.40957641601562,
                37.8989372253418,
                320.3951110839844,
                314.0813903808594
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5086,
            5090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5091,
            5095
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9364771246910095,
              "bbox": [
                0.0,
                0.0,
                194.2222137451172,
                329.4370422363281
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.905439019203186,
              "bbox": [
                93.62471771240234,
                31.374067306518555,
                314.31524658203125,
                332.1023254394531
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5096,
            5100
          ],
          "representative_frame": 5096,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 42
    },
    {
      "second": 170,
      "time_range": [
        170,
        170.999
      ],
      "frame_range": [
        5101,
        5130
      ],
      "unified_description": "1-second scene featuring two boys playing in the water at the beach",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:38",
        "processing_time": 2.35,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5115,
          "frame_range": [
            5111,
            5115
          ],
          "description": "two boys playing in the water at the beach",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.84
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5101,
            5105
          ],
          "representative_frame": 5101,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9440268278121948,
              "bbox": [
                0.0,
                0.0,
                189.78665161132812,
                345.4314270019531
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9244157671928406,
              "bbox": [
                105.81529998779297,
                34.22062683105469,
                324.1150817871094,
                344.1172790527344
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5106,
            5110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5111,
            5115
          ],
          "representative_frame": 5111,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9212497472763062,
              "bbox": [
                0.0,
                0.0,
                192.1504364013672,
                351.6128234863281
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9229233264923096,
              "bbox": [
                126.78443145751953,
                30.45287322998047,
                338.995849609375,
                342.72369384765625
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5116,
            5120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5121,
            5125
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9477468729019165,
              "bbox": [
                0.0,
                0.0,
                200.51600646972656,
                355.92822265625
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9219252467155457,
              "bbox": [
                142.22569274902344,
                42.38793182373047,
                339.36419677734375,
                338.1576843261719
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5126,
            5130
          ],
          "representative_frame": 5126,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 42
    },
    {
      "second": 171,
      "time_range": [
        171,
        171.999
      ],
      "frame_range": [
        5131,
        5160
      ],
      "unified_description": "\n\n- Camera perspective: First person",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:39",
        "processing_time": 2.33,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5145,
          "frame_range": [
            5141,
            5145
          ],
          "description": "a young boy is holding a fish while another boy watches",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.17
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5131,
            5135
          ],
          "representative_frame": 5131,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.920724630355835,
              "bbox": [
                0.0,
                0.0,
                227.64755249023438,
                357.37353515625
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9341825246810913,
              "bbox": [
                169.26405334472656,
                53.08281326293945,
                354.68121337890625,
                334.2976379394531
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5136,
            5140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5141,
            5145
          ],
          "representative_frame": 5141,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9176084995269775,
              "bbox": [
                9.920516014099121,
                92.06190490722656,
                184.0093536376953,
                358.94683837890625
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5146,
            5150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5151,
            5155
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9368338584899902,
              "bbox": [
                12.13298225402832,
                133.8043212890625,
                163.216796875,
                359.46136474609375
              ]
            },
            {
              "track_id": 341,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8348084092140198,
              "bbox": [
                543.4950561523438,
                90.36190032958984,
                585.7164306640625,
                183.05445861816406
              ]
            }
          ],
          "unique_tracks": [
            319,
            341
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5156,
            5160
          ],
          "representative_frame": 5156,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 42
    },
    {
      "second": 172,
      "time_range": [
        172,
        172.999
      ],
      "frame_range": [
        5161,
        5190
      ],
      "unified_description": "3rd person perspective camera mounted on a backpack, tracking moving objects with motion blurring",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:40",
        "processing_time": 2.59,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5175,
          "frame_range": [
            5171,
            5175
          ],
          "description": "a little boy is fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5161,
            5165
          ],
          "representative_frame": 5161,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.930839478969574,
              "bbox": [
                16.863893508911133,
                147.5526885986328,
                161.09364318847656,
                359.2975158691406
              ]
            },
            {
              "track_id": 341,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8253772854804993,
              "bbox": [
                536.374267578125,
                84.69139862060547,
                582.0540161132812,
                185.51275634765625
              ]
            }
          ],
          "unique_tracks": [
            319,
            341
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5166,
            5170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5171,
            5175
          ],
          "representative_frame": 5171,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9344913959503174,
              "bbox": [
                13.615920066833496,
                151.97816467285156,
                157.9364013671875,
                359.3590393066406
              ]
            },
            {
              "track_id": 341,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8597415089607239,
              "bbox": [
                531.92138671875,
                81.54613494873047,
                577.643798828125,
                183.43533325195312
              ]
            }
          ],
          "unique_tracks": [
            319,
            341
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5176,
            5180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5181,
            5185
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            5186,
            5190
          ],
          "representative_frame": 5186,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 43
    },
    {
      "second": 173,
      "time_range": [
        173,
        173.999
      ],
      "frame_range": [
        5191,
        5220
      ],
      "unified_description": "5-second summary: A first-person video shows a man standing in the water with a fish. The camera is mounted on a backpack, capturing the scene as the man catches the fish.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:42",
        "processing_time": 2.87,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5205,
          "frame_range": [
            5201,
            5205
          ],
          "description": "a man standing in the water with a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.61
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5191,
            5195
          ],
          "representative_frame": 5191,
          "detections": [
            {
              "track_id": 343,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9281894564628601,
              "bbox": [
                496.32928466796875,
                0.6596618890762329,
                640.0,
                354.88671875
              ]
            },
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7608978152275085,
              "bbox": [
                164.730224609375,
                195.27825927734375,
                184.01597595214844,
                222.46783447265625
              ]
            }
          ],
          "unique_tracks": [
            343,
            344
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5196,
            5200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5201,
            5205
          ],
          "representative_frame": 5201,
          "detections": [
            {
              "track_id": 343,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9363650679588318,
              "bbox": [
                500.52813720703125,
                0.6749630570411682,
                640.0,
                356.1379089355469
              ]
            },
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7226076722145081,
              "bbox": [
                165.1674346923828,
                195.21780395507812,
                184.34022521972656,
                222.2054443359375
              ]
            }
          ],
          "unique_tracks": [
            343,
            344
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5206,
            5210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5211,
            5215
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 343,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9227842688560486,
              "bbox": [
                506.2726745605469,
                0.38121578097343445,
                640.0,
                355.4765930175781
              ]
            },
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7514481544494629,
              "bbox": [
                165.15890502929688,
                194.67710876464844,
                184.6216583251953,
                221.94387817382812
              ]
            }
          ],
          "unique_tracks": [
            343,
            344
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5216,
            5220
          ],
          "representative_frame": 5216,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 43
    },
    {
      "second": 174,
      "time_range": [
        174,
        174.999
      ],
      "frame_range": [
        5221,
        5250
      ],
      "unified_description": "1-second scene showing a man fishing in the water with a rod.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:43",
        "processing_time": 2.46,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5235,
          "frame_range": [
            5231,
            5235
          ],
          "description": "a man fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.82
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5221,
            5225
          ],
          "representative_frame": 5221,
          "detections": [
            {
              "track_id": 343,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9196679592132568,
              "bbox": [
                509.5222473144531,
                0.2592177093029022,
                640.0,
                355.22161865234375
              ]
            },
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7261301279067993,
              "bbox": [
                165.49465942382812,
                194.7743682861328,
                185.22332763671875,
                222.23297119140625
              ]
            }
          ],
          "unique_tracks": [
            343,
            344
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5226,
            5230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5231,
            5235
          ],
          "representative_frame": 5231,
          "detections": [
            {
              "track_id": 343,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9088490009307861,
              "bbox": [
                513.425537109375,
                0.3059825301170349,
                640.0,
                354.8275146484375
              ]
            },
            {
              "track_id": 344,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.4050411880016327,
              "bbox": [
                166.69308471679688,
                199.7772216796875,
                182.70533752441406,
                221.75624084472656
              ]
            }
          ],
          "unique_tracks": [
            343,
            344
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5236,
            5240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5241,
            5245
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.538180947303772,
              "bbox": [
                168.37451171875,
                196.58840942382812,
                182.64332580566406,
                216.2259063720703
              ]
            }
          ],
          "unique_tracks": [
            344
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5246,
            5250
          ],
          "representative_frame": 5246,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 43
    },
    {
      "second": 175,
      "time_range": [
        175,
        175.999
      ],
      "frame_range": [
        5251,
        5280
      ],
      "unified_description": "360-degree video of a fishing trip. The video was taken with a wide-angle lens, resulting in some distortion at the edges of the frame.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:44",
        "processing_time": 3.32,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5265,
          "frame_range": [
            5261,
            5265
          ],
          "description": "a man is fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.43
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5251,
            5255
          ],
          "representative_frame": 5251,
          "detections": [
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5532517433166504,
              "bbox": [
                169.61801147460938,
                195.63783264160156,
                181.84500122070312,
                212.42286682128906
              ]
            },
            {
              "track_id": 346,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6814907193183899,
              "bbox": [
                597.8801879882812,
                0.437173455953598,
                640.0,
                140.58460998535156
              ]
            }
          ],
          "unique_tracks": [
            344,
            346
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5256,
            5260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5261,
            5265
          ],
          "representative_frame": 5261,
          "detections": [
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.35994991660118103,
              "bbox": [
                169.06239318847656,
                195.4078369140625,
                183.1121368408203,
                214.90103149414062
              ]
            },
            {
              "track_id": 346,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.848861813545227,
              "bbox": [
                596.2578125,
                0.11173190921545029,
                638.7237548828125,
                140.55616760253906
              ]
            }
          ],
          "unique_tracks": [
            344,
            346
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5266,
            5270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5271,
            5275
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.41639116406440735,
              "bbox": [
                169.25767517089844,
                195.29367065429688,
                183.31192016601562,
                214.9426727294922
              ]
            },
            {
              "track_id": 346,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6521244645118713,
              "bbox": [
                594.4468994140625,
                0.16909413039684296,
                640.0,
                163.070556640625
              ]
            },
            {
              "track_id": 348,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4385325312614441,
              "bbox": [
                169.7101287841797,
                195.32354736328125,
                182.97154235839844,
                223.41995239257812
              ]
            }
          ],
          "unique_tracks": [
            344,
            346,
            348
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            5276,
            5280
          ],
          "representative_frame": 5276,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 43
    },
    {
      "second": 176,
      "time_range": [
        176,
        176.999
      ],
      "frame_range": [
        5281,
        5310
      ],
      "unified_description": "1-second scene featuring a man fishing in the water with a rod. Produced using action camera mounted on a backpack.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:46",
        "processing_time": 2.52,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5295,
          "frame_range": [
            5291,
            5295
          ],
          "description": "a man fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.11
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5281,
            5285
          ],
          "representative_frame": 5281,
          "detections": [
            {
              "track_id": 346,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8223833441734314,
              "bbox": [
                588.9314575195312,
                0.412706583738327,
                640.0,
                173.40260314941406
              ]
            },
            {
              "track_id": 348,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.636078953742981,
              "bbox": [
                171.30850219726562,
                195.30467224121094,
                185.679931640625,
                225.527099609375
              ]
            }
          ],
          "unique_tracks": [
            346,
            348
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5286,
            5290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5291,
            5295
          ],
          "representative_frame": 5291,
          "detections": [
            {
              "track_id": 346,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4552532434463501,
              "bbox": [
                583.894775390625,
                0.5657723546028137,
                638.8536987304688,
                182.60482788085938
              ]
            },
            {
              "track_id": 348,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.54554283618927,
              "bbox": [
                170.3324737548828,
                195.47235107421875,
                184.46127319335938,
                225.09425354003906
              ]
            },
            {
              "track_id": 343,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7516137361526489,
              "bbox": [
                542.037353515625,
                0.47423601150512695,
                640.0,
                354.79779052734375
              ]
            }
          ],
          "unique_tracks": [
            346,
            348,
            343
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            5296,
            5300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5301,
            5305
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 346,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3986172080039978,
              "bbox": [
                576.8670043945312,
                0.464653342962265,
                634.4386596679688,
                188.31484985351562
              ]
            },
            {
              "track_id": 348,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5893583297729492,
              "bbox": [
                170.23333740234375,
                195.5476837158203,
                184.2494659423828,
                224.7449951171875
              ]
            },
            {
              "track_id": 343,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4292701184749603,
              "bbox": [
                542.4889526367188,
                0.8680613040924072,
                640.0,
                352.2469482421875
              ]
            }
          ],
          "unique_tracks": [
            346,
            348,
            343
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            5306,
            5310
          ],
          "representative_frame": 5306,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 44
    },
    {
      "second": 177,
      "time_range": [
        177,
        177.999
      ],
      "frame_range": [
        5311,
        5340
      ],
      "unified_description": "\n\n- The scene shows a man standing near some water, holding a fishing rod. There is also a backpack in the scene, possibly belonging to the man.\n\n- The image has been captured using a shaky camera mounted on a backpack, which creates a \"handheld\" perspective. This viewpoint suggests that the camera was positioned above the person's shoulder or attached to their backpack, giving an interesting angle of the man fishing.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:49",
        "processing_time": 3.72,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5325,
          "frame_range": [
            5321,
            5325
          ],
          "description": "a man fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.69
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5311,
            5315
          ],
          "representative_frame": 5311,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            5316,
            5320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5321,
            5325
          ],
          "representative_frame": 5321,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9392979741096497,
              "bbox": [
                30.075132369995117,
                67.46487426757812,
                172.24449157714844,
                356.869384765625
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5326,
            5330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5331,
            5335
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9104964733123779,
              "bbox": [
                25.07503890991211,
                60.655879974365234,
                168.97207641601562,
                354.0326232910156
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5336,
            5340
          ],
          "representative_frame": 5336,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 44
    },
    {
      "second": 178,
      "time_range": [
        178,
        178.999
      ],
      "frame_range": [
        5341,
        5370
      ],
      "unified_description": "1-second scene - A boy holding a fishing rod next to a body of water, with a tripod mounted camera capturing the action.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:50",
        "processing_time": 4.19,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5355,
          "frame_range": [
            5351,
            5355
          ],
          "description": "a boy fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.06
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5341,
            5345
          ],
          "representative_frame": 5341,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9218047857284546,
              "bbox": [
                24.52728843688965,
                52.87847137451172,
                173.64242553710938,
                354.98583984375
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5346,
            5350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5351,
            5355
          ],
          "representative_frame": 5351,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9231960773468018,
              "bbox": [
                24.454898834228516,
                48.07109069824219,
                176.27438354492188,
                355.7867126464844
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5356,
            5360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5361,
            5365
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.909283459186554,
              "bbox": [
                22.33523178100586,
                42.03041076660156,
                172.96018981933594,
                348.0800476074219
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5366,
            5370
          ],
          "representative_frame": 5366,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 44
    },
    {
      "second": 179,
      "time_range": [
        179,
        179.999
      ],
      "frame_range": [
        5371,
        5400
      ],
      "unified_description": "4-second video with various objects and people, shot with a wide-angle lens on a stable camera mount",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:50",
        "processing_time": 3.42,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5385,
          "frame_range": [
            5381,
            5385
          ],
          "description": "a young boy fishing on a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.65
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5371,
            5375
          ],
          "representative_frame": 5371,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9438202381134033,
              "bbox": [
                14.039931297302246,
                47.24640655517578,
                165.80067443847656,
                353.6448059082031
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5376,
            5380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5381,
            5385
          ],
          "representative_frame": 5381,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8675960898399353,
              "bbox": [
                4.618818283081055,
                41.28384780883789,
                159.28997802734375,
                353.222412109375
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5386,
            5390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5391,
            5395
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8995794653892517,
              "bbox": [
                0.0,
                37.90673065185547,
                153.25979614257812,
                353.71905517578125
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5396,
            5400
          ],
          "representative_frame": 5396,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 44
    },
    {
      "second": 180,
      "time_range": [
        180,
        180.999
      ],
      "frame_range": [
        5401,
        5430
      ],
      "unified_description": "3rd person perspective of a fish being held by someone. A wide angle lens is used for capturing the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:53",
        "processing_time": 2.51,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5415,
          "frame_range": [
            5411,
            5415
          ],
          "description": "a person is holding a small fish in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5401,
            5405
          ],
          "representative_frame": 5401,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            5406,
            5410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5411,
            5415
          ],
          "representative_frame": 5411,
          "detections": [
            {
              "track_id": 346,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8330817818641663,
              "bbox": [
                500.2812194824219,
                49.548614501953125,
                567.5701904296875,
                190.58334350585938
              ]
            }
          ],
          "unique_tracks": [
            346
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5416,
            5420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5421,
            5425
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            5426,
            5430
          ],
          "representative_frame": 5426,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 45
    },
    {
      "second": 181,
      "time_range": [
        181,
        181.999
      ],
      "frame_range": [
        5431,
        5460
      ],
      "unified_description": "512 frames in 1 second, showing a man with a fish in his hand.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:54",
        "processing_time": 2.44,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5445,
          "frame_range": [
            5441,
            5445
          ],
          "description": "a man is holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.23
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5431,
            5435
          ],
          "representative_frame": 5431,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            5436,
            5440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5441,
            5445
          ],
          "representative_frame": 5441,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            5446,
            5450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5451,
            5455
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            5456,
            5460
          ],
          "representative_frame": 5456,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 45
    },
    {
      "second": 182,
      "time_range": [
        182,
        182.999
      ],
      "frame_range": [
        5461,
        5490
      ],
      "unified_description": "30 FPS video of a dog being walked on a leash on the road.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:55",
        "processing_time": 2.7,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5475,
          "frame_range": [
            5471,
            5475
          ],
          "description": "a dog is walking on the road with a leash",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.81
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5461,
            5465
          ],
          "representative_frame": 5461,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            5466,
            5470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5471,
            5475
          ],
          "representative_frame": 5471,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            5476,
            5480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5481,
            5485
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            5486,
            5490
          ],
          "representative_frame": 5486,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 45
    },
    {
      "second": 183,
      "time_range": [
        183,
        183.999
      ],
      "frame_range": [
        5491,
        5520
      ],
      "unified_description": "30-second video with multiple objects and people in it",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:56",
        "processing_time": 2.3,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5505,
          "frame_range": [
            5501,
            5505
          ],
          "description": "a man is holding a bag of food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.62
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5491,
            5495
          ],
          "representative_frame": 5491,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8022205829620361,
              "bbox": [
                339.13482666015625,
                11.484094619750977,
                640.0,
                254.48416137695312
              ]
            }
          ],
          "unique_tracks": [
            366
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5496,
            5500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5501,
            5505
          ],
          "representative_frame": 5501,
          "detections": [
            {
              "track_id": 366,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8743597269058228,
              "bbox": [
                274.1254577636719,
                20.510143280029297,
                606.756103515625,
                266.9635925292969
              ]
            },
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5576781630516052,
              "bbox": [
                319.21954345703125,
                65.1202163696289,
                602.8892822265625,
                352.9620056152344
              ]
            }
          ],
          "unique_tracks": [
            366,
            369
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5506,
            5510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5511,
            5515
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            5516,
            5520
          ],
          "representative_frame": 5516,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 45
    },
    {
      "second": 184,
      "time_range": [
        184,
        184.999
      ],
      "frame_range": [
        5521,
        5550
      ],
      "unified_description": "\nFirst-person camera perspective showing a man standing by a river, holding a fishing rod. The scene captures the peaceful surroundings, including the nearby bench. The image also contains visual artifacts like motion blur and lens flare.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:58",
        "processing_time": 2.92,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5535,
          "frame_range": [
            5531,
            5535
          ],
          "description": "a man is fishing in the river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.97
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5521,
            5525
          ],
          "representative_frame": 5521,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            5526,
            5530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5531,
            5535
          ],
          "representative_frame": 5531,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            5536,
            5540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5541,
            5545
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            5546,
            5550
          ],
          "representative_frame": 5546,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 46
    },
    {
      "second": 185,
      "time_range": [
        185,
        185.999
      ],
      "frame_range": [
        5551,
        5580
      ],
      "unified_description": "\nIn this scene, there are two people - a man and a woman. They appear to be standing on the shore, possibly preparing to go fishing together.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:16:59",
        "processing_time": 3.47,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5565,
          "frame_range": [
            5561,
            5565
          ],
          "description": "a man and woman fishing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.81
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5551,
            5555
          ],
          "representative_frame": 5551,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            5556,
            5560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5561,
            5565
          ],
          "representative_frame": 5561,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            5566,
            5570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5571,
            5575
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9130672216415405,
              "bbox": [
                565.04150390625,
                2.2550415992736816,
                639.4678955078125,
                254.75222778320312
              ]
            },
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9392371773719788,
              "bbox": [
                0.0,
                2.2017934322357178,
                420.7179870605469,
                346.9678039550781
              ]
            }
          ],
          "unique_tracks": [
            374,
            366
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5576,
            5580
          ],
          "representative_frame": 5576,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 46
    },
    {
      "second": 186,
      "time_range": [
        186,
        186.999
      ],
      "frame_range": [
        5581,
        5610
      ],
      "unified_description": "30-second videos require different techniques to maintain quality across varying conditions. A detailed description would help to ensure the best results in terms of camera positioning, field of view, and lens characteristics.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:00",
        "processing_time": 3.25,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5595,
          "frame_range": [
            5591,
            5595
          ],
          "description": "a man holding a fish while another man holds it",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.72
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5581,
            5585
          ],
          "representative_frame": 5581,
          "detections": [
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9187454581260681,
              "bbox": [
                567.3665161132812,
                1.6942416429519653,
                640.0,
                255.85533142089844
              ]
            },
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9426503777503967,
              "bbox": [
                0.0,
                0.8503158092498779,
                413.33770751953125,
                353.7829895019531
              ]
            }
          ],
          "unique_tracks": [
            374,
            366
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5586,
            5590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5591,
            5595
          ],
          "representative_frame": 5591,
          "detections": [
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9068547487258911,
              "bbox": [
                566.15869140625,
                0.8847631812095642,
                640.0,
                257.4070129394531
              ]
            },
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.926922082901001,
              "bbox": [
                0.0,
                0.0,
                396.158203125,
                357.36029052734375
              ]
            }
          ],
          "unique_tracks": [
            374,
            366
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5596,
            5600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5601,
            5605
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.91934734582901,
              "bbox": [
                565.6592407226562,
                1.4044791460037231,
                640.0,
                257.3759460449219
              ]
            },
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9333745837211609,
              "bbox": [
                0.0,
                0.0,
                375.2656555175781,
                358.7870178222656
              ]
            }
          ],
          "unique_tracks": [
            374,
            366
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5606,
            5610
          ],
          "representative_frame": 5606,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 46
    },
    {
      "second": 187,
      "time_range": [
        187,
        187.999
      ],
      "frame_range": [
        5611,
        5640
      ],
      "unified_description": "360-degree video capturing an outdoor scene where a man is fishing in a river with a fish visible underwater. The camera's perspective is from a backpack mount, providing a first-person view of the experience.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:02",
        "processing_time": 2.93,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5625,
          "frame_range": [
            5621,
            5625
          ],
          "description": "a man is fishing on the water with a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.33
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5611,
            5615
          ],
          "representative_frame": 5611,
          "detections": [
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5692390203475952,
              "bbox": [
                580.3338012695312,
                27.845354080200195,
                637.49658203125,
                221.0421905517578
              ]
            },
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7584248185157776,
              "bbox": [
                5.335646629333496,
                0.09527631103992462,
                399.00531005859375,
                359.78369140625
              ]
            }
          ],
          "unique_tracks": [
            374,
            366
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5616,
            5620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5621,
            5625
          ],
          "representative_frame": 5621,
          "detections": [
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8640958666801453,
              "bbox": [
                587.3464965820312,
                24.206777572631836,
                640.0,
                217.4116973876953
              ]
            },
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6543794274330139,
              "bbox": [
                20.38423728942871,
                0.010637642815709114,
                406.6833801269531,
                359.6978759765625
              ]
            }
          ],
          "unique_tracks": [
            374,
            366
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5626,
            5630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5631,
            5635
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.707241952419281,
              "bbox": [
                592.934326171875,
                39.2801628112793,
                640.0,
                217.58853149414062
              ]
            },
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8909397125244141,
              "bbox": [
                27.32643699645996,
                0.0,
                406.10015869140625,
                359.1607666015625
              ]
            }
          ],
          "unique_tracks": [
            374,
            366
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5636,
            5640
          ],
          "representative_frame": 5636,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 46
    },
    {
      "second": 188,
      "time_range": [
        188,
        188.999
      ],
      "frame_range": [
        5641,
        5670
      ],
      "unified_description": "\nA man is standing near some water, holding a fishing rod. The camera captures his actions as he casts his line into the water. In the background, there are a few other people around, but they do not seem to be actively participating in any specific activities.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:04",
        "processing_time": 3.44,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5655,
          "frame_range": [
            5651,
            5655
          ],
          "description": "a man is fishing on the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.34
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5641,
            5645
          ],
          "representative_frame": 5641,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8450759053230286,
              "bbox": [
                32.82575225830078,
                0.27928200364112854,
                404.040283203125,
                358.6175537109375
              ]
            }
          ],
          "unique_tracks": [
            366
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5646,
            5650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5651,
            5655
          ],
          "representative_frame": 5651,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7002034783363342,
              "bbox": [
                42.03224563598633,
                0.0,
                406.0140380859375,
                358.9801330566406
              ]
            },
            {
              "track_id": 378,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5456008911132812,
              "bbox": [
                623.9221801757812,
                105.83584594726562,
                638.8037109375,
                241.61849975585938
              ]
            }
          ],
          "unique_tracks": [
            366,
            378
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5656,
            5660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5661,
            5665
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7936193943023682,
              "bbox": [
                38.7495231628418,
                0.0,
                396.4687805175781,
                357.6952819824219
              ]
            },
            {
              "track_id": 378,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.495149165391922,
              "bbox": [
                623.9840087890625,
                109.47456359863281,
                638.4824829101562,
                241.23162841796875
              ]
            }
          ],
          "unique_tracks": [
            366,
            378
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5666,
            5670
          ],
          "representative_frame": 5666,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 47
    },
    {
      "second": 189,
      "time_range": [
        189,
        189.999
      ],
      "frame_range": [
        5671,
        5700
      ],
      "unified_description": "\n\nIn this scene, there is a man standing near the water's edge on the shore of a lake, holding a fishing rod. The camera is positioned in such a way that it captures the man's outdoor fishing experience. Additionally, there are several other objects and people in the vicinity that may be relevant to the overall scene context.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:06",
        "processing_time": 4.77,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5685,
          "frame_range": [
            5681,
            5685
          ],
          "description": "a man is fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.78
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5671,
            5675
          ],
          "representative_frame": 5671,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9044017791748047,
              "bbox": [
                50.774803161621094,
                0.6081656217575073,
                406.3130187988281,
                356.74981689453125
              ]
            },
            {
              "track_id": 378,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5653356313705444,
              "bbox": [
                623.8920288085938,
                109.65845489501953,
                638.4088745117188,
                240.83055114746094
              ]
            }
          ],
          "unique_tracks": [
            366,
            378
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5676,
            5680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5681,
            5685
          ],
          "representative_frame": 5681,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9188506007194519,
              "bbox": [
                54.984928131103516,
                0.5719946622848511,
                403.6469421386719,
                353.1747741699219
              ]
            },
            {
              "track_id": 378,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4108165204524994,
              "bbox": [
                623.903076171875,
                110.81440734863281,
                638.552734375,
                242.3511962890625
              ]
            }
          ],
          "unique_tracks": [
            366,
            378
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5686,
            5690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5691,
            5695
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.915213406085968,
              "bbox": [
                64.3698959350586,
                11.905373573303223,
                400.45672607421875,
                353.0533142089844
              ]
            },
            {
              "track_id": 378,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5908233523368835,
              "bbox": [
                622.7661743164062,
                106.99309539794922,
                638.19384765625,
                244.04144287109375
              ]
            }
          ],
          "unique_tracks": [
            366,
            378
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5696,
            5700
          ],
          "representative_frame": 5696,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 47
    },
    {
      "second": 190,
      "time_range": [
        190,
        190.999
      ],
      "frame_range": [
        5701,
        5730
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:06",
        "processing_time": 2.24,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5715,
          "frame_range": [
            5711,
            5715
          ],
          "description": "a man is fishing on the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.15
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5701,
            5705
          ],
          "representative_frame": 5701,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.26184728741645813,
              "bbox": [
                78.60221862792969,
                30.72465705871582,
                397.3179626464844,
                355.4866027832031
              ]
            },
            {
              "track_id": 378,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5084297060966492,
              "bbox": [
                621.8639526367188,
                97.73182678222656,
                638.5552978515625,
                244.98941040039062
              ]
            }
          ],
          "unique_tracks": [
            366,
            378
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5706,
            5710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5711,
            5715
          ],
          "representative_frame": 5711,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3070394694805145,
              "bbox": [
                81.0107421875,
                52.80995559692383,
                378.72857666015625,
                356.3763122558594
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8669914603233337,
              "bbox": [
                591.429443359375,
                45.22052001953125,
                640.0,
                240.67236328125
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5716,
            5720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5721,
            5725
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.18782831728458405,
              "bbox": [
                85.9681167602539,
                63.81769561767578,
                373.6969909667969,
                355.5003967285156
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9295886754989624,
              "bbox": [
                574.8440551757812,
                19.541797637939453,
                638.638427734375,
                241.50643920898438
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5726,
            5730
          ],
          "representative_frame": 5726,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 47
    },
    {
      "second": 191,
      "time_range": [
        191,
        191.999
      ],
      "frame_range": [
        5731,
        5760
      ],
      "unified_description": "\nBased on these descriptions, the scene seems to be of two men standing near each other on a beach. The camera perspective appears to be a handheld or body-mounted view. The image was likely taken during daytime, giving a clear view of the subjects and their surroundings.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:09",
        "processing_time": 3.14,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5745,
          "frame_range": [
            5741,
            5745
          ],
          "description": "a man in a red jacket and a black jacket is standing on a rocky beach",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.66
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5731,
            5735
          ],
          "representative_frame": 5731,
          "detections": [
            {
              "track_id": 366,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.3676256239414215,
              "bbox": [
                83.3306884765625,
                60.69782638549805,
                372.3822326660156,
                353.24786376953125
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9130101203918457,
              "bbox": [
                576.1196899414062,
                7.066376209259033,
                640.0,
                249.71669006347656
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5736,
            5740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5741,
            5745
          ],
          "representative_frame": 5741,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7040678262710571,
              "bbox": [
                72.81397247314453,
                27.331424713134766,
                394.1393737792969,
                355.00347900390625
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8943873047828674,
              "bbox": [
                580.1460571289062,
                1.9925482273101807,
                640.0,
                255.9514617919922
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5746,
            5750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5751,
            5755
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.940861701965332,
              "bbox": [
                47.34363555908203,
                9.721059799194336,
                377.4328918457031,
                355.8296203613281
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9097604155540466,
              "bbox": [
                571.9265747070312,
                0.1662483513355255,
                640.0,
                258.3453369140625
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5756,
            5760
          ],
          "representative_frame": 5756,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 47
    },
    {
      "second": 192,
      "time_range": [
        192,
        192.999
      ],
      "frame_range": [
        5761,
        5790
      ],
      "unified_description": "1-second scene with a man and a woman in red raincoats standing together against the background of a field. The image also includes some other stuff happening in the vicinity.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:11",
        "processing_time": 3.08,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5775,
          "frame_range": [
            5771,
            5775
          ],
          "description": "a man in a red raincoat and a woman in a red raincoat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.67
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5761,
            5765
          ],
          "representative_frame": 5761,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7100653052330017,
              "bbox": [
                37.96992111206055,
                3.0023036003112793,
                365.4969177246094,
                353.951416015625
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9314975738525391,
              "bbox": [
                566.7294921875,
                0.0,
                638.2199096679688,
                259.601806640625
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5766,
            5770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5771,
            5775
          ],
          "representative_frame": 5771,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6468013525009155,
              "bbox": [
                24.5560359954834,
                0.6056018471717834,
                348.2811584472656,
                354.0653991699219
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9444978833198547,
              "bbox": [
                562.6717529296875,
                0.0,
                635.8582153320312,
                260.313720703125
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5776,
            5780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5781,
            5785
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9205869436264038,
              "bbox": [
                31.525903701782227,
                0.0,
                348.21270751953125,
                354.2514953613281
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9413642883300781,
              "bbox": [
                559.2753295898438,
                0.0,
                634.0709228515625,
                260.30255126953125
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5786,
            5790
          ],
          "representative_frame": 5786,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 48
    },
    {
      "second": 193,
      "time_range": [
        193,
        193.999
      ],
      "frame_range": [
        5791,
        5820
      ],
      "unified_description": "2d cameras were used to capture this scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:10",
        "processing_time": 2.34,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5805,
          "frame_range": [
            5801,
            5805
          ],
          "description": "a man fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.32
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5791,
            5795
          ],
          "representative_frame": 5791,
          "detections": [
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8899666666984558,
              "bbox": [
                265.1890869140625,
                77.94346618652344,
                496.07421875,
                352.5050048828125
              ]
            }
          ],
          "unique_tracks": [
            369
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5796,
            5800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5801,
            5805
          ],
          "representative_frame": 5801,
          "detections": [
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9125574827194214,
              "bbox": [
                260.03338623046875,
                80.64122009277344,
                471.8013916015625,
                355.50372314453125
              ]
            }
          ],
          "unique_tracks": [
            369
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5806,
            5810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5811,
            5815
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9297991394996643,
              "bbox": [
                227.1564483642578,
                80.49889373779297,
                417.5022888183594,
                346.79742431640625
              ]
            }
          ],
          "unique_tracks": [
            369
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5816,
            5820
          ],
          "representative_frame": 5816,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 48
    },
    {
      "second": 194,
      "time_range": [
        194,
        194.999
      ],
      "frame_range": [
        5821,
        5850
      ],
      "unified_description": "\nA man with a fishing rod is standing by the water. The image also shows the surrounding environment which might include other objects or people.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:12",
        "processing_time": 2.58,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5835,
          "frame_range": [
            5831,
            5835
          ],
          "description": "a man fishing on the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.79
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5821,
            5825
          ],
          "representative_frame": 5821,
          "detections": [
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9308459758758545,
              "bbox": [
                199.09474182128906,
                82.68194580078125,
                381.2690124511719,
                352.537109375
              ]
            }
          ],
          "unique_tracks": [
            369
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5826,
            5830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5831,
            5835
          ],
          "representative_frame": 5831,
          "detections": [
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9329923391342163,
              "bbox": [
                167.6722869873047,
                82.09256744384766,
                342.6516418457031,
                355.046142578125
              ]
            }
          ],
          "unique_tracks": [
            369
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5836,
            5840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5841,
            5845
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9146161675453186,
              "bbox": [
                122.33295440673828,
                87.99073028564453,
                284.4218444824219,
                352.3859558105469
              ]
            }
          ],
          "unique_tracks": [
            369
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5846,
            5850
          ],
          "representative_frame": 5846,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 48
    },
    {
      "second": 195,
      "time_range": [
        195,
        195.999
      ],
      "frame_range": [
        5851,
        5880
      ],
      "unified_description": "3rd person perspective camera view",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:13",
        "processing_time": 2.24,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5865,
          "frame_range": [
            5861,
            5865
          ],
          "description": "a man fishing on a lake with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5851,
            5855
          ],
          "representative_frame": 5851,
          "detections": [
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9158307909965515,
              "bbox": [
                55.36655044555664,
                110.60633087158203,
                198.6296844482422,
                350.1976623535156
              ]
            }
          ],
          "unique_tracks": [
            369
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5856,
            5860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5861,
            5865
          ],
          "representative_frame": 5861,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            5866,
            5870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5871,
            5875
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 387,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9282131195068359,
              "bbox": [
                381.4728088378906,
                0.0,
                504.1718444824219,
                353.4304504394531
              ]
            }
          ],
          "unique_tracks": [
            387
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5876,
            5880
          ],
          "representative_frame": 5876,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 48
    },
    {
      "second": 196,
      "time_range": [
        196,
        196.999
      ],
      "frame_range": [
        5881,
        5910
      ],
      "unified_description": "\n\n\"a man standing on a river bank in the rain\"",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:14",
        "processing_time": 2.42,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5895,
          "frame_range": [
            5891,
            5895
          ],
          "description": "a man standing on a river bank in the rain",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.66
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5881,
            5885
          ],
          "representative_frame": 5881,
          "detections": [
            {
              "track_id": 387,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9290095567703247,
              "bbox": [
                374.18487548828125,
                0.10818483680486679,
                493.8714599609375,
                345.066162109375
              ]
            }
          ],
          "unique_tracks": [
            387
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5886,
            5890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5891,
            5895
          ],
          "representative_frame": 5891,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            5896,
            5900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5901,
            5905
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9098967909812927,
              "bbox": [
                296.18572998046875,
                93.54264831542969,
                363.2579345703125,
                271.4231262207031
              ]
            },
            {
              "track_id": 389,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4641462564468384,
              "bbox": [
                112.2907485961914,
                172.37506103515625,
                127.3765640258789,
                189.42697143554688
              ]
            }
          ],
          "unique_tracks": [
            388,
            389
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5906,
            5910
          ],
          "representative_frame": 5906,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 49
    },
    {
      "second": 197,
      "time_range": [
        197,
        197.999
      ],
      "frame_range": [
        5911,
        5940
      ],
      "unified_description": "\nIn this scene, a man is fishing on a river. The camera is mounted on his body, following his movements as he casts his line into the water. There is also a backpack in the vicinity, possibly containing the man's belongings or fishing gear.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:16",
        "processing_time": 3.1,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5925,
          "frame_range": [
            5921,
            5925
          ],
          "description": "a man standing in the water with a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.81
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5911,
            5915
          ],
          "representative_frame": 5911,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9060783386230469,
              "bbox": [
                295.7515563964844,
                93.96939849853516,
                362.9134521484375,
                272.1372375488281
              ]
            },
            {
              "track_id": 389,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4682897925376892,
              "bbox": [
                110.77607727050781,
                171.6742706298828,
                128.19070434570312,
                191.42660522460938
              ]
            }
          ],
          "unique_tracks": [
            388,
            389
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5916,
            5920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5921,
            5925
          ],
          "representative_frame": 5921,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9062952399253845,
              "bbox": [
                296.6114807128906,
                94.06329345703125,
                362.2443542480469,
                268.1982421875
              ]
            },
            {
              "track_id": 389,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.48456108570098877,
              "bbox": [
                109.60469055175781,
                171.49375915527344,
                129.0743865966797,
                193.7005157470703
              ]
            }
          ],
          "unique_tracks": [
            388,
            389
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5926,
            5930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5931,
            5935
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9151055812835693,
              "bbox": [
                295.3161315917969,
                94.0809326171875,
                362.298095703125,
                271.89508056640625
              ]
            },
            {
              "track_id": 389,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4582716226577759,
              "bbox": [
                109.47029876708984,
                171.5293731689453,
                129.83140563964844,
                194.79393005371094
              ]
            }
          ],
          "unique_tracks": [
            388,
            389
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5936,
            5940
          ],
          "representative_frame": 5936,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 49
    },
    {
      "second": 198,
      "time_range": [
        198,
        198.999
      ],
      "frame_range": [
        5941,
        5970
      ],
      "unified_description": "360 video with a man fishing in the middle of a lake. The image shows the man standing on a boat holding a rod. There are multiple objects in the scene such as the boat, the rod in the man's hand and other surrounding objects.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:17",
        "processing_time": 3.84,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5955,
          "frame_range": [
            5951,
            5955
          ],
          "description": "a man fishing in the middle of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.8
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5941,
            5945
          ],
          "representative_frame": 5941,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9252985715866089,
              "bbox": [
                294.46722412109375,
                58.68276596069336,
                378.7442626953125,
                281.550048828125
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5946,
            5950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5951,
            5955
          ],
          "representative_frame": 5951,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9214993715286255,
              "bbox": [
                284.2480163574219,
                42.503074645996094,
                377.8280334472656,
                288.5742492675781
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5956,
            5960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5961,
            5965
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9238731861114502,
              "bbox": [
                259.6632995605469,
                29.572616577148438,
                362.65362548828125,
                299.1722412109375
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5966,
            5970
          ],
          "representative_frame": 5966,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 49
    },
    {
      "second": 199,
      "time_range": [
        199,
        199.999
      ],
      "frame_range": [
        5971,
        6000
      ],
      "unified_description": "1-second scene showing a man fishing in the water with a rod",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:18",
        "processing_time": 3.54,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5985,
          "frame_range": [
            5981,
            5985
          ],
          "description": "a man fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.63
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5971,
            5975
          ],
          "representative_frame": 5971,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9345775246620178,
              "bbox": [
                245.65390014648438,
                18.914880752563477,
                358.1177062988281,
                309.7571716308594
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5976,
            5980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5981,
            5985
          ],
          "representative_frame": 5981,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9488586783409119,
              "bbox": [
                248.0501708984375,
                9.367741584777832,
                373.0955810546875,
                325.4680480957031
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5986,
            5990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5991,
            5995
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9332122206687927,
              "bbox": [
                259.8188171386719,
                0.09568920731544495,
                385.4507751464844,
                299.5788269042969
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5996,
            6000
          ],
          "representative_frame": 5996,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 49
    },
    {
      "second": 200,
      "time_range": [
        200,
        200.999
      ],
      "frame_range": [
        6001,
        6030
      ],
      "unified_description": "1 second video showing a man in a red jacket standing on the shore",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:19",
        "processing_time": 2.33,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6015,
          "frame_range": [
            6011,
            6015
          ],
          "description": "a man in a red jacket is standing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.12
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6001,
            6005
          ],
          "representative_frame": 6001,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9441232681274414,
              "bbox": [
                253.46600341796875,
                0.0,
                388.6316833496094,
                304.4294738769531
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6006,
            6010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6011,
            6015
          ],
          "representative_frame": 6011,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9437474608421326,
              "bbox": [
                246.7202911376953,
                0.0,
                397.7551574707031,
                325.9845886230469
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6016,
            6020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6021,
            6025
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8782771825790405,
              "bbox": [
                241.58070373535156,
                0.0,
                406.6512756347656,
                343.8962097167969
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6026,
            6030
          ],
          "representative_frame": 6026,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 50
    },
    {
      "second": 201,
      "time_range": [
        201,
        201.999
      ],
      "frame_range": [
        6031,
        6060
      ],
      "unified_description": "\n\nThis is an outdoor scene featuring a young boy near a body of water, most likely a lake. The image appears to have been captured using a wide-angle lens, which provides a more immersive view of the surroundings. There are a few other people in the background, indicating that this might be a popular location or a gathering area. Overall, the scene suggests a leisurely and enjoyable time outdoors with people around, perhaps participating in water activities or simply enjoying the natural setting.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:23",
        "processing_time": 3.9,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6045,
          "frame_range": [
            6041,
            6045
          ],
          "description": "a little boy standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.31
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6031,
            6035
          ],
          "representative_frame": 6031,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8989170789718628,
              "bbox": [
                252.36761474609375,
                0.0,
                420.5457763671875,
                353.2558898925781
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6036,
            6040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6041,
            6045
          ],
          "representative_frame": 6041,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.761814534664154,
              "bbox": [
                250.547119140625,
                0.0,
                418.1094970703125,
                356.3153991699219
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6046,
            6050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6051,
            6055
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7973104119300842,
              "bbox": [
                247.8766326904297,
                7.033366680145264,
                411.1996154785156,
                358.48175048828125
              ]
            },
            {
              "track_id": 391,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.5573267936706543,
              "bbox": [
                212.22254943847656,
                55.33290481567383,
                329.07440185546875,
                241.322021484375
              ]
            }
          ],
          "unique_tracks": [
            388,
            391
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            6056,
            6060
          ],
          "representative_frame": 6056,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 50
    },
    {
      "second": 202,
      "time_range": [
        202,
        202.999
      ],
      "frame_range": [
        6061,
        6090
      ],
      "unified_description": "\nI'll try to provide a more detailed description based on what I see in the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:23",
        "processing_time": 4.14,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6075,
          "frame_range": [
            6071,
            6075
          ],
          "description": "a man in a raincoat is fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.24
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6061,
            6065
          ],
          "representative_frame": 6061,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8767443299293518,
              "bbox": [
                233.9271697998047,
                8.778407096862793,
                394.451904296875,
                358.5541687011719
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6066,
            6070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6071,
            6075
          ],
          "representative_frame": 6071,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9420968890190125,
              "bbox": [
                186.2733154296875,
                2.106658458709717,
                361.94134521484375,
                358.5594787597656
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6076,
            6080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6081,
            6085
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9415079355239868,
              "bbox": [
                163.86956787109375,
                0.0,
                352.63330078125,
                358.542236328125
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6086,
            6090
          ],
          "representative_frame": 6086,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 50
    },
    {
      "second": 203,
      "time_range": [
        203,
        203.999
      ],
      "frame_range": [
        6091,
        6120
      ],
      "unified_description": "1-second scene where a man is fishing outdoors in the rain. The image includes some details about the camera's perspective, field of view, and possible artifacts.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:24",
        "processing_time": 4.1,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6105,
          "frame_range": [
            6101,
            6105
          ],
          "description": "a man in a raincoat fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.65
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6091,
            6095
          ],
          "representative_frame": 6091,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9430614709854126,
              "bbox": [
                135.95204162597656,
                0.0,
                339.63623046875,
                357.96533203125
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6096,
            6100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6101,
            6105
          ],
          "representative_frame": 6101,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9112944006919861,
              "bbox": [
                120.48165893554688,
                0.0,
                339.6258544921875,
                358.286376953125
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6106,
            6110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6111,
            6115
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 387,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8293517827987671,
              "bbox": [
                352.3885192871094,
                2.039912700653076,
                487.70556640625,
                355.32061767578125
              ]
            }
          ],
          "unique_tracks": [
            387
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6116,
            6120
          ],
          "representative_frame": 6116,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 50
    },
    {
      "second": 204,
      "time_range": [
        204,
        204.999
      ],
      "frame_range": [
        6121,
        6150
      ],
      "unified_description": "3D object tracking and content analysis, with details like \"a man in a red raincoat fishing on the shore\".",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:27",
        "processing_time": 2.55,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6135,
          "frame_range": [
            6131,
            6135
          ],
          "description": "a man in a red raincoat fishing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.61
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6121,
            6125
          ],
          "representative_frame": 6121,
          "detections": [
            {
              "track_id": 387,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9245981574058533,
              "bbox": [
                355.93743896484375,
                1.1812012195587158,
                502.6437683105469,
                355.88360595703125
              ]
            }
          ],
          "unique_tracks": [
            387
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6126,
            6130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6131,
            6135
          ],
          "representative_frame": 6131,
          "detections": [
            {
              "track_id": 387,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.931547224521637,
              "bbox": [
                354.6319885253906,
                1.0544368028640747,
                507.18731689453125,
                354.9691162109375
              ]
            }
          ],
          "unique_tracks": [
            387
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6136,
            6140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6141,
            6145
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 387,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9312980771064758,
              "bbox": [
                351.8567810058594,
                0.6346862316131592,
                509.6916809082031,
                355.9565734863281
              ]
            }
          ],
          "unique_tracks": [
            387
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6146,
            6150
          ],
          "representative_frame": 6146,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 51
    },
    {
      "second": 205,
      "time_range": [
        205,
        205.999
      ],
      "frame_range": [
        6151,
        6180
      ],
      "unified_description": "36-second scene with a total of 10 unique objects or people detected",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:27",
        "processing_time": 2.52,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6165,
          "frame_range": [
            6161,
            6165
          ],
          "description": "a man in a raincoat is fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.78
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6151,
            6155
          ],
          "representative_frame": 6151,
          "detections": [
            {
              "track_id": 387,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9153900742530823,
              "bbox": [
                349.7563781738281,
                0.30650413036346436,
                510.5262451171875,
                355.8551330566406
              ]
            }
          ],
          "unique_tracks": [
            387
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6156,
            6160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6161,
            6165
          ],
          "representative_frame": 6161,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9306058883666992,
              "bbox": [
                130.06112670898438,
                0.0,
                368.8717956542969,
                354.7546691894531
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6166,
            6170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6171,
            6175
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.933128833770752,
              "bbox": [
                115.3006362915039,
                0.5051048994064331,
                374.9957275390625,
                354.66448974609375
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6176,
            6180
          ],
          "representative_frame": 6176,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 51
    },
    {
      "second": 206,
      "time_range": [
        206,
        206.999
      ],
      "frame_range": [
        6181,
        6210
      ],
      "unified_description": "5-second summary for a video with one person and some water in the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:28",
        "processing_time": 2.69,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6195,
          "frame_range": [
            6191,
            6195
          ],
          "description": "a man in a black jacket is standing near the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.1
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6181,
            6185
          ],
          "representative_frame": 6181,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9064615964889526,
              "bbox": [
                159.94688415527344,
                0.7804595232009888,
                425.7971496582031,
                353.9146423339844
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6186,
            6190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6191,
            6195
          ],
          "representative_frame": 6191,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9015679359436035,
              "bbox": [
                188.20855712890625,
                0.6729761362075806,
                461.447265625,
                354.4644775390625
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6196,
            6200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6201,
            6205
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9016116857528687,
              "bbox": [
                213.82107543945312,
                0.48543763160705566,
                496.3941345214844,
                353.29656982421875
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6206,
            6210
          ],
          "representative_frame": 6206,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 51
    },
    {
      "second": 207,
      "time_range": [
        207,
        207.999
      ],
      "frame_range": [
        6211,
        6240
      ],
      "unified_description": "3D model of a scene with people in it",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:30",
        "processing_time": 2.26,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6225,
          "frame_range": [
            6221,
            6225
          ],
          "description": "a man in a black jacket is standing in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.36
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6211,
            6215
          ],
          "representative_frame": 6211,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9352431297302246,
              "bbox": [
                275.1500549316406,
                0.5937756896018982,
                568.2796020507812,
                354.1919250488281
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6216,
            6220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6221,
            6225
          ],
          "representative_frame": 6221,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            6226,
            6230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6231,
            6235
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8865185379981995,
              "bbox": [
                262.5628356933594,
                0.8138175010681152,
                558.5413818359375,
                355.8460388183594
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6236,
            6240
          ],
          "representative_frame": 6236,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 51
    },
    {
      "second": 208,
      "time_range": [
        208,
        208.999
      ],
      "frame_range": [
        6241,
        6270
      ],
      "unified_description": "30-second camera perspective, third-person POV, wide-angle lens with distortion, stable camera positioning, action camera style, natural outdoor lighting, frame composition including a man standing on the shore of a lake.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:32",
        "processing_time": 2.92,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6255,
          "frame_range": [
            6251,
            6255
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.66
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6241,
            6245
          ],
          "representative_frame": 6241,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9124066233634949,
              "bbox": [
                264.5577392578125,
                0.5308300256729126,
                559.4473266601562,
                354.8349304199219
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6246,
            6250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6251,
            6255
          ],
          "representative_frame": 6251,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.897496223449707,
              "bbox": [
                255.70571899414062,
                0.4767564833164215,
                552.37451171875,
                354.174560546875
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6256,
            6260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6261,
            6265
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8721825480461121,
              "bbox": [
                247.0966339111328,
                0.5763499140739441,
                546.3692626953125,
                353.8887023925781
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6266,
            6270
          ],
          "representative_frame": 6266,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 52
    },
    {
      "second": 209,
      "time_range": [
        209,
        209.999
      ],
      "frame_range": [
        6271,
        6300
      ],
      "unified_description": "3rd person perspective using a wide-angle lens capturing a man holding a fish in his hand.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:33",
        "processing_time": 3.45,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6285,
          "frame_range": [
            6281,
            6285
          ],
          "description": "a man is holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.23
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6271,
            6275
          ],
          "representative_frame": 6271,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9128134846687317,
              "bbox": [
                288.01373291015625,
                0.7237901091575623,
                593.818359375,
                354.83502197265625
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6276,
            6280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6281,
            6285
          ],
          "representative_frame": 6281,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9270437955856323,
              "bbox": [
                300.5902404785156,
                0.9250839948654175,
                611.6962280273438,
                354.7836608886719
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6286,
            6290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6291,
            6295
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9444047212600708,
              "bbox": [
                301.3896484375,
                1.059016466140747,
                617.7859497070312,
                354.5417175292969
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6296,
            6300
          ],
          "representative_frame": 6296,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 52
    },
    {
      "second": 210,
      "time_range": [
        210,
        210.999
      ],
      "frame_range": [
        6301,
        6330
      ],
      "unified_description": "\n- Content: A person is walking with a fishing rod. The camera is pointing towards the person's right side.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:34",
        "processing_time": 2.76,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6315,
          "frame_range": [
            6311,
            6315
          ],
          "description": "a man in a wet suit holding a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.63
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6301,
            6305
          ],
          "representative_frame": 6301,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9502205848693848,
              "bbox": [
                302.4290466308594,
                1.035583734512329,
                622.8338623046875,
                354.15887451171875
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6306,
            6310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6311,
            6315
          ],
          "representative_frame": 6311,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.917542576789856,
              "bbox": [
                299.1771545410156,
                1.0667355060577393,
                624.1326293945312,
                354.5824890136719
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6316,
            6320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6321,
            6325
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9114586710929871,
              "bbox": [
                294.3997802734375,
                0.9156298041343689,
                623.906494140625,
                354.7994079589844
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6326,
            6330
          ],
          "representative_frame": 6326,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 52
    },
    {
      "second": 211,
      "time_range": [
        211,
        211.999
      ],
      "frame_range": [
        6331,
        6360
      ],
      "unified_description": "1-second scene that features a man with a wet suit on, and he is holding a fish. The camera perspective appears to be first-person.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:36",
        "processing_time": 2.64,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6345,
          "frame_range": [
            6341,
            6345
          ],
          "description": "a man in a wet suit is holding a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.55
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6331,
            6335
          ],
          "representative_frame": 6331,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9529431462287903,
              "bbox": [
                294.1497497558594,
                1.0381828546524048,
                626.608154296875,
                354.68560791015625
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6336,
            6340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6341,
            6345
          ],
          "representative_frame": 6341,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9548088908195496,
              "bbox": [
                291.19647216796875,
                0.9526873826980591,
                626.9508666992188,
                354.54705810546875
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6346,
            6350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6351,
            6355
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9530326724052429,
              "bbox": [
                288.46453857421875,
                0.8913083672523499,
                627.5166625976562,
                354.8181457519531
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6356,
            6360
          ],
          "representative_frame": 6356,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 52
    },
    {
      "second": 212,
      "time_range": [
        212,
        212.999
      ],
      "frame_range": [
        6361,
        6390
      ],
      "unified_description": "1-second scene, content description and technical details",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:37",
        "processing_time": 2.34,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6375,
          "frame_range": [
            6371,
            6375
          ],
          "description": "a person holding a small piece of wood",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.79
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6361,
            6365
          ],
          "representative_frame": 6361,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            6366,
            6370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6371,
            6375
          ],
          "representative_frame": 6371,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4224861264228821,
              "bbox": [
                0.0,
                73.1741943359375,
                419.39056396484375,
                349.9325256347656
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6376,
            6380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6381,
            6385
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7953743934631348,
              "bbox": [
                0.0,
                72.8823471069336,
                413.6941223144531,
                351.18560791015625
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6386,
            6390
          ],
          "representative_frame": 6386,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 53
    },
    {
      "second": 213,
      "time_range": [
        213,
        213.999
      ],
      "frame_range": [
        6391,
        6420
      ],
      "unified_description": "\nA person holding a small fish in their hand",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:37",
        "processing_time": 2.37,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6405,
          "frame_range": [
            6401,
            6405
          ],
          "description": "a person holding a small fish in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.16
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6391,
            6395
          ],
          "representative_frame": 6391,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8510057330131531,
              "bbox": [
                2.516371250152588,
                93.71826171875,
                393.74017333984375,
                351.71453857421875
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6396,
            6400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6401,
            6405
          ],
          "representative_frame": 6401,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8924845457077026,
              "bbox": [
                7.370102405548096,
                104.6580581665039,
                381.5767822265625,
                351.0360412597656
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6406,
            6410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6411,
            6415
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8902199268341064,
              "bbox": [
                6.802402019500732,
                108.7662124633789,
                372.7985534667969,
                349.4130859375
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6416,
            6420
          ],
          "representative_frame": 6416,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 53
    },
    {
      "second": 214,
      "time_range": [
        214,
        214.999
      ],
      "frame_range": [
        6421,
        6450
      ],
      "unified_description": "30 second video showing a person with a fish in their hand, taken with a GoPro-style camera, wide-angle perspective, stable camera positioning, and natural outdoor lighting.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:40",
        "processing_time": 2.74,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6435,
          "frame_range": [
            6431,
            6435
          ],
          "description": "a person holding a small fish in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.22
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6421,
            6425
          ],
          "representative_frame": 6421,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8833304047584534,
              "bbox": [
                2.1277084350585938,
                102.5057373046875,
                368.3147277832031,
                343.3427734375
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6426,
            6430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6431,
            6435
          ],
          "representative_frame": 6431,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8008123636245728,
              "bbox": [
                9.06409740447998,
                93.6899642944336,
                351.18951416015625,
                317.7395324707031
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6436,
            6440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6441,
            6445
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8868045806884766,
              "bbox": [
                0.0,
                88.53607940673828,
                361.02752685546875,
                334.3400573730469
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6446,
            6450
          ],
          "representative_frame": 6446,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 53
    },
    {
      "second": 215,
      "time_range": [
        215,
        215.999
      ],
      "frame_range": [
        6451,
        6480
      ],
      "unified_description": "30 fps camera with no idea what's happening in the scene",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:41",
        "processing_time": 2.47,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6465,
          "frame_range": [
            6461,
            6465
          ],
          "description": "a person holding a small animal in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.53
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6451,
            6455
          ],
          "representative_frame": 6451,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7717301249504089,
              "bbox": [
                0.0,
                91.63065338134766,
                369.29742431640625,
                337.4974060058594
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6456,
            6460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6461,
            6465
          ],
          "representative_frame": 6461,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8154164552688599,
              "bbox": [
                0.0,
                60.00202941894531,
                382.0087890625,
                316.80596923828125
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6466,
            6470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6471,
            6475
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.34084075689315796,
              "bbox": [
                269.18951416015625,
                1.0947002172470093,
                597.3445434570312,
                323.91949462890625
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6476,
            6480
          ],
          "representative_frame": 6476,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 53
    },
    {
      "second": 216,
      "time_range": [
        216,
        216.999
      ],
      "frame_range": [
        6481,
        6510
      ],
      "unified_description": "3rd person perspective, stable camera, wide-angle lens, action camera Mount on POV, no technical artifacts",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:42",
        "processing_time": 2.99,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6495,
          "frame_range": [
            6491,
            6495
          ],
          "description": "a man is standing on the beach with a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.23
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6481,
            6485
          ],
          "representative_frame": 6481,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6910065412521362,
              "bbox": [
                274.4746398925781,
                0.437101274728775,
                612.9236450195312,
                326.2739562988281
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6486,
            6490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6491,
            6495
          ],
          "representative_frame": 6491,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9175097346305847,
              "bbox": [
                286.0325012207031,
                0.12682871520519257,
                623.7780151367188,
                322.2907409667969
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6496,
            6500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6501,
            6505
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.921183168888092,
              "bbox": [
                284.1389465332031,
                0.8129590749740601,
                623.9762573242188,
                320.61334228515625
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6506,
            6510
          ],
          "representative_frame": 6506,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 54
    },
    {
      "second": 217,
      "time_range": [
        217,
        217.999
      ],
      "frame_range": [
        6511,
        6540
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:43",
        "processing_time": 2.11,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6525,
          "frame_range": [
            6521,
            6525
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.08
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6511,
            6515
          ],
          "representative_frame": 6511,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9105321764945984,
              "bbox": [
                301.525390625,
                0.9012078046798706,
                640.0,
                330.7409973144531
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8962520360946655,
              "bbox": [
                0.0,
                4.550429821014404,
                474.67633056640625,
                350.79876708984375
              ]
            }
          ],
          "unique_tracks": [
            388,
            402
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            6516,
            6520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6521,
            6525
          ],
          "representative_frame": 6521,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7033097743988037,
              "bbox": [
                280.58154296875,
                1.300646424293518,
                631.238037109375,
                331.4519958496094
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6526,
            6530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6531,
            6535
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.84503173828125,
              "bbox": [
                249.50733947753906,
                1.381282925605774,
                611.8765869140625,
                332.7330322265625
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6536,
            6540
          ],
          "representative_frame": 6536,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 54
    },
    {
      "second": 218,
      "time_range": [
        218,
        218.999
      ],
      "frame_range": [
        6541,
        6570
      ],
      "unified_description": "1-second scene, featuring a man holding a fish in his hand",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:45",
        "processing_time": 2.34,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6555,
          "frame_range": [
            6551,
            6555
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.34
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6541,
            6545
          ],
          "representative_frame": 6541,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5321466326713562,
              "bbox": [
                282.3339538574219,
                1.7357102632522583,
                640.0,
                333.3045959472656
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6661708354949951,
              "bbox": [
                111.01530456542969,
                0.0,
                591.2019653320312,
                335.1111145019531
              ]
            }
          ],
          "unique_tracks": [
            388,
            402
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            6546,
            6550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6551,
            6555
          ],
          "representative_frame": 6551,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.297696590423584,
              "bbox": [
                298.1143798828125,
                3.2354953289031982,
                640.0,
                340.4127502441406
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.25798308849334717,
              "bbox": [
                123.96733856201172,
                0.0,
                616.3834228515625,
                341.0155944824219
              ]
            }
          ],
          "unique_tracks": [
            388,
            402
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            6556,
            6560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6561,
            6565
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5430958271026611,
              "bbox": [
                323.64739990234375,
                2.1703197956085205,
                640.0,
                336.3757629394531
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.20820681750774384,
              "bbox": [
                136.17665100097656,
                0.0,
                622.5206298828125,
                333.8515625
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6751425266265869,
              "bbox": [
                134.83432006835938,
                0.6987549066543579,
                369.99078369140625,
                197.47401428222656
              ]
            }
          ],
          "unique_tracks": [
            388,
            402,
            411
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            6566,
            6570
          ],
          "representative_frame": 6566,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 54
    },
    {
      "second": 219,
      "time_range": [
        219,
        219.999
      ],
      "frame_range": [
        6571,
        6600
      ],
      "unified_description": "1-second scene showing a person with a fish in their hand. The camera is stable, capturing the first-person perspective of the individual. The image exhibits wide-angle distortion, which suggests that it was taken with a fisheye lens or in post-production to achieve an artistic effect.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:46",
        "processing_time": 3.47,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6585,
          "frame_range": [
            6581,
            6585
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6571,
            6575
          ],
          "representative_frame": 6571,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5869698524475098,
              "bbox": [
                334.6568908691406,
                1.9310275316238403,
                640.0,
                334.2169189453125
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.13474994897842407,
              "bbox": [
                130.4361114501953,
                0.0,
                617.165283203125,
                328.1998291015625
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6673977971076965,
              "bbox": [
                125.68344116210938,
                0.3454933166503906,
                354.87896728515625,
                191.5194854736328
              ]
            }
          ],
          "unique_tracks": [
            388,
            402,
            411
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            6576,
            6580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6581,
            6585
          ],
          "representative_frame": 6581,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7235931754112244,
              "bbox": [
                332.7736511230469,
                1.5637383460998535,
                640.0,
                333.091064453125
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.49829578399658203,
              "bbox": [
                123.48512268066406,
                0.9384151697158813,
                346.2714538574219,
                186.02157592773438
              ]
            },
            {
              "track_id": 413,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.5687150359153748,
              "bbox": [
                110.53095245361328,
                110.31366729736328,
                417.93597412109375,
                247.9656982421875
              ]
            }
          ],
          "unique_tracks": [
            388,
            411,
            413
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            6586,
            6590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6591,
            6595
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7118789553642273,
              "bbox": [
                335.7593078613281,
                1.010388731956482,
                640.0,
                335.96209716796875
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5328014492988586,
              "bbox": [
                117.51090240478516,
                0.8589312434196472,
                346.701171875,
                190.59182739257812
              ]
            },
            {
              "track_id": 413,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.49324002861976624,
              "bbox": [
                97.16114044189453,
                108.90518951416016,
                421.3746032714844,
                254.16748046875
              ]
            }
          ],
          "unique_tracks": [
            388,
            411,
            413
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            6596,
            6600
          ],
          "representative_frame": 6596,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 54
    },
    {
      "second": 220,
      "time_range": [
        220,
        220.999
      ],
      "frame_range": [
        6601,
        6630
      ],
      "unified_description": "\n\nIn the image, a woman is standing under a tree in an outdoor setting. A camera captures her image as she stands there. Since there are no additional context or details, we cannot determine if this scene is part of a video production or if it's just a snapshot taken from a larger video. The main focus of the image is the woman and the tree she's standing under.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:48",
        "processing_time": 3.83,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6615,
          "frame_range": [
            6611,
            6615
          ],
          "description": "a woman is standing under a tree",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.6
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6601,
            6605
          ],
          "representative_frame": 6601,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8945109248161316,
              "bbox": [
                122.74779510498047,
                59.19395065307617,
                552.8743896484375,
                348.9988098144531
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6606,
            6610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6611,
            6615
          ],
          "representative_frame": 6611,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4965454936027527,
              "bbox": [
                191.6177215576172,
                131.4430389404297,
                541.4425048828125,
                354.8806457519531
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6616,
            6620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6621,
            6625
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8102216720581055,
              "bbox": [
                188.04017639160156,
                104.78933715820312,
                586.2056274414062,
                355.56280517578125
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6626,
            6630
          ],
          "representative_frame": 6626,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 55
    },
    {
      "second": 221,
      "time_range": [
        221,
        221.999
      ],
      "frame_range": [
        6631,
        6660
      ],
      "unified_description": "\nBased on the image descriptions and object detections, this 1-second scene shows a man and a boy sitting under a tent. The video was captured using a first-person perspective camera setup. The camera positioning appears stable, and the lens characteristics show signs of wide-angle distortion. There are a total of 4 unique tracks in the video, representing various elements within the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:50",
        "processing_time": 4.22,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6645,
          "frame_range": [
            6641,
            6645
          ],
          "description": "a man and a boy sitting under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.93
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6631,
            6635
          ],
          "representative_frame": 6631,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8672677874565125,
              "bbox": [
                131.9727325439453,
                66.69285583496094,
                587.8345947265625,
                355.67803955078125
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6636,
            6640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6641,
            6645
          ],
          "representative_frame": 6641,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8388353586196899,
              "bbox": [
                335.3285217285156,
                58.227256774902344,
                628.4285888671875,
                351.5884094238281
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6646,
            6650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6651,
            6655
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.818041980266571,
              "bbox": [
                19.398387908935547,
                121.20805358886719,
                185.7737274169922,
                356.20208740234375
              ]
            },
            {
              "track_id": 418,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4133085608482361,
              "bbox": [
                212.57901000976562,
                250.42916870117188,
                283.61883544921875,
                334.86029052734375
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.569333553314209,
              "bbox": [
                344.8689270019531,
                56.806297302246094,
                631.2545166015625,
                354.38330078125
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.34227702021598816,
              "bbox": [
                192.151611328125,
                56.418453216552734,
                640.0,
                354.806884765625
              ]
            }
          ],
          "unique_tracks": [
            417,
            418,
            388,
            402
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            6656,
            6660
          ],
          "representative_frame": 6656,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 55
    },
    {
      "second": 222,
      "time_range": [
        222,
        222.999
      ],
      "frame_range": [
        6661,
        6690
      ],
      "unified_description": "4K WIDE ANGLE SHOT OF A TENT WITH SITTING MAN AND BOY",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:50",
        "processing_time": 3.32,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6675,
          "frame_range": [
            6671,
            6675
          ],
          "description": "a man and a boy sitting under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.0
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6661,
            6665
          ],
          "representative_frame": 6661,
          "detections": [
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8470178246498108,
              "bbox": [
                25.97020721435547,
                126.493408203125,
                189.6117706298828,
                356.78424072265625
              ]
            },
            {
              "track_id": 418,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4682199954986572,
              "bbox": [
                206.61386108398438,
                250.27761840820312,
                290.89202880859375,
                350.43109130859375
              ]
            },
            {
              "track_id": 419,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.37720656394958496,
              "bbox": [
                259.916015625,
                139.30503845214844,
                420.57867431640625,
                342.2505798339844
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6563935875892639,
              "bbox": [
                198.15443420410156,
                56.67018508911133,
                639.5816650390625,
                354.8049011230469
              ]
            }
          ],
          "unique_tracks": [
            417,
            418,
            419,
            402
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            6666,
            6670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6671,
            6675
          ],
          "representative_frame": 6671,
          "detections": [
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8492952585220337,
              "bbox": [
                18.382287979125977,
                121.42496490478516,
                185.5686492919922,
                356.40313720703125
              ]
            },
            {
              "track_id": 418,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.570812463760376,
              "bbox": [
                206.75164794921875,
                250.00308227539062,
                292.7203674316406,
                351.9324035644531
              ]
            },
            {
              "track_id": 419,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3571430742740631,
              "bbox": [
                253.45785522460938,
                143.86965942382812,
                410.2074890136719,
                342.1936340332031
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5841333270072937,
              "bbox": [
                215.1419219970703,
                58.368247985839844,
                639.383544921875,
                354.8839111328125
              ]
            }
          ],
          "unique_tracks": [
            417,
            418,
            419,
            402
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            6676,
            6680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6681,
            6685
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6099410057067871,
              "bbox": [
                200.92701721191406,
                20.435991287231445,
                640.0,
                353.39495849609375
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6545197367668152,
              "bbox": [
                66.53907012939453,
                0.4798116981983185,
                311.7594299316406,
                207.47537231445312
              ]
            }
          ],
          "unique_tracks": [
            402,
            411
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            6686,
            6690
          ],
          "representative_frame": 6686,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 55
    },
    {
      "second": 223,
      "time_range": [
        223,
        223.999
      ],
      "frame_range": [
        6691,
        6720
      ],
      "unified_description": "3rd person camera perspective, stable camera positioning, wide-angle distortion, action camera style, low light conditions, etc.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:52",
        "processing_time": 2.82,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6705,
          "frame_range": [
            6701,
            6705
          ],
          "description": "a man is holding a can of paint",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.87
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6691,
            6695
          ],
          "representative_frame": 6691,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.48362594842910767,
              "bbox": [
                139.30543518066406,
                6.200143337249756,
                634.4906616210938,
                354.00250244140625
              ]
            },
            {
              "track_id": 420,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5299025177955627,
              "bbox": [
                205.07920837402344,
                206.9620361328125,
                285.9054870605469,
                263.31427001953125
              ]
            },
            {
              "track_id": 421,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4276667535305023,
              "bbox": [
                0.07315954566001892,
                94.92594909667969,
                71.10456848144531,
                163.15472412109375
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3672417998313904,
              "bbox": [
                63.08264923095703,
                0.15203341841697693,
                304.1863708496094,
                208.2030792236328
              ]
            }
          ],
          "unique_tracks": [
            402,
            420,
            421,
            411
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            6696,
            6700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6701,
            6705
          ],
          "representative_frame": 6701,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6176756024360657,
              "bbox": [
                175.30654907226562,
                1.3424288034439087,
                640.0,
                351.3154602050781
              ]
            },
            {
              "track_id": 420,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4818666875362396,
              "bbox": [
                207.55044555664062,
                207.36141967773438,
                287.6315002441406,
                263.052734375
              ]
            },
            {
              "track_id": 421,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4127226769924164,
              "bbox": [
                0.10494028031826019,
                94.98773193359375,
                71.04601287841797,
                163.12884521484375
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7448037266731262,
              "bbox": [
                64.75691223144531,
                0.3515937328338623,
                302.40240478515625,
                208.9309844970703
              ]
            },
            {
              "track_id": 424,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.4165266156196594,
              "bbox": [
                205.08404541015625,
                207.2623748779297,
                289.0960388183594,
                263.3549499511719
              ]
            }
          ],
          "unique_tracks": [
            402,
            420,
            421,
            411,
            424
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            6706,
            6710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6711,
            6715
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5475406050682068,
              "bbox": [
                135.68069458007812,
                0.0,
                634.2582397460938,
                351.91650390625
              ]
            },
            {
              "track_id": 420,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.42956215143203735,
              "bbox": [
                207.36611938476562,
                207.48646545410156,
                287.8657531738281,
                263.3150634765625
              ]
            },
            {
              "track_id": 421,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4548235535621643,
              "bbox": [
                0.09770779311656952,
                95.01585388183594,
                71.01802062988281,
                163.136962890625
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.12130901962518692,
              "bbox": [
                67.49172973632812,
                0.7013951539993286,
                302.6189270019531,
                210.0314178466797
              ]
            },
            {
              "track_id": 424,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.4694996178150177,
              "bbox": [
                204.91822814941406,
                206.77149963378906,
                290.0022888183594,
                263.5428466796875
              ]
            },
            {
              "track_id": 427,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3270215392112732,
              "bbox": [
                446.8570251464844,
                10.573657035827637,
                636.1282958984375,
                274.8611755371094
              ]
            }
          ],
          "unique_tracks": [
            402,
            420,
            421,
            411,
            424,
            427
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            6716,
            6720
          ],
          "representative_frame": 6716,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 55
    },
    {
      "second": 224,
      "time_range": [
        224,
        224.999
      ],
      "frame_range": [
        6721,
        6750
      ],
      "unified_description": "1-second scene showing an outdoor area with people, buildings, trees, and sky. The main focus is on a man in a black jacket holding a red object. The camera positioning is handheld, capturing motion and following the subject as they move throughout the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:55",
        "processing_time": 3.1,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6735,
          "frame_range": [
            6731,
            6735
          ],
          "description": "a man in a black jacket is holding a red object",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.24
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6721,
            6725
          ],
          "representative_frame": 6721,
          "detections": [
            {
              "track_id": 402,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.1661340743303299,
              "bbox": [
                216.3283233642578,
                0.0,
                640.0,
                351.89306640625
              ]
            },
            {
              "track_id": 420,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.38896769285202026,
              "bbox": [
                206.2515411376953,
                207.83616638183594,
                286.1282043457031,
                263.11639404296875
              ]
            },
            {
              "track_id": 421,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3949429988861084,
              "bbox": [
                0.09066138416528702,
                95.01124572753906,
                70.96114349365234,
                163.08267211914062
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.18848007917404175,
              "bbox": [
                92.72015380859375,
                0.7560828328132629,
                334.7408447265625,
                211.46641540527344
              ]
            },
            {
              "track_id": 424,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.18920472264289856,
              "bbox": [
                204.38198852539062,
                207.8880615234375,
                287.4184875488281,
                263.2628173828125
              ]
            },
            {
              "track_id": 429,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6978908777236938,
              "bbox": [
                132.4040069580078,
                233.7292022705078,
                199.3929901123047,
                292.9944763183594
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3295516073703766,
              "bbox": [
                323.12091064453125,
                6.2806477546691895,
                640.0,
                354.4464111328125
              ]
            }
          ],
          "unique_tracks": [
            402,
            420,
            421,
            411,
            424,
            429,
            388
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            6726,
            6730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6731,
            6735
          ],
          "representative_frame": 6731,
          "detections": [
            {
              "track_id": 402,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.37573936581611633,
              "bbox": [
                144.98045349121094,
                0.0,
                632.8807983398438,
                350.4726867675781
              ]
            },
            {
              "track_id": 420,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.24555394053459167,
              "bbox": [
                205.80226135253906,
                207.80271911621094,
                286.8110656738281,
                263.7187194824219
              ]
            },
            {
              "track_id": 421,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.32127177715301514,
              "bbox": [
                0.10504377633333206,
                94.79680633544922,
                71.01097869873047,
                162.9144744873047
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2033984512090683,
              "bbox": [
                84.58351135253906,
                0.7713331580162048,
                323.62884521484375,
                209.6387481689453
              ]
            },
            {
              "track_id": 424,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3017408549785614,
              "bbox": [
                204.25384521484375,
                208.05752563476562,
                287.43408203125,
                263.4814453125
              ]
            },
            {
              "track_id": 429,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2732551395893097,
              "bbox": [
                132.47857666015625,
                233.8402862548828,
                199.2924041748047,
                292.9268493652344
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.11050843447446823,
              "bbox": [
                295.7803649902344,
                2.442678451538086,
                633.8748168945312,
                353.28448486328125
              ]
            }
          ],
          "unique_tracks": [
            402,
            420,
            421,
            411,
            424,
            429,
            388
          ],
          "total_detections": 7
        },
        {
          "group_index": 3,
          "frame_range": [
            6736,
            6740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6741,
            6745
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9012858271598816,
              "bbox": [
                297.30816650390625,
                4.330109119415283,
                636.0914306640625,
                355.1950988769531
              ]
            },
            {
              "track_id": 413,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8429858088493347,
              "bbox": [
                4.1521148681640625,
                122.38245391845703,
                357.7920837402344,
                295.0251770019531
              ]
            }
          ],
          "unique_tracks": [
            388,
            413
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            6746,
            6750
          ],
          "representative_frame": 6746,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 56
    },
    {
      "second": 225,
      "time_range": [
        225,
        225.999
      ],
      "frame_range": [
        6751,
        6780
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:55",
        "processing_time": 2.44,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6765,
          "frame_range": [
            6761,
            6765
          ],
          "description": "a man in a hat and jacket sitting under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.34
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6751,
            6755
          ],
          "representative_frame": 6751,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8577509522438049,
              "bbox": [
                310.03662109375,
                11.086136817932129,
                640.0,
                355.8888244628906
              ]
            },
            {
              "track_id": 435,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.6177734136581421,
              "bbox": [
                262.214111328125,
                305.9508056640625,
                309.64111328125,
                359.3163146972656
              ]
            },
            {
              "track_id": 413,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5776820182800293,
              "bbox": [
                12.844953536987305,
                123.80950927734375,
                342.3175354003906,
                297.058349609375
              ]
            }
          ],
          "unique_tracks": [
            388,
            435,
            413
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            6756,
            6760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6761,
            6765
          ],
          "representative_frame": 6761,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9159314632415771,
              "bbox": [
                308.7816467285156,
                7.746252536773682,
                640.0,
                356.54345703125
              ]
            },
            {
              "track_id": 435,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.10794641077518463,
              "bbox": [
                264.8383483886719,
                311.6382751464844,
                307.4444885253906,
                359.43115234375
              ]
            },
            {
              "track_id": 413,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.47599363327026367,
              "bbox": [
                19.941160202026367,
                124.22482299804688,
                332.3731689453125,
                300.03533935546875
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.34334689378738403,
              "bbox": [
                10.023387908935547,
                189.95254516601562,
                115.66928100585938,
                293.4367370605469
              ]
            },
            {
              "track_id": 441,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.34692224860191345,
              "bbox": [
                150.0071258544922,
                125.09706115722656,
                261.3541259765625,
                289.0628967285156
              ]
            }
          ],
          "unique_tracks": [
            388,
            435,
            413,
            440,
            441
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            6766,
            6770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6771,
            6775
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9168768525123596,
              "bbox": [
                318.5142822265625,
                6.6789350509643555,
                640.0,
                355.4156494140625
              ]
            },
            {
              "track_id": 435,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.19841037690639496,
              "bbox": [
                262.9247131347656,
                307.1968078613281,
                309.50457763671875,
                359.4585876464844
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.30850425362586975,
              "bbox": [
                9.883787155151367,
                189.9051513671875,
                115.59383392333984,
                293.4459228515625
              ]
            },
            {
              "track_id": 441,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6361762285232544,
              "bbox": [
                125.53994750976562,
                124.95928955078125,
                243.0895233154297,
                296.8571472167969
              ]
            },
            {
              "track_id": 442,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.43733862042427063,
              "bbox": [
                431.6375732421875,
                140.4542999267578,
                518.6357421875,
                257.6273498535156
              ]
            }
          ],
          "unique_tracks": [
            388,
            435,
            440,
            441,
            442
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            6776,
            6780
          ],
          "representative_frame": 6776,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 56
    },
    {
      "second": 226,
      "time_range": [
        226,
        226.999
      ],
      "frame_range": [
        6781,
        6810
      ],
      "unified_description": "\n\"The image is a video with a first person perspective, showing a man in a tent with a backpack. He appears to be standing still, as there is no motion blur visible. The scene is set in a tent-like area, with objects such as the backpack clearly visible. The camera positioning suggests it might have been mounted on the man's body or placed on a tripod.\"",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:17:57",
        "processing_time": 4.45,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6795,
          "frame_range": [
            6791,
            6795
          ],
          "description": "a man in a tent with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.28
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6781,
            6785
          ],
          "representative_frame": 6781,
          "detections": [
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.30330339074134827,
              "bbox": [
                12.139144897460938,
                189.87075805664062,
                117.35159301757812,
                292.7155456542969
              ]
            },
            {
              "track_id": 441,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8804963231086731,
              "bbox": [
                122.75525665283203,
                129.67681884765625,
                240.9300537109375,
                301.1404113769531
              ]
            },
            {
              "track_id": 442,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5289421081542969,
              "bbox": [
                429.84368896484375,
                140.4586944580078,
                522.5213623046875,
                265.87744140625
              ]
            },
            {
              "track_id": 427,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7731870412826538,
              "bbox": [
                435.16619873046875,
                2.7597365379333496,
                640.0,
                354.2037658691406
              ]
            }
          ],
          "unique_tracks": [
            440,
            441,
            442,
            427
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            6786,
            6790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6791,
            6795
          ],
          "representative_frame": 6791,
          "detections": [
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2534921169281006,
              "bbox": [
                13.395275115966797,
                190.0538787841797,
                119.29120635986328,
                293.2493591308594
              ]
            },
            {
              "track_id": 441,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8751628994941711,
              "bbox": [
                118.57791900634766,
                131.09828186035156,
                236.6781768798828,
                301.3661193847656
              ]
            },
            {
              "track_id": 442,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.512095034122467,
              "bbox": [
                429.0535583496094,
                140.7366943359375,
                523.3563232421875,
                269.2372131347656
              ]
            },
            {
              "track_id": 427,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5359945297241211,
              "bbox": [
                437.3916015625,
                1.9696238040924072,
                640.0,
                358.00714111328125
              ]
            },
            {
              "track_id": 435,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.33872854709625244,
              "bbox": [
                268.52069091796875,
                321.1178283691406,
                303.6540222167969,
                359.726318359375
              ]
            }
          ],
          "unique_tracks": [
            440,
            441,
            442,
            427,
            435
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            6796,
            6800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6801,
            6805
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2349052131175995,
              "bbox": [
                13.306594848632812,
                190.0580291748047,
                120.21986389160156,
                293.9296569824219
              ]
            },
            {
              "track_id": 441,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.85634845495224,
              "bbox": [
                117.8202896118164,
                131.29345703125,
                236.7355194091797,
                301.3850402832031
              ]
            },
            {
              "track_id": 442,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.45572394132614136,
              "bbox": [
                428.90545654296875,
                140.8196258544922,
                523.0447998046875,
                270.23748779296875
              ]
            },
            {
              "track_id": 427,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.1941307634115219,
              "bbox": [
                440.98614501953125,
                1.8216675519943237,
                640.0,
                359.7631530761719
              ]
            },
            {
              "track_id": 435,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.46225041151046753,
              "bbox": [
                269.08392333984375,
                323.1315002441406,
                303.1315612792969,
                359.7547302246094
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.771366536617279,
              "bbox": [
                313.06201171875,
                5.131360054016113,
                640.0,
                356.3928527832031
              ]
            }
          ],
          "unique_tracks": [
            440,
            441,
            442,
            427,
            435,
            388
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            6806,
            6810
          ],
          "representative_frame": 6806,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 56
    },
    {
      "second": 227,
      "time_range": [
        227,
        227.999
      ],
      "frame_range": [
        6811,
        6840
      ],
      "unified_description": "3rd person camera view capturing the outdoors, with people, buildings and cars in the scene. The camera is stable and mounted on a tripod for clear image capture.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:01",
        "processing_time": 3.19,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6825,
          "frame_range": [
            6821,
            6825
          ],
          "description": "a man in a red jacket is holding a bottle",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.3
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6811,
            6815
          ],
          "representative_frame": 6811,
          "detections": [
            {
              "track_id": 427,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8186240196228027,
              "bbox": [
                450.5802307128906,
                104.61427307128906,
                629.4789428710938,
                359.2945861816406
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5798450708389282,
              "bbox": [
                0.0,
                1.3928234577178955,
                191.16854858398438,
                339.7421569824219
              ]
            }
          ],
          "unique_tracks": [
            427,
            417
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            6816,
            6820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6821,
            6825
          ],
          "representative_frame": 6821,
          "detections": [
            {
              "track_id": 452,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5660808086395264,
              "bbox": [
                343.1739807128906,
                236.33367919921875,
                412.1368713378906,
                358.1391296386719
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7306510806083679,
              "bbox": [
                0.0,
                0.0,
                185.8615264892578,
                334.87359619140625
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8506879806518555,
              "bbox": [
                351.1827087402344,
                12.950785636901855,
                640.0,
                348.98382568359375
              ]
            }
          ],
          "unique_tracks": [
            452,
            417,
            388
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            6826,
            6830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6831,
            6835
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 452,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2703774869441986,
              "bbox": [
                342.2277526855469,
                236.23040771484375,
                411.464599609375,
                358.39569091796875
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7590495347976685,
              "bbox": [
                0.0,
                0.0,
                183.8363494873047,
                335.4529724121094
              ]
            },
            {
              "track_id": 455,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.513515830039978,
              "bbox": [
                377.69091796875,
                291.5622863769531,
                571.276123046875,
                359.22821044921875
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8211390376091003,
              "bbox": [
                364.6678466796875,
                14.542474746704102,
                640.0,
                341.4444580078125
              ]
            }
          ],
          "unique_tracks": [
            452,
            417,
            455,
            388
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            6836,
            6840
          ],
          "representative_frame": 6836,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 56
    },
    {
      "second": 228,
      "time_range": [
        228,
        228.999
      ],
      "frame_range": [
        6841,
        6870
      ],
      "unified_description": "\nA man in a red jacket is holding a bottle",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:00",
        "processing_time": 2.26,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6855,
          "frame_range": [
            6851,
            6855
          ],
          "description": "a man in a red jacket is holding a bottle",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.19
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6841,
            6845
          ],
          "representative_frame": 6841,
          "detections": [
            {
              "track_id": 452,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4500824511051178,
              "bbox": [
                342.1975402832031,
                236.15695190429688,
                411.53131103515625,
                358.2924499511719
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7172395586967468,
              "bbox": [
                0.0,
                0.0,
                180.88348388671875,
                336.58795166015625
              ]
            },
            {
              "track_id": 455,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4295124411582947,
              "bbox": [
                380.7667236328125,
                285.8868713378906,
                588.4595336914062,
                358.67486572265625
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5911937952041626,
              "bbox": [
                372.4068298339844,
                17.472946166992188,
                640.0,
                334.2238464355469
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.35608530044555664,
              "bbox": [
                217.92202758789062,
                15.482218742370605,
                640.0,
                348.4043273925781
              ]
            },
            {
              "track_id": 413,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8563790321350098,
              "bbox": [
                0.0,
                51.42349624633789,
                412.007080078125,
                354.1822814941406
              ]
            }
          ],
          "unique_tracks": [
            452,
            417,
            455,
            388,
            402,
            413
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            6846,
            6850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6851,
            6855
          ],
          "representative_frame": 6851,
          "detections": [
            {
              "track_id": 452,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4676458537578583,
              "bbox": [
                341.96929931640625,
                236.3419952392578,
                411.3583984375,
                358.2865905761719
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7140898704528809,
              "bbox": [
                0.0,
                0.0,
                177.24156188964844,
                335.5547790527344
              ]
            },
            {
              "track_id": 455,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3972112834453583,
              "bbox": [
                374.51239013671875,
                278.1181335449219,
                602.1869506835938,
                358.3796691894531
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.781935453414917,
              "bbox": [
                374.0222473144531,
                20.417503356933594,
                640.0,
                338.7944030761719
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.11238360404968262,
              "bbox": [
                229.73464965820312,
                17.12054443359375,
                640.0,
                350.8766784667969
              ]
            }
          ],
          "unique_tracks": [
            452,
            417,
            455,
            388,
            402
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            6856,
            6860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6861,
            6865
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 452,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4711056053638458,
              "bbox": [
                342.3114013671875,
                236.41610717773438,
                411.8475036621094,
                358.2175598144531
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7048091888427734,
              "bbox": [
                0.0,
                0.0,
                173.9270782470703,
                333.30029296875
              ]
            },
            {
              "track_id": 455,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.40511494874954224,
              "bbox": [
                370.9161071777344,
                273.86920166015625,
                608.4481201171875,
                358.2864990234375
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8376133441925049,
              "bbox": [
                375.8164978027344,
                22.05154037475586,
                640.0,
                339.4366760253906
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.11600625514984131,
              "bbox": [
                242.41319274902344,
                18.78618049621582,
                640.0,
                351.5207214355469
              ]
            }
          ],
          "unique_tracks": [
            452,
            417,
            455,
            388,
            402
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            6866,
            6870
          ],
          "representative_frame": 6866,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 57
    },
    {
      "second": 229,
      "time_range": [
        229,
        229.999
      ],
      "frame_range": [
        6871,
        6900
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:01",
        "processing_time": 2.3,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6885,
          "frame_range": [
            6881,
            6885
          ],
          "description": "a man in a tent with a bag of food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6871,
            6875
          ],
          "representative_frame": 6871,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9136029481887817,
              "bbox": [
                197.30592346191406,
                8.665512084960938,
                632.939697265625,
                353.3582458496094
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4954475164413452,
              "bbox": [
                19.041061401367188,
                226.61399841308594,
                98.0091552734375,
                301.1745300292969
              ]
            }
          ],
          "unique_tracks": [
            402,
            440
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            6876,
            6880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6881,
            6885
          ],
          "representative_frame": 6881,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8636137247085571,
              "bbox": [
                229.78640747070312,
                3.782989740371704,
                640.0,
                354.4073486328125
              ]
            },
            {
              "track_id": 457,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8233681917190552,
              "bbox": [
                259.1431579589844,
                135.63604736328125,
                332.0317687988281,
                223.3592987060547
              ]
            },
            {
              "track_id": 458,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.31491807103157043,
              "bbox": [
                0.013931456953287125,
                269.2977600097656,
                124.65837097167969,
                358.4083557128906
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3826335668563843,
              "bbox": [
                20.00392723083496,
                229.34011840820312,
                95.09803771972656,
                297.41656494140625
              ]
            }
          ],
          "unique_tracks": [
            402,
            457,
            458,
            440
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            6886,
            6890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6891,
            6895
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8514543175697327,
              "bbox": [
                260.9446105957031,
                1.0905195474624634,
                640.0,
                353.9670104980469
              ]
            },
            {
              "track_id": 457,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8608945608139038,
              "bbox": [
                255.04800415039062,
                135.07432556152344,
                333.75946044921875,
                229.4967803955078
              ]
            },
            {
              "track_id": 458,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3968731164932251,
              "bbox": [
                0.0,
                268.6999206542969,
                125.17280578613281,
                358.43017578125
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.35216936469078064,
              "bbox": [
                19.095741271972656,
                229.1086883544922,
                95.68680572509766,
                296.32196044921875
              ]
            }
          ],
          "unique_tracks": [
            402,
            457,
            458,
            440
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            6896,
            6900
          ],
          "representative_frame": 6896,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 57
    },
    {
      "second": 230,
      "time_range": [
        230,
        230.999
      ],
      "frame_range": [
        6901,
        6930
      ],
      "unified_description": "500 words maximum",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:03",
        "processing_time": 2.19,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6915,
          "frame_range": [
            6911,
            6915
          ],
          "description": "a man in a tent with a baby",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.91
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6901,
            6905
          ],
          "representative_frame": 6901,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9012885689735413,
              "bbox": [
                276.8713073730469,
                0.7036147713661194,
                640.0,
                353.29150390625
              ]
            },
            {
              "track_id": 457,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8740233778953552,
              "bbox": [
                253.4138641357422,
                133.29844665527344,
                337.2029113769531,
                233.4121551513672
              ]
            },
            {
              "track_id": 458,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3024110198020935,
              "bbox": [
                0.9548792243003845,
                268.26055908203125,
                126.7041244506836,
                358.1280212402344
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4833076298236847,
              "bbox": [
                16.731630325317383,
                228.37950134277344,
                96.93751525878906,
                296.864990234375
              ]
            }
          ],
          "unique_tracks": [
            402,
            457,
            458,
            440
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            6906,
            6910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6911,
            6915
          ],
          "representative_frame": 6911,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.853409469127655,
              "bbox": [
                241.0958251953125,
                12.9699125289917,
                629.3676147460938,
                354.5517578125
              ]
            },
            {
              "track_id": 457,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8063774108886719,
              "bbox": [
                258.8204345703125,
                138.55892944335938,
                351.0919494628906,
                250.13168334960938
              ]
            },
            {
              "track_id": 458,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7110651135444641,
              "bbox": [
                0.0,
                266.1201477050781,
                128.44833374023438,
                358.6310119628906
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.27609944343566895,
              "bbox": [
                16.329708099365234,
                227.43373107910156,
                95.52125549316406,
                294.1175537109375
              ]
            }
          ],
          "unique_tracks": [
            402,
            457,
            458,
            440
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            6916,
            6920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6921,
            6925
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8780789971351624,
              "bbox": [
                229.0819854736328,
                17.898977279663086,
                607.0465087890625,
                355.2533874511719
              ]
            },
            {
              "track_id": 457,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8625630140304565,
              "bbox": [
                263.14312744140625,
                140.60910034179688,
                353.888671875,
                251.76290893554688
              ]
            },
            {
              "track_id": 458,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.713030219078064,
              "bbox": [
                0.0,
                265.53033447265625,
                128.71949768066406,
                358.7715759277344
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.22193080186843872,
              "bbox": [
                15.695330619812012,
                227.08995056152344,
                95.6608657836914,
                293.69775390625
              ]
            },
            {
              "track_id": 465,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7865556478500366,
              "bbox": [
                154.4227294921875,
                108.57969665527344,
                242.60707092285156,
                262.98114013671875
              ]
            },
            {
              "track_id": 467,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3220061957836151,
              "bbox": [
                0.43350425362586975,
                266.8280029296875,
                214.6398162841797,
                358.126953125
              ]
            }
          ],
          "unique_tracks": [
            402,
            457,
            458,
            440,
            465,
            467
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            6926,
            6930
          ],
          "representative_frame": 6926,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 57
    },
    {
      "second": 231,
      "time_range": [
        231,
        231.999
      ],
      "frame_range": [
        6931,
        6960
      ],
      "unified_description": "3D model available on request",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:04",
        "processing_time": 2.19,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6945,
          "frame_range": [
            6941,
            6945
          ],
          "description": "a man in a tent with a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.18
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6931,
            6935
          ],
          "representative_frame": 6931,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8529350161552429,
              "bbox": [
                248.95718383789062,
                17.453413009643555,
                614.927978515625,
                354.7611389160156
              ]
            },
            {
              "track_id": 457,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.850034773349762,
              "bbox": [
                264.7929992675781,
                141.206298828125,
                354.7918701171875,
                253.1171417236328
              ]
            },
            {
              "track_id": 458,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7157711982727051,
              "bbox": [
                0.0,
                265.2323303222656,
                128.69065856933594,
                358.8520812988281
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.26940199732780457,
              "bbox": [
                15.0525484085083,
                227.16482543945312,
                96.12730407714844,
                294.0672912597656
              ]
            },
            {
              "track_id": 465,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7570905685424805,
              "bbox": [
                156.95358276367188,
                108.03646087646484,
                240.5365447998047,
                254.38392639160156
              ]
            },
            {
              "track_id": 467,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.41752439737319946,
              "bbox": [
                1.4688165187835693,
                266.904541015625,
                215.6767120361328,
                358.1792907714844
              ]
            },
            {
              "track_id": 468,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6485873460769653,
              "bbox": [
                213.42007446289062,
                242.82354736328125,
                353.0655517578125,
                358.5649719238281
              ]
            }
          ],
          "unique_tracks": [
            402,
            457,
            458,
            440,
            465,
            467,
            468
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            6936,
            6940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6941,
            6945
          ],
          "representative_frame": 6941,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8403683304786682,
              "bbox": [
                252.49090576171875,
                13.989725112915039,
                612.4807739257812,
                354.2956237792969
              ]
            },
            {
              "track_id": 457,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8334612846374512,
              "bbox": [
                267.4932556152344,
                141.5215301513672,
                352.9209289550781,
                249.1789093017578
              ]
            },
            {
              "track_id": 458,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7247782945632935,
              "bbox": [
                0.0,
                265.2107238769531,
                128.5560760498047,
                358.90185546875
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2264600396156311,
              "bbox": [
                14.958361625671387,
                227.3367156982422,
                96.34932708740234,
                293.90380859375
              ]
            },
            {
              "track_id": 465,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8282833695411682,
              "bbox": [
                157.37997436523438,
                111.7190170288086,
                239.92385864257812,
                256.2870788574219
              ]
            },
            {
              "track_id": 467,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.37954118847846985,
              "bbox": [
                0.76870197057724,
                266.4239807128906,
                216.17552185058594,
                358.2045593261719
              ]
            },
            {
              "track_id": 468,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.30808910727500916,
              "bbox": [
                207.20681762695312,
                220.5678253173828,
                372.4353942871094,
                357.8721008300781
              ]
            }
          ],
          "unique_tracks": [
            402,
            457,
            458,
            440,
            465,
            467,
            468
          ],
          "total_detections": 7
        },
        {
          "group_index": 3,
          "frame_range": [
            6946,
            6950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6951,
            6955
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9578766822814941,
              "bbox": [
                232.30352783203125,
                5.266718864440918,
                609.3621215820312,
                354.8163757324219
              ]
            },
            {
              "track_id": 465,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.14959293603897095,
              "bbox": [
                176.93516540527344,
                127.62432098388672,
                246.2564697265625,
                245.57855224609375
              ]
            }
          ],
          "unique_tracks": [
            402,
            465
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            6956,
            6960
          ],
          "representative_frame": 6956,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 57
    },
    {
      "second": 232,
      "time_range": [
        232,
        232.999
      ],
      "frame_range": [
        6961,
        6990
      ],
      "unified_description": "3rd person perspective with slight camera movement. The scene depicts an action packed scene inside a tent with multiple people present.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:05",
        "processing_time": 2.73,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6975,
          "frame_range": [
            6971,
            6975
          ],
          "description": "a man in a tent with a knife and other people",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.3
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6961,
            6965
          ],
          "representative_frame": 6961,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9584329724311829,
              "bbox": [
                227.431884765625,
                1.8691693544387817,
                613.625244140625,
                355.0589904785156
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4150582551956177,
              "bbox": [
                0.7588577270507812,
                73.5188217163086,
                83.83265686035156,
                349.98638916015625
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4742245376110077,
              "bbox": [
                43.089847564697266,
                184.02378845214844,
                159.4669952392578,
                358.7969970703125
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            6966,
            6970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6971,
            6975
          ],
          "representative_frame": 6971,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.959052324295044,
              "bbox": [
                231.0695343017578,
                0.9145864844322205,
                621.37939453125,
                355.17205810546875
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4806930422782898,
              "bbox": [
                0.7388734817504883,
                73.47834777832031,
                83.99208068847656,
                350.4854431152344
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3529253602027893,
              "bbox": [
                43.708492279052734,
                185.43540954589844,
                155.82957458496094,
                360.0
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            6976,
            6980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6981,
            6985
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9460601806640625,
              "bbox": [
                242.7008819580078,
                0.5260948538780212,
                632.5220336914062,
                354.255859375
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6096359491348267,
              "bbox": [
                0.0,
                73.80928802490234,
                66.02099609375,
                295.7817687988281
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.36638426780700684,
              "bbox": [
                44.26191329956055,
                183.04733276367188,
                154.40675354003906,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4378148019313812,
              "bbox": [
                135.55763244628906,
                129.765380859375,
                273.1834411621094,
                262.32745361328125
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            6986,
            6990
          ],
          "representative_frame": 6986,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 58
    },
    {
      "second": 233,
      "time_range": [
        233,
        233.999
      ],
      "frame_range": [
        6991,
        7020
      ],
      "unified_description": "20 people standing in front of a giraffe",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:06",
        "processing_time": 2.32,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7005,
          "frame_range": [
            7001,
            7005
          ],
          "description": "a man in a tent with a cup",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.6
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6991,
            6995
          ],
          "representative_frame": 6991,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8876944780349731,
              "bbox": [
                269.7380065917969,
                0.09606051445007324,
                640.0,
                353.5037536621094
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.45333877205848694,
              "bbox": [
                0.0,
                79.11959075927734,
                66.25006103515625,
                335.17877197265625
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.13853131234645844,
              "bbox": [
                45.359397888183594,
                181.9726104736328,
                153.40577697753906,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5242965817451477,
              "bbox": [
                129.27767944335938,
                126.01863861083984,
                276.6637878417969,
                268.25360107421875
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3472670614719391,
              "bbox": [
                178.26425170898438,
                298.0702209472656,
                223.9020233154297,
                359.6528015136719
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476,
            482
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            6996,
            7000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7001,
            7005
          ],
          "representative_frame": 7001,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8790320158004761,
              "bbox": [
                280.9878234863281,
                0.24527613818645477,
                640.0,
                353.68310546875
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6378664374351501,
              "bbox": [
                0.0,
                80.0490951538086,
                58.128177642822266,
                297.36871337890625
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.1114872470498085,
              "bbox": [
                47.04829406738281,
                182.63172912597656,
                152.0357208251953,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.47399404644966125,
              "bbox": [
                127.12586212158203,
                124.77639770507812,
                277.5972900390625,
                270.4083557128906
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.37357157468795776,
              "bbox": [
                178.06141662597656,
                297.5702209472656,
                224.09532165527344,
                359.67889404296875
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476,
            482
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            7006,
            7010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7011,
            7015
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8673351407051086,
              "bbox": [
                287.2247619628906,
                0.0476604662835598,
                640.0,
                353.2257385253906
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5139912962913513,
              "bbox": [
                0.0,
                79.53573608398438,
                56.341922760009766,
                284.4383850097656
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.10824684053659439,
              "bbox": [
                48.523460388183594,
                182.62486267089844,
                151.3082733154297,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5263538360595703,
              "bbox": [
                127.67791748046875,
                124.71145629882812,
                276.5950927734375,
                269.2793884277344
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.49052876234054565,
              "bbox": [
                176.56532287597656,
                292.8330078125,
                226.04693603515625,
                359.7550354003906
              ]
            },
            {
              "track_id": 485,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.33568719029426575,
              "bbox": [
                319.2976379394531,
                106.75503540039062,
                373.1990966796875,
                158.59474182128906
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476,
            482,
            485
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            7016,
            7020
          ],
          "representative_frame": 7016,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 58
    },
    {
      "second": 234,
      "time_range": [
        234,
        234.999
      ],
      "frame_range": [
        7021,
        7050
      ],
      "unified_description": "\nThe image features a family in their home, with the father setting up a fun activity for his kids. They have gathered some toys and other items to participate in this enjoyable endeavor. The scene is set indoors within their living space where they often spend quality time together.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:08",
        "processing_time": 3.12,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7035,
          "frame_range": [
            7031,
            7035
          ],
          "description": "a man in a tent with two children",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7021,
            7025
          ],
          "representative_frame": 7021,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8625051975250244,
              "bbox": [
                289.9076232910156,
                0.022684982046484947,
                640.0,
                353.4309387207031
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6020572185516357,
              "bbox": [
                0.0,
                79.0031967163086,
                55.741172790527344,
                280.22503662109375
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.19060511887073517,
              "bbox": [
                49.69758224487305,
                182.66543579101562,
                150.63998413085938,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4642104506492615,
              "bbox": [
                128.37722778320312,
                125.01689147949219,
                275.7571105957031,
                268.6005554199219
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4145583510398865,
              "bbox": [
                176.7177734375,
                293.2164001464844,
                225.82518005371094,
                359.7292175292969
              ]
            },
            {
              "track_id": 485,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.6739083528518677,
              "bbox": [
                318.5480041503906,
                103.4946517944336,
                372.33477783203125,
                155.27767944335938
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476,
            482,
            485
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7026,
            7030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7031,
            7035
          ],
          "representative_frame": 7031,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8813963532447815,
              "bbox": [
                290.9293518066406,
                0.07278735935688019,
                640.0,
                354.3145446777344
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5786324739456177,
              "bbox": [
                0.0,
                79.04752349853516,
                55.61615753173828,
                279.6311950683594
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.12587343156337738,
              "bbox": [
                50.731868743896484,
                182.8064727783203,
                150.05029296875,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.469056636095047,
              "bbox": [
                128.7705841064453,
                124.84249114990234,
                275.4042663574219,
                268.30126953125
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.40025681257247925,
              "bbox": [
                177.4287872314453,
                295.1539306640625,
                225.0986328125,
                359.72955322265625
              ]
            },
            {
              "track_id": 485,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.6891332268714905,
              "bbox": [
                317.7949523925781,
                102.11734771728516,
                371.2287292480469,
                153.60975646972656
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476,
            482,
            485
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            7036,
            7040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7041,
            7045
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9054608941078186,
              "bbox": [
                293.9869079589844,
                0.4286781847476959,
                640.0,
                354.47149658203125
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6625608801841736,
              "bbox": [
                0.0,
                79.98149108886719,
                54.561397552490234,
                278.5587158203125
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.6197117567062378,
              "bbox": [
                51.45446014404297,
                183.16372680664062,
                149.30540466308594,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7661114931106567,
              "bbox": [
                143.18807983398438,
                124.55045318603516,
                277.5133056640625,
                254.29615783691406
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.27198830246925354,
              "bbox": [
                178.68093872070312,
                298.55865478515625,
                223.91432189941406,
                359.616943359375
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476,
            482
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7046,
            7050
          ],
          "representative_frame": 7046,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 58
    },
    {
      "second": 235,
      "time_range": [
        235,
        235.999
      ],
      "frame_range": [
        7051,
        7080
      ],
      "unified_description": "3rd person camera perspective showing an outdoor scene with people, tents, and other objects.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:09",
        "processing_time": 2.68,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7065,
          "frame_range": [
            7061,
            7065
          ],
          "description": "a man in a tent with a man in a hat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.22
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7051,
            7055
          ],
          "representative_frame": 7051,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9164955615997314,
              "bbox": [
                294.4214782714844,
                0.7028676271438599,
                640.0,
                353.8016052246094
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6860536336898804,
              "bbox": [
                0.0,
                80.67367553710938,
                53.81477737426758,
                278.1680908203125
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.40501776337623596,
              "bbox": [
                52.02840805053711,
                183.5350799560547,
                148.66639709472656,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6329675912857056,
              "bbox": [
                145.93869018554688,
                123.76118469238281,
                279.7756042480469,
                251.57916259765625
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.33416640758514404,
              "bbox": [
                177.1312713623047,
                294.1618957519531,
                225.4115447998047,
                359.5683288574219
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476,
            482
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7056,
            7060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7061,
            7065
          ],
          "representative_frame": 7061,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9249724745750427,
              "bbox": [
                292.10015869140625,
                0.7298018336296082,
                640.0,
                353.4800720214844
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6985617280006409,
              "bbox": [
                0.0,
                80.73072814941406,
                53.445003509521484,
                275.78228759765625
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5159158706665039,
              "bbox": [
                145.25186157226562,
                122.78148651123047,
                280.13818359375,
                250.5629119873047
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3107468783855438,
              "bbox": [
                177.13192749023438,
                293.28839111328125,
                225.94268798828125,
                359.545166015625
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            7066,
            7070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7071,
            7075
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9160416126251221,
              "bbox": [
                287.906982421875,
                0.8650400042533875,
                640.0,
                353.4119873046875
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5453139543533325,
              "bbox": [
                0.0,
                80.95523071289062,
                53.85555648803711,
                278.4161682128906
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8214492201805115,
              "bbox": [
                140.622802734375,
                122.43836975097656,
                275.9875183105469,
                250.24867248535156
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2923630177974701,
              "bbox": [
                178.9070281982422,
                298.6294860839844,
                224.06871032714844,
                359.5020446777344
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3331242799758911,
              "bbox": [
                52.282142639160156,
                181.0599365234375,
                148.81788635253906,
                359.9612731933594
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482,
            441
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7076,
            7080
          ],
          "representative_frame": 7076,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 58
    },
    {
      "second": 236,
      "time_range": [
        236,
        236.999
      ],
      "frame_range": [
        7081,
        7110
      ],
      "unified_description": "3rd person camera, stable on a tripod, capturing the scene of a man in a tent with a cell.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:09",
        "processing_time": 2.91,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7095,
          "frame_range": [
            7091,
            7095
          ],
          "description": "a man in a tent with a cell",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.73
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7081,
            7085
          ],
          "representative_frame": 7081,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9225226044654846,
              "bbox": [
                287.66729736328125,
                0.9742242693901062,
                640.0,
                353.52508544921875
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4356691539287567,
              "bbox": [
                0.0,
                81.07884979248047,
                54.57181930541992,
                280.3038024902344
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5406004786491394,
              "bbox": [
                139.42564392089844,
                121.59951782226562,
                273.9418640136719,
                247.98680114746094
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3393201231956482,
              "bbox": [
                177.7324676513672,
                295.5814514160156,
                225.01919555664062,
                359.4980163574219
              ]
            },
            {
              "track_id": 491,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.5644126534461975,
              "bbox": [
                263.1962890625,
                189.59896850585938,
                283.3963623046875,
                215.28981018066406
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.15748615562915802,
              "bbox": [
                53.24711227416992,
                181.3973846435547,
                148.28709411621094,
                359.1809997558594
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482,
            491,
            441
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7086,
            7090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7091,
            7095
          ],
          "representative_frame": 7091,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9471574425697327,
              "bbox": [
                289.911865234375,
                0.9601112008094788,
                640.0,
                354.4098205566406
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.23321621119976044,
              "bbox": [
                0.0,
                78.36995697021484,
                54.287078857421875,
                279.8919982910156
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.50784832239151,
              "bbox": [
                138.48558044433594,
                121.33110809326172,
                273.6882629394531,
                247.43515014648438
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.32298770546913147,
              "bbox": [
                178.09410095214844,
                297.0168762207031,
                224.4686737060547,
                359.5770568847656
              ]
            },
            {
              "track_id": 491,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.4681428074836731,
              "bbox": [
                265.2649841308594,
                193.01234436035156,
                284.6055908203125,
                217.71633911132812
              ]
            },
            {
              "track_id": 493,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.3117983937263489,
              "bbox": [
                0.3692871928215027,
                276.7031555175781,
                48.93646240234375,
                358.4153747558594
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482,
            491,
            493
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            7096,
            7100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7101,
            7105
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9141881465911865,
              "bbox": [
                267.66937255859375,
                0.8223068118095398,
                628.4371948242188,
                354.508056640625
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4006868302822113,
              "bbox": [
                0.0,
                76.42372131347656,
                54.31513977050781,
                280.4767150878906
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5237272381782532,
              "bbox": [
                135.7574005126953,
                120.34978485107422,
                274.99420166015625,
                249.83033752441406
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2761947512626648,
              "bbox": [
                177.50379943847656,
                295.1762390136719,
                225.28390502929688,
                359.7592468261719
              ]
            },
            {
              "track_id": 493,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.2755538523197174,
              "bbox": [
                0.3052240312099457,
                276.6531982421875,
                48.84467315673828,
                358.3212890625
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.365171879529953,
              "bbox": [
                0.0,
                78.07160186767578,
                57.79546356201172,
                349.2713928222656
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482,
            493,
            495
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            7106,
            7110
          ],
          "representative_frame": 7106,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 59
    },
    {
      "second": 237,
      "time_range": [
        237,
        237.999
      ],
      "frame_range": [
        7111,
        7140
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:12",
        "processing_time": 2.08,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7125,
          "frame_range": [
            7121,
            7125
          ],
          "description": "a man in a tent with a bunch of food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.67
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7111,
            7115
          ],
          "representative_frame": 7111,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9309440851211548,
              "bbox": [
                274.79254150390625,
                0.6510568857192993,
                636.3473510742188,
                355.7155456542969
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5416102409362793,
              "bbox": [
                0.0,
                76.25423431396484,
                54.2464599609375,
                280.7546081542969
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6485273838043213,
              "bbox": [
                130.65188598632812,
                120.71366882324219,
                273.39483642578125,
                253.9691162109375
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2911493182182312,
              "bbox": [
                178.38311767578125,
                297.51458740234375,
                224.52890014648438,
                359.6712341308594
              ]
            },
            {
              "track_id": 493,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.2971864342689514,
              "bbox": [
                0.37282055616378784,
                276.7535400390625,
                48.91032409667969,
                358.4108581542969
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.19300994277000427,
              "bbox": [
                0.7860912084579468,
                78.23521423339844,
                58.47787857055664,
                347.4379577636719
              ]
            },
            {
              "track_id": 499,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5974728465080261,
              "bbox": [
                275.08282470703125,
                314.7859802246094,
                330.1525573730469,
                350.7295227050781
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482,
            493,
            495,
            499
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            7116,
            7120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7121,
            7125
          ],
          "representative_frame": 7121,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9185000061988831,
              "bbox": [
                277.41302490234375,
                0.4822138845920563,
                638.4686279296875,
                356.2249450683594
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5356913805007935,
              "bbox": [
                0.0,
                76.2988052368164,
                54.16169738769531,
                281.30517578125
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5988385081291199,
              "bbox": [
                128.0443878173828,
                121.33773040771484,
                273.1365051269531,
                257.5572204589844
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4057933986186981,
              "bbox": [
                179.34852600097656,
                300.6723327636719,
                223.51210021972656,
                359.6469421386719
              ]
            },
            {
              "track_id": 493,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.27790147066116333,
              "bbox": [
                0.46147915720939636,
                276.9183654785156,
                48.96238708496094,
                358.4927673339844
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2616114616394043,
              "bbox": [
                0.13623107969760895,
                78.18976593017578,
                57.55588150024414,
                346.2047119140625
              ]
            },
            {
              "track_id": 499,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5470415949821472,
              "bbox": [
                273.5174560546875,
                314.8482360839844,
                331.3990173339844,
                352.98992919921875
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482,
            493,
            495,
            499
          ],
          "total_detections": 7
        },
        {
          "group_index": 3,
          "frame_range": [
            7126,
            7130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7131,
            7135
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8939712643623352,
              "bbox": [
                261.6943054199219,
                0.4754543900489807,
                626.1386108398438,
                355.5608825683594
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46065056324005127,
              "bbox": [
                0.0,
                76.80677795410156,
                53.99114990234375,
                281.7170104980469
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.54485684633255,
              "bbox": [
                128.3579559326172,
                122.50968170166016,
                274.8243103027344,
                261.0240783691406
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5332210659980774,
              "bbox": [
                179.2870635986328,
                300.9225769042969,
                223.5318603515625,
                359.7237243652344
              ]
            },
            {
              "track_id": 493,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.2470107078552246,
              "bbox": [
                0.47097113728523254,
                276.947509765625,
                48.91500473022461,
                358.4048156738281
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.34485819935798645,
              "bbox": [
                0.44304096698760986,
                78.17247009277344,
                58.07290267944336,
                347.0194091796875
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482,
            493,
            495
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            7136,
            7140
          ],
          "representative_frame": 7136,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 59
    },
    {
      "second": 238,
      "time_range": [
        238,
        238.999
      ],
      "frame_range": [
        7141,
        7170
      ],
      "unified_description": "3d, 360, virtual reality, augmented reality, mixed reality",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:13",
        "processing_time": 2.55,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7155,
          "frame_range": [
            7151,
            7155
          ],
          "description": "a man holding a bottle of beer",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.46
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7141,
            7145
          ],
          "representative_frame": 7141,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7617302536964417,
              "bbox": [
                310.3711853027344,
                0.8447405099868774,
                640.0,
                336.20513916015625
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.30973994731903076,
              "bbox": [
                1.6865428686141968,
                80.6738510131836,
                50.63480758666992,
                258.0514831542969
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8447892069816589,
              "bbox": [
                38.5333251953125,
                33.15327072143555,
                169.14723205566406,
                277.8338623046875
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            417
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            7146,
            7150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7151,
            7155
          ],
          "representative_frame": 7151,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9293692708015442,
              "bbox": [
                305.5116882324219,
                1.0991376638412476,
                640.0,
                346.434814453125
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.43119868636131287,
              "bbox": [
                212.99359130859375,
                82.66386413574219,
                343.5417175292969,
                211.8782196044922
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8812316656112671,
              "bbox": [
                12.118356704711914,
                28.737632751464844,
                147.5070343017578,
                278.97308349609375
              ]
            },
            {
              "track_id": 457,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5122563242912292,
              "bbox": [
                281.56414794921875,
                173.6093292236328,
                407.4764709472656,
                347.1879577636719
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            457
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            7156,
            7160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7161,
            7165
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9544684886932373,
              "bbox": [
                304.7966613769531,
                1.382267713546753,
                640.0,
                351.8780822753906
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3258250951766968,
              "bbox": [
                213.83778381347656,
                82.6830825805664,
                343.7372131347656,
                211.1994171142578
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9086689352989197,
              "bbox": [
                4.955087184906006,
                27.527606964111328,
                142.21029663085938,
                279.4150695800781
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4740968942642212,
              "bbox": [
                88.1131591796875,
                279.5060119628906,
                123.47235107421875,
                319.8712158203125
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.42194464802742004,
              "bbox": [
                226.589599609375,
                182.69497680664062,
                303.9703369140625,
                237.2140655517578
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            507
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7166,
            7170
          ],
          "representative_frame": 7166,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 59
    },
    {
      "second": 239,
      "time_range": [
        239,
        239.999
      ],
      "frame_range": [
        7171,
        7200
      ],
      "unified_description": "1-second scene including a man in a tent with a bottle of beer",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:13",
        "processing_time": 2.65,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7185,
          "frame_range": [
            7181,
            7185
          ],
          "description": "a man in a tent with a bottle of beer",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.13
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7171,
            7175
          ],
          "representative_frame": 7171,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9383586049079895,
              "bbox": [
                307.3551330566406,
                1.372209906578064,
                640.0,
                353.30975341796875
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7990290522575378,
              "bbox": [
                213.79327392578125,
                83.16168975830078,
                344.1145935058594,
                212.03805541992188
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8996047377586365,
              "bbox": [
                17.260162353515625,
                34.69989013671875,
                149.97364807128906,
                279.1985168457031
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4309808909893036,
              "bbox": [
                87.93636322021484,
                279.5274658203125,
                123.17550659179688,
                319.7394104003906
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2582351863384247,
              "bbox": [
                225.6383514404297,
                182.67848205566406,
                303.4696044921875,
                237.4931640625
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            507
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7176,
            7180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7181,
            7185
          ],
          "representative_frame": 7181,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9534249901771545,
              "bbox": [
                305.1172790527344,
                1.1592400074005127,
                640.0,
                353.87994384765625
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8690560460090637,
              "bbox": [
                214.20286560058594,
                83.1540298461914,
                344.0811462402344,
                211.4830322265625
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8510628938674927,
              "bbox": [
                33.8415641784668,
                44.43952560424805,
                158.6475067138672,
                279.4278564453125
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4583035111427307,
              "bbox": [
                87.86434173583984,
                279.4587097167969,
                123.09477996826172,
                319.6478271484375
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.37199798226356506,
              "bbox": [
                226.19253540039062,
                182.526123046875,
                304.2615051269531,
                237.53224182128906
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46839606761932373,
              "bbox": [
                3.984327793121338,
                81.86956024169922,
                50.715667724609375,
                247.10020446777344
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            507,
            471
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            7186,
            7190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7191,
            7195
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9419125318527222,
              "bbox": [
                313.1111755371094,
                1.1767475605010986,
                640.0,
                354.2900695800781
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7005867958068848,
              "bbox": [
                195.10047912597656,
                82.6950912475586,
                362.4758605957031,
                250.33633422851562
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.635633111000061,
              "bbox": [
                58.9831428527832,
                52.75755310058594,
                171.9183349609375,
                264.9661865234375
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7013967633247375,
              "bbox": [
                88.25641632080078,
                279.67059326171875,
                123.05687713623047,
                319.3218688964844
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.20583857595920563,
              "bbox": [
                3.7786219120025635,
                83.02811431884766,
                52.26103210449219,
                251.2787628173828
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            471
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7196,
            7200
          ],
          "representative_frame": 7196,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 59
    },
    {
      "second": 240,
      "time_range": [
        240,
        240.999
      ],
      "frame_range": [
        7201,
        7230
      ],
      "unified_description": "3rd person perspective, camera on body, stable camera positioning, wide-angle lens, documenting a man in a tent with a cell, indoor lighting, no motion blur or fisheye effect, no technical artifacts, etc.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:16",
        "processing_time": 2.95,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7215,
          "frame_range": [
            7211,
            7215
          ],
          "description": "a man in a tent with a cell",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.85
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7201,
            7205
          ],
          "representative_frame": 7201,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9427052736282349,
              "bbox": [
                318.42840576171875,
                1.2618974447250366,
                640.0,
                354.1117858886719
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6490203738212585,
              "bbox": [
                189.65298461914062,
                82.43245697021484,
                366.902587890625,
                262.61962890625
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8152101039886475,
              "bbox": [
                72.18123626708984,
                60.8257942199707,
                177.3951416015625,
                258.4482116699219
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6412745118141174,
              "bbox": [
                88.3988265991211,
                279.797607421875,
                123.05780792236328,
                319.2180480957031
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.33581534028053284,
              "bbox": [
                3.3507003784179688,
                83.12890625,
                52.923274993896484,
                252.61106872558594
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            471
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7206,
            7210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7211,
            7215
          ],
          "representative_frame": 7211,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9218435883522034,
              "bbox": [
                318.8907165527344,
                1.5743807554244995,
                640.0,
                354.7977294921875
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.47220656275749207,
              "bbox": [
                186.53953552246094,
                82.20855712890625,
                368.78302001953125,
                270.70745849609375
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8144562840461731,
              "bbox": [
                70.81021881103516,
                60.7482795715332,
                175.93836975097656,
                258.08843994140625
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6303836703300476,
              "bbox": [
                88.4529800415039,
                279.84375,
                123.11804962158203,
                319.1971740722656
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4242258369922638,
              "bbox": [
                2.873769760131836,
                83.23477935791016,
                52.97474670410156,
                252.49432373046875
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.26043227314949036,
              "bbox": [
                225.263916015625,
                181.26519775390625,
                305.2509460449219,
                237.77394104003906
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            471,
            507
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            7216,
            7220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7221,
            7225
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9135652184486389,
              "bbox": [
                320.0137023925781,
                0.829786479473114,
                640.0,
                353.6490173339844
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5600600838661194,
              "bbox": [
                186.71192932128906,
                81.7132568359375,
                367.1763916015625,
                271.72760009765625
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8166478872299194,
              "bbox": [
                73.60013580322266,
                56.53996658325195,
                180.12730407714844,
                261.76226806640625
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6233459711074829,
              "bbox": [
                88.35942840576172,
                279.84356689453125,
                123.22398376464844,
                319.3593444824219
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.23346103727817535,
              "bbox": [
                2.552262306213379,
                83.19864654541016,
                53.24168395996094,
                252.6892852783203
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3977508246898651,
              "bbox": [
                225.37319946289062,
                180.2075653076172,
                305.0098876953125,
                236.63636779785156
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.3252844214439392,
              "bbox": [
                0.0,
                238.47467041015625,
                89.51871490478516,
                321.9989318847656
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            471,
            507,
            440
          ],
          "total_detections": 7
        },
        {
          "group_index": 5,
          "frame_range": [
            7226,
            7230
          ],
          "representative_frame": 7226,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 60
    },
    {
      "second": 241,
      "time_range": [
        241,
        241.999
      ],
      "frame_range": [
        7231,
        7260
      ],
      "unified_description": "4k video with objects of interest",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:16",
        "processing_time": 2.27,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7245,
          "frame_range": [
            7241,
            7245
          ],
          "description": "a man and a boy are sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.47
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7231,
            7235
          ],
          "representative_frame": 7231,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9290370345115662,
              "bbox": [
                321.267578125,
                1.0927320718765259,
                640.0,
                353.07305908203125
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5366250276565552,
              "bbox": [
                194.69435119628906,
                80.82356262207031,
                359.6209716796875,
                256.2987365722656
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7203680276870728,
              "bbox": [
                66.11061096191406,
                54.27647399902344,
                175.9736328125,
                266.442626953125
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5750441551208496,
              "bbox": [
                88.29204559326172,
                279.8730163574219,
                123.3503646850586,
                319.560546875
              ]
            },
            {
              "track_id": 471,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.18257464468479156,
              "bbox": [
                2.3586695194244385,
                83.05488586425781,
                53.18722915649414,
                251.22450256347656
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2516566812992096,
              "bbox": [
                223.24928283691406,
                178.3580322265625,
                306.1164855957031,
                237.44216918945312
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.3467983305454254,
              "bbox": [
                0.0,
                238.5653076171875,
                87.83758544921875,
                322.23638916015625
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            471,
            507,
            440
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            7236,
            7240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7241,
            7245
          ],
          "representative_frame": 7241,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.934419572353363,
              "bbox": [
                322.0921630859375,
                1.008590817451477,
                640.0,
                355.3524475097656
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.15788383781909943,
              "bbox": [
                190.4619598388672,
                82.9706802368164,
                363.7265625,
                271.0837707519531
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3075050413608551,
              "bbox": [
                225.55221557617188,
                180.10153198242188,
                304.98834228515625,
                236.79400634765625
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8402278423309326,
              "bbox": [
                31.35500144958496,
                2.8268277645111084,
                116.05023193359375,
                354.8923034667969
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            507,
            495
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            7246,
            7250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7251,
            7255
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9434314966201782,
              "bbox": [
                305.48992919921875,
                0.9636185765266418,
                637.59765625,
                356.5345764160156
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.40447133779525757,
              "bbox": [
                202.2225341796875,
                83.76475524902344,
                389.5064392089844,
                287.1304016113281
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5280889868736267,
              "bbox": [
                226.56948852539062,
                180.86004638671875,
                304.3719177246094,
                236.4309844970703
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8266900777816772,
              "bbox": [
                29.200050354003906,
                0.0,
                122.74484252929688,
                355.5811462402344
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.3952716290950775,
              "bbox": [
                0.0,
                241.26976013183594,
                93.0210189819336,
                343.8675842285156
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            507,
            495,
            440
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7256,
            7260
          ],
          "representative_frame": 7256,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 60
    },
    {
      "second": 242,
      "time_range": [
        242,
        242.999
      ],
      "frame_range": [
        7261,
        7290
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:17",
        "processing_time": 2.11,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7275,
          "frame_range": [
            7271,
            7275
          ],
          "description": "a man and a boy are sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.3
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7261,
            7265
          ],
          "representative_frame": 7261,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9254406690597534,
              "bbox": [
                277.99188232421875,
                0.4860745072364807,
                615.3926391601562,
                353.3788146972656
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5286161303520203,
              "bbox": [
                198.33555603027344,
                84.42286682128906,
                373.0435791015625,
                277.63653564453125
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.54997318983078,
              "bbox": [
                226.5016632080078,
                181.25193786621094,
                304.51910400390625,
                237.0108642578125
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8464850187301636,
              "bbox": [
                25.933996200561523,
                0.0,
                126.15555572509766,
                355.2262268066406
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.1307644546031952,
              "bbox": [
                0.0,
                242.16806030273438,
                93.90727233886719,
                353.74285888671875
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            507,
            495,
            440
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7266,
            7270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7271,
            7275
          ],
          "representative_frame": 7271,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9283338189125061,
              "bbox": [
                259.46197509765625,
                0.2673349976539612,
                606.2996826171875,
                354.871826171875
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.38458704948425293,
              "bbox": [
                197.45123291015625,
                84.71125793457031,
                364.44677734375,
                272.6145324707031
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.42086830735206604,
              "bbox": [
                227.1042938232422,
                181.63272094726562,
                304.1062927246094,
                236.62689208984375
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9029285311698914,
              "bbox": [
                19.841270446777344,
                0.0,
                124.31767272949219,
                356.207275390625
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.5276060700416565,
              "bbox": [
                0.0,
                242.78390502929688,
                94.20641326904297,
                357.39398193359375
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            507,
            495,
            440
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            7276,
            7280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7281,
            7285
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9481056332588196,
              "bbox": [
                259.6529846191406,
                0.2468900978565216,
                610.6856079101562,
                353.7020568847656
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6682677268981934,
              "bbox": [
                198.601806640625,
                84.70626831054688,
                359.60504150390625,
                268.7812194824219
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9115738272666931,
              "bbox": [
                21.247669219970703,
                5.307453632354736,
                129.6984100341797,
                356.9976501464844
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.1572439968585968,
              "bbox": [
                0.0,
                246.03990173339844,
                93.1590347290039,
                358.3507080078125
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            495,
            440
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            7286,
            7290
          ],
          "representative_frame": 7286,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 60
    },
    {
      "second": 243,
      "time_range": [
        243,
        243.999
      ],
      "frame_range": [
        7291,
        7320
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:19",
        "processing_time": 2.11,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7305,
          "frame_range": [
            7301,
            7305
          ],
          "description": "a man and two boys sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.78
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7291,
            7295
          ],
          "representative_frame": 7291,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9193848371505737,
              "bbox": [
                310.732421875,
                0.7182453274726868,
                640.0,
                350.2632141113281
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8317773938179016,
              "bbox": [
                218.5258026123047,
                84.10189819335938,
                400.84912109375,
                288.5741271972656
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9130707383155823,
              "bbox": [
                26.30730438232422,
                3.7381558418273926,
                128.305908203125,
                309.3319091796875
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.13352926075458527,
              "bbox": [
                0.0,
                247.55250549316406,
                92.02222442626953,
                346.7287902832031
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7066324949264526,
              "bbox": [
                88.82273864746094,
                279.968017578125,
                123.04431915283203,
                318.4915466308594
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            495,
            440,
            506
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7296,
            7300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7301,
            7305
          ],
          "representative_frame": 7301,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8786625266075134,
              "bbox": [
                338.0544128417969,
                0.8383297920227051,
                640.0,
                351.1611022949219
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8444907069206238,
              "bbox": [
                226.14930725097656,
                83.864501953125,
                419.2273864746094,
                296.05010986328125
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.889946460723877,
              "bbox": [
                46.30126190185547,
                14.798380851745605,
                141.327880859375,
                290.04571533203125
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.2506255805492401,
              "bbox": [
                0.0,
                247.6885986328125,
                97.04103088378906,
                354.86962890625
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7589966058731079,
              "bbox": [
                88.88011169433594,
                279.8883972167969,
                122.8860855102539,
                317.9775085449219
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2921571731567383,
              "bbox": [
                0.9260995388031006,
                82.74994659423828,
                52.801414489746094,
                253.4814910888672
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            495,
            440,
            506,
            471
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            7306,
            7310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7311,
            7315
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8582961559295654,
              "bbox": [
                349.8944091796875,
                0.526900053024292,
                640.0,
                351.7326354980469
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8568300604820251,
              "bbox": [
                230.2433624267578,
                84.13726806640625,
                429.15545654296875,
                298.56854248046875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9007025957107544,
              "bbox": [
                56.37685775756836,
                24.848003387451172,
                149.44960021972656,
                282.631591796875
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.19629274308681488,
              "bbox": [
                0.0,
                247.8638153076172,
                98.6880111694336,
                357.6977844238281
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7130752801895142,
              "bbox": [
                88.82501220703125,
                279.76593017578125,
                122.97042083740234,
                317.83477783203125
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.26291364431381226,
              "bbox": [
                1.0090529918670654,
                82.72946166992188,
                53.03227615356445,
                252.79312133789062
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            495,
            440,
            506,
            471
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            7316,
            7320
          ],
          "representative_frame": 7316,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 60
    },
    {
      "second": 244,
      "time_range": [
        244,
        244.999
      ],
      "frame_range": [
        7321,
        7350
      ],
      "unified_description": "3rd person perspective showing a man in a tent with a backpack and a backpack. The camera is positioned on a tripod, providing a stable view.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:21",
        "processing_time": 2.64,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7335,
          "frame_range": [
            7331,
            7335
          ],
          "description": "a man in a tent with a backpack and a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7321,
            7325
          ],
          "representative_frame": 7321,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8609594702720642,
              "bbox": [
                331.9089660644531,
                0.16192199289798737,
                640.0,
                353.67791748046875
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8567918539047241,
              "bbox": [
                230.98463439941406,
                84.00471496582031,
                434.0008544921875,
                299.1820068359375
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.906947135925293,
              "bbox": [
                60.60603332519531,
                30.845338821411133,
                154.60302734375,
                280.3515625
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.15459325909614563,
              "bbox": [
                0.0,
                247.92910766601562,
                99.0739974975586,
                358.46881103515625
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.72216796875,
              "bbox": [
                88.12076568603516,
                279.1524658203125,
                123.52146911621094,
                318.7394104003906
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.35776984691619873,
              "bbox": [
                0.9034574031829834,
                82.68433380126953,
                53.207069396972656,
                252.80799865722656
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            495,
            440,
            506,
            471
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7326,
            7330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7331,
            7335
          ],
          "representative_frame": 7331,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7319095730781555,
              "bbox": [
                308.320556640625,
                0.4036094844341278,
                636.7963256835938,
                353.9518737792969
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8968572616577148,
              "bbox": [
                60.62342834472656,
                31.166624069213867,
                156.25999450683594,
                279.7083740234375
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.46422335505485535,
              "bbox": [
                88.36669158935547,
                279.1760559082031,
                123.09774017333984,
                317.9517822265625
              ]
            },
            {
              "track_id": 471,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.11442117393016815,
              "bbox": [
                2.2588131427764893,
                83.1283950805664,
                55.51546096801758,
                253.67095947265625
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            471
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            7336,
            7340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7341,
            7345
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7349086999893188,
              "bbox": [
                300.15484619140625,
                0.3479152023792267,
                631.2009887695312,
                354.0530090332031
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8963592052459717,
              "bbox": [
                59.758209228515625,
                31.132173538208008,
                157.23854064941406,
                279.8603210449219
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.48222285509109497,
              "bbox": [
                88.43708038330078,
                279.18017578125,
                122.96829223632812,
                317.67510986328125
              ]
            },
            {
              "track_id": 471,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.14205315709114075,
              "bbox": [
                2.075369119644165,
                83.4226303100586,
                55.88011932373047,
                254.1944122314453
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            471
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            7346,
            7350
          ],
          "representative_frame": 7346,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 61
    },
    {
      "second": 245,
      "time_range": [
        245,
        245.999
      ],
      "frame_range": [
        7351,
        7380
      ],
      "unified_description": "\n\n1. The video shows a man and a woman in a tent. The man is wearing a backpack. They appear to be talking to each other or engaging in some form of interaction.\n\n2. The camera perspective suggests that it could be a first-person perspective, capturing the experience of one of the individuals in the scene.\n\n3. There are a total of 11 unique tracks, representing various elements within the image, including people, backpacks, and other objects.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:23",
        "processing_time": 4.75,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7365,
          "frame_range": [
            7361,
            7365
          ],
          "description": "a man in a tent with a backpack and a woman",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.56
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7351,
            7355
          ],
          "representative_frame": 7351,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.706386387348175,
              "bbox": [
                297.733642578125,
                0.3588479459285736,
                630.6798095703125,
                354.109375
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8947905898094177,
              "bbox": [
                57.71800231933594,
                30.78813934326172,
                157.25717163085938,
                279.7484130859375
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.44227346777915955,
              "bbox": [
                88.47466278076172,
                279.1546325683594,
                122.912109375,
                317.4754333496094
              ]
            },
            {
              "track_id": 471,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.13682730495929718,
              "bbox": [
                0.4316537380218506,
                83.5962142944336,
                54.00292205810547,
                254.21864318847656
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            471
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            7356,
            7360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7361,
            7365
          ],
          "representative_frame": 7361,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.856946587562561,
              "bbox": [
                381.06683349609375,
                0.5175322890281677,
                640.0,
                340.24102783203125
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8902748823165894,
              "bbox": [
                59.645511627197266,
                56.45637512207031,
                154.73825073242188,
                286.7790832519531
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2199341356754303,
              "bbox": [
                88.83513641357422,
                278.50994873046875,
                123.29304504394531,
                316.9892272949219
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5043247938156128,
              "bbox": [
                270.2518310546875,
                339.8638000488281,
                310.8144836425781,
                359.5981750488281
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.49948179721832275,
              "bbox": [
                248.7771759033203,
                83.75129699707031,
                461.42449951171875,
                298.4681396484375
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            499,
            502
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            7366,
            7370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7371,
            7375
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6340979337692261,
              "bbox": [
                418.3433837890625,
                0.7849204540252686,
                640.0,
                335.4190368652344
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8639644384384155,
              "bbox": [
                59.23054504394531,
                57.8796272277832,
                156.32737731933594,
                288.3500061035156
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5077927708625793,
              "bbox": [
                89.09957885742188,
                279.0702209472656,
                122.85208129882812,
                316.6365661621094
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4092625081539154,
              "bbox": [
                245.39083862304688,
                234.36251831054688,
                289.0946960449219,
                320.24176025390625
              ]
            },
            {
              "track_id": 529,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3465447723865509,
              "bbox": [
                214.51626586914062,
                81.91712951660156,
                341.1351623535156,
                260.203857421875
              ]
            },
            {
              "track_id": 530,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.380859911441803,
              "bbox": [
                176.012451171875,
                336.6335754394531,
                223.24722290039062,
                359.71978759765625
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3540850877761841,
              "bbox": [
                220.22280883789062,
                292.6589050292969,
                298.830322265625,
                336.625244140625
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5250748991966248,
              "bbox": [
                266.74053955078125,
                340.1445617675781,
                314.1151123046875,
                359.6671142578125
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3772861063480377,
              "bbox": [
                247.43508911132812,
                83.57500457763672,
                467.9491271972656,
                297.54840087890625
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3572643995285034,
              "bbox": [
                232.6959228515625,
                181.08419799804688,
                308.1200866699219,
                234.9254608154297
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            529,
            530,
            532,
            499,
            502,
            507
          ],
          "total_detections": 10
        },
        {
          "group_index": 5,
          "frame_range": [
            7376,
            7380
          ],
          "representative_frame": 7376,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 61
    },
    {
      "second": 246,
      "time_range": [
        246,
        246.999
      ],
      "frame_range": [
        7381,
        7410
      ],
      "unified_description": "1-second scene with a man and two boys sitting in a tent. The camera perspective is first-person, mounted on a backpack. The field of view is wide-angle showing the entire tent.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:24",
        "processing_time": 4.71,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7395,
          "frame_range": [
            7391,
            7395
          ],
          "description": "a man and two boys sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.62
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7381,
            7385
          ],
          "representative_frame": 7381,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8566742539405823,
              "bbox": [
                431.1439208984375,
                0.6363078951835632,
                640.0,
                343.1882629394531
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8996645212173462,
              "bbox": [
                56.42137145996094,
                51.49993133544922,
                158.0376434326172,
                289.94061279296875
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.539696455001831,
              "bbox": [
                89.30322265625,
                279.2105712890625,
                122.89724731445312,
                316.550048828125
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4298855662345886,
              "bbox": [
                245.5125732421875,
                234.54412841796875,
                289.0923767089844,
                320.1787414550781
              ]
            },
            {
              "track_id": 529,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.23203948140144348,
              "bbox": [
                208.96238708496094,
                82.01985168457031,
                347.9358825683594,
                277.9246520996094
              ]
            },
            {
              "track_id": 530,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3911176919937134,
              "bbox": [
                175.90113830566406,
                336.4924621582031,
                223.35223388671875,
                359.68377685546875
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3749064803123474,
              "bbox": [
                219.96922302246094,
                292.72552490234375,
                298.4577331542969,
                336.6261901855469
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5205863118171692,
              "bbox": [
                264.0340270996094,
                340.21026611328125,
                316.5553894042969,
                359.697998046875
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6234648823738098,
              "bbox": [
                243.62294006347656,
                83.55206298828125,
                471.0846252441406,
                297.0150451660156
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.18790559470653534,
              "bbox": [
                233.59030151367188,
                180.68182373046875,
                308.69354248046875,
                234.15992736816406
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            529,
            530,
            532,
            499,
            502,
            507
          ],
          "total_detections": 10
        },
        {
          "group_index": 1,
          "frame_range": [
            7386,
            7390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7391,
            7395
          ],
          "representative_frame": 7391,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8910920023918152,
              "bbox": [
                435.8809814453125,
                0.616276741027832,
                640.0,
                346.5589904785156
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.89995276927948,
              "bbox": [
                54.517311096191406,
                49.695716857910156,
                158.40750122070312,
                290.9925842285156
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5219413638114929,
              "bbox": [
                89.32554626464844,
                279.29840087890625,
                122.90028381347656,
                316.5680236816406
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5156735181808472,
              "bbox": [
                245.40960693359375,
                234.19833374023438,
                289.14599609375,
                320.1617126464844
              ]
            },
            {
              "track_id": 529,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5288711786270142,
              "bbox": [
                225.90220642089844,
                82.05241394042969,
                328.6763916015625,
                224.78248596191406
              ]
            },
            {
              "track_id": 530,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.37487828731536865,
              "bbox": [
                176.03997802734375,
                336.5218200683594,
                223.54957580566406,
                359.740234375
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.39281895756721497,
              "bbox": [
                220.0202178955078,
                292.868896484375,
                298.134033203125,
                336.5557556152344
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5380290150642395,
              "bbox": [
                262.0084228515625,
                340.2052001953125,
                318.6131896972656,
                359.7113952636719
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.16094209253787994,
              "bbox": [
                237.085693359375,
                83.57380676269531,
                469.7339172363281,
                297.0433044433594
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3133641481399536,
              "bbox": [
                233.05113220214844,
                181.0418701171875,
                308.28863525390625,
                234.59783935546875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            529,
            530,
            532,
            499,
            502,
            507
          ],
          "total_detections": 10
        },
        {
          "group_index": 3,
          "frame_range": [
            7396,
            7400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7401,
            7405
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9239234924316406,
              "bbox": [
                447.9897766113281,
                0.47418296337127686,
                640.0,
                329.671875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.886395275592804,
              "bbox": [
                53.357383728027344,
                49.413780212402344,
                158.49786376953125,
                291.2700500488281
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4787009060382843,
              "bbox": [
                89.27383422851562,
                279.22332763671875,
                122.95387268066406,
                316.5834045410156
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4507104158401489,
              "bbox": [
                245.47482299804688,
                234.55592346191406,
                289.0360412597656,
                320.1780090332031
              ]
            },
            {
              "track_id": 529,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.39828577637672424,
              "bbox": [
                231.81521606445312,
                81.80290985107422,
                321.3904113769531,
                203.9014434814453
              ]
            },
            {
              "track_id": 530,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.37318846583366394,
              "bbox": [
                175.92262268066406,
                336.45660400390625,
                223.53656005859375,
                359.7338562011719
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3654443025588989,
              "bbox": [
                220.17355346679688,
                293.1042785644531,
                298.0208435058594,
                336.6296691894531
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5229966044425964,
              "bbox": [
                260.5281982421875,
                340.162353515625,
                320.39508056640625,
                359.6889343261719
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.29385003447532654,
              "bbox": [
                233.25799560546875,
                83.4326171875,
                471.50653076171875,
                297.34295654296875
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.197768896818161,
              "bbox": [
                232.2860870361328,
                180.87196350097656,
                307.819091796875,
                234.7379150390625
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            529,
            530,
            532,
            499,
            502,
            507
          ],
          "total_detections": 10
        },
        {
          "group_index": 5,
          "frame_range": [
            7406,
            7410
          ],
          "representative_frame": 7406,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 61
    },
    {
      "second": 247,
      "time_range": [
        247,
        247.999
      ],
      "frame_range": [
        7411,
        7440
      ],
      "unified_description": "1-second scene with multiple groups of people sitting in a tent",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:24",
        "processing_time": 2.7,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7425,
          "frame_range": [
            7421,
            7425
          ],
          "description": "a group of people sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.86
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7411,
            7415
          ],
          "representative_frame": 7411,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7192034721374512,
              "bbox": [
                454.55694580078125,
                0.14682266116142273,
                640.0,
                323.9666748046875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8973478674888611,
              "bbox": [
                51.38408660888672,
                44.7963752746582,
                158.8118438720703,
                291.7001953125
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3861158490180969,
              "bbox": [
                89.28279876708984,
                279.2680358886719,
                122.93016052246094,
                316.55572509765625
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3381742238998413,
              "bbox": [
                245.42486572265625,
                234.49481201171875,
                289.0135803222656,
                320.1983642578125
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.32014670968055725,
              "bbox": [
                175.8420867919922,
                336.61572265625,
                223.0601806640625,
                359.68487548828125
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3784950077533722,
              "bbox": [
                220.14390563964844,
                293.0392150878906,
                298.06884765625,
                336.5936279296875
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5344905853271484,
              "bbox": [
                259.1763000488281,
                340.08123779296875,
                321.837646484375,
                359.677490234375
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.15052849054336548,
              "bbox": [
                233.0155029296875,
                83.38617706298828,
                475.4044189453125,
                296.715087890625
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3006557524204254,
              "bbox": [
                233.37513732910156,
                181.20872497558594,
                307.75860595703125,
                234.09243774414062
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3748861253261566,
              "bbox": [
                208.44100952148438,
                81.40258026123047,
                344.91461181640625,
                261.9798889160156
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            530,
            532,
            499,
            502,
            507,
            537
          ],
          "total_detections": 10
        },
        {
          "group_index": 1,
          "frame_range": [
            7416,
            7420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7421,
            7425
          ],
          "representative_frame": 7421,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.91773921251297,
              "bbox": [
                380.5546569824219,
                0.57460618019104,
                630.2977294921875,
                339.4525451660156
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8859418034553528,
              "bbox": [
                45.01064682006836,
                40.047733306884766,
                154.86354064941406,
                291.56390380859375
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4377598762512207,
              "bbox": [
                89.05353546142578,
                278.97955322265625,
                123.12116241455078,
                316.7981262207031
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3859987258911133,
              "bbox": [
                245.557861328125,
                234.64256286621094,
                289.050048828125,
                320.1625671386719
              ]
            },
            {
              "track_id": 530,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.31092318892478943,
              "bbox": [
                176.18881225585938,
                336.70440673828125,
                223.0763397216797,
                359.58966064453125
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.40183544158935547,
              "bbox": [
                219.9119873046875,
                292.9102783203125,
                298.085693359375,
                336.5921630859375
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5817398428916931,
              "bbox": [
                257.8451232910156,
                339.9554138183594,
                322.9630432128906,
                359.65789794921875
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.24872516095638275,
              "bbox": [
                233.67156982421875,
                181.14002990722656,
                308.2079162597656,
                233.90626525878906
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.276500940322876,
              "bbox": [
                200.8603973388672,
                82.04103088378906,
                338.29620361328125,
                264.5858154296875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            530,
            532,
            499,
            507,
            537
          ],
          "total_detections": 9
        },
        {
          "group_index": 3,
          "frame_range": [
            7426,
            7430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7431,
            7435
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7643857002258301,
              "bbox": [
                324.1133728027344,
                0.5090335011482239,
                593.3572998046875,
                346.7439880371094
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8963658213615417,
              "bbox": [
                43.02727508544922,
                39.21781539916992,
                153.43994140625,
                291.28167724609375
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.42232152819633484,
              "bbox": [
                89.01738739013672,
                278.929443359375,
                123.17332458496094,
                316.8980407714844
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.40897229313850403,
              "bbox": [
                245.74330139160156,
                235.31655883789062,
                288.8596496582031,
                320.0849609375
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.28715914487838745,
              "bbox": [
                176.0329132080078,
                336.8467102050781,
                222.7957000732422,
                359.62884521484375
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5164082646369934,
              "bbox": [
                219.73806762695312,
                292.8006286621094,
                298.2079772949219,
                336.6381530761719
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5530390739440918,
              "bbox": [
                256.8955383300781,
                339.99078369140625,
                323.4248962402344,
                359.56146240234375
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            530,
            532,
            499
          ],
          "total_detections": 7
        },
        {
          "group_index": 5,
          "frame_range": [
            7436,
            7440
          ],
          "representative_frame": 7436,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 61
    },
    {
      "second": 248,
      "time_range": [
        248,
        248.999
      ],
      "frame_range": [
        7441,
        7470
      ],
      "unified_description": "3rd person perspective with a focus on the hand holding the camera.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:26",
        "processing_time": 2.34,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7455,
          "frame_range": [
            7451,
            7455
          ],
          "description": "a man and a boy are in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7441,
            7445
          ],
          "representative_frame": 7441,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7091614603996277,
              "bbox": [
                296.9579772949219,
                0.8945208787918091,
                582.228271484375,
                350.8666076660156
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8975578546524048,
              "bbox": [
                42.602867126464844,
                38.81105422973633,
                153.30072021484375,
                291.0474548339844
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.317211389541626,
              "bbox": [
                89.15061950683594,
                279.2083435058594,
                123.04072570800781,
                316.8491516113281
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.22869840264320374,
              "bbox": [
                245.91122436523438,
                236.20895385742188,
                288.6017150878906,
                320.055419921875
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.29966849088668823,
              "bbox": [
                175.80514526367188,
                336.70343017578125,
                222.9066619873047,
                359.62823486328125
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5193011164665222,
              "bbox": [
                219.84188842773438,
                292.89898681640625,
                297.9971008300781,
                336.5426940917969
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.522904098033905,
              "bbox": [
                255.67112731933594,
                339.6150817871094,
                324.7836608886719,
                359.5518493652344
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            530,
            532,
            499
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            7446,
            7450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7451,
            7455
          ],
          "representative_frame": 7451,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.29438334703445435,
              "bbox": [
                294.1935119628906,
                0.31968367099761963,
                588.5012817382812,
                349.63299560546875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9012776017189026,
              "bbox": [
                43.000816345214844,
                37.39511489868164,
                153.67759704589844,
                289.6709899902344
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2610333561897278,
              "bbox": [
                89.16827392578125,
                279.28460693359375,
                123.012451171875,
                316.85772705078125
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.18603180348873138,
              "bbox": [
                245.91749572753906,
                236.4400634765625,
                288.5334777832031,
                320.09039306640625
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.40517377853393555,
              "bbox": [
                175.7425994873047,
                336.6346740722656,
                223.1046600341797,
                359.6441650390625
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5286619663238525,
              "bbox": [
                220.1917266845703,
                292.95361328125,
                298.14105224609375,
                336.4433898925781
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5240322351455688,
              "bbox": [
                254.79603576660156,
                339.4417724609375,
                325.6116027832031,
                359.5428466796875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            530,
            532,
            499
          ],
          "total_detections": 7
        },
        {
          "group_index": 3,
          "frame_range": [
            7456,
            7460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7461,
            7465
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9324536919593811,
              "bbox": [
                296.306640625,
                0.09884592145681381,
                598.994384765625,
                351.2931823730469
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9004548788070679,
              "bbox": [
                40.92997360229492,
                41.974708557128906,
                150.63453674316406,
                290.4320983886719
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.39956316351890564,
              "bbox": [
                89.17095947265625,
                279.45672607421875,
                122.93843841552734,
                316.8438415527344
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2774089276790619,
              "bbox": [
                175.67860412597656,
                336.61627197265625,
                222.96441650390625,
                359.52642822265625
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5035368800163269,
              "bbox": [
                220.08184814453125,
                292.6575622558594,
                298.4903259277344,
                336.4018249511719
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5825037956237793,
              "bbox": [
                254.32456970214844,
                339.5238037109375,
                326.0445556640625,
                359.5547180175781
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3867867588996887,
              "bbox": [
                206.61048889160156,
                82.61026763916016,
                345.4497985839844,
                267.724853515625
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            530,
            532,
            499,
            537
          ],
          "total_detections": 7
        },
        {
          "group_index": 5,
          "frame_range": [
            7466,
            7470
          ],
          "representative_frame": 7466,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 62
    },
    {
      "second": 249,
      "time_range": [
        249,
        249.999
      ],
      "frame_range": [
        7471,
        7500
      ],
      "unified_description": "1-second scene where a man and two children are sitting in a tent, with multiple object detections.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:28",
        "processing_time": 2.49,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7485,
          "frame_range": [
            7481,
            7485
          ],
          "description": "a man and two children sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.24
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7471,
            7475
          ],
          "representative_frame": 7471,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8428304195404053,
              "bbox": [
                325.5948791503906,
                0.35753774642944336,
                627.3587646484375,
                352.0533752441406
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8896459937095642,
              "bbox": [
                42.135658264160156,
                45.718631744384766,
                151.5089569091797,
                290.3043518066406
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4610774517059326,
              "bbox": [
                89.05048370361328,
                279.5572204589844,
                122.85274505615234,
                316.8795166015625
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.26706117391586304,
              "bbox": [
                175.27828979492188,
                336.7922668457031,
                222.72015380859375,
                359.6630859375
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4548344314098358,
              "bbox": [
                219.7155303955078,
                292.4430847167969,
                298.5483703613281,
                336.46002197265625
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5715601444244385,
              "bbox": [
                253.99014282226562,
                339.6903991699219,
                326.3545227050781,
                359.6011962890625
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5032652020454407,
              "bbox": [
                208.64651489257812,
                82.74222564697266,
                345.2084045410156,
                265.1434326171875
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.45444729924201965,
              "bbox": [
                233.03646850585938,
                181.22113037109375,
                307.8511047363281,
                234.3529510498047
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4390975832939148,
              "bbox": [
                245.76730346679688,
                235.34620666503906,
                288.9819030761719,
                320.1312255859375
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            530,
            532,
            499,
            537,
            507,
            528
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            7476,
            7480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7481,
            7485
          ],
          "representative_frame": 7481,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8623733520507812,
              "bbox": [
                334.48846435546875,
                0.6221952438354492,
                636.5707397460938,
                353.43572998046875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.891788899898529,
              "bbox": [
                46.165077209472656,
                60.29927062988281,
                151.81051635742188,
                291.626708984375
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6067025661468506,
              "bbox": [
                88.75196838378906,
                279.8044128417969,
                122.51285552978516,
                317.01422119140625
              ]
            },
            {
              "track_id": 530,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.32766491174697876,
              "bbox": [
                174.87527465820312,
                337.0235900878906,
                222.1551513671875,
                359.7832336425781
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.41282275319099426,
              "bbox": [
                220.00228881835938,
                292.9137878417969,
                298.468017578125,
                336.69293212890625
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6499586701393127,
              "bbox": [
                253.56942749023438,
                339.73858642578125,
                326.72894287109375,
                359.6353759765625
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46014755964279175,
              "bbox": [
                209.2735137939453,
                82.52501678466797,
                344.06591796875,
                263.09088134765625
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.43226420879364014,
              "bbox": [
                233.399169921875,
                181.4464874267578,
                307.9456787109375,
                234.4215850830078
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4100729823112488,
              "bbox": [
                245.5308380126953,
                234.79861450195312,
                289.034912109375,
                320.2548522949219
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5480766296386719,
              "bbox": [
                206.14662170410156,
                83.16421508789062,
                445.4901428222656,
                296.5021057128906
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            530,
            532,
            499,
            537,
            507,
            528,
            502
          ],
          "total_detections": 10
        },
        {
          "group_index": 3,
          "frame_range": [
            7486,
            7490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7491,
            7495
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8271175622940063,
              "bbox": [
                335.0554504394531,
                0.25180482864379883,
                637.8473510742188,
                353.8123474121094
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8721750974655151,
              "bbox": [
                47.260887145996094,
                68.7909927368164,
                151.89036560058594,
                292.5832214355469
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.45985087752342224,
              "bbox": [
                87.93048858642578,
                278.4596252441406,
                123.19546508789062,
                317.4947204589844
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.36121734976768494,
              "bbox": [
                174.66668701171875,
                337.010498046875,
                221.96975708007812,
                359.7377624511719
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.42717525362968445,
              "bbox": [
                220.0568084716797,
                293.10223388671875,
                298.294189453125,
                336.7180480957031
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6796278357505798,
              "bbox": [
                253.07241821289062,
                339.72906494140625,
                326.92852783203125,
                359.6238708496094
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.16921475529670715,
              "bbox": [
                209.3312225341797,
                82.14141845703125,
                342.6912536621094,
                261.4120788574219
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4504370391368866,
              "bbox": [
                233.38597106933594,
                181.27626037597656,
                308.1451110839844,
                234.38946533203125
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4534894526004791,
              "bbox": [
                245.50607299804688,
                234.6524658203125,
                289.07659912109375,
                320.2989196777344
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3737312853336334,
              "bbox": [
                206.14064025878906,
                84.0201644897461,
                442.2666931152344,
                296.19305419921875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            530,
            532,
            499,
            537,
            507,
            528,
            502
          ],
          "total_detections": 10
        },
        {
          "group_index": 5,
          "frame_range": [
            7496,
            7500
          ],
          "representative_frame": 7496,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 62
    },
    {
      "second": 250,
      "time_range": [
        250,
        250.999
      ],
      "frame_range": [
        7501,
        7530
      ],
      "unified_description": "360-degree video of the exterior of a home, taken from an overhead perspective. The video showcases several objects and people in various positions throughout the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:29",
        "processing_time": 3.2,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7515,
          "frame_range": [
            7511,
            7515
          ],
          "description": "a man is putting a bucket in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.13
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7501,
            7505
          ],
          "representative_frame": 7501,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5554124712944031,
              "bbox": [
                286.896484375,
                0.6675883531570435,
                602.6030883789062,
                355.2637023925781
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8529826998710632,
              "bbox": [
                45.263328552246094,
                71.37537384033203,
                154.13137817382812,
                300.655517578125
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.1053764745593071,
              "bbox": [
                91.576171875,
                282.9543151855469,
                122.9514389038086,
                317.1978759765625
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3945203125476837,
              "bbox": [
                174.7501983642578,
                337.0666198730469,
                221.88568115234375,
                359.69183349609375
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5313340425491333,
              "bbox": [
                219.86712646484375,
                293.2644348144531,
                297.8927917480469,
                336.7269592285156
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6551806926727295,
              "bbox": [
                252.68724060058594,
                339.7489318847656,
                326.9201965332031,
                359.577880859375
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.18880733847618103,
              "bbox": [
                194.12197875976562,
                82.13394165039062,
                335.89208984375,
                278.40484619140625
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.24854987859725952,
              "bbox": [
                232.3677520751953,
                181.73141479492188,
                306.89080810546875,
                234.64645385742188
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4028366208076477,
              "bbox": [
                245.61590576171875,
                234.88720703125,
                289.016357421875,
                320.25140380859375
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            530,
            532,
            499,
            537,
            507,
            528
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            7506,
            7510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7511,
            7515
          ],
          "representative_frame": 7511,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8410707712173462,
              "bbox": [
                287.6759033203125,
                1.0496501922607422,
                608.3494262695312,
                354.7972106933594
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.851408839225769,
              "bbox": [
                45.503231048583984,
                75.64421081542969,
                154.04248046875,
                299.96502685546875
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.10995490849018097,
              "bbox": [
                94.39768981933594,
                286.5942687988281,
                122.8493881225586,
                317.208740234375
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.41037848591804504,
              "bbox": [
                174.893798828125,
                336.97894287109375,
                222.15826416015625,
                359.6513671875
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.49206656217575073,
              "bbox": [
                219.70050048828125,
                293.20587158203125,
                297.89031982421875,
                336.7583312988281
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6379777789115906,
              "bbox": [
                252.4528350830078,
                339.8043518066406,
                327.0829772949219,
                359.5794677734375
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.11595466732978821,
              "bbox": [
                196.7446746826172,
                82.24998474121094,
                332.5185852050781,
                273.235595703125
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.10418377071619034,
              "bbox": [
                231.8850555419922,
                182.14515686035156,
                304.97100830078125,
                234.34518432617188
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.49234306812286377,
              "bbox": [
                245.5955047607422,
                234.84576416015625,
                288.9594421386719,
                320.2037048339844
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            530,
            532,
            499,
            537,
            507,
            528
          ],
          "total_detections": 9
        },
        {
          "group_index": 3,
          "frame_range": [
            7516,
            7520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7521,
            7525
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.742397665977478,
              "bbox": [
                270.488525390625,
                0.3769533634185791,
                600.7731323242188,
                355.1896057128906
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8669044375419617,
              "bbox": [
                46.04319381713867,
                80.37248229980469,
                153.49832153320312,
                297.86785888671875
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.17549128830432892,
              "bbox": [
                95.20832061767578,
                288.34857177734375,
                122.556884765625,
                317.2244873046875
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.40518781542778015,
              "bbox": [
                174.9102020263672,
                336.8310546875,
                222.45571899414062,
                359.6422119140625
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5449492335319519,
              "bbox": [
                219.77334594726562,
                293.1002502441406,
                298.13037109375,
                336.74969482421875
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6548979878425598,
              "bbox": [
                252.04808044433594,
                339.72918701171875,
                327.5101318359375,
                359.6041564941406
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.12045890837907791,
              "bbox": [
                191.41195678710938,
                81.81875610351562,
                326.7498474121094,
                278.16058349609375
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3485892415046692,
              "bbox": [
                245.7718048095703,
                235.27798461914062,
                288.8538818359375,
                320.06524658203125
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46439221501350403,
              "bbox": [
                206.55174255371094,
                82.74532318115234,
                308.4295959472656,
                200.2280731201172
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            530,
            532,
            499,
            537,
            528,
            549
          ],
          "total_detections": 9
        },
        {
          "group_index": 5,
          "frame_range": [
            7526,
            7530
          ],
          "representative_frame": 7526,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 62
    },
    {
      "second": 251,
      "time_range": [
        251,
        251.999
      ],
      "frame_range": [
        7531,
        7560
      ],
      "unified_description": "1-second scene showing a man with a tent and a bucket",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:29",
        "processing_time": 2.42,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7545,
          "frame_range": [
            7541,
            7545
          ],
          "description": "a man is putting a bucket in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.78
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7531,
            7535
          ],
          "representative_frame": 7531,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7407189011573792,
              "bbox": [
                277.7456970214844,
                0.6624779105186462,
                611.7347412109375,
                354.8701477050781
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8555931448936462,
              "bbox": [
                43.62089920043945,
                74.61241149902344,
                156.57650756835938,
                301.10821533203125
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.32898402214050293,
              "bbox": [
                175.04254150390625,
                336.8287048339844,
                222.57025146484375,
                359.6128234863281
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5105057954788208,
              "bbox": [
                219.40805053710938,
                292.6767272949219,
                298.4927673339844,
                336.79339599609375
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.641162633895874,
              "bbox": [
                251.56675720214844,
                339.7236633300781,
                327.5769958496094,
                359.64849853515625
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2342071533203125,
              "bbox": [
                194.10516357421875,
                81.65760040283203,
                325.1507568359375,
                275.9242858886719
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.40960612893104553,
              "bbox": [
                245.63319396972656,
                235.1884002685547,
                288.7447509765625,
                320.09161376953125
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5403099656105042,
              "bbox": [
                207.85044860839844,
                82.23989868164062,
                311.6966552734375,
                202.09295654296875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            530,
            532,
            499,
            537,
            528,
            549
          ],
          "total_detections": 8
        },
        {
          "group_index": 1,
          "frame_range": [
            7536,
            7540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7541,
            7545
          ],
          "representative_frame": 7541,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8848007917404175,
              "bbox": [
                262.4577941894531,
                0.6152881979942322,
                604.8724365234375,
                355.1905212402344
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8904051184654236,
              "bbox": [
                45.35576248168945,
                73.75244140625,
                156.88954162597656,
                294.7408752441406
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3172752261161804,
              "bbox": [
                174.94973754882812,
                337.0137023925781,
                222.23553466796875,
                359.6370849609375
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5298157930374146,
              "bbox": [
                219.34567260742188,
                292.60626220703125,
                298.6577453613281,
                336.89990234375
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6656977534294128,
              "bbox": [
                251.31629943847656,
                339.7099914550781,
                327.6957702636719,
                359.6479797363281
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.16516149044036865,
              "bbox": [
                188.35177612304688,
                81.35489654541016,
                319.674072265625,
                283.0660705566406
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4337952136993408,
              "bbox": [
                245.74855041503906,
                235.36151123046875,
                288.8125305175781,
                320.1558532714844
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.29913419485092163,
              "bbox": [
                202.21823120117188,
                82.42049407958984,
                304.43841552734375,
                201.0555419921875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            530,
            532,
            499,
            537,
            528,
            549
          ],
          "total_detections": 8
        },
        {
          "group_index": 3,
          "frame_range": [
            7546,
            7550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7551,
            7555
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9536371231079102,
              "bbox": [
                245.20423889160156,
                0.21140311658382416,
                596.6765747070312,
                353.93115234375
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9134361147880554,
              "bbox": [
                4.943719863891602,
                51.560447692871094,
                134.25965881347656,
                313.9759216308594
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2239680141210556,
              "bbox": [
                164.74220275878906,
                72.895263671875,
                319.1589050292969,
                314.3980407714844
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.32662779092788696,
              "bbox": [
                185.16368103027344,
                71.73273468017578,
                295.8480529785156,
                199.23831176757812
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            537,
            549
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            7556,
            7560
          ],
          "representative_frame": 7556,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 62
    },
    {
      "second": 252,
      "time_range": [
        252,
        252.999
      ],
      "frame_range": [
        7561,
        7590
      ],
      "unified_description": "1-second scene showing a man in a tent with a child",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:31",
        "processing_time": 2.3,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7575,
          "frame_range": [
            7571,
            7575
          ],
          "description": "a man in a tent with a child",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.17
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7561,
            7565
          ],
          "representative_frame": 7561,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9205979108810425,
              "bbox": [
                238.1060028076172,
                0.9274649620056152,
                597.0634155273438,
                353.56884765625
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9061326384544373,
              "bbox": [
                0.0,
                43.985809326171875,
                125.25765991210938,
                320.3857421875
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.17314651608467102,
              "bbox": [
                151.6046600341797,
                60.54939651489258,
                318.949462890625,
                327.01708984375
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.21190273761749268,
              "bbox": [
                176.13949584960938,
                58.25062942504883,
                297.660400390625,
                197.86444091796875
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4719252288341522,
              "bbox": [
                72.1484146118164,
                321.0682678222656,
                111.67305755615234,
                359.65478515625
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.33771923184394836,
              "bbox": [
                97.77629852294922,
                57.31414031982422,
                306.7970886230469,
                332.87042236328125
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            537,
            549,
            554,
            556
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7566,
            7570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7571,
            7575
          ],
          "representative_frame": 7571,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9309747219085693,
              "bbox": [
                231.40574645996094,
                0.8049759268760681,
                598.9798583984375,
                354.04351806640625
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8953536748886108,
              "bbox": [
                0.0,
                40.15318298339844,
                120.89360809326172,
                322.5387268066406
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4996802508831024,
              "bbox": [
                72.2471694946289,
                321.0747985839844,
                111.70293426513672,
                359.59307861328125
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            554
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            7576,
            7580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7581,
            7585
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9285020232200623,
              "bbox": [
                228.23585510253906,
                0.3508148789405823,
                603.376953125,
                354.3309326171875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9025625586509705,
              "bbox": [
                0.0,
                38.433815002441406,
                118.49305725097656,
                323.1876220703125
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.43592193722724915,
              "bbox": [
                72.31127166748047,
                321.10687255859375,
                111.7388687133789,
                359.60418701171875
              ]
            },
            {
              "track_id": 558,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3391458988189697,
              "bbox": [
                192.64866638183594,
                300.9081726074219,
                271.6261291503906,
                353.5664367675781
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4916033148765564,
              "bbox": [
                167.4320831298828,
                66.85687255859375,
                302.61236572265625,
                280.3817138671875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            554,
            558,
            537
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7586,
            7590
          ],
          "representative_frame": 7586,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 63
    },
    {
      "second": 253,
      "time_range": [
        253,
        253.999
      ],
      "frame_range": [
        7591,
        7620
      ],
      "unified_description": "1-second scene that includes a man cooking food in a tent, shot with action camera mounted on top of his head",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:32",
        "processing_time": 2.56,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7605,
          "frame_range": [
            7601,
            7605
          ],
          "description": "a man is cooking food in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.92
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7591,
            7595
          ],
          "representative_frame": 7591,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9502729773521423,
              "bbox": [
                244.85801696777344,
                0.528377115726471,
                622.1488037109375,
                355.4309997558594
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9049022197723389,
              "bbox": [
                0.0,
                34.12733840942383,
                118.20951843261719,
                323.7422180175781
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5957215428352356,
              "bbox": [
                72.39653778076172,
                321.1680603027344,
                111.74076843261719,
                359.5765380859375
              ]
            },
            {
              "track_id": 558,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3648374378681183,
              "bbox": [
                192.55386352539062,
                301.00115966796875,
                271.5475769042969,
                353.6704406738281
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5822335481643677,
              "bbox": [
                153.92051696777344,
                67.75614929199219,
                277.5240173339844,
                269.53253173828125
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.46096014976501465,
              "bbox": [
                213.12454223632812,
                149.82415771484375,
                328.1890563964844,
                236.2985076904297
              ]
            },
            {
              "track_id": 528,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7717136740684509,
              "bbox": [
                256.1542053222656,
                236.1510467529297,
                289.3752136230469,
                285.5033264160156
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            554,
            558,
            537,
            507,
            528
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            7596,
            7600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7601,
            7605
          ],
          "representative_frame": 7601,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9414275288581848,
              "bbox": [
                254.4295654296875,
                0.5883328318595886,
                632.262939453125,
                355.819580078125
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9153849482536316,
              "bbox": [
                0.0,
                31.7489013671875,
                117.8805923461914,
                324.1448974609375
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6229018568992615,
              "bbox": [
                72.41107940673828,
                321.1953125,
                111.7222900390625,
                359.5550231933594
              ]
            },
            {
              "track_id": 558,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4051643908023834,
              "bbox": [
                192.89047241210938,
                301.09698486328125,
                271.7037353515625,
                353.6291198730469
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7450037598609924,
              "bbox": [
                151.5294952392578,
                68.13690948486328,
                268.10723876953125,
                264.1643371582031
              ]
            },
            {
              "track_id": 560,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.8273548483848572,
              "bbox": [
                312.3805236816406,
                103.99440002441406,
                353.4501037597656,
                176.02227783203125
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.1303820013999939,
              "bbox": [
                219.96542358398438,
                145.3494873046875,
                338.9901123046875,
                235.1441192626953
              ]
            },
            {
              "track_id": 528,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6860154271125793,
              "bbox": [
                257.351806640625,
                234.44326782226562,
                294.35321044921875,
                279.7515869140625
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            554,
            558,
            537,
            560,
            507,
            528
          ],
          "total_detections": 8
        },
        {
          "group_index": 3,
          "frame_range": [
            7606,
            7610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7611,
            7615
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9539279937744141,
              "bbox": [
                253.66859436035156,
                0.5207457542419434,
                632.8244018554688,
                355.75201416015625
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9224666357040405,
              "bbox": [
                0.0,
                29.45660400390625,
                117.17037200927734,
                324.28851318359375
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6854422092437744,
              "bbox": [
                72.37290954589844,
                321.18536376953125,
                111.72164154052734,
                359.5697021484375
              ]
            },
            {
              "track_id": 558,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2961985766887665,
              "bbox": [
                192.93594360351562,
                301.0367126464844,
                271.6940002441406,
                353.5141906738281
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7590565085411072,
              "bbox": [
                155.1143035888672,
                68.45442199707031,
                269.3683166503906,
                264.1578369140625
              ]
            },
            {
              "track_id": 560,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.3671760857105255,
              "bbox": [
                313.4065246582031,
                107.51990509033203,
                353.01947021484375,
                177.00518798828125
              ]
            },
            {
              "track_id": 507,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.1316932886838913,
              "bbox": [
                201.8814697265625,
                142.5867919921875,
                344.5787658691406,
                258.3111572265625
              ]
            },
            {
              "track_id": 528,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.23032599687576294,
              "bbox": [
                248.94302368164062,
                235.6732940673828,
                285.9496765136719,
                276.988037109375
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            554,
            558,
            537,
            560,
            507,
            528
          ],
          "total_detections": 8
        },
        {
          "group_index": 5,
          "frame_range": [
            7616,
            7620
          ],
          "representative_frame": 7616,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 63
    },
    {
      "second": 254,
      "time_range": [
        254,
        254.999
      ],
      "frame_range": [
        7621,
        7650
      ],
      "unified_description": "1-second scene that includes a man cooking food in a tent",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:33",
        "processing_time": 2.49,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7635,
          "frame_range": [
            7631,
            7635
          ],
          "description": "a man is cooking food in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.65
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7621,
            7625
          ],
          "representative_frame": 7621,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9476842284202576,
              "bbox": [
                253.94561767578125,
                0.43059736490249634,
                634.104248046875,
                355.7200012207031
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9101656079292297,
              "bbox": [
                0.0,
                27.90563201904297,
                116.59452819824219,
                324.47235107421875
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.674058198928833,
              "bbox": [
                72.32379150390625,
                321.1689758300781,
                111.70284271240234,
                359.5759582519531
              ]
            },
            {
              "track_id": 558,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.25263965129852295,
              "bbox": [
                192.8848114013672,
                301.0283508300781,
                271.7041931152344,
                353.5293273925781
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7598714232444763,
              "bbox": [
                157.5796661376953,
                68.93334197998047,
                268.9894714355469,
                263.00494384765625
              ]
            },
            {
              "track_id": 560,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.6327352523803711,
              "bbox": [
                312.318359375,
                106.10486602783203,
                352.1416015625,
                175.99502563476562
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            554,
            558,
            537,
            560
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7626,
            7630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7631,
            7635
          ],
          "representative_frame": 7631,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9385333061218262,
              "bbox": [
                254.45294189453125,
                0.36114391684532166,
                635.2061767578125,
                355.4956359863281
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9163208603858948,
              "bbox": [
                0.0,
                27.150287628173828,
                115.69025421142578,
                324.2547912597656
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6588802337646484,
              "bbox": [
                72.4929428100586,
                321.2551574707031,
                111.7790756225586,
                359.566162109375
              ]
            },
            {
              "track_id": 558,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2799589931964874,
              "bbox": [
                192.86483764648438,
                301.123291015625,
                271.6437683105469,
                353.5771484375
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7406448125839233,
              "bbox": [
                156.26307678222656,
                68.24636840820312,
                265.244140625,
                262.54754638671875
              ]
            },
            {
              "track_id": 560,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.4579509496688843,
              "bbox": [
                308.4655456542969,
                99.89262390136719,
                349.5890808105469,
                171.99867248535156
              ]
            },
            {
              "track_id": 528,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6843342781066895,
              "bbox": [
                253.41091918945312,
                234.14707946777344,
                296.8857116699219,
                276.9252624511719
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            554,
            558,
            537,
            560,
            528
          ],
          "total_detections": 7
        },
        {
          "group_index": 3,
          "frame_range": [
            7636,
            7640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7641,
            7645
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.44623568654060364,
              "bbox": [
                255.2880859375,
                42.50497817993164,
                581.1650390625,
                349.45037841796875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6971521377563477,
              "bbox": [
                5.610039234161377,
                100.4989013671875,
                100.8593978881836,
                312.71405029296875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            7646,
            7650
          ],
          "representative_frame": 7646,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 63
    },
    {
      "second": 255,
      "time_range": [
        255,
        255.999
      ],
      "frame_range": [
        7651,
        7680
      ],
      "unified_description": "1-second scene that includes a man in a tent with a baby",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:34",
        "processing_time": 2.33,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7665,
          "frame_range": [
            7661,
            7665
          ],
          "description": "a man in a tent with a baby",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.61
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7651,
            7655
          ],
          "representative_frame": 7651,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.376690536737442,
              "bbox": [
                253.15223693847656,
                63.48888397216797,
                551.1636962890625,
                345.79296875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4856211543083191,
              "bbox": [
                13.94025707244873,
                133.91217041015625,
                94.41275787353516,
                304.2418518066406
              ]
            },
            {
              "track_id": 566,
              "class_id": 63,
              "class_name": "laptop",
              "confidence": 0.5105618238449097,
              "bbox": [
                259.8336181640625,
                228.2732696533203,
                349.04052734375,
                296.0308532714844
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46579596400260925,
              "bbox": [
                53.822296142578125,
                69.04608154296875,
                534.1393432617188,
                354.889404296875
              ]
            },
            {
              "track_id": 569,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3287600576877594,
              "bbox": [
                524.1956787109375,
                302.71636962890625,
                553.1370849609375,
                359.6155090332031
              ]
            },
            {
              "track_id": 554,
              "class_id": 40,
              "class_name": "wine glass",
              "confidence": 0.4798943102359772,
              "bbox": [
                70.16487121582031,
                318.5701904296875,
                110.78779602050781,
                359.26226806640625
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            566,
            567,
            569,
            554
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7656,
            7660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7661,
            7665
          ],
          "representative_frame": 7661,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6169909238815308,
              "bbox": [
                252.12107849121094,
                73.9441909790039,
                540.9550170898438,
                348.88201904296875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5737124681472778,
              "bbox": [
                16.701353073120117,
                146.98922729492188,
                92.88910675048828,
                300.1582946777344
              ]
            },
            {
              "track_id": 566,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.12398587912321091,
              "bbox": [
                251.24261474609375,
                229.71389770507812,
                342.0080261230469,
                298.646728515625
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3006954491138458,
              "bbox": [
                46.280174255371094,
                74.04032897949219,
                519.1742553710938,
                355.0531005859375
              ]
            },
            {
              "track_id": 569,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3177367150783539,
              "bbox": [
                524.5862426757812,
                302.3779602050781,
                552.4319458007812,
                357.0550537109375
              ]
            },
            {
              "track_id": 554,
              "class_id": 40,
              "class_name": "wine glass",
              "confidence": 0.36897528171539307,
              "bbox": [
                70.62451934814453,
                318.063720703125,
                110.4925765991211,
                359.1262512207031
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            566,
            567,
            569,
            554
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            7666,
            7670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7671,
            7675
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7141402363777161,
              "bbox": [
                243.99749755859375,
                85.49649047851562,
                527.13818359375,
                352.6100158691406
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.581976056098938,
              "bbox": [
                17.473176956176758,
                152.8427276611328,
                94.34679412841797,
                300.01849365234375
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3003460168838501,
              "bbox": [
                55.63614273071289,
                84.4566421508789,
                512.65576171875,
                355.2481994628906
              ]
            },
            {
              "track_id": 569,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.38949936628341675,
              "bbox": [
                524.0364379882812,
                302.2304382324219,
                551.6015625,
                356.1740417480469
              ]
            },
            {
              "track_id": 554,
              "class_id": 40,
              "class_name": "wine glass",
              "confidence": 0.3472013473510742,
              "bbox": [
                71.06295776367188,
                317.8844909667969,
                110.03285217285156,
                359.10418701171875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            567,
            569,
            554
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7676,
            7680
          ],
          "representative_frame": 7676,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 63
    },
    {
      "second": 256,
      "time_range": [
        256,
        256.999
      ],
      "frame_range": [
        7681,
        7710
      ],
      "unified_description": "1-second scene featuring a man in a tent eating food",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:35",
        "processing_time": 2.29,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7695,
          "frame_range": [
            7691,
            7695
          ],
          "description": "a man in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.99
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7681,
            7685
          ],
          "representative_frame": 7681,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.819219172000885,
              "bbox": [
                243.57891845703125,
                94.3348617553711,
                519.920166015625,
                352.80413818359375
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7246634364128113,
              "bbox": [
                19.350383758544922,
                157.18019104003906,
                99.5657958984375,
                302.89276123046875
              ]
            },
            {
              "track_id": 569,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2613163888454437,
              "bbox": [
                524.4139404296875,
                302.353759765625,
                552.0338745117188,
                356.2904968261719
              ]
            },
            {
              "track_id": 554,
              "class_id": 40,
              "class_name": "wine glass",
              "confidence": 0.31810957193374634,
              "bbox": [
                70.84439086914062,
                317.78668212890625,
                109.10960388183594,
                359.1521911621094
              ]
            },
            {
              "track_id": 566,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.4284970462322235,
              "bbox": [
                228.88919067382812,
                232.21298217773438,
                328.466064453125,
                308.1055603027344
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            569,
            554,
            566
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7686,
            7690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7691,
            7695
          ],
          "representative_frame": 7691,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8666374087333679,
              "bbox": [
                244.27227783203125,
                96.13782501220703,
                521.03271484375,
                354.0563659667969
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3903978765010834,
              "bbox": [
                18.042949676513672,
                164.83352661132812,
                99.30081176757812,
                305.9966125488281
              ]
            },
            {
              "track_id": 569,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3396154046058655,
              "bbox": [
                524.1065063476562,
                302.0283203125,
                552.1986694335938,
                356.7974853515625
              ]
            },
            {
              "track_id": 566,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.382841557264328,
              "bbox": [
                225.3849334716797,
                230.83389282226562,
                325.2588806152344,
                307.1147766113281
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            569,
            566
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            7696,
            7700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7701,
            7705
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6262475252151489,
              "bbox": [
                280.1875915527344,
                111.35636901855469,
                436.1061096191406,
                267.67474365234375
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6522505879402161,
              "bbox": [
                42.46006393432617,
                57.14279556274414,
                273.7978210449219,
                356.1489562988281
              ]
            }
          ],
          "unique_tracks": [
            502,
            556
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            7706,
            7710
          ],
          "representative_frame": 7706,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 64
    },
    {
      "second": 257,
      "time_range": [
        257,
        257.999
      ],
      "frame_range": [
        7711,
        7740
      ],
      "unified_description": "3D model of a scene with a man sitting in a tent with a camera",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:36",
        "processing_time": 2.5,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7725,
          "frame_range": [
            7721,
            7725
          ],
          "description": "a man sitting in a tent with a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7711,
            7715
          ],
          "representative_frame": 7711,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8698768019676208,
              "bbox": [
                434.29681396484375,
                106.78318786621094,
                638.2105102539062,
                350.3267517089844
              ]
            },
            {
              "track_id": 578,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.45445960760116577,
              "bbox": [
                302.48907470703125,
                262.823486328125,
                353.4419250488281,
                310.35357666015625
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6977660059928894,
              "bbox": [
                286.43798828125,
                111.6436767578125,
                430.1633605957031,
                266.5108337402344
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2925803065299988,
              "bbox": [
                38.97080612182617,
                56.955230712890625,
                274.2197265625,
                356.1958923339844
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5613552927970886,
              "bbox": [
                42.29206848144531,
                59.113250732421875,
                546.7744140625,
                356.4622497558594
              ]
            }
          ],
          "unique_tracks": [
            577,
            578,
            502,
            556,
            567
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7716,
            7720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7721,
            7725
          ],
          "representative_frame": 7721,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8735467195510864,
              "bbox": [
                434.143798828125,
                106.9299545288086,
                638.5621948242188,
                351.07122802734375
              ]
            },
            {
              "track_id": 578,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.49782276153564453,
              "bbox": [
                302.7502746582031,
                263.2759094238281,
                353.181640625,
                310.3290100097656
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6629215478897095,
              "bbox": [
                290.4226379394531,
                112.86375427246094,
                426.61627197265625,
                267.4031982421875
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.366801381111145,
              "bbox": [
                49.7759895324707,
                56.51093673706055,
                295.3638916015625,
                357.2577819824219
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5646761655807495,
              "bbox": [
                38.709869384765625,
                55.45533752441406,
                552.2687377929688,
                356.5682067871094
              ]
            }
          ],
          "unique_tracks": [
            577,
            578,
            502,
            556,
            567
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            7726,
            7730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7731,
            7735
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.891140341758728,
              "bbox": [
                433.8585510253906,
                106.97230529785156,
                639.3043823242188,
                352.3725891113281
              ]
            },
            {
              "track_id": 578,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.45277315378189087,
              "bbox": [
                302.91021728515625,
                263.5628662109375,
                353.06951904296875,
                310.37469482421875
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.657962441444397,
              "bbox": [
                281.0495910644531,
                111.81452941894531,
                421.4076843261719,
                274.88568115234375
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3972069025039673,
              "bbox": [
                67.01094055175781,
                57.553123474121094,
                325.82562255859375,
                357.35638427734375
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.595070481300354,
              "bbox": [
                36.098445892333984,
                54.098793029785156,
                554.33837890625,
                356.5059509277344
              ]
            },
            {
              "track_id": 507,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4833923876285553,
              "bbox": [
                167.15321350097656,
                129.28785705566406,
                340.9277038574219,
                290.83819580078125
              ]
            }
          ],
          "unique_tracks": [
            577,
            578,
            502,
            556,
            567,
            507
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            7736,
            7740
          ],
          "representative_frame": 7736,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 64
    },
    {
      "second": 258,
      "time_range": [
        258,
        258.999
      ],
      "frame_range": [
        7741,
        7770
      ],
      "unified_description": "3rd person perspective, wide-angle lens distortion, shaky camera, action camera on top of it, etc.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:37",
        "processing_time": 2.63,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7755,
          "frame_range": [
            7751,
            7755
          ],
          "description": "a man sitting in a tent with a woman",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.62
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7741,
            7745
          ],
          "representative_frame": 7741,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8934260010719299,
              "bbox": [
                433.83978271484375,
                107.23434448242188,
                639.3844604492188,
                352.7665710449219
              ]
            },
            {
              "track_id": 578,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4150995910167694,
              "bbox": [
                302.649658203125,
                263.15765380859375,
                353.12969970703125,
                310.2882385253906
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5771262645721436,
              "bbox": [
                287.4677429199219,
                108.99349975585938,
                422.1562805175781,
                270.4227600097656
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5736387372016907,
              "bbox": [
                42.750877380371094,
                55.79813766479492,
                303.6181335449219,
                357.0894470214844
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4973750412464142,
              "bbox": [
                15.026573181152344,
                53.36849594116211,
                531.7425537109375,
                356.7583312988281
              ]
            }
          ],
          "unique_tracks": [
            577,
            578,
            502,
            556,
            567
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7746,
            7750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7751,
            7755
          ],
          "representative_frame": 7751,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6340901255607605,
              "bbox": [
                425.083740234375,
                109.4396743774414,
                617.8822021484375,
                339.5040283203125
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5546645522117615,
              "bbox": [
                314.1473693847656,
                114.79830932617188,
                422.3676452636719,
                250.53248596191406
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4648040533065796,
              "bbox": [
                67.15714263916016,
                61.58842849731445,
                327.97003173828125,
                356.4964599609375
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.36324334144592285,
              "bbox": [
                49.45112609863281,
                58.859458923339844,
                557.4072875976562,
                356.0325927734375
              ]
            }
          ],
          "unique_tracks": [
            577,
            502,
            556,
            567
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            7756,
            7760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7761,
            7765
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.743389904499054,
              "bbox": [
                431.1119079589844,
                109.72595977783203,
                620.8782348632812,
                335.52789306640625
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7254534363746643,
              "bbox": [
                327.90264892578125,
                116.57332611083984,
                423.29107666015625,
                241.739990234375
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7823887467384338,
              "bbox": [
                83.98014831542969,
                68.04219055175781,
                344.6986083984375,
                356.247314453125
              ]
            },
            {
              "track_id": 591,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4141917824745178,
              "bbox": [
                368.5849304199219,
                251.70010375976562,
                397.30615234375,
                295.9822692871094
              ]
            },
            {
              "track_id": 592,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.32579490542411804,
              "bbox": [
                532.8878173828125,
                224.62261962890625,
                550.374267578125,
                245.16925048828125
              ]
            }
          ],
          "unique_tracks": [
            577,
            502,
            556,
            591,
            592
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7766,
            7770
          ],
          "representative_frame": 7766,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 64
    },
    {
      "second": 259,
      "time_range": [
        259,
        259.999
      ],
      "frame_range": [
        7771,
        7800
      ],
      "unified_description": "2 men are on a boat in the water, with one man sitting and another standing",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:39",
        "processing_time": 2.39,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7785,
          "frame_range": [
            7781,
            7785
          ],
          "description": "a man is sitting in a tent with a woman",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.47
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7771,
            7775
          ],
          "representative_frame": 7771,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7883833050727844,
              "bbox": [
                432.0392150878906,
                108.02316284179688,
                622.83740234375,
                334.5957946777344
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5685481429100037,
              "bbox": [
                339.2668151855469,
                117.5333480834961,
                413.6600646972656,
                214.74502563476562
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5075016021728516,
              "bbox": [
                104.14092254638672,
                76.7581558227539,
                367.38470458984375,
                356.0312805175781
              ]
            },
            {
              "track_id": 591,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.145355686545372,
              "bbox": [
                371.164306640625,
                254.3321075439453,
                398.533935546875,
                296.5712890625
              ]
            },
            {
              "track_id": 592,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.31982696056365967,
              "bbox": [
                532.7703857421875,
                224.58616638183594,
                550.5635375976562,
                245.5016326904297
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5777743458747864,
              "bbox": [
                92.48564147949219,
                74.85154724121094,
                579.5316772460938,
                355.47802734375
              ]
            }
          ],
          "unique_tracks": [
            577,
            502,
            556,
            591,
            592,
            567
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7776,
            7780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7781,
            7785
          ],
          "representative_frame": 7781,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8130096793174744,
              "bbox": [
                432.8922119140625,
                108.2724609375,
                623.6364135742188,
                334.29217529296875
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5366196632385254,
              "bbox": [
                337.7547912597656,
                117.84489440917969,
                421.3226318359375,
                231.16976928710938
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7738736867904663,
              "bbox": [
                95.05431365966797,
                83.49048614501953,
                356.9321594238281,
                356.1695861816406
              ]
            },
            {
              "track_id": 591,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.46821972727775574,
              "bbox": [
                370.63763427734375,
                255.79600524902344,
                396.7701110839844,
                295.90704345703125
              ]
            },
            {
              "track_id": 592,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.31652191281318665,
              "bbox": [
                532.7114868164062,
                224.5685272216797,
                550.6472778320312,
                245.6643524169922
              ]
            }
          ],
          "unique_tracks": [
            577,
            502,
            556,
            591,
            592
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            7786,
            7790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7791,
            7795
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.875271201133728,
              "bbox": [
                1.7034807205200195,
                0.0,
                211.29617309570312,
                259.93096923828125
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6440327167510986,
              "bbox": [
                170.6505889892578,
                271.70404052734375,
                240.7667694091797,
                325.19195556640625
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8824350833892822,
              "bbox": [
                177.37144470214844,
                15.651848793029785,
                640.0,
                348.3174133300781
              ]
            }
          ],
          "unique_tracks": [
            549,
            566,
            567
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            7796,
            7800
          ],
          "representative_frame": 7796,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 64
    },
    {
      "second": 260,
      "time_range": [
        260,
        260.999
      ],
      "frame_range": [
        7801,
        7830
      ],
      "unified_description": "2nd person POV, stable camera, wide-angle lens, action camera setup.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:40",
        "processing_time": 2.65,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7815,
          "frame_range": [
            7811,
            7815
          ],
          "description": "a group of people sitting around a campfire",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.18
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7801,
            7805
          ],
          "representative_frame": 7801,
          "detections": [
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8184486031532288,
              "bbox": [
                246.05836486816406,
                260.1163635253906,
                337.6142883300781,
                354.5032043457031
              ]
            },
            {
              "track_id": 599,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4855619966983795,
              "bbox": [
                293.4425964355469,
                188.0897216796875,
                338.27178955078125,
                270.4271545410156
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5674962401390076,
              "bbox": [
                242.33885192871094,
                0.582501232624054,
                354.04638671875,
                167.03042602539062
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5359711050987244,
              "bbox": [
                357.7357177734375,
                231.35409545898438,
                413.8015441894531,
                270.09051513671875
              ]
            },
            {
              "track_id": 602,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.4701174199581146,
              "bbox": [
                279.0531311035156,
                256.5345153808594,
                292.8875732421875,
                323.7298583984375
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3293510675430298,
              "bbox": [
                146.747314453125,
                244.15438842773438,
                187.95530700683594,
                285.2140808105469
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8742265105247498,
              "bbox": [
                3.7127840518951416,
                0.0,
                203.37071228027344,
                260.99810791015625
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6652869582176208,
              "bbox": [
                169.50161743164062,
                273.16082763671875,
                238.81869506835938,
                326.01556396484375
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8944928646087646,
              "bbox": [
                207.34658813476562,
                3.6901793479919434,
                640.0,
                348.7406311035156
              ]
            }
          ],
          "unique_tracks": [
            598,
            599,
            600,
            601,
            602,
            604,
            549,
            566,
            567
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            7806,
            7810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7811,
            7815
          ],
          "representative_frame": 7811,
          "detections": [
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8211644887924194,
              "bbox": [
                245.93695068359375,
                260.0547180175781,
                337.9334411621094,
                354.92156982421875
              ]
            },
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.19137121737003326,
              "bbox": [
                296.9610900878906,
                202.5146026611328,
                334.4245910644531,
                270.9916076660156
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5650442242622375,
              "bbox": [
                238.9411163330078,
                0.7321977615356445,
                365.7888488769531,
                189.9690704345703
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7373805642127991,
              "bbox": [
                357.7828674316406,
                231.46388244628906,
                413.4844665527344,
                269.9374084472656
              ]
            },
            {
              "track_id": 602,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.5609801411628723,
              "bbox": [
                279.4705810546875,
                257.0418701171875,
                293.1692810058594,
                323.54632568359375
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3623912036418915,
              "bbox": [
                146.68568420410156,
                244.4261016845703,
                187.20045471191406,
                284.79754638671875
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8896141052246094,
              "bbox": [
                3.281736135482788,
                0.0,
                196.54063415527344,
                260.3577880859375
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7014169692993164,
              "bbox": [
                168.55540466308594,
                273.48321533203125,
                238.0959014892578,
                326.5959777832031
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8679739236831665,
              "bbox": [
                225.6018829345703,
                0.0,
                640.0,
                346.35125732421875
              ]
            }
          ],
          "unique_tracks": [
            598,
            599,
            600,
            601,
            602,
            604,
            549,
            566,
            567
          ],
          "total_detections": 9
        },
        {
          "group_index": 3,
          "frame_range": [
            7816,
            7820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7821,
            7825
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8759799003601074,
              "bbox": [
                245.9820098876953,
                260.11492919921875,
                338.0930480957031,
                355.1387023925781
              ]
            },
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.31104373931884766,
              "bbox": [
                298.6872253417969,
                208.5252685546875,
                332.5486145019531,
                269.9013671875
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5259049534797668,
              "bbox": [
                236.51904296875,
                0.7980812788009644,
                367.7872314453125,
                197.12210083007812
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.660748302936554,
              "bbox": [
                356.3290710449219,
                231.3438262939453,
                412.313720703125,
                270.0654602050781
              ]
            },
            {
              "track_id": 602,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.5559680461883545,
              "bbox": [
                279.6984558105469,
                257.0911865234375,
                293.3919982910156,
                323.5429382324219
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4631485044956207,
              "bbox": [
                146.5123291015625,
                244.5350341796875,
                186.8457489013672,
                284.7112121582031
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8990877866744995,
              "bbox": [
                1.9477680921554565,
                0.0,
                191.21270751953125,
                260.00811767578125
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6514652967453003,
              "bbox": [
                168.64434814453125,
                273.4975280761719,
                237.90757751464844,
                326.43560791015625
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8995376825332642,
              "bbox": [
                373.8443908691406,
                10.9376859664917,
                640.0,
                347.2146911621094
              ]
            }
          ],
          "unique_tracks": [
            598,
            599,
            600,
            601,
            602,
            604,
            549,
            566,
            577
          ],
          "total_detections": 9
        },
        {
          "group_index": 5,
          "frame_range": [
            7826,
            7830
          ],
          "representative_frame": 7826,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 65
    },
    {
      "second": 261,
      "time_range": [
        261,
        261.999
      ],
      "frame_range": [
        7831,
        7860
      ],
      "unified_description": "3D video with object tracking showing a family in their tent as they go about their daily activities.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:41",
        "processing_time": 2.59,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7845,
          "frame_range": [
            7841,
            7845
          ],
          "description": "a man and two boys sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7831,
            7835
          ],
          "representative_frame": 7831,
          "detections": [
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8188042640686035,
              "bbox": [
                245.84829711914062,
                260.1484375,
                338.019775390625,
                355.2801513671875
              ]
            },
            {
              "track_id": 599,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.1942485272884369,
              "bbox": [
                297.8838806152344,
                206.5232391357422,
                333.3027038574219,
                270.2416076660156
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7712603211402893,
              "bbox": [
                270.1752624511719,
                2.5507752895355225,
                417.4220886230469,
                217.68942260742188
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.31764841079711914,
              "bbox": [
                358.3394470214844,
                230.98684692382812,
                415.2397766113281,
                270.2345886230469
              ]
            },
            {
              "track_id": 602,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.545951783657074,
              "bbox": [
                279.76959228515625,
                257.30877685546875,
                293.4152526855469,
                323.4789123535156
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.39648133516311646,
              "bbox": [
                146.9555206298828,
                244.78326416015625,
                186.87060546875,
                284.5259094238281
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8847560286521912,
              "bbox": [
                3.038357734680176,
                0.0,
                189.70510864257812,
                260.7254638671875
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5946100950241089,
              "bbox": [
                168.6851043701172,
                273.28662109375,
                238.2143096923828,
                326.49481201171875
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9006168246269226,
              "bbox": [
                373.7734069824219,
                0.0,
                640.0,
                349.67041015625
              ]
            }
          ],
          "unique_tracks": [
            598,
            599,
            600,
            601,
            602,
            604,
            549,
            566,
            577
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            7836,
            7840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7841,
            7845
          ],
          "representative_frame": 7841,
          "detections": [
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8152426481246948,
              "bbox": [
                245.73675537109375,
                259.99102783203125,
                338.0329284667969,
                355.3218994140625
              ]
            },
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.21355268359184265,
              "bbox": [
                298.1757507324219,
                208.48434448242188,
                332.8879089355469,
                270.23046875
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8168147802352905,
              "bbox": [
                281.41253662109375,
                3.829667568206787,
                439.63787841796875,
                228.777099609375
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5236912965774536,
              "bbox": [
                356.78216552734375,
                231.33746337890625,
                412.70440673828125,
                269.9788818359375
              ]
            },
            {
              "track_id": 602,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.56082683801651,
              "bbox": [
                279.8162536621094,
                257.3871765136719,
                293.44921875,
                323.4407043457031
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.29911699891090393,
              "bbox": [
                147.00311279296875,
                244.6531219482422,
                186.94720458984375,
                284.37420654296875
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8706158995628357,
              "bbox": [
                4.133296966552734,
                0.0,
                186.72772216796875,
                260.0934143066406
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.587751567363739,
              "bbox": [
                168.8310546875,
                273.0838928222656,
                238.61643981933594,
                326.54180908203125
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9097880721092224,
              "bbox": [
                373.2124328613281,
                0.0,
                640.0,
                353.4469909667969
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3825327455997467,
              "bbox": [
                2.9965269565582275,
                38.91764450073242,
                63.767799377441406,
                288.26959228515625
              ]
            }
          ],
          "unique_tracks": [
            598,
            599,
            600,
            601,
            602,
            604,
            549,
            566,
            577,
            611
          ],
          "total_detections": 10
        },
        {
          "group_index": 3,
          "frame_range": [
            7846,
            7850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7851,
            7855
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.37333282828330994,
              "bbox": [
                298.02520751953125,
                208.3551788330078,
                333.3457946777344,
                270.4613037109375
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.15159066021442413,
              "bbox": [
                246.47689819335938,
                1.5144364833831787,
                413.5141296386719,
                229.38026428222656
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4675767719745636,
              "bbox": [
                356.3475341796875,
                231.60391235351562,
                411.322998046875,
                269.6554870605469
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5539857745170593,
              "bbox": [
                147.01812744140625,
                244.57095336914062,
                186.9679412841797,
                284.2517395019531
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.808035135269165,
              "bbox": [
                43.54302978515625,
                0.0,
                238.0503387451172,
                262.4453125
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6407478451728821,
              "bbox": [
                168.9718017578125,
                272.9296875,
                239.08676147460938,
                326.7448425292969
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8704676628112793,
              "bbox": [
                358.7338562011719,
                0.0,
                640.0,
                354.7736511230469
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.14936195313930511,
              "bbox": [
                1.9783945083618164,
                38.55961608886719,
                62.955528259277344,
                288.4941711425781
              ]
            },
            {
              "track_id": 507,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.7944835424423218,
              "bbox": [
                114.46428680419922,
                30.198144912719727,
                327.8582763671875,
                266.30316162109375
              ]
            }
          ],
          "unique_tracks": [
            599,
            600,
            601,
            604,
            549,
            566,
            577,
            611,
            507
          ],
          "total_detections": 9
        },
        {
          "group_index": 5,
          "frame_range": [
            7856,
            7860
          ],
          "representative_frame": 7856,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 65
    },
    {
      "second": 262,
      "time_range": [
        262,
        262.999
      ],
      "frame_range": [
        7861,
        7890
      ],
      "unified_description": "2 people are in the tent, but there is no further information provided about the scene or objects within it.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:43",
        "processing_time": 2.47,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7875,
          "frame_range": [
            7871,
            7875
          ],
          "description": "a man and a child are sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.44
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7861,
            7865
          ],
          "representative_frame": 7861,
          "detections": [
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3133520483970642,
              "bbox": [
                297.821044921875,
                208.00746154785156,
                333.7710266113281,
                270.48486328125
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5041131377220154,
              "bbox": [
                356.634521484375,
                231.85531616210938,
                410.8843688964844,
                269.4330139160156
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5667537450790405,
              "bbox": [
                147.1002197265625,
                244.55374145507812,
                186.90350341796875,
                284.0376281738281
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.690704882144928,
              "bbox": [
                57.291717529296875,
                0.0,
                261.3267822265625,
                263.6546325683594
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.572167694568634,
              "bbox": [
                169.24105834960938,
                272.807373046875,
                239.25335693359375,
                326.62445068359375
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8806492686271667,
              "bbox": [
                352.3626403808594,
                0.0,
                640.0,
                354.9083251953125
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.16669215261936188,
              "bbox": [
                4.98515510559082,
                36.86772918701172,
                66.34983825683594,
                286.93939208984375
              ]
            },
            {
              "track_id": 618,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.47038283944129944,
              "bbox": [
                265.9341735839844,
                231.86642456054688,
                347.3503112792969,
                289.7350158691406
              ]
            },
            {
              "track_id": 507,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.7494091987609863,
              "bbox": [
                121.96963500976562,
                19.95294761657715,
                317.6092224121094,
                266.5902404785156
              ]
            }
          ],
          "unique_tracks": [
            599,
            601,
            604,
            549,
            566,
            577,
            611,
            618,
            507
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            7866,
            7870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7871,
            7875
          ],
          "representative_frame": 7871,
          "detections": [
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2778940200805664,
              "bbox": [
                297.5782775878906,
                207.68106079101562,
                334.13677978515625,
                270.47332763671875
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5558037161827087,
              "bbox": [
                356.509033203125,
                231.80918884277344,
                410.8767395019531,
                269.53863525390625
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5765309929847717,
              "bbox": [
                147.15585327148438,
                244.56248474121094,
                186.89105224609375,
                283.92657470703125
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8347865343093872,
              "bbox": [
                27.524885177612305,
                0.009339859709143639,
                225.41094970703125,
                264.1105651855469
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6384732127189636,
              "bbox": [
                169.40121459960938,
                272.7052917480469,
                239.46238708496094,
                326.64007568359375
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9269866347312927,
              "bbox": [
                348.53656005859375,
                0.0,
                639.480712890625,
                354.9598388671875
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.18320421874523163,
              "bbox": [
                6.181600093841553,
                34.003692626953125,
                68.616943359375,
                286.4483642578125
              ]
            },
            {
              "track_id": 618,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.582889199256897,
              "bbox": [
                265.93145751953125,
                231.9242706298828,
                347.1929016113281,
                289.6826171875
              ]
            },
            {
              "track_id": 507,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.7267904281616211,
              "bbox": [
                134.22869873046875,
                33.4616813659668,
                302.9788513183594,
                266.7933654785156
              ]
            },
            {
              "track_id": 621,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.31823888421058655,
              "bbox": [
                314.326904296875,
                315.5809631347656,
                341.2976989746094,
                359.4454345703125
              ]
            }
          ],
          "unique_tracks": [
            599,
            601,
            604,
            549,
            566,
            577,
            611,
            618,
            507,
            621
          ],
          "total_detections": 10
        },
        {
          "group_index": 3,
          "frame_range": [
            7876,
            7880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7881,
            7885
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.1899392157793045,
              "bbox": [
                297.4054260253906,
                207.59825134277344,
                334.5098571777344,
                270.560791015625
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.49192142486572266,
              "bbox": [
                147.448974609375,
                244.6746368408203,
                186.88755798339844,
                283.7061462402344
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8645784854888916,
              "bbox": [
                17.301185607910156,
                0.0,
                210.26177978515625,
                264.7126159667969
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4841373860836029,
              "bbox": [
                169.82833862304688,
                272.68865966796875,
                239.40057373046875,
                326.24237060546875
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.823799192905426,
              "bbox": [
                349.08990478515625,
                0.0,
                638.8978271484375,
                353.9356384277344
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2542608082294464,
              "bbox": [
                4.298168182373047,
                35.98799514770508,
                66.91964721679688,
                288.0118408203125
              ]
            },
            {
              "track_id": 618,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5374207496643066,
              "bbox": [
                265.92388916015625,
                232.17153930664062,
                346.8584899902344,
                289.7264099121094
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3870600163936615,
              "bbox": [
                273.7140197753906,
                2.2398924827575684,
                454.317138671875,
                235.91432189941406
              ]
            }
          ],
          "unique_tracks": [
            599,
            604,
            549,
            566,
            577,
            611,
            618,
            600
          ],
          "total_detections": 8
        },
        {
          "group_index": 5,
          "frame_range": [
            7886,
            7890
          ],
          "representative_frame": 7886,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 65
    },
    {
      "second": 263,
      "time_range": [
        263,
        263.999
      ],
      "frame_range": [
        7891,
        7920
      ],
      "unified_description": "1-second scene where a man and a child sit inside a tent with a backpack nearby. The camera is handheld and capturing the scene in wide-angle perspective.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:44",
        "processing_time": 2.94,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7905,
          "frame_range": [
            7901,
            7905
          ],
          "description": "a man and a child are sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.54
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7891,
            7895
          ],
          "representative_frame": 7891,
          "detections": [
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.17661833763122559,
              "bbox": [
                297.16241455078125,
                207.4002227783203,
                334.8381042480469,
                270.5979309082031
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4660899043083191,
              "bbox": [
                147.5347442626953,
                244.6913604736328,
                186.94039916992188,
                283.6617431640625
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8567741513252258,
              "bbox": [
                14.72562313079834,
                0.0,
                203.3983612060547,
                265.1016540527344
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5058155059814453,
              "bbox": [
                170.01815795898438,
                272.6361999511719,
                239.4937744140625,
                326.1225891113281
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8442144989967346,
              "bbox": [
                349.3287658691406,
                0.0,
                638.7401123046875,
                353.8481750488281
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.21109606325626373,
              "bbox": [
                5.340224742889404,
                37.1773567199707,
                65.85893249511719,
                278.165283203125
              ]
            },
            {
              "track_id": 618,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5387206673622131,
              "bbox": [
                266.1761474609375,
                232.18814086914062,
                346.9583740234375,
                289.6554870605469
              ]
            },
            {
              "track_id": 622,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.36090993881225586,
              "bbox": [
                219.55072021484375,
                0.628192126750946,
                350.7532043457031,
                109.92105102539062
              ]
            },
            {
              "track_id": 623,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.35667386651039124,
              "bbox": [
                221.62368774414062,
                0.2673492431640625,
                348.0079040527344,
                187.03363037109375
              ]
            }
          ],
          "unique_tracks": [
            599,
            604,
            549,
            566,
            577,
            611,
            618,
            622,
            623
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            7896,
            7900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7901,
            7905
          ],
          "representative_frame": 7901,
          "detections": [
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.1596611589193344,
              "bbox": [
                296.91839599609375,
                207.26199340820312,
                335.0923767089844,
                270.591064453125
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4547119140625,
              "bbox": [
                147.6407470703125,
                244.70352172851562,
                186.8531494140625,
                283.42474365234375
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8556984066963196,
              "bbox": [
                14.879300117492676,
                0.09554842859506607,
                198.99087524414062,
                264.51507568359375
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.49570736289024353,
              "bbox": [
                170.1539306640625,
                272.5854187011719,
                239.59266662597656,
                326.05010986328125
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8178321123123169,
              "bbox": [
                365.3197937011719,
                0.0,
                640.0,
                354.41949462890625
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.17351676523685455,
              "bbox": [
                4.517327785491943,
                37.21647262573242,
                67.68770599365234,
                286.84210205078125
              ]
            },
            {
              "track_id": 618,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5250137448310852,
              "bbox": [
                266.2718811035156,
                232.1985626220703,
                346.9693298339844,
                289.6286926269531
              ]
            },
            {
              "track_id": 622,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2613714337348938,
              "bbox": [
                215.9748992919922,
                0.48690053820610046,
                345.50653076171875,
                108.0077896118164
              ]
            },
            {
              "track_id": 623,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.37724006175994873,
              "bbox": [
                216.85488891601562,
                0.44977736473083496,
                343.0958557128906,
                186.2418975830078
              ]
            },
            {
              "track_id": 507,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.46438491344451904,
              "bbox": [
                134.1395263671875,
                9.463577270507812,
                303.0074157714844,
                266.253173828125
              ]
            }
          ],
          "unique_tracks": [
            599,
            604,
            549,
            566,
            577,
            611,
            618,
            622,
            623,
            507
          ],
          "total_detections": 10
        },
        {
          "group_index": 3,
          "frame_range": [
            7906,
            7910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7911,
            7915
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7152742743492126,
              "bbox": [
                375.77972412109375,
                0.0,
                640.0,
                346.95611572265625
              ]
            }
          ],
          "unique_tracks": [
            577
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            7916,
            7920
          ],
          "representative_frame": 7916,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 65
    },
    {
      "second": 264,
      "time_range": [
        264,
        264.999
      ],
      "frame_range": [
        7921,
        7950
      ],
      "unified_description": "2 people standing by a wall, one of them closer to the center of the image, and the other further to the right. A backpack is visible near both individuals. The scene appears to be captured using a first-person perspective, suggesting that the camera may have been mounted on the body of one of the subjects. The overall image quality seems to be relatively low due to potential camera movement or shaky handling during filming.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:46",
        "processing_time": 4.56,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7935,
          "frame_range": [
            7931,
            7935
          ],
          "description": "a man is sitting in the grass with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7921,
            7925
          ],
          "representative_frame": 7921,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6278578639030457,
              "bbox": [
                389.90911865234375,
                0.0,
                640.0,
                344.72418212890625
              ]
            },
            {
              "track_id": 628,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7874366044998169,
              "bbox": [
                350.0651550292969,
                201.87252807617188,
                461.38580322265625,
                292.5496520996094
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3878105878829956,
              "bbox": [
                250.66363525390625,
                146.5224151611328,
                339.2921447753906,
                200.58636474609375
              ]
            },
            {
              "track_id": 631,
              "class_id": 43,
              "class_name": "knife",
              "confidence": 0.416880339384079,
              "bbox": [
                302.1962585449219,
                325.9880065917969,
                474.5410461425781,
                355.2725830078125
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5017807483673096,
              "bbox": [
                140.98983764648438,
                176.22935485839844,
                220.76414489746094,
                230.42623901367188
              ]
            },
            {
              "track_id": 502,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.5230221152305603,
              "bbox": [
                369.1566467285156,
                82.59373474121094,
                479.30902099609375,
                242.2916259765625
              ]
            }
          ],
          "unique_tracks": [
            577,
            628,
            629,
            631,
            633,
            502
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7926,
            7930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7931,
            7935
          ],
          "representative_frame": 7931,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8844832181930542,
              "bbox": [
                389.3044128417969,
                0.0,
                640.0,
                342.41387939453125
              ]
            },
            {
              "track_id": 628,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.504423975944519,
              "bbox": [
                338.354248046875,
                200.0646209716797,
                462.23944091796875,
                301.6775817871094
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5655696392059326,
              "bbox": [
                250.92291259765625,
                146.5704803466797,
                339.1591491699219,
                200.38978576660156
              ]
            },
            {
              "track_id": 631,
              "class_id": 43,
              "class_name": "knife",
              "confidence": 0.1663529872894287,
              "bbox": [
                306.0856018066406,
                325.9882507324219,
                471.21099853515625,
                354.01068115234375
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.40996456146240234,
              "bbox": [
                140.90792846679688,
                176.16964721679688,
                220.69210815429688,
                230.38671875
              ]
            }
          ],
          "unique_tracks": [
            577,
            628,
            629,
            631,
            633
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            7936,
            7940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7941,
            7945
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9262943863868713,
              "bbox": [
                355.01025390625,
                0.0,
                626.067626953125,
                342.593505859375
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.503821074962616,
              "bbox": [
                252.3436279296875,
                146.69227600097656,
                338.89276123046875,
                199.4132080078125
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.29458144307136536,
              "bbox": [
                141.36083984375,
                176.2274169921875,
                220.40977478027344,
                229.94300842285156
              ]
            },
            {
              "track_id": 635,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.31781941652297974,
              "bbox": [
                4.760979652404785,
                273.6971130371094,
                254.80088806152344,
                357.7924499511719
              ]
            }
          ],
          "unique_tracks": [
            577,
            629,
            633,
            635
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            7946,
            7950
          ],
          "representative_frame": 7946,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 66
    },
    {
      "second": 265,
      "time_range": [
        265,
        265.999
      ],
      "frame_range": [
        7951,
        7980
      ],
      "unified_description": "1-second scene including a man, camera perspective, field of view, and lens characteristics.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:47",
        "processing_time": 2.58,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7965,
          "frame_range": [
            7961,
            7965
          ],
          "description": "a man is sitting on the ground with a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.0
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7951,
            7955
          ],
          "representative_frame": 7951,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9407230615615845,
              "bbox": [
                339.84259033203125,
                0.0,
                616.8089599609375,
                343.0104675292969
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3893735408782959,
              "bbox": [
                252.47792053222656,
                146.63851928710938,
                339.4270935058594,
                199.5338592529297
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.34709349274635315,
              "bbox": [
                141.50579833984375,
                176.32559204101562,
                220.44561767578125,
                229.96331787109375
              ]
            },
            {
              "track_id": 635,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.29215294122695923,
              "bbox": [
                3.5419440269470215,
                272.53131103515625,
                257.6829528808594,
                357.96978759765625
              ]
            }
          ],
          "unique_tracks": [
            577,
            629,
            633,
            635
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            7956,
            7960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7961,
            7965
          ],
          "representative_frame": 7961,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9299252033233643,
              "bbox": [
                333.52862548828125,
                0.0,
                615.5663452148438,
                343.1455993652344
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.42980891466140747,
              "bbox": [
                252.2836151123047,
                146.657958984375,
                339.5376892089844,
                199.67083740234375
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.31878477334976196,
              "bbox": [
                141.55914306640625,
                176.3154296875,
                220.4447021484375,
                229.90980529785156
              ]
            },
            {
              "track_id": 635,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2775896191596985,
              "bbox": [
                0.9032386541366577,
                272.01727294921875,
                256.35235595703125,
                357.8988952636719
              ]
            }
          ],
          "unique_tracks": [
            577,
            629,
            633,
            635
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            7966,
            7970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7971,
            7975
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.930353045463562,
              "bbox": [
                329.70367431640625,
                0.0,
                616.168701171875,
                343.0703125
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.43384069204330444,
              "bbox": [
                252.2691192626953,
                146.65565490722656,
                339.7165222167969,
                199.69961547851562
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4147486388683319,
              "bbox": [
                141.61927795410156,
                176.3184814453125,
                220.3747100830078,
                229.81524658203125
              ]
            },
            {
              "track_id": 635,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.29568591713905334,
              "bbox": [
                2.017534017562866,
                271.9769592285156,
                257.56182861328125,
                357.8284606933594
              ]
            }
          ],
          "unique_tracks": [
            577,
            629,
            633,
            635
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            7976,
            7980
          ],
          "representative_frame": 7976,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 66
    },
    {
      "second": 266,
      "time_range": [
        266,
        266.999
      ],
      "frame_range": [
        7981,
        8010
      ],
      "unified_description": "\nThe image shows a person standing outdoors with a camera recording their activities. They appear to be near a wall with objects hanging on it. Several other objects are in various positions throughout the scene, and there is another person nearby. The camera captures the entire scene, showcasing the various elements within the frame.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:49",
        "processing_time": 3.54,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7995,
          "frame_range": [
            7991,
            7995
          ],
          "description": "a man is putting a fish in a bucket",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.07
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7981,
            7985
          ],
          "representative_frame": 7981,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9211560487747192,
              "bbox": [
                313.3548889160156,
                0.0,
                605.8030395507812,
                340.3551940917969
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.55855792760849,
              "bbox": [
                251.1384735107422,
                146.43740844726562,
                339.9976806640625,
                200.3741912841797
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.40730002522468567,
              "bbox": [
                142.419677734375,
                176.11427307128906,
                219.37503051757812,
                228.28289794921875
              ]
            },
            {
              "track_id": 635,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2148115634918213,
              "bbox": [
                0.4147382378578186,
                270.8072509765625,
                258.4449157714844,
                357.5169982910156
              ]
            }
          ],
          "unique_tracks": [
            577,
            629,
            633,
            635
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            7986,
            7990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7991,
            7995
          ],
          "representative_frame": 7991,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9184203147888184,
              "bbox": [
                304.60589599609375,
                0.0,
                603.6199951171875,
                339.05670166015625
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.545185923576355,
              "bbox": [
                250.86122131347656,
                146.36239624023438,
                340.10089111328125,
                200.5536346435547
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4536355137825012,
              "bbox": [
                142.43040466308594,
                175.92665100097656,
                219.5101776123047,
                228.06300354003906
              ]
            },
            {
              "track_id": 635,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.299805611371994,
              "bbox": [
                0.0,
                270.432861328125,
                259.17095947265625,
                357.6207275390625
              ]
            },
            {
              "track_id": 638,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3235057294368744,
              "bbox": [
                229.56396484375,
                110.99848175048828,
                260.0094909667969,
                143.29974365234375
              ]
            },
            {
              "track_id": 639,
              "class_id": 51,
              "class_name": "carrot",
              "confidence": 0.30440282821655273,
              "bbox": [
                490.86505126953125,
                311.58892822265625,
                614.6846923828125,
                359.8641662597656
              ]
            }
          ],
          "unique_tracks": [
            577,
            629,
            633,
            635,
            638,
            639
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            7996,
            8000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8001,
            8005
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9253782033920288,
              "bbox": [
                299.43914794921875,
                0.0,
                605.0035400390625,
                338.7336730957031
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.561390221118927,
              "bbox": [
                250.775634765625,
                146.3450164794922,
                339.98095703125,
                200.54014587402344
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4706999957561493,
              "bbox": [
                142.43336486816406,
                175.87559509277344,
                219.56666564941406,
                227.9219970703125
              ]
            },
            {
              "track_id": 635,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.28516021370887756,
              "bbox": [
                2.5756516456604004,
                272.318115234375,
                256.4001770019531,
                357.5332946777344
              ]
            },
            {
              "track_id": 638,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3402214050292969,
              "bbox": [
                229.56932067871094,
                110.99024200439453,
                260.0537414550781,
                143.3318328857422
              ]
            },
            {
              "track_id": 639,
              "class_id": 51,
              "class_name": "carrot",
              "confidence": 0.27256709337234497,
              "bbox": [
                490.9561462402344,
                311.5071716308594,
                615.2764892578125,
                359.9691467285156
              ]
            },
            {
              "track_id": 642,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.3074233829975128,
              "bbox": [
                90.3803482055664,
                221.4825897216797,
                137.67416381835938,
                258.85345458984375
              ]
            }
          ],
          "unique_tracks": [
            577,
            629,
            633,
            635,
            638,
            639,
            642
          ],
          "total_detections": 7
        },
        {
          "group_index": 5,
          "frame_range": [
            8006,
            8010
          ],
          "representative_frame": 8006,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 66
    },
    {
      "second": 267,
      "time_range": [
        267,
        267.999
      ],
      "frame_range": [
        8011,
        8040
      ],
      "unified_description": "3D model of a scene with objects in it",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:50",
        "processing_time": 2.26,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8025,
          "frame_range": [
            8021,
            8025
          ],
          "description": "a man in a tent with a backpack and a cup",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.49
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8011,
            8015
          ],
          "representative_frame": 8011,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9495038390159607,
              "bbox": [
                310.97930908203125,
                1.1951147317886353,
                624.8020629882812,
                349.0202331542969
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6450350284576416,
              "bbox": [
                268.1917419433594,
                303.92730712890625,
                326.71929931640625,
                359.1546630859375
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.4371529817581177,
              "bbox": [
                36.29724884033203,
                54.59129333496094,
                174.3241729736328,
                248.90908813476562
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.41516315937042236,
              "bbox": [
                1.8258076906204224,
                83.43616485595703,
                65.03755950927734,
                331.11126708984375
              ]
            }
          ],
          "unique_tracks": [
            577,
            598,
            549,
            611
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            8016,
            8020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8021,
            8025
          ],
          "representative_frame": 8021,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9347538352012634,
              "bbox": [
                313.4991149902344,
                0.8780788779258728,
                631.536865234375,
                352.5781555175781
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6963168382644653,
              "bbox": [
                160.5066680908203,
                340.02899169921875,
                230.87673950195312,
                360.0
              ]
            },
            {
              "track_id": 646,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.3374529480934143,
              "bbox": [
                111.78490447998047,
                146.08285522460938,
                188.99293518066406,
                210.5769500732422
              ]
            },
            {
              "track_id": 647,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.35461899638175964,
              "bbox": [
                119.99447631835938,
                175.26507568359375,
                210.46316528320312,
                274.6095886230469
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.34637847542762756,
              "bbox": [
                164.5900421142578,
                133.71368408203125,
                255.81585693359375,
                333.37005615234375
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6810886859893799,
              "bbox": [
                266.79803466796875,
                304.60614013671875,
                328.3543395996094,
                359.2446594238281
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.6565223336219788,
              "bbox": [
                37.22441101074219,
                56.80027770996094,
                174.95834350585938,
                248.15028381347656
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3756777048110962,
              "bbox": [
                0.9243791699409485,
                85.02125549316406,
                64.27743530273438,
                332.6090087890625
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            646,
            647,
            650,
            598,
            549,
            611
          ],
          "total_detections": 8
        },
        {
          "group_index": 3,
          "frame_range": [
            8026,
            8030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8031,
            8035
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9385920166969299,
              "bbox": [
                306.5524597167969,
                0.22226236760616302,
                628.9182739257812,
                353.9943542480469
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.70845627784729,
              "bbox": [
                160.678955078125,
                340.03619384765625,
                231.02999877929688,
                360.0
              ]
            },
            {
              "track_id": 646,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.2101489007472992,
              "bbox": [
                111.87105560302734,
                146.0838165283203,
                188.8012237548828,
                210.3255615234375
              ]
            },
            {
              "track_id": 647,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.25086545944213867,
              "bbox": [
                120.33035278320312,
                175.32054138183594,
                210.9259033203125,
                274.8006286621094
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.20139570534229279,
              "bbox": [
                165.41090393066406,
                137.67596435546875,
                254.80763244628906,
                333.22869873046875
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.719292938709259,
              "bbox": [
                265.5951843261719,
                304.914306640625,
                329.6181640625,
                359.2928466796875
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.5663294196128845,
              "bbox": [
                36.8721923828125,
                57.526058197021484,
                175.51251220703125,
                248.22801208496094
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.45769673585891724,
              "bbox": [
                0.8382664918899536,
                85.7662582397461,
                64.53602600097656,
                333.7569274902344
              ]
            },
            {
              "track_id": 651,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.38455072045326233,
              "bbox": [
                285.735107421875,
                278.2958679199219,
                330.384033203125,
                343.3463439941406
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            646,
            647,
            650,
            598,
            549,
            611,
            651
          ],
          "total_detections": 9
        },
        {
          "group_index": 5,
          "frame_range": [
            8036,
            8040
          ],
          "representative_frame": 8036,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 66
    },
    {
      "second": 268,
      "time_range": [
        268,
        268.999
      ],
      "frame_range": [
        8041,
        8070
      ],
      "unified_description": "\nThe image captures a scene with a man in a hat and jacket sitting next to a tent. There are several other objects and people in the frame, creating a dynamic and engaging visual narrative. The camera perspective offers an interesting viewpoint, and various technical details reveal information about the video production style and characteristics of the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:52",
        "processing_time": 3.42,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8055,
          "frame_range": [
            8051,
            8055
          ],
          "description": "a man in a hat and jacket is sitting next to a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.58
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8041,
            8045
          ],
          "representative_frame": 8041,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9383443593978882,
              "bbox": [
                299.9027099609375,
                0.4486452043056488,
                625.7906494140625,
                354.6112976074219
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7185695171356201,
              "bbox": [
                160.6860809326172,
                340.0345764160156,
                231.0509033203125,
                360.0
              ]
            },
            {
              "track_id": 646,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.1782827377319336,
              "bbox": [
                112.0142822265625,
                146.10946655273438,
                188.70907592773438,
                210.12600708007812
              ]
            },
            {
              "track_id": 647,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.14900141954421997,
              "bbox": [
                120.53988647460938,
                175.27304077148438,
                211.2177734375,
                274.84051513671875
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.13458985090255737,
              "bbox": [
                165.54217529296875,
                138.0707550048828,
                254.66844177246094,
                332.9001159667969
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7294853329658508,
              "bbox": [
                264.40753173828125,
                304.8670959472656,
                330.6588134765625,
                359.2572937011719
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.42906466126441956,
              "bbox": [
                36.01852035522461,
                57.674869537353516,
                175.8178253173828,
                248.3496551513672
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4679699242115021,
              "bbox": [
                1.2297269105911255,
                85.9064712524414,
                65.43782806396484,
                334.29779052734375
              ]
            },
            {
              "track_id": 651,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3731842637062073,
              "bbox": [
                285.41595458984375,
                278.12225341796875,
                330.6414794921875,
                344.031005859375
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.35604071617126465,
              "bbox": [
                277.3768310546875,
                196.67111206054688,
                353.4567565917969,
                266.2159423828125
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            646,
            647,
            650,
            598,
            549,
            611,
            651,
            653
          ],
          "total_detections": 10
        },
        {
          "group_index": 1,
          "frame_range": [
            8046,
            8050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8051,
            8055
          ],
          "representative_frame": 8051,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8983263969421387,
              "bbox": [
                322.1054382324219,
                0.05025646090507507,
                640.0,
                355.4842224121094
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7177516222000122,
              "bbox": [
                160.61392211914062,
                340.01544189453125,
                231.06048583984375,
                360.0
              ]
            },
            {
              "track_id": 646,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.21083451807498932,
              "bbox": [
                112.7548828125,
                146.01663208007812,
                188.2949981689453,
                208.9998779296875
              ]
            },
            {
              "track_id": 647,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.12469696253538132,
              "bbox": [
                120.59027862548828,
                175.1923370361328,
                211.3203125,
                274.833740234375
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.1420917510986328,
              "bbox": [
                164.5265350341797,
                133.68955993652344,
                255.7467498779297,
                333.1707458496094
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5884374380111694,
              "bbox": [
                263.39251708984375,
                304.56884765625,
                331.6753234863281,
                359.1527404785156
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.5992873311042786,
              "bbox": [
                36.05835723876953,
                57.647132873535156,
                176.5907745361328,
                248.1451416015625
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.33091384172439575,
              "bbox": [
                0.9067584276199341,
                85.74657440185547,
                65.56268310546875,
                335.1447448730469
              ]
            },
            {
              "track_id": 651,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.36925023794174194,
              "bbox": [
                285.3174743652344,
                278.1474304199219,
                330.4917907714844,
                343.9823913574219
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.259699285030365,
              "bbox": [
                277.2196960449219,
                196.15122985839844,
                354.1013488769531,
                266.3919372558594
              ]
            },
            {
              "track_id": 659,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3309248089790344,
              "bbox": [
                239.18727111816406,
                262.8521423339844,
                264.32794189453125,
                296.92803955078125
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            646,
            647,
            650,
            598,
            549,
            611,
            651,
            653,
            659
          ],
          "total_detections": 11
        },
        {
          "group_index": 3,
          "frame_range": [
            8056,
            8060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8061,
            8065
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.859757661819458,
              "bbox": [
                326.5896301269531,
                0.5601310729980469,
                640.0,
                355.9991760253906
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6887543201446533,
              "bbox": [
                160.5790557861328,
                340.02166748046875,
                231.01531982421875,
                359.9981994628906
              ]
            },
            {
              "track_id": 646,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.22723999619483948,
              "bbox": [
                113.01802062988281,
                145.98580932617188,
                188.19581604003906,
                208.57960510253906
              ]
            },
            {
              "track_id": 647,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.13491332530975342,
              "bbox": [
                120.64825439453125,
                175.15145874023438,
                211.37977600097656,
                274.8081359863281
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.15864160656929016,
              "bbox": [
                164.26409912109375,
                132.46957397460938,
                255.99452209472656,
                333.1331481933594
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.522554337978363,
              "bbox": [
                262.808837890625,
                304.4588928222656,
                332.69122314453125,
                359.1156921386719
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.5649957060813904,
              "bbox": [
                35.545982360839844,
                57.44453048706055,
                177.058349609375,
                248.17774963378906
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.36163529753685,
              "bbox": [
                1.0091758966445923,
                85.65120697021484,
                65.94821166992188,
                335.0978088378906
              ]
            },
            {
              "track_id": 651,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.30734360218048096,
              "bbox": [
                285.3262634277344,
                278.14349365234375,
                330.45916748046875,
                343.9186096191406
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.1961495727300644,
              "bbox": [
                277.1480407714844,
                195.9325408935547,
                354.3869934082031,
                266.446533203125
              ]
            },
            {
              "track_id": 659,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3202872574329376,
              "bbox": [
                239.20887756347656,
                262.9393310546875,
                264.3111572265625,
                296.95257568359375
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            646,
            647,
            650,
            598,
            549,
            611,
            651,
            653,
            659
          ],
          "total_detections": 11
        },
        {
          "group_index": 5,
          "frame_range": [
            8066,
            8070
          ],
          "representative_frame": 8066,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 67
    },
    {
      "second": 269,
      "time_range": [
        269,
        269.999
      ],
      "frame_range": [
        8071,
        8100
      ],
      "unified_description": "\n\n---",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:52",
        "processing_time": 2.18,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8085,
          "frame_range": [
            8081,
            8085
          ],
          "description": "a man in a military uniform is sitting next to a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.81
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8071,
            8075
          ],
          "representative_frame": 8071,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8514448404312134,
              "bbox": [
                321.5810852050781,
                0.0,
                640.0,
                356.1910095214844
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.743587851524353,
              "bbox": [
                160.80747985839844,
                340.0617980957031,
                231.08709716796875,
                359.9900817871094
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.24023526906967163,
              "bbox": [
                165.0554656982422,
                136.07772827148438,
                255.1336669921875,
                332.8147277832031
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6028187870979309,
              "bbox": [
                262.7891540527344,
                304.3929443359375,
                334.0854187011719,
                359.1031188964844
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.22073671221733093,
              "bbox": [
                34.1169319152832,
                57.05022048950195,
                177.0792999267578,
                248.76834106445312
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2685353755950928,
              "bbox": [
                1.8059515953063965,
                85.6388168334961,
                66.9951400756836,
                333.8293762207031
              ]
            },
            {
              "track_id": 651,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.10268690437078476,
              "bbox": [
                285.2955017089844,
                278.22412109375,
                330.52935791015625,
                344.16668701171875
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2565721273422241,
              "bbox": [
                276.814208984375,
                195.3539581298828,
                354.64501953125,
                266.3569030761719
              ]
            },
            {
              "track_id": 659,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2961989641189575,
              "bbox": [
                239.71234130859375,
                263.1175231933594,
                264.2769775390625,
                296.38275146484375
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            650,
            598,
            549,
            611,
            651,
            653,
            659
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            8076,
            8080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8081,
            8085
          ],
          "representative_frame": 8081,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9328076839447021,
              "bbox": [
                315.3712158203125,
                0.15476812422275543,
                638.098388671875,
                356.30743408203125
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7290010452270508,
              "bbox": [
                160.83865356445312,
                340.0501403808594,
                231.16665649414062,
                359.99261474609375
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2115788757801056,
              "bbox": [
                165.3726348876953,
                137.43319702148438,
                254.95309448242188,
                332.7576904296875
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.44960877299308777,
              "bbox": [
                257.48876953125,
                304.1228942871094,
                328.2451477050781,
                358.9582824707031
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.2770785391330719,
              "bbox": [
                33.28230285644531,
                56.932334899902344,
                177.11097717285156,
                248.85020446777344
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.33537527918815613,
              "bbox": [
                1.7749550342559814,
                85.25150299072266,
                67.50923919677734,
                333.9721984863281
              ]
            },
            {
              "track_id": 651,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.18492470681667328,
              "bbox": [
                285.6001892089844,
                278.5963134765625,
                330.0461120605469,
                343.3623352050781
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2975195646286011,
              "bbox": [
                276.71063232421875,
                195.4772186279297,
                354.4578552246094,
                266.3573913574219
              ]
            },
            {
              "track_id": 659,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.24169959127902985,
              "bbox": [
                239.69398498535156,
                263.20965576171875,
                264.1924133300781,
                296.35797119140625
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            650,
            598,
            549,
            611,
            651,
            653,
            659
          ],
          "total_detections": 9
        },
        {
          "group_index": 3,
          "frame_range": [
            8086,
            8090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8091,
            8095
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8927926421165466,
              "bbox": [
                346.8075866699219,
                0.43130114674568176,
                640.0,
                356.0892639160156
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7499568462371826,
              "bbox": [
                160.84034729003906,
                340.0540466308594,
                231.1736297607422,
                359.9972839355469
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2811225950717926,
              "bbox": [
                165.46922302246094,
                138.3148193359375,
                254.837158203125,
                332.83380126953125
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7135522961616516,
              "bbox": [
                260.02972412109375,
                304.2004699707031,
                331.91058349609375,
                359.05206298828125
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.5255730748176575,
              "bbox": [
                33.04704284667969,
                57.07278060913086,
                177.6902313232422,
                249.4958038330078
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3738633990287781,
              "bbox": [
                1.3884432315826416,
                84.92070007324219,
                67.47298431396484,
                333.9981994628906
              ]
            },
            {
              "track_id": 651,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.14509962499141693,
              "bbox": [
                285.7803039550781,
                278.8202209472656,
                329.8724670410156,
                343.0423583984375
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.27313700318336487,
              "bbox": [
                276.5315246582031,
                195.47874450683594,
                354.31121826171875,
                266.3570251464844
              ]
            },
            {
              "track_id": 659,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.26962918043136597,
              "bbox": [
                239.63523864746094,
                263.0598449707031,
                264.24627685546875,
                296.33782958984375
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            650,
            598,
            549,
            611,
            651,
            653,
            659
          ],
          "total_detections": 9
        },
        {
          "group_index": 5,
          "frame_range": [
            8096,
            8100
          ],
          "representative_frame": 8096,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 67
    },
    {
      "second": 270,
      "time_range": [
        270,
        270.999
      ],
      "frame_range": [
        8101,
        8130
      ],
      "unified_description": "1-second scene featuring a man in a tent with a backpack and a backpack. The image also includes other objects such as a bed roll, a chair, and a handbag. The scene appears to be captured using a camera with a wide field of view, potentially causing some distortion or artifacts in the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:54",
        "processing_time": 3.3,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8115,
          "frame_range": [
            8111,
            8115
          ],
          "description": "a man in a tent with a backpack and a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8101,
            8105
          ],
          "representative_frame": 8101,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9447904229164124,
              "bbox": [
                329.689697265625,
                0.7298304438591003,
                640.0,
                354.9380798339844
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7409225702285767,
              "bbox": [
                160.8096160888672,
                340.04620361328125,
                231.17044067382812,
                359.9990539550781
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3665713667869568,
              "bbox": [
                165.1295928955078,
                136.8960418701172,
                255.26004028320312,
                332.8912353515625
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7405303716659546,
              "bbox": [
                260.70086669921875,
                304.2088928222656,
                333.63006591796875,
                359.12176513671875
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.33412694931030273,
              "bbox": [
                32.08954620361328,
                56.94122314453125,
                177.39503479003906,
                249.44717407226562
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3781096339225769,
              "bbox": [
                1.252553105354309,
                84.8447265625,
                67.5353012084961,
                333.7138671875
              ]
            },
            {
              "track_id": 651,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.17230795323848724,
              "bbox": [
                285.8486328125,
                278.9329833984375,
                329.8294677734375,
                342.9439392089844
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.1968296617269516,
              "bbox": [
                276.40740966796875,
                195.3868408203125,
                354.2628173828125,
                266.31011962890625
              ]
            },
            {
              "track_id": 659,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2234199047088623,
              "bbox": [
                239.60093688964844,
                262.9795837402344,
                264.2921447753906,
                296.3420104980469
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            650,
            598,
            549,
            611,
            651,
            653,
            659
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            8106,
            8110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8111,
            8115
          ],
          "representative_frame": 8111,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.909260094165802,
              "bbox": [
                313.3771667480469,
                1.146308422088623,
                630.8642578125,
                354.88824462890625
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7436057329177856,
              "bbox": [
                160.8348846435547,
                340.0467834472656,
                231.1919403076172,
                359.99969482421875
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.22883670032024384,
              "bbox": [
                164.97821044921875,
                136.4132080078125,
                255.38687133789062,
                332.76580810546875
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7470622658729553,
              "bbox": [
                260.74530029296875,
                304.1885986328125,
                334.60614013671875,
                359.155029296875
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.38706520199775696,
              "bbox": [
                32.054805755615234,
                56.91496276855469,
                177.75555419921875,
                249.34225463867188
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.38300633430480957,
              "bbox": [
                0.968189001083374,
                84.33783721923828,
                67.53019714355469,
                333.6414489746094
              ]
            },
            {
              "track_id": 651,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.15013976395130157,
              "bbox": [
                285.8249816894531,
                278.9306335449219,
                329.8511962890625,
                342.9665222167969
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6094152331352234,
              "bbox": [
                276.7596740722656,
                196.034423828125,
                354.1123046875,
                266.3790283203125
              ]
            },
            {
              "track_id": 659,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.1899891048669815,
              "bbox": [
                239.4189453125,
                262.5805358886719,
                264.5299987792969,
                296.5281982421875
              ]
            },
            {
              "track_id": 664,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3373177945613861,
              "bbox": [
                361.00335693359375,
                278.00372314453125,
                412.08050537109375,
                310.3976135253906
              ]
            },
            {
              "track_id": 665,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.38157349824905396,
              "bbox": [
                28.626142501831055,
                56.5316047668457,
                179.64620971679688,
                249.93914794921875
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            650,
            598,
            549,
            611,
            651,
            653,
            659,
            664,
            665
          ],
          "total_detections": 11
        },
        {
          "group_index": 3,
          "frame_range": [
            8116,
            8120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8121,
            8125
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            8126,
            8130
          ],
          "representative_frame": 8126,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 67
    },
    {
      "second": 271,
      "time_range": [
        271,
        271.999
      ],
      "frame_range": [
        8131,
        8160
      ],
      "unified_description": "\n\nIn this outdoor scene, people are standing near a cooking stove, likely engaged in food preparation or socializing. The image captures multiple elements - objects, individuals, their spatial relationships, as well as the surrounding environment. \n\nAdditionally, consider factors like camera positioning, field of view, lens characteristics, video production style, and any technical artifacts that might be present in the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:57",
        "processing_time": 3.57,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8145,
          "frame_range": [
            8141,
            8145
          ],
          "description": "a group of people are gathered around a stove",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.27
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8131,
            8135
          ],
          "representative_frame": 8131,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            8136,
            8140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8141,
            8145
          ],
          "representative_frame": 8141,
          "detections": [
            {
              "track_id": 671,
              "class_id": 61,
              "class_name": "toilet",
              "confidence": 0.40502026677131653,
              "bbox": [
                228.294921875,
                47.965576171875,
                440.50689697265625,
                312.4706115722656
              ]
            }
          ],
          "unique_tracks": [
            671
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            8146,
            8150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8151,
            8155
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 671,
              "class_id": 61,
              "class_name": "toilet",
              "confidence": 0.23577980697155,
              "bbox": [
                258.1995849609375,
                9.99492073059082,
                489.98883056640625,
                298.0068664550781
              ]
            },
            {
              "track_id": 639,
              "class_id": 61,
              "class_name": "toilet",
              "confidence": 0.40917307138442993,
              "bbox": [
                438.8185119628906,
                308.2851867675781,
                577.9846801757812,
                359.4863586425781
              ]
            },
            {
              "track_id": 577,
              "class_id": 61,
              "class_name": "toilet",
              "confidence": 0.36396849155426025,
              "bbox": [
                268.3017883300781,
                1.4933847188949585,
                590.361572265625,
                355.6514587402344
              ]
            }
          ],
          "unique_tracks": [
            671,
            639,
            577
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8156,
            8160
          ],
          "representative_frame": 8156,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 67
    },
    {
      "second": 272,
      "time_range": [
        272,
        272.999
      ],
      "frame_range": [
        8161,
        8190
      ],
      "unified_description": "3D Camera Perspective: POV, Wide-angle lens, Camera positioning: Handheld, Field of view: Wide-angle",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:58",
        "processing_time": 4.25,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8175,
          "frame_range": [
            8171,
            8175
          ],
          "description": "a man is putting a bucket with a blue bucket",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.31
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8161,
            8165
          ],
          "representative_frame": 8161,
          "detections": [
            {
              "track_id": 671,
              "class_id": 61,
              "class_name": "toilet",
              "confidence": 0.10355758666992188,
              "bbox": [
                262.89019775390625,
                19.68854522705078,
                482.1932373046875,
                291.12420654296875
              ]
            },
            {
              "track_id": 673,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4975804388523102,
              "bbox": [
                482.5943603515625,
                9.338061332702637,
                625.3853759765625,
                150.99044799804688
              ]
            },
            {
              "track_id": 674,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4772900938987732,
              "bbox": [
                168.36282348632812,
                313.0674133300781,
                300.2247314453125,
                359.67388916015625
              ]
            },
            {
              "track_id": 639,
              "class_id": 61,
              "class_name": "toilet",
              "confidence": 0.21374349296092987,
              "bbox": [
                434.2660827636719,
                306.1713562011719,
                584.9154663085938,
                359.5401611328125
              ]
            }
          ],
          "unique_tracks": [
            671,
            673,
            674,
            639
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            8166,
            8170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8171,
            8175
          ],
          "representative_frame": 8171,
          "detections": [
            {
              "track_id": 673,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6623270511627197,
              "bbox": [
                473.4820861816406,
                21.41168785095215,
                614.237060546875,
                159.8958740234375
              ]
            },
            {
              "track_id": 674,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4128812849521637,
              "bbox": [
                162.09439086914062,
                312.7708740234375,
                294.39776611328125,
                359.5982971191406
              ]
            },
            {
              "track_id": 639,
              "class_id": 61,
              "class_name": "toilet",
              "confidence": 0.21796061098575592,
              "bbox": [
                430.3311462402344,
                306.02484130859375,
                585.7534790039062,
                359.2520751953125
              ]
            }
          ],
          "unique_tracks": [
            673,
            674,
            639
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8176,
            8180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8181,
            8185
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.6907257437705994,
              "bbox": [
                499.7606201171875,
                185.05349731445312,
                626.7178955078125,
                336.5383605957031
              ]
            }
          ],
          "unique_tracks": [
            600
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            8186,
            8190
          ],
          "representative_frame": 8186,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 68
    },
    {
      "second": 273,
      "time_range": [
        273,
        273.999
      ],
      "frame_range": [
        8191,
        8220
      ],
      "unified_description": "36-second scene showing man placing cup on ground, with various other objects present in the background.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:18:58",
        "processing_time": 3.25,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8205,
          "frame_range": [
            8201,
            8205
          ],
          "description": "a man is putting a cup in the ground",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8191,
            8195
          ],
          "representative_frame": 8191,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7715901732444763,
              "bbox": [
                419.7798767089844,
                227.16973876953125,
                521.2611694335938,
                318.98675537109375
              ]
            },
            {
              "track_id": 680,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.45889022946357727,
              "bbox": [
                236.22906494140625,
                144.47071838378906,
                442.6356506347656,
                330.958984375
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.3886028528213501,
              "bbox": [
                498.8221435546875,
                186.03599548339844,
                631.23779296875,
                337.7335510253906
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8196,
            8200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8201,
            8205
          ],
          "representative_frame": 8201,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7599921822547913,
              "bbox": [
                419.9873046875,
                227.55429077148438,
                521.1891479492188,
                319.1032409667969
              ]
            },
            {
              "track_id": 680,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.38338878750801086,
              "bbox": [
                236.07135009765625,
                147.77755737304688,
                441.5894470214844,
                333.3359375
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.48289158940315247,
              "bbox": [
                498.47869873046875,
                187.96441650390625,
                632.4344482421875,
                336.2998046875
              ]
            },
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6085454821586609,
              "bbox": [
                1.0232553482055664,
                10.058880805969238,
                378.55914306640625,
                351.37139892578125
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600,
            682
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            8206,
            8210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8211,
            8215
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8860388398170471,
              "bbox": [
                419.83099365234375,
                227.43881225585938,
                521.2083740234375,
                319.1211242675781
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7275215983390808,
              "bbox": [
                231.909912109375,
                138.6117401123047,
                443.85906982421875,
                330.1499938964844
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.5746181011199951,
              "bbox": [
                496.4182434082031,
                188.0586395263672,
                633.4818115234375,
                336.4581604003906
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8216,
            8220
          ],
          "representative_frame": 8216,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 68
    },
    {
      "second": 274,
      "time_range": [
        274,
        274.999
      ],
      "frame_range": [
        8221,
        8250
      ],
      "unified_description": "1-second scene featuring a man cooking food in a pot",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:00",
        "processing_time": 2.3,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8235,
          "frame_range": [
            8231,
            8235
          ],
          "description": "a man is cooking food in a pot",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.1
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8221,
            8225
          ],
          "representative_frame": 8221,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8887909650802612,
              "bbox": [
                419.84332275390625,
                227.4036865234375,
                521.244384765625,
                319.07537841796875
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6459640264511108,
              "bbox": [
                231.22850036621094,
                136.34510803222656,
                443.9661560058594,
                328.80157470703125
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.5802865624427795,
              "bbox": [
                494.8475341796875,
                187.68479919433594,
                634.3840942382812,
                336.32958984375
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8226,
            8230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8231,
            8235
          ],
          "representative_frame": 8231,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8632297515869141,
              "bbox": [
                419.706787109375,
                227.32159423828125,
                521.3927001953125,
                319.231689453125
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5951364636421204,
              "bbox": [
                231.18960571289062,
                135.4635772705078,
                444.48980712890625,
                328.7242431640625
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.3789713382720947,
              "bbox": [
                494.01007080078125,
                187.64593505859375,
                634.7186889648438,
                335.41107177734375
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8236,
            8240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8241,
            8245
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8821757435798645,
              "bbox": [
                419.700439453125,
                227.23594665527344,
                521.4200439453125,
                319.15069580078125
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6559593677520752,
              "bbox": [
                230.81741333007812,
                135.5743408203125,
                443.2489013671875,
                328.1915588378906
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.3114747107028961,
              "bbox": [
                493.1903076171875,
                187.28343200683594,
                635.0178833007812,
                334.47320556640625
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8246,
            8250
          ],
          "representative_frame": 8246,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 68
    },
    {
      "second": 275,
      "time_range": [
        275,
        275.999
      ],
      "frame_range": [
        8251,
        8280
      ],
      "unified_description": "1-second scene that includes a man cooking food in a pot, multiple objects/people visible, shot with a fisheye lens causing distortion, and camera held stabilizing image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:02",
        "processing_time": 2.75,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8265,
          "frame_range": [
            8261,
            8265
          ],
          "description": "a man cooking food in a pot",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.32
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8251,
            8255
          ],
          "representative_frame": 8251,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.9072585701942444,
              "bbox": [
                419.7293395996094,
                227.31187438964844,
                521.3622436523438,
                319.0994567871094
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7953140139579773,
              "bbox": [
                231.6116180419922,
                134.2996368408203,
                444.4041748046875,
                327.72052001953125
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.35890188813209534,
              "bbox": [
                491.4747314453125,
                186.0122833251953,
                636.7249145507812,
                335.9140930175781
              ]
            },
            {
              "track_id": 635,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6049836874008179,
              "bbox": [
                0.0,
                185.79302978515625,
                303.0506591796875,
                355.9292907714844
              ]
            },
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.343718558549881,
              "bbox": [
                0.0,
                1.8646413087844849,
                331.8852233886719,
                350.34320068359375
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600,
            635,
            682
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            8256,
            8260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8261,
            8265
          ],
          "representative_frame": 8261,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8990572690963745,
              "bbox": [
                419.5184020996094,
                227.2092742919922,
                521.3477783203125,
                319.1208801269531
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7914568781852722,
              "bbox": [
                230.37026977539062,
                134.42361450195312,
                442.76251220703125,
                327.6429138183594
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.37823861837387085,
              "bbox": [
                489.9778747558594,
                184.48220825195312,
                637.9656982421875,
                336.7066955566406
              ]
            },
            {
              "track_id": 693,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3228192627429962,
              "bbox": [
                163.31321716308594,
                232.11268615722656,
                200.51712036132812,
                297.80963134765625
              ]
            },
            {
              "track_id": 635,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6093676686286926,
              "bbox": [
                0.0,
                182.77401733398438,
                280.108642578125,
                355.90765380859375
              ]
            },
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.529945969581604,
              "bbox": [
                0.0,
                1.7106844186782837,
                336.70904541015625,
                351.978759765625
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600,
            693,
            635,
            682
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            8266,
            8270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8271,
            8275
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.9073889851570129,
              "bbox": [
                419.4505615234375,
                227.13198852539062,
                521.3936157226562,
                319.1035461425781
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.9021164774894714,
              "bbox": [
                230.39068603515625,
                135.43756103515625,
                440.9078063964844,
                326.8916015625
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.33431708812713623,
              "bbox": [
                489.18524169921875,
                183.95924377441406,
                638.5169677734375,
                337.1451416015625
              ]
            },
            {
              "track_id": 693,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.35786837339401245,
              "bbox": [
                163.4328155517578,
                232.030517578125,
                200.50033569335938,
                297.47052001953125
              ]
            },
            {
              "track_id": 635,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.60030597448349,
              "bbox": [
                0.0,
                182.0198974609375,
                262.7467346191406,
                355.9869384765625
              ]
            },
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.654940128326416,
              "bbox": [
                0.0,
                18.783266067504883,
                324.7594299316406,
                352.7079162597656
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600,
            693,
            635,
            682
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            8276,
            8280
          ],
          "representative_frame": 8276,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 68
    },
    {
      "second": 276,
      "time_range": [
        276,
        276.999
      ],
      "frame_range": [
        8281,
        8310
      ],
      "unified_description": "1-second scene with a GoPro-style action camera perspective, showing a group of people sitting under a tent.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:02",
        "processing_time": 3.07,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8295,
          "frame_range": [
            8291,
            8295
          ],
          "description": "a group of people sitting under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.05
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8281,
            8285
          ],
          "representative_frame": 8281,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8672164082527161,
              "bbox": [
                419.453125,
                227.5155487060547,
                521.4509887695312,
                319.541015625
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8573867678642273,
              "bbox": [
                232.0493621826172,
                136.7130889892578,
                441.732177734375,
                327.8148498535156
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.1677524894475937,
              "bbox": [
                482.0130920410156,
                163.67510986328125,
                640.0,
                333.7101745605469
              ]
            },
            {
              "track_id": 693,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2426934540271759,
              "bbox": [
                162.9453125,
                231.5080108642578,
                200.4344940185547,
                297.7569274902344
              ]
            },
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5841145515441895,
              "bbox": [
                0.0,
                14.225756645202637,
                320.4797058105469,
                352.8753356933594
              ]
            },
            {
              "track_id": 698,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5652976036071777,
              "bbox": [
                587.1342163085938,
                283.06121826171875,
                640.0,
                358.66229248046875
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600,
            693,
            682,
            698
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            8286,
            8290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8291,
            8295
          ],
          "representative_frame": 8291,
          "detections": [
            {
              "track_id": 680,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.13636229932308197,
              "bbox": [
                213.64532470703125,
                150.32518005371094,
                433.9620361328125,
                347.11328125
              ]
            }
          ],
          "unique_tracks": [
            680
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            8296,
            8300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8301,
            8305
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4272075295448303,
              "bbox": [
                268.33111572265625,
                0.603424072265625,
                440.5166931152344,
                173.4474334716797
              ]
            },
            {
              "track_id": 705,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.445965439081192,
              "bbox": [
                466.2825622558594,
                35.64337921142578,
                562.7267456054688,
                100.0042495727539
              ]
            }
          ],
          "unique_tracks": [
            701,
            705
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            8306,
            8310
          ],
          "representative_frame": 8306,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 69
    },
    {
      "second": 277,
      "time_range": [
        277,
        277.999
      ],
      "frame_range": [
        8311,
        8340
      ],
      "unified_description": "5-second descriptions are welcome too.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:03",
        "processing_time": 2.29,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8325,
          "frame_range": [
            8321,
            8325
          ],
          "description": "a man is kneeling down to a small child",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.7
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8311,
            8315
          ],
          "representative_frame": 8311,
          "detections": [
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5744313597679138,
              "bbox": [
                264.35736083984375,
                0.958890974521637,
                453.8680419921875,
                190.62742614746094
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5114699602127075,
              "bbox": [
                314.7013244628906,
                172.41746520996094,
                538.88037109375,
                356.6984558105469
              ]
            },
            {
              "track_id": 680,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3324994742870331,
              "bbox": [
                218.79037475585938,
                171.3256072998047,
                426.96875,
                355.3582763671875
              ]
            }
          ],
          "unique_tracks": [
            701,
            577,
            680
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8316,
            8320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8321,
            8325
          ],
          "representative_frame": 8321,
          "detections": [
            {
              "track_id": 647,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.526203453540802,
              "bbox": [
                80.35899353027344,
                179.9204559326172,
                179.03451538085938,
                282.05706787109375
              ]
            }
          ],
          "unique_tracks": [
            647
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            8326,
            8330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8331,
            8335
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 647,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.49859169125556946,
              "bbox": [
                56.49880599975586,
                176.49176025390625,
                175.44189453125,
                300.2080383300781
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2886229455471039,
              "bbox": [
                306.50152587890625,
                183.2107391357422,
                514.86572265625,
                356.5336608886719
              ]
            }
          ],
          "unique_tracks": [
            647,
            577
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            8336,
            8340
          ],
          "representative_frame": 8336,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 69
    },
    {
      "second": 278,
      "time_range": [
        278,
        278.999
      ],
      "frame_range": [
        8341,
        8370
      ],
      "unified_description": "3D model of a scene with objects and people in it",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:05",
        "processing_time": 2.3,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8355,
          "frame_range": [
            8351,
            8355
          ],
          "description": "a man is sitting under a tent with a dog",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.36
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8341,
            8345
          ],
          "representative_frame": 8341,
          "detections": [
            {
              "track_id": 647,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.32130172848701477,
              "bbox": [
                34.635581970214844,
                164.5151824951172,
                169.9696807861328,
                307.0030517578125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.44250601530075073,
              "bbox": [
                314.8825378417969,
                2.6395263671875,
                583.1942749023438,
                295.9870300292969
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2128419727087021,
              "bbox": [
                295.24102783203125,
                172.2912139892578,
                517.8662719726562,
                355.9223327636719
              ]
            }
          ],
          "unique_tracks": [
            647,
            715,
            577
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8346,
            8350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8351,
            8355
          ],
          "representative_frame": 8351,
          "detections": [
            {
              "track_id": 647,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.17545238137245178,
              "bbox": [
                22.287738800048828,
                166.4137420654297,
                156.27357482910156,
                308.79376220703125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2572386562824249,
              "bbox": [
                309.56817626953125,
                1.8953096866607666,
                564.221435546875,
                279.80242919921875
              ]
            },
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.184891015291214,
              "bbox": [
                303.7881164550781,
                167.9728546142578,
                506.6920471191406,
                337.985595703125
              ]
            }
          ],
          "unique_tracks": [
            647,
            715,
            577
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8356,
            8360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8361,
            8365
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.34533172845840454,
              "bbox": [
                317.001220703125,
                1.7392675876617432,
                576.7523193359375,
                283.37335205078125
              ]
            },
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4611983299255371,
              "bbox": [
                301.8240966796875,
                169.36178588867188,
                504.07562255859375,
                341.9311218261719
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.39181458950042725,
              "bbox": [
                495.9150390625,
                126.61155700683594,
                640.0,
                297.1492004394531
              ]
            }
          ],
          "unique_tracks": [
            715,
            577,
            600
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8366,
            8370
          ],
          "representative_frame": 8366,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 69
    },
    {
      "second": 279,
      "time_range": [
        279,
        279.999
      ],
      "frame_range": [
        8371,
        8400
      ],
      "unified_description": " The image depicts an outdoor scene where a man is sitting in the grass with a knife. There are several other objects in the frame, which may include various natural elements like trees or water bodies. The camera perspective provides a first-person view, capturing the man's position and surroundings as he rests on the ground. The field of view includes some distortion, possibly due to the wide-angle lens used for filming. This gives a sense of the expansive outdoor setting where the man finds himself in this particular moment captured in the video.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:08",
        "processing_time": 4.16,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8385,
          "frame_range": [
            8381,
            8385
          ],
          "description": "a man is sitting in the grass with a knife",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.56
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8371,
            8375
          ],
          "representative_frame": 8371,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4618159532546997,
              "bbox": [
                308.7461853027344,
                151.8022003173828,
                516.3775634765625,
                331.1743469238281
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5912972092628479,
              "bbox": [
                477.04718017578125,
                122.66627502441406,
                640.0,
                307.6696472167969
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.752717912197113,
              "bbox": [
                162.16787719726562,
                1.0691297054290771,
                484.0007019042969,
                328.40191650390625
              ]
            }
          ],
          "unique_tracks": [
            577,
            600,
            701
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8376,
            8380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8381,
            8385
          ],
          "representative_frame": 8381,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5138702392578125,
              "bbox": [
                308.16119384765625,
                144.00758361816406,
                518.0050659179688,
                326.0974426269531
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2848127484321594,
              "bbox": [
                477.4794006347656,
                118.00899505615234,
                640.0,
                305.511474609375
              ]
            },
            {
              "track_id": 719,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5395159125328064,
              "bbox": [
                487.6485900878906,
                71.42515563964844,
                580.83251953125,
                129.50759887695312
              ]
            },
            {
              "track_id": 721,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.47850292921066284,
              "bbox": [
                47.951168060302734,
                62.9456787109375,
                579.990478515625,
                352.05157470703125
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7856190204620361,
              "bbox": [
                152.9789276123047,
                1.289709448814392,
                478.1614685058594,
                336.64312744140625
              ]
            }
          ],
          "unique_tracks": [
            577,
            600,
            719,
            721,
            701
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            8386,
            8390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8391,
            8395
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3910767734050751,
              "bbox": [
                312.6521911621094,
                146.31317138671875,
                517.3936157226562,
                324.65411376953125
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3671460747718811,
              "bbox": [
                486.97100830078125,
                125.76296997070312,
                640.0,
                300.20599365234375
              ]
            },
            {
              "track_id": 719,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.48407402634620667,
              "bbox": [
                487.7420349121094,
                72.06672668457031,
                581.8087158203125,
                130.75094604492188
              ]
            },
            {
              "track_id": 721,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.17653438448905945,
              "bbox": [
                0.0,
                11.973152160644531,
                621.149169921875,
                350.84423828125
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7905701398849487,
              "bbox": [
                158.45635986328125,
                1.586763620376587,
                456.6051025390625,
                306.9786682128906
              ]
            }
          ],
          "unique_tracks": [
            577,
            600,
            719,
            721,
            701
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            8396,
            8400
          ],
          "representative_frame": 8396,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 69
    },
    {
      "second": 280,
      "time_range": [
        280,
        280.999
      ],
      "frame_range": [
        8401,
        8430
      ],
      "unified_description": "3rd person camera with image stabilization technology.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:08",
        "processing_time": 4.25,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8415,
          "frame_range": [
            8411,
            8415
          ],
          "description": "a man is cooking food in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.99
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8401,
            8405
          ],
          "representative_frame": 8401,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4902665615081787,
              "bbox": [
                308.1658935546875,
                158.9306640625,
                509.0430603027344,
                331.8301696777344
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6282799243927002,
              "bbox": [
                478.8171691894531,
                40.861454010009766,
                640.0,
                267.82232666015625
              ]
            },
            {
              "track_id": 719,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.37701237201690674,
              "bbox": [
                492.8141174316406,
                73.91069030761719,
                579.959716796875,
                128.18003845214844
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7612797021865845,
              "bbox": [
                172.62564086914062,
                1.6293494701385498,
                454.2549743652344,
                286.53802490234375
              ]
            },
            {
              "track_id": 674,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6506497859954834,
              "bbox": [
                35.9478645324707,
                244.8920135498047,
                326.12835693359375,
                358.51519775390625
              ]
            }
          ],
          "unique_tracks": [
            577,
            600,
            719,
            701,
            674
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            8406,
            8410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8411,
            8415
          ],
          "representative_frame": 8411,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.46236303448677063,
              "bbox": [
                313.95928955078125,
                154.2886962890625,
                517.34033203125,
                330.7557373046875
              ]
            },
            {
              "track_id": 719,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.15343071520328522,
              "bbox": [
                500.6068115234375,
                77.19068908691406,
                570.9297485351562,
                120.60025024414062
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5027593970298767,
              "bbox": [
                175.01275634765625,
                1.6494863033294678,
                452.1273193359375,
                281.5623779296875
              ]
            }
          ],
          "unique_tracks": [
            577,
            719,
            701
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8416,
            8420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8421,
            8425
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4609783887863159,
              "bbox": [
                328.3043518066406,
                154.0300750732422,
                526.981689453125,
                328.14691162109375
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6800786256790161,
              "bbox": [
                208.76718139648438,
                1.3990789651870728,
                435.1009216308594,
                223.67259216308594
              ]
            },
            {
              "track_id": 730,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4859764277935028,
              "bbox": [
                520.715087890625,
                95.58621215820312,
                638.23095703125,
                225.108154296875
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.47477707266807556,
              "bbox": [
                485.02459716796875,
                6.3365278244018555,
                640.0,
                232.6030731201172
              ]
            }
          ],
          "unique_tracks": [
            577,
            701,
            730,
            600
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            8426,
            8430
          ],
          "representative_frame": 8426,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 70
    },
    {
      "second": 281,
      "time_range": [
        281,
        281.999
      ],
      "frame_range": [
        8431,
        8460
      ],
      "unified_description": "3rd person perspective camera view",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:09",
        "processing_time": 2.6,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8445,
          "frame_range": [
            8441,
            8445
          ],
          "description": "a man is cooking food in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.65
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8431,
            8435
          ],
          "representative_frame": 8431,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5005574226379395,
              "bbox": [
                346.1760559082031,
                157.2196044921875,
                540.966552734375,
                330.2109069824219
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7041968703269958,
              "bbox": [
                230.32183837890625,
                1.2454559803009033,
                416.58636474609375,
                179.60537719726562
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5108651518821716,
              "bbox": [
                448.23382568359375,
                0.10980909317731857,
                640.0,
                248.48951721191406
              ]
            }
          ],
          "unique_tracks": [
            577,
            701,
            600
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8436,
            8440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8441,
            8445
          ],
          "representative_frame": 8441,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6114435791969299,
              "bbox": [
                376.3225402832031,
                163.2926788330078,
                563.56396484375,
                331.3927001953125
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4970749020576477,
              "bbox": [
                443.0359191894531,
                35.84638595581055,
                622.6973266601562,
                243.62789916992188
              ]
            }
          ],
          "unique_tracks": [
            577,
            600
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            8446,
            8450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8451,
            8455
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5310240983963013,
              "bbox": [
                391.31732177734375,
                168.60789489746094,
                574.8035888671875,
                334.28790283203125
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7816324234008789,
              "bbox": [
                442.64276123046875,
                9.857368469238281,
                618.9537353515625,
                207.33787536621094
              ]
            },
            {
              "track_id": 743,
              "class_id": 48,
              "class_name": "sandwich",
              "confidence": 0.5294140577316284,
              "bbox": [
                261.8804931640625,
                91.23816680908203,
                351.46002197265625,
                175.75775146484375
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4756387174129486,
              "bbox": [
                265.79864501953125,
                0.9498291611671448,
                426.2525329589844,
                151.1443328857422
              ]
            }
          ],
          "unique_tracks": [
            577,
            600,
            743,
            701
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            8456,
            8460
          ],
          "representative_frame": 8456,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 70
    },
    {
      "second": 282,
      "time_range": [
        282,
        282.999
      ],
      "frame_range": [
        8461,
        8490
      ],
      "unified_description": "\nThe image is a first-person perspective of a man standing inside of a tent with a backpack on his back.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:12",
        "processing_time": 2.5,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8475,
          "frame_range": [
            8471,
            8475
          ],
          "description": "a man in a tent with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.8
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8461,
            8465
          ],
          "representative_frame": 8461,
          "detections": [
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.635389506816864,
              "bbox": [
                461.4066467285156,
                1.14967679977417,
                626.8309936523438,
                184.2535400390625
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6334195137023926,
              "bbox": [
                259.2773132324219,
                0.4213605225086212,
                447.4657897949219,
                176.5860137939453
              ]
            }
          ],
          "unique_tracks": [
            600,
            701
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            8466,
            8470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8471,
            8475
          ],
          "representative_frame": 8471,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8189634084701538,
              "bbox": [
                33.6370964050293,
                44.43655776977539,
                328.28753662109375,
                353.44744873046875
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6937017440795898,
              "bbox": [
                345.83135986328125,
                1.3944975137710571,
                640.0,
                352.10906982421875
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            8476,
            8480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8481,
            8485
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7572672367095947,
              "bbox": [
                53.03411102294922,
                45.3379020690918,
                322.8703918457031,
                352.07843017578125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7001845836639404,
              "bbox": [
                349.8866271972656,
                8.426109313964844,
                640.0,
                355.20751953125
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            8486,
            8490
          ],
          "representative_frame": 8486,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 70
    },
    {
      "second": 283,
      "time_range": [
        283,
        283.999
      ],
      "frame_range": [
        8491,
        8520
      ],
      "unified_description": "1-second scene including two men sitting in a tent with a wide-angle perspective.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:13",
        "processing_time": 2.57,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8505,
          "frame_range": [
            8501,
            8505
          ],
          "description": "two men sitting in a tent with a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.99
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8491,
            8495
          ],
          "representative_frame": 8491,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7193369269371033,
              "bbox": [
                59.31637191772461,
                45.531715393066406,
                313.7701110839844,
                352.4110412597656
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9137688279151917,
              "bbox": [
                384.610107421875,
                3.6454195976257324,
                640.0,
                357.5373840332031
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            8496,
            8500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8501,
            8505
          ],
          "representative_frame": 8501,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7003128528594971,
              "bbox": [
                63.62644958496094,
                45.03269958496094,
                307.26226806640625,
                353.7634582519531
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9067030549049377,
              "bbox": [
                402.3805236816406,
                1.4448202848434448,
                640.0,
                357.2315368652344
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            8506,
            8510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8511,
            8515
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7570958733558655,
              "bbox": [
                68.29850769042969,
                44.939353942871094,
                302.17669677734375,
                353.802001953125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9430510401725769,
              "bbox": [
                409.10382080078125,
                1.1100302934646606,
                640.0,
                357.3575134277344
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            8516,
            8520
          ],
          "representative_frame": 8516,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 70
    },
    {
      "second": 284,
      "time_range": [
        284,
        284.999
      ],
      "frame_range": [
        8521,
        8550
      ],
      "unified_description": "1-second scene that includes two men sitting in a tent eating food",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:13",
        "processing_time": 3.01,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8535,
          "frame_range": [
            8531,
            8535
          ],
          "description": "two men are sitting in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.79
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8521,
            8525
          ],
          "representative_frame": 8521,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7832171320915222,
              "bbox": [
                70.71913146972656,
                45.593772888183594,
                296.3458557128906,
                353.0531921386719
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9456557035446167,
              "bbox": [
                409.611572265625,
                0.7806121706962585,
                640.0,
                356.3418884277344
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            8526,
            8530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8531,
            8535
          ],
          "representative_frame": 8531,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8162623047828674,
              "bbox": [
                67.50647735595703,
                46.045082092285156,
                288.5345153808594,
                353.3917236328125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9279364943504333,
              "bbox": [
                412.5677795410156,
                0.5387188792228699,
                640.0,
                355.34051513671875
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            8536,
            8540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8541,
            8545
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7777233719825745,
              "bbox": [
                65.12696838378906,
                45.330833435058594,
                283.48211669921875,
                353.9430236816406
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9459239840507507,
              "bbox": [
                415.4972839355469,
                0.5613887906074524,
                640.0,
                355.6762390136719
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            8546,
            8550
          ],
          "representative_frame": 8546,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 71
    },
    {
      "second": 285,
      "time_range": [
        285,
        285.999
      ],
      "frame_range": [
        8551,
        8580
      ],
      "unified_description": "2 men eating food in a tent",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:16",
        "processing_time": 2.21,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8565,
          "frame_range": [
            8561,
            8565
          ],
          "description": "two men in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.43
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8551,
            8555
          ],
          "representative_frame": 8551,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7085879445075989,
              "bbox": [
                73.93081665039062,
                37.827754974365234,
                291.0812683105469,
                353.801025390625
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9274218678474426,
              "bbox": [
                407.85150146484375,
                0.3288797438144684,
                640.0,
                355.0831298828125
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            8556,
            8560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8561,
            8565
          ],
          "representative_frame": 8561,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8675175905227661,
              "bbox": [
                79.11580657958984,
                35.002159118652344,
                292.4574279785156,
                353.5606994628906
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9399844408035278,
              "bbox": [
                414.764404296875,
                0.3177465498447418,
                640.0,
                354.16729736328125
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7842220664024353,
              "bbox": [
                463.6563720703125,
                203.34786987304688,
                525.0075073242188,
                230.76992797851562
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8566,
            8570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8571,
            8575
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8527374863624573,
              "bbox": [
                82.85652160644531,
                34.360355377197266,
                291.4578857421875,
                353.0081481933594
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.93369060754776,
              "bbox": [
                411.584228515625,
                0.4037875831127167,
                640.0,
                354.9322814941406
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8023021221160889,
              "bbox": [
                462.8555908203125,
                206.2093048095703,
                524.263427734375,
                233.5117645263672
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8576,
            8580
          ],
          "representative_frame": 8576,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 71
    },
    {
      "second": 286,
      "time_range": [
        286,
        286.999
      ],
      "frame_range": [
        8581,
        8610
      ],
      "unified_description": "2 men sitting in a tent eating food",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:17",
        "processing_time": 2.3,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8595,
          "frame_range": [
            8591,
            8595
          ],
          "description": "two men sitting in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.59
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8581,
            8585
          ],
          "representative_frame": 8581,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8456036448478699,
              "bbox": [
                85.22021484375,
                34.13063049316406,
                289.8560791015625,
                352.98736572265625
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9355683326721191,
              "bbox": [
                405.9984130859375,
                0.41338202357292175,
                640.0,
                354.9429016113281
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6487619876861572,
              "bbox": [
                461.7823791503906,
                204.8396453857422,
                526.7835693359375,
                233.59552001953125
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8586,
            8590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8591,
            8595
          ],
          "representative_frame": 8591,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8488779664039612,
              "bbox": [
                86.87686920166016,
                33.95787048339844,
                287.97088623046875,
                353.01043701171875
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9455877542495728,
              "bbox": [
                412.9900817871094,
                0.9673503041267395,
                640.0,
                355.7232971191406
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            8596,
            8600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8601,
            8605
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.839895486831665,
              "bbox": [
                88.5030746459961,
                33.826194763183594,
                286.4043884277344,
                353.01470947265625
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9446759223937988,
              "bbox": [
                409.9608154296875,
                0.8556731939315796,
                640.0,
                355.66265869140625
              ]
            },
            {
              "track_id": 759,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.7259524464607239,
              "bbox": [
                464.9008483886719,
                171.54617309570312,
                548.384521484375,
                199.11378479003906
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            759
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8606,
            8610
          ],
          "representative_frame": 8606,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 71
    },
    {
      "second": 287,
      "time_range": [
        287,
        287.999
      ],
      "frame_range": [
        8611,
        8640
      ],
      "unified_description": "1-second scene showing a man in a tent with a child",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:17",
        "processing_time": 2.62,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8625,
          "frame_range": [
            8621,
            8625
          ],
          "description": "a man in a tent with a child",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.24
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8611,
            8615
          ],
          "representative_frame": 8611,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8422041535377502,
              "bbox": [
                88.70318603515625,
                35.19291305541992,
                284.1007385253906,
                354.2685241699219
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9156575202941895,
              "bbox": [
                427.8829345703125,
                0.6649968028068542,
                640.0,
                354.2335205078125
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7317802309989929,
              "bbox": [
                467.89349365234375,
                198.9252166748047,
                552.0379638671875,
                236.32229614257812
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8616,
            8620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8621,
            8625
          ],
          "representative_frame": 8621,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.816788375377655,
              "bbox": [
                88.86784362792969,
                36.35239791870117,
                281.3891906738281,
                354.3350830078125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9046206474304199,
              "bbox": [
                433.9285583496094,
                0.5778802633285522,
                640.0,
                354.46209716796875
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.776271641254425,
              "bbox": [
                470.542724609375,
                200.1566162109375,
                553.1212768554688,
                236.90992736816406
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8626,
            8630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8631,
            8635
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8440826535224915,
              "bbox": [
                88.84568786621094,
                38.850433349609375,
                278.4687805175781,
                354.5103454589844
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9122850298881531,
              "bbox": [
                440.0517883300781,
                0.6097180843353271,
                640.0,
                354.3954772949219
              ]
            },
            {
              "track_id": 752,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.656849205493927,
              "bbox": [
                471.0250549316406,
                201.4739532470703,
                555.156494140625,
                238.955078125
              ]
            },
            {
              "track_id": 763,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5201357007026672,
              "bbox": [
                469.4204406738281,
                202.04994201660156,
                553.7750854492188,
                239.02850341796875
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752,
            763
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            8636,
            8640
          ],
          "representative_frame": 8636,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 71
    },
    {
      "second": 288,
      "time_range": [
        288,
        288.999
      ],
      "frame_range": [
        8641,
        8670
      ],
      "unified_description": "1-second scene, what is happening, location, camera perspective, style, production characteristics, any artifacts or issues.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:20",
        "processing_time": 2.54,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8655,
          "frame_range": [
            8651,
            8655
          ],
          "description": "a man and a boy are sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.52
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8641,
            8645
          ],
          "representative_frame": 8641,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8495498299598694,
              "bbox": [
                88.97891998291016,
                40.80047607421875,
                276.20867919921875,
                354.4305725097656
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9026899337768555,
              "bbox": [
                441.5154113769531,
                0.8926835060119629,
                640.0,
                354.6441650390625
              ]
            },
            {
              "track_id": 752,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.4565008580684662,
              "bbox": [
                468.2552185058594,
                202.44366455078125,
                553.8851928710938,
                240.8988037109375
              ]
            },
            {
              "track_id": 763,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7620696425437927,
              "bbox": [
                465.6752014160156,
                202.82542419433594,
                552.0367431640625,
                240.77630615234375
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752,
            763
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            8646,
            8650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8651,
            8655
          ],
          "representative_frame": 8651,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8456276655197144,
              "bbox": [
                88.96011352539062,
                39.093101501464844,
                275.8426513671875,
                353.7221984863281
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.908703088760376,
              "bbox": [
                443.06005859375,
                0.6649316549301147,
                640.0,
                354.0298767089844
              ]
            },
            {
              "track_id": 752,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.41688382625579834,
              "bbox": [
                465.94805908203125,
                203.41708374023438,
                557.1975708007812,
                244.8612060546875
              ]
            },
            {
              "track_id": 763,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7960022687911987,
              "bbox": [
                462.5259094238281,
                203.85711669921875,
                555.377197265625,
                244.86305236816406
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752,
            763
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            8656,
            8660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8661,
            8665
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8554278612136841,
              "bbox": [
                88.0731201171875,
                37.20601272583008,
                276.0299377441406,
                354.4512023925781
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.906449019908905,
              "bbox": [
                444.3797912597656,
                0.6359472274780273,
                640.0,
                353.605224609375
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7995142936706543,
              "bbox": [
                464.2357177734375,
                203.77716064453125,
                555.8631591796875,
                245.91915893554688
              ]
            },
            {
              "track_id": 763,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.40838250517845154,
              "bbox": [
                461.25750732421875,
                204.13128662109375,
                556.6185913085938,
                246.53016662597656
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752,
            763
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            8666,
            8670
          ],
          "representative_frame": 8666,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 72
    },
    {
      "second": 289,
      "time_range": [
        289,
        289.999
      ],
      "frame_range": [
        8671,
        8700
      ],
      "unified_description": "3 groups of people sitting in a tent, with one person on the left, another in the middle, and the third person on the right",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:22",
        "processing_time": 2.65,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8685,
          "frame_range": [
            8681,
            8685
          ],
          "description": "two men are sitting in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.39
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8671,
            8675
          ],
          "representative_frame": 8671,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8871050477027893,
              "bbox": [
                73.20134735107422,
                34.74254608154297,
                264.8244934082031,
                354.36376953125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9571120738983154,
              "bbox": [
                380.9923400878906,
                1.5040154457092285,
                605.701171875,
                353.72674560546875
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            8676,
            8680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8681,
            8685
          ],
          "representative_frame": 8681,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8757275342941284,
              "bbox": [
                66.75669860839844,
                33.5145263671875,
                260.9463806152344,
                354.0548095703125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9536450505256653,
              "bbox": [
                344.92462158203125,
                1.68590247631073,
                583.8524780273438,
                353.60174560546875
              ]
            },
            {
              "track_id": 766,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7807235717773438,
              "bbox": [
                216.04867553710938,
                164.69056701660156,
                327.7060852050781,
                210.07667541503906
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            766
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8686,
            8690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8691,
            8695
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8792321681976318,
              "bbox": [
                63.801177978515625,
                33.051849365234375,
                259.9656677246094,
                353.876708984375
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9584642052650452,
              "bbox": [
                322.0100402832031,
                0.587548017501831,
                576.3458862304688,
                354.53900146484375
              ]
            },
            {
              "track_id": 766,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6851165890693665,
              "bbox": [
                211.98846435546875,
                164.7470245361328,
                328.4535827636719,
                212.16419982910156
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            766
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8696,
            8700
          ],
          "representative_frame": 8696,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 72
    },
    {
      "second": 290,
      "time_range": [
        290,
        290.999
      ],
      "frame_range": [
        8701,
        8730
      ],
      "unified_description": "3D model of a scene with people in it",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:22",
        "processing_time": 2.76,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8715,
          "frame_range": [
            8711,
            8715
          ],
          "description": "a man and a boy are eating food in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.17
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8701,
            8705
          ],
          "representative_frame": 8701,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8877875804901123,
              "bbox": [
                62.450927734375,
                32.78465270996094,
                260.4859924316406,
                353.9217224121094
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9576496481895447,
              "bbox": [
                324.8580627441406,
                1.578284740447998,
                587.596923828125,
                354.2195739746094
              ]
            },
            {
              "track_id": 766,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.44481605291366577,
              "bbox": [
                209.75682067871094,
                166.4156494140625,
                327.0044860839844,
                214.2496795654297
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            766
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8706,
            8710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8711,
            8715
          ],
          "representative_frame": 8711,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8989514708518982,
              "bbox": [
                65.22457885742188,
                31.81869888305664,
                264.4819030761719,
                353.897705078125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9591394662857056,
              "bbox": [
                327.9871520996094,
                1.275492548942566,
                598.3626098632812,
                354.46990966796875
              ]
            },
            {
              "track_id": 766,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2934466004371643,
              "bbox": [
                206.97190856933594,
                167.15475463867188,
                323.9527893066406,
                215.01817321777344
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            766
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8716,
            8720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8721,
            8725
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8471513390541077,
              "bbox": [
                99.41919708251953,
                61.257598876953125,
                271.5440979003906,
                343.6888427734375
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9355133771896362,
              "bbox": [
                387.7048034667969,
                35.79396057128906,
                630.47314453125,
                355.9689636230469
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6536519527435303,
              "bbox": [
                479.4382019042969,
                206.95204162597656,
                538.3621826171875,
                233.5693817138672
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8726,
            8730
          ],
          "representative_frame": 8726,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 72
    },
    {
      "second": 291,
      "time_range": [
        291,
        291.999
      ],
      "frame_range": [
        8731,
        8760
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:23",
        "processing_time": 2.12,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8745,
          "frame_range": [
            8741,
            8745
          ],
          "description": "two men sitting in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.84
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8731,
            8735
          ],
          "representative_frame": 8731,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8269533514976501,
              "bbox": [
                112.20684814453125,
                75.87142181396484,
                271.2862548828125,
                338.7926025390625
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9370195865631104,
              "bbox": [
                410.6921081542969,
                48.47621536254883,
                640.0,
                356.4241943359375
              ]
            },
            {
              "track_id": 752,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.339901864528656,
              "bbox": [
                484.1343078613281,
                209.93234252929688,
                537.8399047851562,
                233.47244262695312
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8736,
            8740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8741,
            8745
          ],
          "representative_frame": 8741,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8412433862686157,
              "bbox": [
                116.76189422607422,
                81.29547119140625,
                270.5773620605469,
                336.99884033203125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9412896633148193,
              "bbox": [
                419.18804931640625,
                52.10540008544922,
                640.0,
                356.65423583984375
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6571595072746277,
              "bbox": [
                479.1544494628906,
                212.8522491455078,
                533.1324462890625,
                236.4110565185547
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8746,
            8750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8751,
            8755
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8419924974441528,
              "bbox": [
                118.38742065429688,
                82.89058685302734,
                270.04058837890625,
                336.54486083984375
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9437013864517212,
              "bbox": [
                422.6565246582031,
                52.64371109008789,
                640.0,
                356.8370361328125
              ]
            },
            {
              "track_id": 752,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.21617437899112701,
              "bbox": [
                480.20703125,
                213.5102081298828,
                533.9969482421875,
                236.79954528808594
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8756,
            8760
          ],
          "representative_frame": 8756,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 72
    },
    {
      "second": 292,
      "time_range": [
        292,
        292.999
      ],
      "frame_range": [
        8761,
        8790
      ],
      "unified_description": "\nBased on these image descriptions and object detections, provide a first-person perspective of two men sitting in a tent eating food. The camera was likely mounted on a body harness or POV for an immersive experience.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:27",
        "processing_time": 2.98,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8775,
          "frame_range": [
            8771,
            8775
          ],
          "description": "two men sitting in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.37
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8761,
            8765
          ],
          "representative_frame": 8761,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8494242429733276,
              "bbox": [
                119.18309020996094,
                83.39457702636719,
                269.7894592285156,
                336.74371337890625
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9491853713989258,
              "bbox": [
                424.1156921386719,
                51.79049301147461,
                640.0,
                356.31707763671875
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            8766,
            8770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8771,
            8775
          ],
          "representative_frame": 8771,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8260519504547119,
              "bbox": [
                118.79362487792969,
                82.09675598144531,
                269.688720703125,
                337.47271728515625
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9541914463043213,
              "bbox": [
                422.05267333984375,
                50.493595123291016,
                640.0,
                356.1273498535156
              ]
            },
            {
              "track_id": 772,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3327616751194,
              "bbox": [
                352.79254150390625,
                309.3744812011719,
                396.6261291503906,
                359.5536804199219
              ]
            },
            {
              "track_id": 774,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.3447723686695099,
              "bbox": [
                6.270752429962158,
                2.085980176925659,
                638.5624389648438,
                353.2785949707031
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            772,
            774
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            8776,
            8780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8781,
            8785
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8497476577758789,
              "bbox": [
                118.94120788574219,
                82.35594177246094,
                269.25299072265625,
                337.8666687011719
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9420079588890076,
              "bbox": [
                423.91436767578125,
                50.26322937011719,
                640.0,
                355.8131103515625
              ]
            },
            {
              "track_id": 772,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3042689561843872,
              "bbox": [
                352.8448181152344,
                309.41949462890625,
                396.61517333984375,
                359.52178955078125
              ]
            },
            {
              "track_id": 774,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.36647525429725647,
              "bbox": [
                5.628697872161865,
                2.0315451622009277,
                637.5360717773438,
                352.9956970214844
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            772,
            774
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            8786,
            8790
          ],
          "representative_frame": 8786,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 73
    },
    {
      "second": 293,
      "time_range": [
        293,
        293.999
      ],
      "frame_range": [
        8791,
        8820
      ],
      "unified_description": "360 degrees of field of view, but not wide-angle distortion. Camera is mounted on a tripod, allowing for stable footage.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:28",
        "processing_time": 3.45,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8805,
          "frame_range": [
            8801,
            8805
          ],
          "description": "two men sitting in a tent with a drink",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.41
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8791,
            8795
          ],
          "representative_frame": 8791,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8436102271080017,
              "bbox": [
                119.12120819091797,
                81.07514953613281,
                269.0320739746094,
                337.1544189453125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9483200907707214,
              "bbox": [
                425.73529052734375,
                51.01835632324219,
                640.0,
                355.6471252441406
              ]
            },
            {
              "track_id": 772,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.325162410736084,
              "bbox": [
                352.8658752441406,
                309.45928955078125,
                396.59503173828125,
                359.5070495605469
              ]
            },
            {
              "track_id": 774,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.3468056917190552,
              "bbox": [
                6.436812877655029,
                1.904168963432312,
                638.80322265625,
                353.1677551269531
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            772,
            774
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            8796,
            8800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8801,
            8805
          ],
          "representative_frame": 8801,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8557202816009521,
              "bbox": [
                117.2483139038086,
                82.0352783203125,
                266.40472412109375,
                337.369873046875
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9298546314239502,
              "bbox": [
                433.7127685546875,
                60.68293380737305,
                640.0,
                355.3185119628906
              ]
            },
            {
              "track_id": 772,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3489897847175598,
              "bbox": [
                352.9105224609375,
                309.47003173828125,
                396.6701354980469,
                359.5496520996094
              ]
            },
            {
              "track_id": 774,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.17952439188957214,
              "bbox": [
                5.588088035583496,
                2.0254080295562744,
                637.4659423828125,
                352.96270751953125
              ]
            },
            {
              "track_id": 778,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4594060182571411,
              "bbox": [
                351.4233093261719,
                235.2530517578125,
                422.1129150390625,
                293.4020080566406
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            772,
            774,
            778
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            8806,
            8810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8811,
            8815
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8702453374862671,
              "bbox": [
                116.4498291015625,
                82.35992431640625,
                265.31451416015625,
                337.7427062988281
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8802894353866577,
              "bbox": [
                441.92303466796875,
                61.54030990600586,
                640.0,
                354.55072021484375
              ]
            },
            {
              "track_id": 772,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3078908324241638,
              "bbox": [
                352.9468078613281,
                309.58135986328125,
                396.6362609863281,
                359.56866455078125
              ]
            },
            {
              "track_id": 774,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.2561250925064087,
              "bbox": [
                5.221530914306641,
                2.068392753601074,
                636.969482421875,
                352.8699035644531
              ]
            },
            {
              "track_id": 778,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4681071937084198,
              "bbox": [
                351.42181396484375,
                235.37196350097656,
                422.07415771484375,
                293.48828125
              ]
            },
            {
              "track_id": 779,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.40730810165405273,
              "bbox": [
                476.73046875,
                283.84600830078125,
                526.0992431640625,
                329.7958984375
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            772,
            774,
            778,
            779
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            8816,
            8820
          ],
          "representative_frame": 8816,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 73
    },
    {
      "second": 294,
      "time_range": [
        294,
        294.999
      ],
      "frame_range": [
        8821,
        8850
      ],
      "unified_description": "\nBased on these image descriptions and object detections, provide a first-person perspective of two men sitting in a tent with a dog. The camera is handheld and shows signs of shaky footage. There are also several other people in the background who appear to be engaged in various activities.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:30",
        "processing_time": 4.73,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8835,
          "frame_range": [
            8831,
            8835
          ],
          "description": "two men sitting in a tent with a dog",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.85
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8821,
            8825
          ],
          "representative_frame": 8821,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8669565916061401,
              "bbox": [
                115.47954559326172,
                79.9287109375,
                265.620361328125,
                338.43682861328125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9103055000305176,
              "bbox": [
                436.7196960449219,
                58.35385513305664,
                640.0,
                355.4434814453125
              ]
            },
            {
              "track_id": 772,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3185895085334778,
              "bbox": [
                352.953857421875,
                309.6424255371094,
                396.6175537109375,
                359.5787353515625
              ]
            },
            {
              "track_id": 774,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.3030654489994049,
              "bbox": [
                5.419304847717285,
                1.973803997039795,
                636.555419921875,
                352.33001708984375
              ]
            },
            {
              "track_id": 778,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.43029722571372986,
              "bbox": [
                351.3587646484375,
                235.41275024414062,
                422.0413513183594,
                293.5528869628906
              ]
            },
            {
              "track_id": 779,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4228099286556244,
              "bbox": [
                476.7105407714844,
                284.90191650390625,
                527.3590698242188,
                331.9117126464844
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            772,
            774,
            778,
            779
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            8826,
            8830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8831,
            8835
          ],
          "representative_frame": 8831,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8526851534843445,
              "bbox": [
                115.86040496826172,
                78.3760757446289,
                266.7349548339844,
                338.9038391113281
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9342955350875854,
              "bbox": [
                431.69110107421875,
                56.93640899658203,
                640.0,
                356.0322570800781
              ]
            },
            {
              "track_id": 772,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2858963906764984,
              "bbox": [
                352.9417419433594,
                309.630615234375,
                396.62689208984375,
                359.56854248046875
              ]
            },
            {
              "track_id": 774,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.35241419076919556,
              "bbox": [
                5.613714694976807,
                1.8441274166107178,
                637.4974975585938,
                352.6356201171875
              ]
            },
            {
              "track_id": 778,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4402325749397278,
              "bbox": [
                351.3723449707031,
                235.47555541992188,
                421.96356201171875,
                293.5420227050781
              ]
            },
            {
              "track_id": 779,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6014470458030701,
              "bbox": [
                476.0260009765625,
                285.2490539550781,
                530.2195434570312,
                335.41143798828125
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            772,
            774,
            778,
            779
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            8836,
            8840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8841,
            8845
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8959181308746338,
              "bbox": [
                100.67201232910156,
                20.800600051879883,
                640.0,
                355.0097961425781
              ]
            },
            {
              "track_id": 778,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8505604863166809,
              "bbox": [
                366.1095275878906,
                236.9126739501953,
                426.78546142578125,
                286.3656311035156
              ]
            }
          ],
          "unique_tracks": [
            774,
            778
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            8846,
            8850
          ],
          "representative_frame": 8846,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 73
    },
    {
      "second": 295,
      "time_range": [
        295,
        295.999
      ],
      "frame_range": [
        8851,
        8880
      ],
      "unified_description": "\nThis is a video recording taken from a first-person perspective, showing a man sitting in a tent with a backpack on his back. The camera is mounted on his head, capturing his viewpoint as he looks around the tent. The video also includes some action camera footage, potentially capturing the surrounding environment or other people present at the location.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:32",
        "processing_time": 3.39,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8865,
          "frame_range": [
            8861,
            8865
          ],
          "description": "a man sitting in a tent with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.43
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8851,
            8855
          ],
          "representative_frame": 8851,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9119630455970764,
              "bbox": [
                158.57443237304688,
                26.042665481567383,
                640.0,
                355.0865478515625
              ]
            },
            {
              "track_id": 780,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4602694511413574,
              "bbox": [
                80.28254699707031,
                134.4978485107422,
                166.61227416992188,
                356.9146423339844
              ]
            },
            {
              "track_id": 781,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3692761957645416,
              "bbox": [
                179.94712829589844,
                210.2213592529297,
                248.62835693359375,
                271.7645568847656
              ]
            },
            {
              "track_id": 782,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3281539976596832,
              "bbox": [
                38.73257064819336,
                169.66146850585938,
                109.67972564697266,
                209.533447265625
              ]
            }
          ],
          "unique_tracks": [
            774,
            780,
            781,
            782
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            8856,
            8860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8861,
            8865
          ],
          "representative_frame": 8861,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8599078059196472,
              "bbox": [
                156.79507446289062,
                30.819156646728516,
                640.0,
                355.88592529296875
              ]
            },
            {
              "track_id": 780,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5992517471313477,
              "bbox": [
                79.39742279052734,
                129.6020965576172,
                167.24755859375,
                356.541748046875
              ]
            },
            {
              "track_id": 781,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.34920430183410645,
              "bbox": [
                179.849853515625,
                210.10589599609375,
                248.779541015625,
                271.88250732421875
              ]
            },
            {
              "track_id": 782,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3201660215854645,
              "bbox": [
                38.69478225708008,
                169.58860778808594,
                109.67981719970703,
                209.4812774658203
              ]
            }
          ],
          "unique_tracks": [
            774,
            780,
            781,
            782
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            8866,
            8870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8871,
            8875
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9338117837905884,
              "bbox": [
                159.94717407226562,
                35.79563522338867,
                640.0,
                356.2485046386719
              ]
            },
            {
              "track_id": 780,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.6086471676826477,
              "bbox": [
                79.90455627441406,
                131.89793395996094,
                166.6183319091797,
                356.5959167480469
              ]
            },
            {
              "track_id": 781,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.44178637862205505,
              "bbox": [
                179.76422119140625,
                210.1644744873047,
                248.62840270996094,
                271.90478515625
              ]
            },
            {
              "track_id": 782,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.332722932100296,
              "bbox": [
                39.09781265258789,
                169.44400024414062,
                108.93684387207031,
                208.67684936523438
              ]
            }
          ],
          "unique_tracks": [
            774,
            780,
            781,
            782
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            8876,
            8880
          ],
          "representative_frame": 8876,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 73
    },
    {
      "second": 296,
      "time_range": [
        296,
        296.999
      ],
      "frame_range": [
        8881,
        8910
      ],
      "unified_description": "1-second scene with a man in a tent with a backpack",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:33",
        "processing_time": 3.05,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8895,
          "frame_range": [
            8891,
            8895
          ],
          "description": "a man in a tent with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.33
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8881,
            8885
          ],
          "representative_frame": 8881,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9435821175575256,
              "bbox": [
                179.1053009033203,
                35.57624053955078,
                640.0,
                356.7399597167969
              ]
            },
            {
              "track_id": 780,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5998051762580872,
              "bbox": [
                79.36986541748047,
                128.38148498535156,
                167.1797637939453,
                356.9918212890625
              ]
            },
            {
              "track_id": 781,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5122541785240173,
              "bbox": [
                179.6302490234375,
                210.22482299804688,
                248.739013671875,
                272.2237243652344
              ]
            },
            {
              "track_id": 782,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3483733832836151,
              "bbox": [
                39.620094299316406,
                169.37261962890625,
                108.29988098144531,
                207.91006469726562
              ]
            }
          ],
          "unique_tracks": [
            774,
            780,
            781,
            782
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            8886,
            8890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8891,
            8895
          ],
          "representative_frame": 8891,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9281983971595764,
              "bbox": [
                191.33506774902344,
                30.586666107177734,
                640.0,
                356.1870422363281
              ]
            },
            {
              "track_id": 780,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5278052091598511,
              "bbox": [
                79.07437133789062,
                124.6951904296875,
                167.623779296875,
                356.63604736328125
              ]
            },
            {
              "track_id": 781,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.557097852230072,
              "bbox": [
                179.8948974609375,
                210.18304443359375,
                248.59124755859375,
                271.85113525390625
              ]
            },
            {
              "track_id": 782,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.297606498003006,
              "bbox": [
                39.554443359375,
                169.47384643554688,
                108.2675552368164,
                207.9921112060547
              ]
            }
          ],
          "unique_tracks": [
            774,
            780,
            781,
            782
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            8896,
            8900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8901,
            8905
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.897192656993866,
              "bbox": [
                194.65338134765625,
                34.7344970703125,
                629.25048828125,
                356.6764221191406
              ]
            },
            {
              "track_id": 780,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.560452401638031,
              "bbox": [
                79.27781677246094,
                123.96952056884766,
                167.47557067871094,
                356.5153503417969
              ]
            },
            {
              "track_id": 781,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5202021598815918,
              "bbox": [
                180.0912322998047,
                210.24664306640625,
                248.49710083007812,
                271.6898193359375
              ]
            },
            {
              "track_id": 782,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2786591649055481,
              "bbox": [
                39.594730377197266,
                169.52134704589844,
                108.24137878417969,
                207.95416259765625
              ]
            }
          ],
          "unique_tracks": [
            774,
            780,
            781,
            782
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            8906,
            8910
          ],
          "representative_frame": 8906,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 74
    },
    {
      "second": 297,
      "time_range": [
        297,
        297.999
      ],
      "frame_range": [
        8911,
        8940
      ],
      "unified_description": "\nI'll try to help with these descriptions by providing additional context and clarification as needed.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:33",
        "processing_time": 2.63,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8925,
          "frame_range": [
            8921,
            8925
          ],
          "description": "a man in a tent with a knife and a knife",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.94
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8911,
            8915
          ],
          "representative_frame": 8911,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9340123534202576,
              "bbox": [
                201.25433349609375,
                36.86934280395508,
                617.0166015625,
                356.6185302734375
              ]
            },
            {
              "track_id": 780,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5836701393127441,
              "bbox": [
                80.58267211914062,
                128.25558471679688,
                166.55914306640625,
                356.211181640625
              ]
            },
            {
              "track_id": 781,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.37071824073791504,
              "bbox": [
                180.24005126953125,
                210.39385986328125,
                248.27943420410156,
                271.5232849121094
              ]
            },
            {
              "track_id": 782,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.28033846616744995,
              "bbox": [
                39.86457824707031,
                169.45069885253906,
                108.0157241821289,
                207.51829528808594
              ]
            }
          ],
          "unique_tracks": [
            774,
            780,
            781,
            782
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            8916,
            8920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8921,
            8925
          ],
          "representative_frame": 8921,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8943515419960022,
              "bbox": [
                199.10687255859375,
                38.57217025756836,
                597.2200317382812,
                355.5400695800781
              ]
            },
            {
              "track_id": 782,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.13365255296230316,
              "bbox": [
                39.1379280090332,
                173.16348266601562,
                106.57443237304688,
                210.86669921875
              ]
            }
          ],
          "unique_tracks": [
            774,
            782
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            8926,
            8930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8931,
            8935
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            8936,
            8940
          ],
          "representative_frame": 8936,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 74
    },
    {
      "second": 298,
      "time_range": [
        298,
        298.999
      ],
      "frame_range": [
        8941,
        8970
      ],
      "unified_description": "1-second scene with a man wearing a hat and jacket holding a knife. It appears to be shot in wide-angle perspective showing several objects simultaneously.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:37",
        "processing_time": 2.64,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8955,
          "frame_range": [
            8951,
            8955
          ],
          "description": "a man in a hat and jacket is holding a knife",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.44
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8941,
            8945
          ],
          "representative_frame": 8941,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            8946,
            8950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8951,
            8955
          ],
          "representative_frame": 8951,
          "detections": [
            {
              "track_id": 763,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5861160755157471,
              "bbox": [
                404.8348083496094,
                227.7129669189453,
                522.16552734375,
                290.0976867675781
              ]
            }
          ],
          "unique_tracks": [
            763
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            8956,
            8960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8961,
            8965
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            8966,
            8970
          ],
          "representative_frame": 8966,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 74
    },
    {
      "second": 299,
      "time_range": [
        299,
        299.999
      ],
      "frame_range": [
        8971,
        9000
      ],
      "unified_description": "3D model of the inside of a building",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:38",
        "processing_time": 2.33,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8985,
          "frame_range": [
            8981,
            8985
          ],
          "description": "a person is standing in the woods with a blue hat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.7
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8971,
            8975
          ],
          "representative_frame": 8971,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            8976,
            8980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8981,
            8985
          ],
          "representative_frame": 8981,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9263936877250671,
              "bbox": [
                121.02526092529297,
                1.9876787662506104,
                352.47119140625,
                355.36383056640625
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            8986,
            8990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8991,
            8995
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8334255218505859,
              "bbox": [
                91.24868774414062,
                7.243940830230713,
                330.4860534667969,
                355.4740295410156
              ]
            },
            {
              "track_id": 780,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5069637298583984,
              "bbox": [
                73.72638702392578,
                118.09910583496094,
                171.53065490722656,
                357.250244140625
              ]
            }
          ],
          "unique_tracks": [
            682,
            780
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            8996,
            9000
          ],
          "representative_frame": 8996,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 74
    },
    {
      "second": 300,
      "time_range": [
        300,
        300.999
      ],
      "frame_range": [
        9001,
        9030
      ],
      "unified_description": "\n\nFirst-person video with a man in an outdoor setting, close to water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:38",
        "processing_time": 2.63,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9015,
          "frame_range": [
            9011,
            9015
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.17
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9001,
            9005
          ],
          "representative_frame": 9001,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8794298768043518,
              "bbox": [
                57.2736701965332,
                14.760794639587402,
                302.562744140625,
                356.4481201171875
              ]
            },
            {
              "track_id": 780,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2214379906654358,
              "bbox": [
                56.785152435302734,
                152.1563720703125,
                150.94874572753906,
                356.9646301269531
              ]
            }
          ],
          "unique_tracks": [
            682,
            780
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            9006,
            9010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9011,
            9015
          ],
          "representative_frame": 9011,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9171873331069946,
              "bbox": [
                60.44990158081055,
                26.749544143676758,
                299.982421875,
                356.86798095703125
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9016,
            9020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9021,
            9025
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.913673460483551,
              "bbox": [
                72.6177978515625,
                40.04457473754883,
                305.3981628417969,
                357.1348571777344
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9026,
            9030
          ],
          "representative_frame": 9026,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 75
    },
    {
      "second": 301,
      "time_range": [
        301,
        301.999
      ],
      "frame_range": [
        9031,
        9060
      ],
      "unified_description": "\nA man holding a fishing rod next to a body of water. A mountain can be seen in the background. The camera is capturing the scene with an overview of the area, and the fish are visible in the water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:43",
        "processing_time": 2.97,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9045,
          "frame_range": [
            9041,
            9045
          ],
          "description": "a man is fishing on the water near a mountain",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.31
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9031,
            9035
          ],
          "representative_frame": 9031,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9315428733825684,
              "bbox": [
                80.43568420410156,
                35.905975341796875,
                316.1678466796875,
                356.8798522949219
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9036,
            9040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9041,
            9045
          ],
          "representative_frame": 9041,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9185761213302612,
              "bbox": [
                80.41460418701172,
                46.66106414794922,
                312.1235046386719,
                357.4001159667969
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9046,
            9050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9051,
            9055
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6537664532661438,
              "bbox": [
                100.8968276977539,
                68.40653991699219,
                327.22186279296875,
                357.28009033203125
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9056,
            9060
          ],
          "representative_frame": 9056,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 75
    },
    {
      "second": 302,
      "time_range": [
        302,
        302.999
      ],
      "frame_range": [
        9061,
        9090
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:43",
        "processing_time": 3.0,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9075,
          "frame_range": [
            9071,
            9075
          ],
          "description": "a man is fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.02
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9061,
            9065
          ],
          "representative_frame": 9061,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8751081228256226,
              "bbox": [
                65.94760131835938,
                46.46015167236328,
                307.67236328125,
                356.2617492675781
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9066,
            9070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9071,
            9075
          ],
          "representative_frame": 9071,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8796796202659607,
              "bbox": [
                64.90274047851562,
                33.03371810913086,
                319.8965148925781,
                356.1458435058594
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9076,
            9080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9081,
            9085
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8865836262702942,
              "bbox": [
                59.502281188964844,
                11.52979564666748,
                336.9010925292969,
                355.26739501953125
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9086,
            9090
          ],
          "representative_frame": 9086,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 75
    },
    {
      "second": 303,
      "time_range": [
        303,
        303.999
      ],
      "frame_range": [
        9091,
        9120
      ],
      "unified_description": "1-second scene with a man on the shore of a lake. A group of people is seen sitting and standing in various positions around the area. The camera appears to be stable as it captures the scene, showing no signs of motion blur or other technical artifacts.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:44",
        "processing_time": 4.24,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9105,
          "frame_range": [
            9101,
            9105
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.81
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9091,
            9095
          ],
          "representative_frame": 9091,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9224257469177246,
              "bbox": [
                72.4295883178711,
                87.47465515136719,
                278.342041015625,
                327.7080993652344
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9096,
            9100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9101,
            9105
          ],
          "representative_frame": 9101,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9266918897628784,
              "bbox": [
                67.06444549560547,
                117.87085723876953,
                264.7137756347656,
                345.2372131347656
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9106,
            9110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9111,
            9115
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8534634113311768,
              "bbox": [
                83.13939666748047,
                119.07278442382812,
                259.6898193359375,
                318.10382080078125
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9116,
            9120
          ],
          "representative_frame": 9116,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 75
    },
    {
      "second": 304,
      "time_range": [
        304,
        304.999
      ],
      "frame_range": [
        9121,
        9150
      ],
      "unified_description": "\nIn this image, there's a man fishing on the shore of a lake. The camera is positioned on the man's body, recording the action in a wide-angle view that includes the surroundings. The camera captures a stable shot of the man and his fishing rod as he casts his line into the water. There are no visible technical artifacts in this particular image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:49",
        "processing_time": 3.52,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9135,
          "frame_range": [
            9131,
            9135
          ],
          "description": "a man is fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.51
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9121,
            9125
          ],
          "representative_frame": 9121,
          "detections": [
            {
              "track_id": 682,
              "class_id": 17,
              "class_name": "horse",
              "confidence": 0.755854606628418,
              "bbox": [
                97.40499114990234,
                106.19219970703125,
                281.2183837890625,
                314.60455322265625
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9126,
            9130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9131,
            9135
          ],
          "representative_frame": 9131,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8485732078552246,
              "bbox": [
                109.82762145996094,
                90.88783264160156,
                298.76806640625,
                311.559814453125
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9136,
            9140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9141,
            9145
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7984352111816406,
              "bbox": [
                114.94719696044922,
                83.60579681396484,
                302.5076904296875,
                307.6490783691406
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9146,
            9150
          ],
          "representative_frame": 9146,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 76
    },
    {
      "second": 305,
      "time_range": [
        305,
        305.999
      ],
      "frame_range": [
        9151,
        9180
      ],
      "unified_description": "30 second video shot with an action camera",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:49",
        "processing_time": 3.74,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9165,
          "frame_range": [
            9161,
            9165
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.49
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9151,
            9155
          ],
          "representative_frame": 9151,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7051936984062195,
              "bbox": [
                124.31321716308594,
                81.17738342285156,
                301.2207336425781,
                299.61456298828125
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9156,
            9160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9161,
            9165
          ],
          "representative_frame": 9161,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7396057844161987,
              "bbox": [
                121.32254028320312,
                89.54520416259766,
                287.9325256347656,
                297.11279296875
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9166,
            9170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9171,
            9175
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7462294101715088,
              "bbox": [
                121.00320434570312,
                84.19380187988281,
                292.44866943359375,
                304.9273681640625
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9176,
            9180
          ],
          "representative_frame": 9176,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 76
    },
    {
      "second": 306,
      "time_range": [
        306,
        306.999
      ],
      "frame_range": [
        9181,
        9210
      ],
      "unified_description": "36 seconds of camera footage showing a man standing in the water near a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:49",
        "processing_time": 3.75,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9195,
          "frame_range": [
            9191,
            9195
          ],
          "description": "a man is standing in the water near a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.43
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9181,
            9185
          ],
          "representative_frame": 9181,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9130895137786865,
              "bbox": [
                122.34514617919922,
                79.91890716552734,
                298.13995361328125,
                312.10943603515625
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9186,
            9190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9191,
            9195
          ],
          "representative_frame": 9191,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9074528217315674,
              "bbox": [
                123.16747283935547,
                80.2166519165039,
                297.8955383300781,
                316.3680725097656
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9196,
            9200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9201,
            9205
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9187049865722656,
              "bbox": [
                128.3675537109375,
                74.72443389892578,
                302.4773254394531,
                314.52386474609375
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9206,
            9210
          ],
          "representative_frame": 9206,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 76
    },
    {
      "second": 307,
      "time_range": [
        307,
        307.999
      ],
      "frame_range": [
        9211,
        9240
      ],
      "unified_description": "20 minutes ago, there was one uninterrupted shot of a man standing in the water near a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:53",
        "processing_time": 2.47,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9225,
          "frame_range": [
            9221,
            9225
          ],
          "description": "a man is standing in the water near a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.39
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9211,
            9215
          ],
          "representative_frame": 9211,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9210420846939087,
              "bbox": [
                142.97886657714844,
                71.8009033203125,
                323.4046630859375,
                317.7079772949219
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9216,
            9220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9221,
            9225
          ],
          "representative_frame": 9221,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9121853709220886,
              "bbox": [
                139.23638916015625,
                71.68729400634766,
                317.329833984375,
                316.691650390625
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9226,
            9230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9231,
            9235
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.885265052318573,
              "bbox": [
                132.47462463378906,
                77.5968246459961,
                304.2561340332031,
                318.97802734375
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9236,
            9240
          ],
          "representative_frame": 9236,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 76
    },
    {
      "second": 308,
      "time_range": [
        308,
        308.999
      ],
      "frame_range": [
        9241,
        9270
      ],
      "unified_description": "2 people standing together near the shoreline of a body of water, like a lake or river.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:54",
        "processing_time": 2.95,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9255,
          "frame_range": [
            9251,
            9255
          ],
          "description": "a man is standing in the water near a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.16
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9241,
            9245
          ],
          "representative_frame": 9241,
          "detections": [
            {
              "track_id": 780,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8663136959075928,
              "bbox": [
                29.453445434570312,
                78.02365112304688,
                159.3516845703125,
                329.66766357421875
              ]
            }
          ],
          "unique_tracks": [
            780
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9246,
            9250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9251,
            9255
          ],
          "representative_frame": 9251,
          "detections": [
            {
              "track_id": 780,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9192563891410828,
              "bbox": [
                17.751583099365234,
                72.961181640625,
                161.21319580078125,
                336.999755859375
              ]
            }
          ],
          "unique_tracks": [
            780
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9256,
            9260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9261,
            9265
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 780,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7644904851913452,
              "bbox": [
                6.208741664886475,
                69.84639739990234,
                153.38780212402344,
                340.54583740234375
              ]
            }
          ],
          "unique_tracks": [
            780
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9266,
            9270
          ],
          "representative_frame": 9266,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 77
    },
    {
      "second": 309,
      "time_range": [
        309,
        309.999
      ],
      "frame_range": [
        9271,
        9300
      ],
      "unified_description": "1-second scene with a man standing on a rocky shore next to a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:55",
        "processing_time": 3.28,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9285,
          "frame_range": [
            9281,
            9285
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.86
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9271,
            9275
          ],
          "representative_frame": 9271,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            9276,
            9280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9281,
            9285
          ],
          "representative_frame": 9281,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7647782564163208,
              "bbox": [
                322.0390319824219,
                91.91746520996094,
                404.85491943359375,
                306.2868347167969
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9286,
            9290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9291,
            9295
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7022567987442017,
              "bbox": [
                327.67205810546875,
                94.65116882324219,
                407.16680908203125,
                300.9037780761719
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9296,
            9300
          ],
          "representative_frame": 9296,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 77
    },
    {
      "second": 310,
      "time_range": [
        310,
        310.999
      ],
      "frame_range": [
        9301,
        9330
      ],
      "unified_description": "\nA stable camera perspective provides a clear view of the man on the rocky shore next to the lake. The surrounding environment is also captured in the image, which can give context to the scene. This wide-angle shot covers a significant portion of the area and seems to be taken from a stationary position.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:59",
        "processing_time": 3.22,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9315,
          "frame_range": [
            9311,
            9315
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.87
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9301,
            9305
          ],
          "representative_frame": 9301,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8913310766220093,
              "bbox": [
                329.4876403808594,
                94.9555892944336,
                406.818603515625,
                296.2981872558594
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9306,
            9310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9311,
            9315
          ],
          "representative_frame": 9311,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.855391263961792,
              "bbox": [
                318.5394287109375,
                91.04556274414062,
                397.7451171875,
                296.11798095703125
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9316,
            9320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9321,
            9325
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8470504879951477,
              "bbox": [
                333.6313781738281,
                87.79356384277344,
                412.4627380371094,
                295.5239562988281
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9326,
            9330
          ],
          "representative_frame": 9326,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 77
    },
    {
      "second": 311,
      "time_range": [
        311,
        311.999
      ],
      "frame_range": [
        9331,
        9360
      ],
      "unified_description": "10-second video showing a man standing on a rocky shore next to a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:19:59",
        "processing_time": 3.05,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9345,
          "frame_range": [
            9341,
            9345
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9331,
            9335
          ],
          "representative_frame": 9331,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.890697717666626,
              "bbox": [
                334.3518981933594,
                85.08626556396484,
                413.2437438964844,
                296.0361022949219
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9336,
            9340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9341,
            9345
          ],
          "representative_frame": 9341,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.889342188835144,
              "bbox": [
                332.7818908691406,
                82.46451568603516,
                411.77392578125,
                296.21044921875
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9346,
            9350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9351,
            9355
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.885489821434021,
              "bbox": [
                322.971435546875,
                79.70833587646484,
                404.6072082519531,
                296.57427978515625
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9356,
            9360
          ],
          "representative_frame": 9356,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 77
    },
    {
      "second": 312,
      "time_range": [
        312,
        312.999
      ],
      "frame_range": [
        9361,
        9390
      ],
      "unified_description": "2D scene with one person standing by water with lake in background. There is also a clock visible in the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:00",
        "processing_time": 3.57,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9375,
          "frame_range": [
            9371,
            9375
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.6
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9361,
            9365
          ],
          "representative_frame": 9361,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9252041578292847,
              "bbox": [
                318.06573486328125,
                77.17115020751953,
                402.78411865234375,
                300.2295837402344
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9366,
            9370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9371,
            9375
          ],
          "representative_frame": 9371,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9173749089241028,
              "bbox": [
                322.2918701171875,
                74.64947509765625,
                409.0042419433594,
                302.77288818359375
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9376,
            9380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9381,
            9385
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9286816120147705,
              "bbox": [
                310.0118408203125,
                68.41122436523438,
                403.1986999511719,
                305.9261779785156
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9386,
            9390
          ],
          "representative_frame": 9386,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 78
    },
    {
      "second": 313,
      "time_range": [
        313,
        313.999
      ],
      "frame_range": [
        9391,
        9420
      ],
      "unified_description": "1-second scene of a man standing on a rocky shore next to a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:03",
        "processing_time": 2.38,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9405,
          "frame_range": [
            9401,
            9405
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.89
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9391,
            9395
          ],
          "representative_frame": 9391,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9257926344871521,
              "bbox": [
                304.79559326171875,
                57.7254753112793,
                410.2374267578125,
                322.4269714355469
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9396,
            9400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9401,
            9405
          ],
          "representative_frame": 9401,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9458834528923035,
              "bbox": [
                313.8543395996094,
                52.422279357910156,
                428.1537780761719,
                330.5685729980469
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9406,
            9410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9411,
            9415
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9284369349479675,
              "bbox": [
                315.67822265625,
                40.78864669799805,
                435.13909912109375,
                338.0635070800781
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9416,
            9420
          ],
          "representative_frame": 9416,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 78
    },
    {
      "second": 314,
      "time_range": [
        314,
        314.999
      ],
      "frame_range": [
        9421,
        9450
      ],
      "unified_description": "1-second scene of a beach with a man standing by the shore of a lake.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:04",
        "processing_time": 2.58,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9435,
          "frame_range": [
            9431,
            9435
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.9
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9421,
            9425
          ],
          "representative_frame": 9421,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.940004825592041,
              "bbox": [
                301.8255920410156,
                13.767142295837402,
                449.525146484375,
                349.94647216796875
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9426,
            9430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9431,
            9435
          ],
          "representative_frame": 9431,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9489104151725769,
              "bbox": [
                294.8775329589844,
                3.1219992637634277,
                461.2873229980469,
                354.7069091796875
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9436,
            9440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9441,
            9445
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9489545226097107,
              "bbox": [
                286.91162109375,
                0.0,
                468.9864501953125,
                356.44683837890625
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9446,
            9450
          ],
          "representative_frame": 9446,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 78
    },
    {
      "second": 315,
      "time_range": [
        315,
        315.999
      ],
      "frame_range": [
        9451,
        9480
      ],
      "unified_description": "2 men are fishing in the water, standing near the shore",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:04",
        "processing_time": 2.71,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9465,
          "frame_range": [
            9461,
            9465
          ],
          "description": "a man is holding a fish while standing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.54
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9451,
            9455
          ],
          "representative_frame": 9451,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9534424543380737,
              "bbox": [
                284.51397705078125,
                0.0,
                479.0364685058594,
                357.1738586425781
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9456,
            9460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9461,
            9465
          ],
          "representative_frame": 9461,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.93632572889328,
              "bbox": [
                286.948486328125,
                0.0,
                490.18695068359375,
                357.3031921386719
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9466,
            9470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9471,
            9475
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9463950395584106,
              "bbox": [
                296.9604187011719,
                0.0,
                506.0475158691406,
                357.2763366699219
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9476,
            9480
          ],
          "representative_frame": 9476,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 78
    },
    {
      "second": 316,
      "time_range": [
        316,
        316.999
      ],
      "frame_range": [
        9481,
        9510
      ],
      "unified_description": "30-second video that captures a scene where a man is standing on the shore of a lake with a wide-angle perspective",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:07",
        "processing_time": 2.58,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9495,
          "frame_range": [
            9491,
            9495
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.59
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9481,
            9485
          ],
          "representative_frame": 9481,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9425563216209412,
              "bbox": [
                299.9328308105469,
                0.0,
                513.8505859375,
                357.3236999511719
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9486,
            9490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9491,
            9495
          ],
          "representative_frame": 9491,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9448176622390747,
              "bbox": [
                298.03277587890625,
                0.0,
                517.0904541015625,
                357.0916442871094
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9496,
            9500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9501,
            9505
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9468625783920288,
              "bbox": [
                297.3017578125,
                0.0,
                520.3326416015625,
                356.9604797363281
              ]
            }
          ],
          "unique_tracks": [
            800
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9506,
            9510
          ],
          "representative_frame": 9506,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 79
    },
    {
      "second": 317,
      "time_range": [
        317,
        317.999
      ],
      "frame_range": [
        9511,
        9540
      ],
      "unified_description": "1-second scene including a man fishing on a lake with a fishing rod",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:08",
        "processing_time": 2.49,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9525,
          "frame_range": [
            9521,
            9525
          ],
          "description": "a man fishing on a lake with a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.71
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9511,
            9515
          ],
          "representative_frame": 9511,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9380192756652832,
              "bbox": [
                293.2082214355469,
                0.0,
                521.435791015625,
                357.3730163574219
              ]
            },
            {
              "track_id": 809,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3478790819644928,
              "bbox": [
                50.66866683959961,
                205.63743591308594,
                130.90513610839844,
                249.81617736816406
              ]
            }
          ],
          "unique_tracks": [
            800,
            809
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            9516,
            9520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9521,
            9525
          ],
          "representative_frame": 9521,
          "detections": [
            {
              "track_id": 800,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9463711380958557,
              "bbox": [
                287.1692199707031,
                0.0,
                521.942138671875,
                356.94488525390625
              ]
            },
            {
              "track_id": 809,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.12608397006988525,
              "bbox": [
                54.50312042236328,
                203.3900146484375,
                132.78219604492188,
                246.47097778320312
              ]
            }
          ],
          "unique_tracks": [
            800,
            809
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            9526,
            9530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9531,
            9535
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9070220589637756,
              "bbox": [
                178.4345245361328,
                32.85085678100586,
                361.3476257324219,
                325.6744384765625
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9536,
            9540
          ],
          "representative_frame": 9536,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 79
    },
    {
      "second": 318,
      "time_range": [
        318,
        318.999
      ],
      "frame_range": [
        9541,
        9570
      ],
      "unified_description": "1-second scene featuring a man fishing on the shore of a lake with several objects in view",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:08",
        "processing_time": 2.99,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9555,
          "frame_range": [
            9551,
            9555
          ],
          "description": "a man fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.36
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9541,
            9545
          ],
          "representative_frame": 9541,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9192751049995422,
              "bbox": [
                189.91709899902344,
                43.72916793823242,
                353.5059509277344,
                318.2184753417969
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9546,
            9550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9551,
            9555
          ],
          "representative_frame": 9551,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9299842119216919,
              "bbox": [
                193.63941955566406,
                58.0626106262207,
                346.25250244140625,
                316.1791076660156
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9556,
            9560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9561,
            9565
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8360750079154968,
              "bbox": [
                211.0043182373047,
                89.94087219238281,
                340.0424499511719,
                292.7921447753906
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9566,
            9570
          ],
          "representative_frame": 9566,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 79
    },
    {
      "second": 319,
      "time_range": [
        319,
        319.999
      ],
      "frame_range": [
        9571,
        9600
      ],
      "unified_description": "10-second description of image for easy understanding.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:10",
        "processing_time": 2.29,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9585,
          "frame_range": [
            9581,
            9585
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.1
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9571,
            9575
          ],
          "representative_frame": 9571,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9055071473121643,
              "bbox": [
                211.84750366210938,
                105.78373718261719,
                341.1504821777344,
                301.9380798339844
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9576,
            9580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9581,
            9585
          ],
          "representative_frame": 9581,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8942917585372925,
              "bbox": [
                206.11793518066406,
                110.06781768798828,
                340.925537109375,
                310.64129638671875
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9586,
            9590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9591,
            9595
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9020895957946777,
              "bbox": [
                202.01084899902344,
                106.01426696777344,
                343.1907653808594,
                313.4105529785156
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9596,
            9600
          ],
          "representative_frame": 9596,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 79
    },
    {
      "second": 320,
      "time_range": [
        320,
        320.999
      ],
      "frame_range": [
        9601,
        9630
      ],
      "unified_description": "1-second scene where a man is fishing on the shore of a lake. The camera is positioned on a tripod, producing stable footage with a wide field of view.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:12",
        "processing_time": 2.72,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9615,
          "frame_range": [
            9611,
            9615
          ],
          "description": "a man is fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.5
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9601,
            9605
          ],
          "representative_frame": 9601,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8882972002029419,
              "bbox": [
                172.82022094726562,
                75.07866668701172,
                344.8535461425781,
                339.9547119140625
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9606,
            9610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9611,
            9615
          ],
          "representative_frame": 9611,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7783212065696716,
              "bbox": [
                154.8151092529297,
                29.291534423828125,
                349.17529296875,
                347.3518981933594
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9616,
            9620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9621,
            9625
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8485222458839417,
              "bbox": [
                146.378173828125,
                9.800188064575195,
                352.1596984863281,
                353.5386047363281
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9626,
            9630
          ],
          "representative_frame": 9626,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 80
    },
    {
      "second": 321,
      "time_range": [
        321,
        321.999
      ],
      "frame_range": [
        9631,
        9660
      ],
      "unified_description": "1-second scene that includes a man standing near a body of water, with objects such as backpack, handbag, and a cell phone visible in the frame.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:13",
        "processing_time": 3.42,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9645,
          "frame_range": [
            9641,
            9645
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.14
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9631,
            9635
          ],
          "representative_frame": 9631,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9179505109786987,
              "bbox": [
                127.4617919921875,
                1.6859387159347534,
                335.51654052734375,
                356.8898620605469
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9636,
            9640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9641,
            9645
          ],
          "representative_frame": 9641,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8611209392547607,
              "bbox": [
                79.86337280273438,
                0.0,
                296.0096130371094,
                357.8297119140625
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9646,
            9650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9651,
            9655
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9281287789344788,
              "bbox": [
                66.86325073242188,
                0.0,
                287.4574890136719,
                358.7850341796875
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9656,
            9660
          ],
          "representative_frame": 9656,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 80
    },
    {
      "second": 322,
      "time_range": [
        322,
        322.999
      ],
      "frame_range": [
        9661,
        9690
      ],
      "unified_description": "1-second scene with a man standing by a body of water. Camera positioning is stable and shows wide-angle distortion. Video style appears to be action camera or documentary.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:14",
        "processing_time": 2.81,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9675,
          "frame_range": [
            9671,
            9675
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.79
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9661,
            9665
          ],
          "representative_frame": 9661,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9091858863830566,
              "bbox": [
                57.616676330566406,
                0.0,
                280.72528076171875,
                358.49615478515625
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9666,
            9670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9671,
            9675
          ],
          "representative_frame": 9671,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9248761534690857,
              "bbox": [
                49.64897537231445,
                0.0,
                276.65838623046875,
                358.3146667480469
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9676,
            9680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9681,
            9685
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9468597173690796,
              "bbox": [
                63.42963790893555,
                0.0,
                304.94647216796875,
                357.716552734375
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9686,
            9690
          ],
          "representative_frame": 9686,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 80
    },
    {
      "second": 323,
      "time_range": [
        323,
        323.999
      ],
      "frame_range": [
        9691,
        9720
      ],
      "unified_description": "10-second video capturing a person fishing in a river with a wide-angle perspective, showing the surrounding trees and landscape.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:15",
        "processing_time": 2.57,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9705,
          "frame_range": [
            9701,
            9705
          ],
          "description": "a man is fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.84
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9691,
            9695
          ],
          "representative_frame": 9691,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9467637538909912,
              "bbox": [
                67.39195251464844,
                0.0,
                323.0365905761719,
                357.21270751953125
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9696,
            9700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9701,
            9705
          ],
          "representative_frame": 9701,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9536508917808533,
              "bbox": [
                66.55172729492188,
                0.0,
                337.1361389160156,
                356.8067932128906
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9706,
            9710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9711,
            9715
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9482287168502808,
              "bbox": [
                73.16305541992188,
                0.0,
                355.90777587890625,
                356.63983154296875
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9716,
            9720
          ],
          "representative_frame": 9716,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 80
    },
    {
      "second": 324,
      "time_range": [
        324,
        324.999
      ],
      "frame_range": [
        9721,
        9750
      ],
      "unified_description": "1-second scene showing a man pointing at the water with multiple objects and people in the frame.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:16",
        "processing_time": 2.62,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9735,
          "frame_range": [
            9731,
            9735
          ],
          "description": "a man is pointing at the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.66
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9721,
            9725
          ],
          "representative_frame": 9721,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9421402812004089,
              "bbox": [
                80.5155029296875,
                0.0,
                373.60125732421875,
                356.6566162109375
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9726,
            9730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9731,
            9735
          ],
          "representative_frame": 9731,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9376534819602966,
              "bbox": [
                83.46562194824219,
                0.0,
                385.9258728027344,
                356.1931457519531
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9736,
            9740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9741,
            9745
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9309436082839966,
              "bbox": [
                48.28602981567383,
                0.0,
                351.9921875,
                356.5904846191406
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9746,
            9750
          ],
          "representative_frame": 9746,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 81
    },
    {
      "second": 325,
      "time_range": [
        325,
        325.999
      ],
      "frame_range": [
        9751,
        9780
      ],
      "unified_description": "1-second scene featuring a man in sunglasses and a hat standing on the shore. A camera perspective showing the man's point of view as he looks around. This could be action camera footage or documentary-style video. There may be some wide-angle distortion, fisheye effect, or telephoto compression in the image due to the camera type used.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:19",
        "processing_time": 3.66,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9765,
          "frame_range": [
            9761,
            9765
          ],
          "description": "a man in sunglasses and a hat is standing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.82
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9751,
            9755
          ],
          "representative_frame": 9751,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9278216361999512,
              "bbox": [
                18.22936248779297,
                0.0,
                319.7146911621094,
                356.5691833496094
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9756,
            9760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9761,
            9765
          ],
          "representative_frame": 9761,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9374359250068665,
              "bbox": [
                0.0,
                0.0,
                296.53515625,
                356.4792785644531
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9766,
            9770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9771,
            9775
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9281235337257385,
              "bbox": [
                0.0,
                0.0,
                283.5643005371094,
                356.46630859375
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9776,
            9780
          ],
          "representative_frame": 9776,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 81
    },
    {
      "second": 326,
      "time_range": [
        326,
        326.999
      ],
      "frame_range": [
        9781,
        9810
      ],
      "unified_description": "1-second scene including a man wearing sunglasses and a hat, standing by the water, with additional details like trees and sand. Camera perspective is first-person, mounted on a backpack, capturing a wide-angle view, and the camera positioning is stable.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:20",
        "processing_time": 3.49,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9795,
          "frame_range": [
            9791,
            9795
          ],
          "description": "a man in sunglasses and a hat is standing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.38
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9781,
            9785
          ],
          "representative_frame": 9781,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9378423690795898,
              "bbox": [
                0.0,
                0.0,
                285.85284423828125,
                356.4261474609375
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9786,
            9790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9791,
            9795
          ],
          "representative_frame": 9791,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9376208782196045,
              "bbox": [
                0.09800208359956741,
                0.0,
                296.07257080078125,
                356.4081115722656
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9796,
            9800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9801,
            9805
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9282922744750977,
              "bbox": [
                0.0,
                0.0,
                292.9158020019531,
                356.426513671875
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9806,
            9810
          ],
          "representative_frame": 9806,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 81
    },
    {
      "second": 327,
      "time_range": [
        327,
        327.999
      ],
      "frame_range": [
        9811,
        9840
      ],
      "unified_description": "3rd person camera perspective showing a man in a hat fishing at the pond",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:21",
        "processing_time": 3.43,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9825,
          "frame_range": [
            9821,
            9825
          ],
          "description": "a man in a hat is fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.17
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9811,
            9815
          ],
          "representative_frame": 9811,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9311608076095581,
              "bbox": [
                0.0,
                0.06277434527873993,
                286.6567687988281,
                356.1327819824219
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9816,
            9820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9821,
            9825
          ],
          "representative_frame": 9821,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9116370677947998,
              "bbox": [
                0.0,
                0.0,
                291.6504211425781,
                354.9154968261719
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9826,
            9830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9831,
            9835
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.902787446975708,
              "bbox": [
                3.8570032119750977,
                0.45177024602890015,
                299.15008544921875,
                355.2290954589844
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9836,
            9840
          ],
          "representative_frame": 9836,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 81
    },
    {
      "second": 328,
      "time_range": [
        328,
        328.999
      ],
      "frame_range": [
        9841,
        9870
      ],
      "unified_description": "\n\nVideo taken outdoors with natural lighting. It shows a man with a hat and sunglasses holding a fish. The camera is in a stable position, possibly mounted on a tripod, and the field of view is relatively wide-angle, capturing the surroundings as well. There are no technical artifacts visible in the image, suggesting a clean and clear capture.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:24",
        "processing_time": 3.75,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9855,
          "frame_range": [
            9851,
            9855
          ],
          "description": "a man in a hat and sunglasses is holding a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.51
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9841,
            9845
          ],
          "representative_frame": 9841,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9623956084251404,
              "bbox": [
                15.44648265838623,
                0.5336822271347046,
                313.5614929199219,
                354.3945617675781
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9846,
            9850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9851,
            9855
          ],
          "representative_frame": 9851,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9598355889320374,
              "bbox": [
                34.671173095703125,
                0.3716053068637848,
                336.4432373046875,
                354.44390869140625
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9856,
            9860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9861,
            9865
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9630807638168335,
              "bbox": [
                25.809106826782227,
                0.23745441436767578,
                331.4307556152344,
                353.49566650390625
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9866,
            9870
          ],
          "representative_frame": 9866,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 82
    },
    {
      "second": 329,
      "time_range": [
        329,
        329.999
      ],
      "frame_range": [
        9871,
        9900
      ],
      "unified_description": "\nAn outdoor scene with a man wearing sunglasses and a hat standing in front of rocks. The camera perspective appears to be first-person, capturing the man's point of view as he looks around him. The field of view is relatively wide, allowing for several objects or people to be visible simultaneously. The image has an action camera style, suggesting that it may have been captured during a thrilling experience or adventure.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:26",
        "processing_time": 3.79,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9885,
          "frame_range": [
            9881,
            9885
          ],
          "description": "a man in a hat and sunglasses is standing on a rock",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.12
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9871,
            9875
          ],
          "representative_frame": 9871,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9512225389480591,
              "bbox": [
                18.130611419677734,
                0.0,
                326.7032775878906,
                353.08697509765625
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9876,
            9880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9881,
            9885
          ],
          "representative_frame": 9881,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9442335963249207,
              "bbox": [
                15.893305778503418,
                0.1531880497932434,
                327.0376281738281,
                352.5787353515625
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9886,
            9890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9891,
            9895
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9480531811714172,
              "bbox": [
                7.646123886108398,
                0.4444146156311035,
                319.7951965332031,
                353.4005126953125
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            9896,
            9900
          ],
          "representative_frame": 9896,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 82
    },
    {
      "second": 330,
      "time_range": [
        330,
        330.999
      ],
      "frame_range": [
        9901,
        9930
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:26",
        "processing_time": 3.51,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9915,
          "frame_range": [
            9911,
            9915
          ],
          "description": "a man in a hat and sunglasses is holding a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.97
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9901,
            9905
          ],
          "representative_frame": 9901,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9446896314620972,
              "bbox": [
                13.305538177490234,
                0.5101507902145386,
                329.5360412597656,
                354.0723876953125
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9906,
            9910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9911,
            9915
          ],
          "representative_frame": 9911,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7891209125518799,
              "bbox": [
                33.39287567138672,
                0.8427767157554626,
                356.7227478027344,
                351.48626708984375
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            9916,
            9920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9921,
            9925
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            9926,
            9930
          ],
          "representative_frame": 9926,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 82
    },
    {
      "second": 331,
      "time_range": [
        331,
        331.999
      ],
      "frame_range": [
        9931,
        9960
      ],
      "unified_description": "1-second scene featuring a man kneeling down on a rock in the woods",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:28",
        "processing_time": 2.5,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9945,
          "frame_range": [
            9941,
            9945
          ],
          "description": "a man kneeling down on a rock in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.16
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9931,
            9935
          ],
          "representative_frame": 9931,
          "detections": [
            {
              "track_id": 814,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.948988139629364,
              "bbox": [
                240.44561767578125,
                108.19168853759766,
                499.6185302734375,
                356.86895751953125
              ]
            },
            {
              "track_id": 815,
              "class_id": 33,
              "class_name": "kite",
              "confidence": 0.48094046115875244,
              "bbox": [
                187.80455017089844,
                243.37547302246094,
                307.05780029296875,
                347.0812072753906
              ]
            }
          ],
          "unique_tracks": [
            814,
            815
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            9936,
            9940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9941,
            9945
          ],
          "representative_frame": 9941,
          "detections": [
            {
              "track_id": 814,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.950661301612854,
              "bbox": [
                240.50022888183594,
                108.72848510742188,
                499.28375244140625,
                357.0272216796875
              ]
            },
            {
              "track_id": 815,
              "class_id": 33,
              "class_name": "kite",
              "confidence": 0.5100222826004028,
              "bbox": [
                188.56112670898438,
                243.78782653808594,
                306.1926574707031,
                346.0495910644531
              ]
            }
          ],
          "unique_tracks": [
            814,
            815
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            9946,
            9950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9951,
            9955
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 814,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.947170615196228,
              "bbox": [
                240.14456176757812,
                108.97135925292969,
                498.5577697753906,
                356.9015197753906
              ]
            },
            {
              "track_id": 815,
              "class_id": 33,
              "class_name": "kite",
              "confidence": 0.35073819756507874,
              "bbox": [
                187.337890625,
                244.56314086914062,
                305.9363098144531,
                347.58111572265625
              ]
            }
          ],
          "unique_tracks": [
            814,
            815
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            9956,
            9960
          ],
          "representative_frame": 9956,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 82
    },
    {
      "second": 332,
      "time_range": [
        332,
        332.999
      ],
      "frame_range": [
        9961,
        9990
      ],
      "unified_description": "3rd person perspective, camera is mounted on a backpack, showing a man sitting on the ground with a fish.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:31",
        "processing_time": 2.51,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 9975,
          "frame_range": [
            9971,
            9975
          ],
          "description": "a man sitting on the ground with a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.8
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9961,
            9965
          ],
          "representative_frame": 9961,
          "detections": [
            {
              "track_id": 814,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9189203381538391,
              "bbox": [
                234.6885986328125,
                43.094242095947266,
                556.5440673828125,
                356.1739807128906
              ]
            },
            {
              "track_id": 815,
              "class_id": 73,
              "class_name": "book",
              "confidence": 0.21503199636936188,
              "bbox": [
                188.53457641601562,
                245.29307556152344,
                307.0912780761719,
                348.0575866699219
              ]
            }
          ],
          "unique_tracks": [
            814,
            815
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            9966,
            9970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            9971,
            9975
          ],
          "representative_frame": 9971,
          "detections": [
            {
              "track_id": 814,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.913878858089447,
              "bbox": [
                234.8766326904297,
                21.150651931762695,
                573.5961303710938,
                356.1138610839844
              ]
            },
            {
              "track_id": 815,
              "class_id": 73,
              "class_name": "book",
              "confidence": 0.18640755116939545,
              "bbox": [
                188.92588806152344,
                245.42922973632812,
                307.6141357421875,
                348.0378112792969
              ]
            }
          ],
          "unique_tracks": [
            814,
            815
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            9976,
            9980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            9981,
            9985
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 814,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.897997260093689,
              "bbox": [
                237.27220153808594,
                13.249980926513672,
                577.4102172851562,
                355.9449157714844
              ]
            },
            {
              "track_id": 815,
              "class_id": 33,
              "class_name": "kite",
              "confidence": 0.3775879442691803,
              "bbox": [
                188.7347869873047,
                245.34420776367188,
                307.27777099609375,
                347.4222106933594
              ]
            }
          ],
          "unique_tracks": [
            814,
            815
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            9986,
            9990
          ],
          "representative_frame": 9986,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 83
    },
    {
      "second": 333,
      "time_range": [
        333,
        333.999
      ],
      "frame_range": [
        9991,
        10020
      ],
      "unified_description": "1-second scene that has a boy fishing by the water, with multiple objects and people visible",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:31",
        "processing_time": 3.01,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10005,
          "frame_range": [
            10001,
            10005
          ],
          "description": "a boy fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.76
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            9991,
            9995
          ],
          "representative_frame": 9991,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9016424417495728,
              "bbox": [
                208.02874755859375,
                100.6519775390625,
                426.7903137207031,
                354.90020751953125
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            9996,
            10000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10001,
            10005
          ],
          "representative_frame": 10001,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9145239591598511,
              "bbox": [
                224.30381774902344,
                95.5080337524414,
                430.8780517578125,
                352.10687255859375
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10006,
            10010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10011,
            10015
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9213866591453552,
              "bbox": [
                232.284423828125,
                102.35873413085938,
                423.7980651855469,
                355.8971252441406
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10016,
            10020
          ],
          "representative_frame": 10016,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 83
    },
    {
      "second": 334,
      "time_range": [
        334,
        334.999
      ],
      "frame_range": [
        10021,
        10050
      ],
      "unified_description": "1-second scene with a boy fishing on the water in a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:32",
        "processing_time": 3.04,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10035,
          "frame_range": [
            10031,
            10035
          ],
          "description": "a boy fishing on the water in a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.07
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10021,
            10025
          ],
          "representative_frame": 10021,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8632994294166565,
              "bbox": [
                220.0258331298828,
                92.4582748413086,
                408.63525390625,
                354.1048278808594
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10026,
            10030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10031,
            10035
          ],
          "representative_frame": 10031,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            10036,
            10040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10041,
            10045
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9011377096176147,
              "bbox": [
                422.2344665527344,
                170.9937286376953,
                528.6854248046875,
                358.20745849609375
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10046,
            10050
          ],
          "representative_frame": 10046,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 83
    },
    {
      "second": 335,
      "time_range": [
        335,
        335.999
      ],
      "frame_range": [
        10051,
        10080
      ],
      "unified_description": "\nThese are descriptions of what is happening in the scene (content) and details about the camera and production style (technics).",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:35",
        "processing_time": 2.56,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10065,
          "frame_range": [
            10061,
            10065
          ],
          "description": "a boy is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.61
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10051,
            10055
          ],
          "representative_frame": 10051,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8642680048942566,
              "bbox": [
                425.24029541015625,
                170.53671264648438,
                532.3109741210938,
                358.6500549316406
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10056,
            10060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10061,
            10065
          ],
          "representative_frame": 10061,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8969552516937256,
              "bbox": [
                427.17919921875,
                175.398681640625,
                531.68701171875,
                358.6687316894531
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10066,
            10070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10071,
            10075
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9155656099319458,
              "bbox": [
                429.6044616699219,
                177.05111694335938,
                533.8123168945312,
                358.92572021484375
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10076,
            10080
          ],
          "representative_frame": 10076,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 83
    },
    {
      "second": 336,
      "time_range": [
        336,
        336.999
      ],
      "frame_range": [
        10081,
        10110
      ],
      "unified_description": "1-second scene with a boy standing in the dirt outside. A camera is mounted on the boy's head, capturing the view from his perspective. The image shows the surroundings from his point of view.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:36",
        "processing_time": 3.09,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10095,
          "frame_range": [
            10091,
            10095
          ],
          "description": "a little boy is standing in the dirt",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.68
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10081,
            10085
          ],
          "representative_frame": 10081,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            10086,
            10090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10091,
            10095
          ],
          "representative_frame": 10091,
          "detections": [
            {
              "track_id": 815,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9498509764671326,
              "bbox": [
                70.45474243164062,
                66.5841293334961,
                381.8237609863281,
                357.52447509765625
              ]
            }
          ],
          "unique_tracks": [
            815
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10096,
            10100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10101,
            10105
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 815,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9471032619476318,
              "bbox": [
                78.51282501220703,
                62.642032623291016,
                373.2755126953125,
                358.05126953125
              ]
            }
          ],
          "unique_tracks": [
            815
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10106,
            10110
          ],
          "representative_frame": 10106,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 84
    },
    {
      "second": 337,
      "time_range": [
        337,
        337.999
      ],
      "frame_range": [
        10111,
        10140
      ],
      "unified_description": "3D WORKspace - STILL IMAGE",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:36",
        "processing_time": 3.08,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10125,
          "frame_range": [
            10121,
            10125
          ],
          "description": "a man standing on a rocky beach next to a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.58
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10111,
            10115
          ],
          "representative_frame": 10111,
          "detections": [
            {
              "track_id": 815,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9374508261680603,
              "bbox": [
                78.74517822265625,
                53.510501861572266,
                363.2767639160156,
                357.7864990234375
              ]
            }
          ],
          "unique_tracks": [
            815
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10116,
            10120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10121,
            10125
          ],
          "representative_frame": 10121,
          "detections": [
            {
              "track_id": 815,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9312106370925903,
              "bbox": [
                83.4278335571289,
                42.55517578125,
                357.9595031738281,
                357.74932861328125
              ]
            },
            {
              "track_id": 822,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.43018218874931335,
              "bbox": [
                387.50726318359375,
                71.1824951171875,
                576.947998046875,
                181.25930786132812
              ]
            }
          ],
          "unique_tracks": [
            815,
            822
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            10126,
            10130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10131,
            10135
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 815,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9265826940536499,
              "bbox": [
                77.55237579345703,
                37.12106704711914,
                338.82830810546875,
                357.9415588378906
              ]
            }
          ],
          "unique_tracks": [
            815
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10136,
            10140
          ],
          "representative_frame": 10136,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 84
    },
    {
      "second": 338,
      "time_range": [
        338,
        338.999
      ],
      "frame_range": [
        10141,
        10170
      ],
      "unified_description": "10-second scene featuring a person walking through the woods carrying camping supplies.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:38",
        "processing_time": 2.41,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10155,
          "frame_range": [
            10151,
            10155
          ],
          "description": "a man standing in the woods with a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.91
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10141,
            10145
          ],
          "representative_frame": 10141,
          "detections": [
            {
              "track_id": 815,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8963860869407654,
              "bbox": [
                60.07343292236328,
                42.039154052734375,
                303.16754150390625,
                357.4679260253906
              ]
            },
            {
              "track_id": 822,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.42361265420913696,
              "bbox": [
                368.8934020996094,
                80.60454559326172,
                541.8894653320312,
                180.6854705810547
              ]
            }
          ],
          "unique_tracks": [
            815,
            822
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            10146,
            10150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10151,
            10155
          ],
          "representative_frame": 10151,
          "detections": [
            {
              "track_id": 815,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9281108975410461,
              "bbox": [
                19.173437118530273,
                48.624427795410156,
                245.54739379882812,
                356.4713134765625
              ]
            }
          ],
          "unique_tracks": [
            815
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10156,
            10160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10161,
            10165
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 815,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9430176615715027,
              "bbox": [
                0.0,
                56.22633743286133,
                182.7802276611328,
                356.6814270019531
              ]
            }
          ],
          "unique_tracks": [
            815
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10166,
            10170
          ],
          "representative_frame": 10166,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 84
    },
    {
      "second": 339,
      "time_range": [
        339,
        339.999
      ],
      "frame_range": [
        10171,
        10200
      ],
      "unified_description": "1-second scene including a man, a tent, and woods",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:41",
        "processing_time": 2.67,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10185,
          "frame_range": [
            10181,
            10185
          ],
          "description": "a man is standing near a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.88
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10171,
            10175
          ],
          "representative_frame": 10171,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            10176,
            10180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10181,
            10185
          ],
          "representative_frame": 10181,
          "detections": [
            {
              "track_id": 822,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9128050208091736,
              "bbox": [
                308.9993591308594,
                44.774017333984375,
                551.0784301757812,
                192.0984344482422
              ]
            }
          ],
          "unique_tracks": [
            822
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10186,
            10190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10191,
            10195
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            10196,
            10200
          ],
          "representative_frame": 10196,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 84
    },
    {
      "second": 340,
      "time_range": [
        340,
        340.999
      ],
      "frame_range": [
        10201,
        10230
      ],
      "unified_description": "5-second summary descriptions for each second of the video.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:40",
        "processing_time": 2.31,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10215,
          "frame_range": [
            10211,
            10215
          ],
          "description": "a man is fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.51
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10201,
            10205
          ],
          "representative_frame": 10201,
          "detections": [
            {
              "track_id": 815,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9000510573387146,
              "bbox": [
                18.463926315307617,
                45.2963752746582,
                149.41134643554688,
                241.53765869140625
              ]
            }
          ],
          "unique_tracks": [
            815
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10206,
            10210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10211,
            10215
          ],
          "representative_frame": 10211,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            10216,
            10220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10221,
            10225
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9399964213371277,
              "bbox": [
                441.2782897949219,
                1.638953447341919,
                640.0,
                355.6146545410156
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10226,
            10230
          ],
          "representative_frame": 10226,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 85
    },
    {
      "second": 341,
      "time_range": [
        341,
        341.999
      ],
      "frame_range": [
        10231,
        10260
      ],
      "unified_description": "4k video with a lot of motion, mainly outdoors with some indoor scenes",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:41",
        "processing_time": 2.51,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10245,
          "frame_range": [
            10241,
            10245
          ],
          "description": "a man in a black jacket is standing on a boat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10231,
            10235
          ],
          "representative_frame": 10231,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9565227627754211,
              "bbox": [
                420.6387939453125,
                0.0,
                632.6250610351562,
                354.8730773925781
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10236,
            10240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10241,
            10245
          ],
          "representative_frame": 10241,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9396315813064575,
              "bbox": [
                396.9001159667969,
                7.343101978302002,
                615.8311157226562,
                355.2651062011719
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10246,
            10250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10251,
            10255
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9554216861724854,
              "bbox": [
                363.9478454589844,
                6.606009483337402,
                599.7899169921875,
                355.6903381347656
              ]
            },
            {
              "track_id": 833,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3248142898082733,
              "bbox": [
                501.3584289550781,
                175.2831573486328,
                636.2047729492188,
                355.8637390136719
              ]
            }
          ],
          "unique_tracks": [
            817,
            833
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            10256,
            10260
          ],
          "representative_frame": 10256,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 85
    },
    {
      "second": 342,
      "time_range": [
        342,
        342.999
      ],
      "frame_range": [
        10261,
        10290
      ],
      "unified_description": "10-second video with various objects and people captured in the frame.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:44",
        "processing_time": 2.37,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10275,
          "frame_range": [
            10271,
            10275
          ],
          "description": "a man is standing on the edge of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10261,
            10265
          ],
          "representative_frame": 10261,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9429519176483154,
              "bbox": [
                358.85699462890625,
                10.076972007751465,
                603.17822265625,
                356.0630187988281
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10266,
            10270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10271,
            10275
          ],
          "representative_frame": 10271,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            10276,
            10280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10281,
            10285
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 834,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9068393707275391,
              "bbox": [
                277.4444580078125,
                88.54399108886719,
                334.565185546875,
                236.8244171142578
              ]
            },
            {
              "track_id": 835,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.5238478183746338,
              "bbox": [
                193.50103759765625,
                233.8345184326172,
                215.62216186523438,
                246.70994567871094
              ]
            }
          ],
          "unique_tracks": [
            834,
            835
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            10286,
            10290
          ],
          "representative_frame": 10286,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 85
    },
    {
      "second": 343,
      "time_range": [
        343,
        343.999
      ],
      "frame_range": [
        10291,
        10320
      ],
      "unified_description": "1-second scene showing a man fishing next to a lake. The image was taken using a wide-angle lens, which captures the surrounding area, including some people in the background. There is also a backpack nearby, possibly belonging to one of the people in the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:46",
        "processing_time": 3.43,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10305,
          "frame_range": [
            10301,
            10305
          ],
          "description": "a man is fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.72
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10291,
            10295
          ],
          "representative_frame": 10291,
          "detections": [
            {
              "track_id": 834,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.915040910243988,
              "bbox": [
                284.328857421875,
                90.90679168701172,
                341.93121337890625,
                237.90284729003906
              ]
            },
            {
              "track_id": 835,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.4681794047355652,
              "bbox": [
                193.48020935058594,
                233.85191345214844,
                215.6639862060547,
                246.7660675048828
              ]
            }
          ],
          "unique_tracks": [
            834,
            835
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            10296,
            10300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10301,
            10305
          ],
          "representative_frame": 10301,
          "detections": [
            {
              "track_id": 834,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9187362790107727,
              "bbox": [
                283.9369812011719,
                91.51802825927734,
                343.35064697265625,
                239.38192749023438
              ]
            },
            {
              "track_id": 835,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.48441439867019653,
              "bbox": [
                193.4912872314453,
                233.84811401367188,
                215.66392517089844,
                246.75888061523438
              ]
            }
          ],
          "unique_tracks": [
            834,
            835
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            10306,
            10310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10311,
            10315
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 834,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.92693030834198,
              "bbox": [
                281.6007080078125,
                92.4090805053711,
                342.8202209472656,
                240.19241333007812
              ]
            },
            {
              "track_id": 835,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.5804177522659302,
              "bbox": [
                193.51318359375,
                233.8507080078125,
                215.6470489501953,
                246.7409210205078
              ]
            }
          ],
          "unique_tracks": [
            834,
            835
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            10316,
            10320
          ],
          "representative_frame": 10316,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 85
    },
    {
      "second": 344,
      "time_range": [
        344,
        344.999
      ],
      "frame_range": [
        10321,
        10350
      ],
      "unified_description": "\n1st person POV camera perspective: Handheld camera.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:46",
        "processing_time": 3.48,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10335,
          "frame_range": [
            10331,
            10335
          ],
          "description": "a man fishing on a lake with a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.17
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10321,
            10325
          ],
          "representative_frame": 10321,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            10326,
            10330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10331,
            10335
          ],
          "representative_frame": 10331,
          "detections": [
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9025573134422302,
              "bbox": [
                181.89695739746094,
                43.86826705932617,
                268.5207824707031,
                288.37591552734375
              ]
            }
          ],
          "unique_tracks": [
            836
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10336,
            10340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10341,
            10345
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9268380999565125,
              "bbox": [
                184.4002685546875,
                47.56373596191406,
                270.0660095214844,
                289.0665283203125
              ]
            },
            {
              "track_id": 838,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.36284175515174866,
              "bbox": [
                221.4869842529297,
                294.0620422363281,
                239.16624450683594,
                311.239501953125
              ]
            }
          ],
          "unique_tracks": [
            836,
            838
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            10346,
            10350
          ],
          "representative_frame": 10346,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 86
    },
    {
      "second": 345,
      "time_range": [
        345,
        345.999
      ],
      "frame_range": [
        10351,
        10380
      ],
      "unified_description": "\nThere is a man standing by the edge of the lake in the image. The camera is positioned on a tripod which is stable and provides a clear view of the subject. The lighting in the scene is natural outdoor lighting, giving a well-lit and balanced exposure.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:49",
        "processing_time": 3.19,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10365,
          "frame_range": [
            10361,
            10365
          ],
          "description": "a man in a black jacket is standing near the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.2
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10351,
            10355
          ],
          "representative_frame": 10351,
          "detections": [
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.890906035900116,
              "bbox": [
                179.91552734375,
                59.29904556274414,
                261.299560546875,
                288.6788330078125
              ]
            },
            {
              "track_id": 838,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4018494188785553,
              "bbox": [
                221.49700927734375,
                294.1046142578125,
                239.07647705078125,
                311.1856384277344
              ]
            }
          ],
          "unique_tracks": [
            836,
            838
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            10356,
            10360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10361,
            10365
          ],
          "representative_frame": 10361,
          "detections": [
            {
              "track_id": 822,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.7242534160614014,
              "bbox": [
                166.74349975585938,
                2.523876190185547,
                430.5172119140625,
                173.62110900878906
              ]
            },
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8046416640281677,
              "bbox": [
                246.6814422607422,
                51.134883880615234,
                483.2901916503906,
                353.7540588378906
              ]
            }
          ],
          "unique_tracks": [
            822,
            817
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            10366,
            10370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10371,
            10375
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8395776152610779,
              "bbox": [
                246.89859008789062,
                14.677348136901855,
                522.8916015625,
                354.6274719238281
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10376,
            10380
          ],
          "representative_frame": 10376,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 86
    },
    {
      "second": 346,
      "time_range": [
        346,
        346.999
      ],
      "frame_range": [
        10381,
        10410
      ],
      "unified_description": "1-second scene featuring a man in a raincoat standing on a rock, shot with a GoPro camera, showing wide-angle distortion",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:50",
        "processing_time": 2.65,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10395,
          "frame_range": [
            10391,
            10395
          ],
          "description": "a man in a raincoat is standing on a rock",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.54
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10381,
            10385
          ],
          "representative_frame": 10381,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9256631731987,
              "bbox": [
                275.9375,
                4.943135738372803,
                569.3004150390625,
                354.46771240234375
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10386,
            10390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10391,
            10395
          ],
          "representative_frame": 10391,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8680192232131958,
              "bbox": [
                280.3629455566406,
                0.9435863494873047,
                589.5155029296875,
                353.76275634765625
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10396,
            10400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10401,
            10405
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7859993577003479,
              "bbox": [
                282.54498291015625,
                0.2875780761241913,
                601.6345825195312,
                353.55279541015625
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10406,
            10410
          ],
          "representative_frame": 10406,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 86
    },
    {
      "second": 347,
      "time_range": [
        347,
        347.999
      ],
      "frame_range": [
        10411,
        10440
      ],
      "unified_description": "1 second of video, showcasing a man in a raincoat standing in front of some trees",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:51",
        "processing_time": 2.78,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10425,
          "frame_range": [
            10421,
            10425
          ],
          "description": "a man in a raincoat is standing on a rock",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.57
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10411,
            10415
          ],
          "representative_frame": 10411,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8420531749725342,
              "bbox": [
                298.0516662597656,
                0.0,
                619.94482421875,
                354.11944580078125
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10416,
            10420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10421,
            10425
          ],
          "representative_frame": 10421,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4947797656059265,
              "bbox": [
                250.3609619140625,
                3.477297782897949,
                560.2547607421875,
                353.00738525390625
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10426,
            10430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10431,
            10435
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            10436,
            10440
          ],
          "representative_frame": 10436,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 86
    },
    {
      "second": 348,
      "time_range": [
        348,
        348.999
      ],
      "frame_range": [
        10441,
        10470
      ],
      "unified_description": "1-second scene featuring a man in a raincoat walking through the woods",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:52",
        "processing_time": 2.49,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10455,
          "frame_range": [
            10451,
            10455
          ],
          "description": "a man in a raincoat is walking through the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.84
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10441,
            10445
          ],
          "representative_frame": 10441,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7105184197425842,
              "bbox": [
                202.36349487304688,
                57.54354476928711,
                462.2771911621094,
                353.9489440917969
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10446,
            10450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10451,
            10455
          ],
          "representative_frame": 10451,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.49393123388290405,
              "bbox": [
                135.3534698486328,
                25.4129581451416,
                421.1819152832031,
                353.83184814453125
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10456,
            10460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10461,
            10465
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            10466,
            10470
          ],
          "representative_frame": 10466,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 87
    },
    {
      "second": 349,
      "time_range": [
        349,
        349.999
      ],
      "frame_range": [
        10471,
        10500
      ],
      "unified_description": "30 seconds of action-packed footage of a person riding on top of a vehicle in wet conditions",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:54",
        "processing_time": 2.44,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10485,
          "frame_range": [
            10481,
            10485
          ],
          "description": "a man is standing in the rain",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.11
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10471,
            10475
          ],
          "representative_frame": 10471,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            10476,
            10480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10481,
            10485
          ],
          "representative_frame": 10481,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6420929431915283,
              "bbox": [
                79.99671936035156,
                5.300407886505127,
                394.42083740234375,
                352.5409851074219
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10486,
            10490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10491,
            10495
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8442816734313965,
              "bbox": [
                194.82350158691406,
                1.5547428131103516,
                526.0132446289062,
                354.4986877441406
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10496,
            10500
          ],
          "representative_frame": 10496,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 87
    },
    {
      "second": 350,
      "time_range": [
        350,
        350.999
      ],
      "frame_range": [
        10501,
        10530
      ],
      "unified_description": "3rd person perspective, camera is mounted on a backpack, wide-angle lens with some distortion, action camera style, focus on main subject, shaky camera, indoor setting.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:55",
        "processing_time": 2.87,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10515,
          "frame_range": [
            10511,
            10515
          ],
          "description": "a man is standing in the middle of a pile of trash",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.39
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10501,
            10505
          ],
          "representative_frame": 10501,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7706275582313538,
              "bbox": [
                256.97320556640625,
                0.01320778951048851,
                584.0928344726562,
                342.63482666015625
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10506,
            10510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10511,
            10515
          ],
          "representative_frame": 10511,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6163833737373352,
              "bbox": [
                263.0719299316406,
                0.10606859624385834,
                598.2501831054688,
                342.8818664550781
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10516,
            10520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10521,
            10525
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.36924421787261963,
              "bbox": [
                234.1182861328125,
                0.04770800471305847,
                567.321533203125,
                344.58740234375
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10526,
            10530
          ],
          "representative_frame": 10526,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 87
    },
    {
      "second": 351,
      "time_range": [
        351,
        351.999
      ],
      "frame_range": [
        10531,
        10560
      ],
      "unified_description": "\n\nIn this scene, there is an action camera mounted on a person's head, capturing the surrounding environment. The camera is pointing forward, showing a group of people standing in a tent-like area. There are several people visible in the frame, with one person more prominently featured than others. The rest of the individuals appear as if they are gathered around a shared central point.\n\nThe image shows an outdoor setting with natural lighting, and no visible signs of wide-angle distortion or fisheye effect. There is some motion blur in the scene, possibly indicating that the subjects are moving or the camera is panning. Overall, this video captures a social gathering or event taking place in an outdoor environment.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:20:58",
        "processing_time": 5.57,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10545,
          "frame_range": [
            10541,
            10545
          ],
          "description": "a group of people in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.57
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10531,
            10535
          ],
          "representative_frame": 10531,
          "detections": [
            {
              "track_id": 817,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.1001654714345932,
              "bbox": [
                163.88063049316406,
                0.0,
                533.167236328125,
                349.6884765625
              ]
            },
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9351122975349426,
              "bbox": [
                173.69964599609375,
                157.1408233642578,
                268.2284851074219,
                356.0511779785156
              ]
            }
          ],
          "unique_tracks": [
            817,
            836
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            10536,
            10540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10541,
            10545
          ],
          "representative_frame": 10541,
          "detections": [
            {
              "track_id": 855,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.33833667635917664,
              "bbox": [
                2.4813950061798096,
                204.1885986328125,
                104.84546661376953,
                344.3193664550781
              ]
            },
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9250832796096802,
              "bbox": [
                159.83758544921875,
                157.51727294921875,
                271.0345153808594,
                357.24560546875
              ]
            }
          ],
          "unique_tracks": [
            855,
            836
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            10546,
            10550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10551,
            10555
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 855,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5602743029594421,
              "bbox": [
                1.3169865608215332,
                206.0069122314453,
                102.73648834228516,
                344.79058837890625
              ]
            },
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9163305759429932,
              "bbox": [
                149.22943115234375,
                159.71971130371094,
                271.81695556640625,
                357.7545471191406
              ]
            }
          ],
          "unique_tracks": [
            855,
            836
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            10556,
            10560
          ],
          "representative_frame": 10556,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 87
    },
    {
      "second": 352,
      "time_range": [
        352,
        352.999
      ],
      "frame_range": [
        10561,
        10590
      ],
      "unified_description": "\nIn this outdoor scene, several people are gathered in a shaded tent-like area. The camera is held in a stabilized position capturing the group of people, possibly for an event or social gathering. The video might have been taken during daylight hours, as there seems to be sufficient light in the setting.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:00",
        "processing_time": 5.27,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10575,
          "frame_range": [
            10571,
            10575
          ],
          "description": "a group of people in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.84
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10561,
            10565
          ],
          "representative_frame": 10561,
          "detections": [
            {
              "track_id": 855,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5338728427886963,
              "bbox": [
                1.0779560804367065,
                207.65225219726562,
                103.69078826904297,
                347.99578857421875
              ]
            },
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9310922622680664,
              "bbox": [
                139.86740112304688,
                160.89511108398438,
                272.2156982421875,
                358.265625
              ]
            }
          ],
          "unique_tracks": [
            855,
            836
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            10566,
            10570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10571,
            10575
          ],
          "representative_frame": 10571,
          "detections": [
            {
              "track_id": 855,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.22768239676952362,
              "bbox": [
                0.0,
                208.8014678955078,
                101.46165466308594,
                350.9768371582031
              ]
            },
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9357001781463623,
              "bbox": [
                131.83917236328125,
                161.52029418945312,
                272.1337585449219,
                358.1800231933594
              ]
            }
          ],
          "unique_tracks": [
            855,
            836
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            10576,
            10580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10581,
            10585
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 855,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4417581260204315,
              "bbox": [
                0.0,
                209.0242919921875,
                95.59671783447266,
                350.8310852050781
              ]
            },
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9279784560203552,
              "bbox": [
                124.35767364501953,
                160.2487030029297,
                272.531005859375,
                358.2593078613281
              ]
            },
            {
              "track_id": 862,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3588113784790039,
              "bbox": [
                244.27308654785156,
                125.88887023925781,
                333.9595031738281,
                351.13739013671875
              ]
            }
          ],
          "unique_tracks": [
            855,
            836,
            862
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            10586,
            10590
          ],
          "representative_frame": 10586,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 88
    },
    {
      "second": 353,
      "time_range": [
        353,
        353.999
      ],
      "frame_range": [
        10591,
        10620
      ],
      "unified_description": "100 words maximum",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:00",
        "processing_time": 3.91,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10605,
          "frame_range": [
            10601,
            10605
          ],
          "description": "a group of people standing in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.14
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10591,
            10595
          ],
          "representative_frame": 10591,
          "detections": [
            {
              "track_id": 855,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5204756259918213,
              "bbox": [
                0.0,
                211.39404296875,
                96.76161193847656,
                352.8981628417969
              ]
            },
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9215099215507507,
              "bbox": [
                117.94779205322266,
                165.77914428710938,
                269.0635681152344,
                357.8468933105469
              ]
            },
            {
              "track_id": 862,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.24054840207099915,
              "bbox": [
                247.02940368652344,
                128.8256072998047,
                335.4710693359375,
                350.1348876953125
              ]
            }
          ],
          "unique_tracks": [
            855,
            836,
            862
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            10596,
            10600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10601,
            10605
          ],
          "representative_frame": 10601,
          "detections": [
            {
              "track_id": 855,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.21310237050056458,
              "bbox": [
                0.0,
                213.40411376953125,
                94.15837860107422,
                355.3545227050781
              ]
            },
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9189150333404541,
              "bbox": [
                108.93096923828125,
                174.50796508789062,
                261.01727294921875,
                357.76519775390625
              ]
            },
            {
              "track_id": 862,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3981178104877472,
              "bbox": [
                249.00457763671875,
                130.04237365722656,
                336.95697021484375,
                348.2320556640625
              ]
            }
          ],
          "unique_tracks": [
            855,
            836,
            862
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            10606,
            10610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10611,
            10615
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 855,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.12349764257669449,
              "bbox": [
                0.0,
                214.4853057861328,
                87.38094329833984,
                353.0418395996094
              ]
            },
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9302361011505127,
              "bbox": [
                99.52082824707031,
                181.7496337890625,
                253.69058227539062,
                357.8523864746094
              ]
            },
            {
              "track_id": 862,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3154762089252472,
              "bbox": [
                240.04742431640625,
                129.78260803222656,
                323.7792053222656,
                336.8600769042969
              ]
            }
          ],
          "unique_tracks": [
            855,
            836,
            862
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            10616,
            10620
          ],
          "representative_frame": 10616,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 88
    },
    {
      "second": 354,
      "time_range": [
        354,
        354.999
      ],
      "frame_range": [
        10621,
        10650
      ],
      "unified_description": "3-second scene including a man in a tent, 6 groups of objects with their spatial relationships, shot with a GoPro-style action camera capturing the entire scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:02",
        "processing_time": 2.76,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10635,
          "frame_range": [
            10631,
            10635
          ],
          "description": "a man is standing in a tent with a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.11
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10621,
            10625
          ],
          "representative_frame": 10621,
          "detections": [
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9260417222976685,
              "bbox": [
                91.63227844238281,
                184.20663452148438,
                250.60333251953125,
                357.7690734863281
              ]
            },
            {
              "track_id": 862,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.19570499658584595,
              "bbox": [
                229.0233154296875,
                127.3955307006836,
                314.4228820800781,
                339.8438415527344
              ]
            }
          ],
          "unique_tracks": [
            836,
            862
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            10626,
            10630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10631,
            10635
          ],
          "representative_frame": 10631,
          "detections": [
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9331924915313721,
              "bbox": [
                84.4328384399414,
                184.91836547851562,
                248.95523071289062,
                357.8008117675781
              ]
            },
            {
              "track_id": 862,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.30488231778144836,
              "bbox": [
                222.31631469726562,
                124.5015869140625,
                307.9037170410156,
                338.6084289550781
              ]
            }
          ],
          "unique_tracks": [
            836,
            862
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            10636,
            10640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10641,
            10645
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9381869435310364,
              "bbox": [
                77.72425842285156,
                187.32974243164062,
                245.7545928955078,
                357.3864440917969
              ]
            },
            {
              "track_id": 862,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.19898591935634613,
              "bbox": [
                224.9015350341797,
                120.13751983642578,
                303.8362121582031,
                315.46820068359375
              ]
            }
          ],
          "unique_tracks": [
            836,
            862
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            10646,
            10650
          ],
          "representative_frame": 10646,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 88
    },
    {
      "second": 355,
      "time_range": [
        355,
        355.999
      ],
      "frame_range": [
        10651,
        10680
      ],
      "unified_description": "1-second scene that includes a man standing in a tent with a camera",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:04",
        "processing_time": 2.7,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10665,
          "frame_range": [
            10661,
            10665
          ],
          "description": "a man is standing in a tent with a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.73
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10651,
            10655
          ],
          "representative_frame": 10651,
          "detections": [
            {
              "track_id": 836,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9346359372138977,
              "bbox": [
                68.36808013916016,
                185.67884826660156,
                243.1318359375,
                357.0823059082031
              ]
            },
            {
              "track_id": 862,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.42736729979515076,
              "bbox": [
                231.4259796142578,
                114.68464660644531,
                310.5716857910156,
                305.7698059082031
              ]
            }
          ],
          "unique_tracks": [
            836,
            862
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            10656,
            10660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10661,
            10665
          ],
          "representative_frame": 10661,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9269475340843201,
              "bbox": [
                263.2966003417969,
                42.92741775512695,
                590.670654296875,
                355.0836181640625
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10666,
            10670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10671,
            10675
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9304923415184021,
              "bbox": [
                273.1854248046875,
                42.71349334716797,
                600.5013427734375,
                355.38677978515625
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10676,
            10680
          ],
          "representative_frame": 10676,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 88
    },
    {
      "second": 356,
      "time_range": [
        356,
        356.999
      ],
      "frame_range": [
        10681,
        10710
      ],
      "unified_description": "3D WIDE ANGLE VIDEO SHOOTING A MAN IN A TENT",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:04",
        "processing_time": 2.45,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10695,
          "frame_range": [
            10691,
            10695
          ],
          "description": "a man in a tent with a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.27
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10681,
            10685
          ],
          "representative_frame": 10681,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9304717183113098,
              "bbox": [
                277.5536804199219,
                48.12874221801758,
                600.8695678710938,
                355.52978515625
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10686,
            10690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10691,
            10695
          ],
          "representative_frame": 10691,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9332442879676819,
              "bbox": [
                277.6056213378906,
                45.65294647216797,
                604.70068359375,
                355.6749572753906
              ]
            },
            {
              "track_id": 868,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.41290736198425293,
              "bbox": [
                0.5972537398338318,
                293.61212158203125,
                68.95687866210938,
                358.04254150390625
              ]
            }
          ],
          "unique_tracks": [
            817,
            868
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            10696,
            10700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10701,
            10705
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9227346181869507,
              "bbox": [
                279.4176330566406,
                44.88623046875,
                608.1784057617188,
                355.6175842285156
              ]
            },
            {
              "track_id": 868,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.36193788051605225,
              "bbox": [
                1.1209129095077515,
                292.4305725097656,
                70.7151107788086,
                357.9881896972656
              ]
            }
          ],
          "unique_tracks": [
            817,
            868
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            10706,
            10710
          ],
          "representative_frame": 10706,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 89
    },
    {
      "second": 357,
      "time_range": [
        357,
        357.999
      ],
      "frame_range": [
        10711,
        10740
      ],
      "unified_description": "1-second scene of a man in a tent with a camera",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:05",
        "processing_time": 2.41,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10725,
          "frame_range": [
            10721,
            10725
          ],
          "description": "a man in a tent with a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.65
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10711,
            10715
          ],
          "representative_frame": 10711,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9246487617492676,
              "bbox": [
                281.9656066894531,
                43.88136291503906,
                612.2142944335938,
                355.2884826660156
              ]
            },
            {
              "track_id": 868,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.17125655710697174,
              "bbox": [
                0.0,
                287.54278564453125,
                74.24177551269531,
                357.5745849609375
              ]
            }
          ],
          "unique_tracks": [
            817,
            868
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            10716,
            10720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10721,
            10725
          ],
          "representative_frame": 10721,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9201266765594482,
              "bbox": [
                283.51123046875,
                42.771690368652344,
                615.6500854492188,
                355.4169921875
              ]
            },
            {
              "track_id": 868,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.39322948455810547,
              "bbox": [
                0.0,
                285.08984375,
                76.79072570800781,
                357.54736328125
              ]
            }
          ],
          "unique_tracks": [
            817,
            868
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            10726,
            10730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10731,
            10735
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.922065019607544,
              "bbox": [
                286.0067138671875,
                41.64544677734375,
                620.0513916015625,
                355.3944091796875
              ]
            },
            {
              "track_id": 868,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.36183589696884155,
              "bbox": [
                0.0,
                285.03350830078125,
                76.95069122314453,
                357.7825622558594
              ]
            }
          ],
          "unique_tracks": [
            817,
            868
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            10736,
            10740
          ],
          "representative_frame": 10736,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 89
    },
    {
      "second": 358,
      "time_range": [
        358,
        358.999
      ],
      "frame_range": [
        10741,
        10770
      ],
      "unified_description": "3D object detection & extraction from videos",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:08",
        "processing_time": 2.26,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10755,
          "frame_range": [
            10751,
            10755
          ],
          "description": "a man in a black shirt and hat standing under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.06
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10741,
            10745
          ],
          "representative_frame": 10741,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9336591362953186,
              "bbox": [
                286.70794677734375,
                39.17356872558594,
                623.9697875976562,
                355.5189208984375
              ]
            },
            {
              "track_id": 868,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4938949942588806,
              "bbox": [
                0.7955614924430847,
                284.8174743652344,
                78.24883270263672,
                357.78192138671875
              ]
            }
          ],
          "unique_tracks": [
            817,
            868
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            10746,
            10750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10751,
            10755
          ],
          "representative_frame": 10751,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9354597330093384,
              "bbox": [
                286.15234375,
                37.553646087646484,
                625.4711303710938,
                355.6031799316406
              ]
            },
            {
              "track_id": 868,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.49021488428115845,
              "bbox": [
                0.0,
                285.1103515625,
                77.01385498046875,
                357.75030517578125
              ]
            }
          ],
          "unique_tracks": [
            817,
            868
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            10756,
            10760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10761,
            10765
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9222085475921631,
              "bbox": [
                281.6829833984375,
                35.41344451904297,
                623.8397216796875,
                355.62811279296875
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10766,
            10770
          ],
          "representative_frame": 10766,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 89
    },
    {
      "second": 359,
      "time_range": [
        359,
        359.999
      ],
      "frame_range": [
        10771,
        10800
      ],
      "unified_description": "\n\nA camera is mounted on top of a person's head, capturing their point of view as they walk through an outdoor area with tents.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:09",
        "processing_time": 2.97,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10785,
          "frame_range": [
            10781,
            10785
          ],
          "description": "a man in a tent with a bag of food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.76
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10771,
            10775
          ],
          "representative_frame": 10771,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9345420002937317,
              "bbox": [
                280.14111328125,
                32.8558235168457,
                625.1011962890625,
                355.3554992675781
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10776,
            10780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10781,
            10785
          ],
          "representative_frame": 10781,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.934584379196167,
              "bbox": [
                281.19134521484375,
                31.68488121032715,
                627.5025024414062,
                355.33685302734375
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10786,
            10790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10791,
            10795
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9315915107727051,
              "bbox": [
                281.826416015625,
                30.97281265258789,
                629.0745849609375,
                355.5249938964844
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10796,
            10800
          ],
          "representative_frame": 10796,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 89
    },
    {
      "second": 360,
      "time_range": [
        360,
        360.999
      ],
      "frame_range": [
        10801,
        10830
      ],
      "unified_description": "4k, 30 fps, POV camera perspective, wide-angle lens, no special effects or distortions detected.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:10",
        "processing_time": 3.49,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10815,
          "frame_range": [
            10811,
            10815
          ],
          "description": "a man in a tent with a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.07
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10801,
            10805
          ],
          "representative_frame": 10801,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9327177405357361,
              "bbox": [
                282.03143310546875,
                30.68460464477539,
                629.118408203125,
                355.1278381347656
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10806,
            10810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10811,
            10815
          ],
          "representative_frame": 10811,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9365087747573853,
              "bbox": [
                282.7828369140625,
                26.471099853515625,
                634.1038818359375,
                355.1347351074219
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10816,
            10820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10821,
            10825
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9252581596374512,
              "bbox": [
                275.07666015625,
                14.34816837310791,
                639.2808227539062,
                355.4681396484375
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10826,
            10830
          ],
          "representative_frame": 10826,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 90
    },
    {
      "second": 361,
      "time_range": [
        361,
        361.999
      ],
      "frame_range": [
        10831,
        10860
      ],
      "unified_description": "\n\nThis is an outdoor scene with several people sitting near one another under a tent. The camera captures the scene from above, providing a clear view of the individuals and their surroundings. The people seem to be socializing or enjoying leisurely moments together in the shaded area provided by the tent.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:12",
        "processing_time": 3.2,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10845,
          "frame_range": [
            10841,
            10845
          ],
          "description": "a group of people sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10831,
            10835
          ],
          "representative_frame": 10831,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9342823028564453,
              "bbox": [
                254.30679321289062,
                4.91990327835083,
                631.3012084960938,
                355.45928955078125
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10836,
            10840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10841,
            10845
          ],
          "representative_frame": 10841,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8130667209625244,
              "bbox": [
                319.17706298828125,
                74.41797637939453,
                626.7042846679688,
                356.4653625488281
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10846,
            10850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10851,
            10855
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5868911147117615,
              "bbox": [
                346.2380065917969,
                103.42669677734375,
                625.8203125,
                356.8194580078125
              ]
            },
            {
              "track_id": 872,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4923340380191803,
              "bbox": [
                47.537837982177734,
                158.80043029785156,
                189.83450317382812,
                356.431396484375
              ]
            }
          ],
          "unique_tracks": [
            817,
            872
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            10856,
            10860
          ],
          "representative_frame": 10856,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 90
    },
    {
      "second": 362,
      "time_range": [
        362,
        362.999
      ],
      "frame_range": [
        10861,
        10890
      ],
      "unified_description": "2 men sitting in a tent eating food",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:12",
        "processing_time": 2.54,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10875,
          "frame_range": [
            10871,
            10875
          ],
          "description": "two men sitting in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.07
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10861,
            10865
          ],
          "representative_frame": 10861,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7443410754203796,
              "bbox": [
                347.96075439453125,
                111.97599792480469,
                622.1883544921875,
                356.74359130859375
              ]
            },
            {
              "track_id": 872,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.176481232047081,
              "bbox": [
                47.23373031616211,
                160.1067352294922,
                188.286376953125,
                356.0606689453125
              ]
            }
          ],
          "unique_tracks": [
            817,
            872
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            10866,
            10870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10871,
            10875
          ],
          "representative_frame": 10871,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5870877504348755,
              "bbox": [
                348.72369384765625,
                115.1875991821289,
                622.5576171875,
                356.3578186035156
              ]
            },
            {
              "track_id": 872,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4237118363380432,
              "bbox": [
                54.9962272644043,
                127.587646484375,
                219.51832580566406,
                355.3819885253906
              ]
            },
            {
              "track_id": 884,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4814698100090027,
              "bbox": [
                231.77468872070312,
                241.1601104736328,
                372.7191467285156,
                354.9862976074219
              ]
            }
          ],
          "unique_tracks": [
            817,
            872,
            884
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            10876,
            10880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10881,
            10885
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.39472317695617676,
              "bbox": [
                359.328369140625,
                118.22856903076172,
                629.0542602539062,
                354.49578857421875
              ]
            },
            {
              "track_id": 872,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2384689748287201,
              "bbox": [
                47.693450927734375,
                122.7411117553711,
                214.88760375976562,
                354.71185302734375
              ]
            },
            {
              "track_id": 884,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4593960642814636,
              "bbox": [
                242.64878845214844,
                238.7349090576172,
                383.03656005859375,
                352.31982421875
              ]
            },
            {
              "track_id": 885,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5151339769363403,
              "bbox": [
                237.97825622558594,
                91.6382064819336,
                381.6705322265625,
                263.7397155761719
              ]
            },
            {
              "track_id": 886,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.6737673282623291,
              "bbox": [
                605.6511840820312,
                228.28573608398438,
                623.8478393554688,
                256.8450622558594
              ]
            },
            {
              "track_id": 887,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.43421468138694763,
              "bbox": [
                424.73486328125,
                116.20436096191406,
                640.0,
                324.1770324707031
              ]
            }
          ],
          "unique_tracks": [
            817,
            872,
            884,
            885,
            886,
            887
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            10886,
            10890
          ],
          "representative_frame": 10886,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 90
    },
    {
      "second": 363,
      "time_range": [
        363,
        363.999
      ],
      "frame_range": [
        10891,
        10920
      ],
      "unified_description": "1-second scene, with a man sitting in a tent, possibly at night, as evidenced by the presence of a backpack, a chair, and a cell phone. The camera's perspective is likely first-person, capturing the man's point of view while he rests in his tent.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:14",
        "processing_time": 3.93,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10905,
          "frame_range": [
            10901,
            10905
          ],
          "description": "a man sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.61
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10891,
            10895
          ],
          "representative_frame": 10891,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8203684687614441,
              "bbox": [
                298.5093078613281,
                40.11156463623047,
                640.0,
                354.22161865234375
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10896,
            10900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10901,
            10905
          ],
          "representative_frame": 10901,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7561189532279968,
              "bbox": [
                280.6305236816406,
                14.75195026397705,
                640.0,
                354.1431579589844
              ]
            },
            {
              "track_id": 889,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4626859426498413,
              "bbox": [
                153.9325408935547,
                125.24043273925781,
                395.85028076171875,
                336.0676574707031
              ]
            },
            {
              "track_id": 890,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.49756383895874023,
              "bbox": [
                2.0364363193511963,
                141.23065185546875,
                94.99292755126953,
                355.3338623046875
              ]
            }
          ],
          "unique_tracks": [
            817,
            889,
            890
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            10906,
            10910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10911,
            10915
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7751170992851257,
              "bbox": [
                273.6995544433594,
                5.064767360687256,
                640.0,
                353.84930419921875
              ]
            },
            {
              "track_id": 889,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6280165314674377,
              "bbox": [
                155.1956329345703,
                125.18104553222656,
                396.52764892578125,
                335.46624755859375
              ]
            },
            {
              "track_id": 890,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.40109983086586,
              "bbox": [
                0.0,
                127.49309539794922,
                97.73275756835938,
                355.0110168457031
              ]
            }
          ],
          "unique_tracks": [
            817,
            889,
            890
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            10916,
            10920
          ],
          "representative_frame": 10916,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 90
    },
    {
      "second": 364,
      "time_range": [
        364,
        364.999
      ],
      "frame_range": [
        10921,
        10950
      ],
      "unified_description": "1-second scene with a man in a tent with a baby. Shot with action camera, wide-angle distortion, fisheye effect, low light conditions, etc.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:16",
        "processing_time": 2.76,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10935,
          "frame_range": [
            10931,
            10935
          ],
          "description": "a man in a tent with a baby",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.41
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10921,
            10925
          ],
          "representative_frame": 10921,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6751854419708252,
              "bbox": [
                287.0757141113281,
                0.0,
                640.0,
                353.4822998046875
              ]
            },
            {
              "track_id": 889,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.41316694021224976,
              "bbox": [
                131.0862274169922,
                124.59003448486328,
                366.7677001953125,
                331.6477966308594
              ]
            },
            {
              "track_id": 890,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.30146175622940063,
              "bbox": [
                0.0,
                123.55070495605469,
                97.5102310180664,
                354.50335693359375
              ]
            }
          ],
          "unique_tracks": [
            817,
            889,
            890
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            10926,
            10930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10931,
            10935
          ],
          "representative_frame": 10931,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8452068567276001,
              "bbox": [
                289.27056884765625,
                0.0,
                640.0,
                353.8319091796875
              ]
            },
            {
              "track_id": 889,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.508980393409729,
              "bbox": [
                138.03326416015625,
                124.62064361572266,
                375.4198303222656,
                333.9424743652344
              ]
            },
            {
              "track_id": 890,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.22131773829460144,
              "bbox": [
                0.0,
                122.31874084472656,
                97.53315734863281,
                355.6206359863281
              ]
            }
          ],
          "unique_tracks": [
            817,
            889,
            890
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            10936,
            10940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10941,
            10945
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8758066296577454,
              "bbox": [
                170.96421813964844,
                0.510962188243866,
                558.334228515625,
                354.96331787109375
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10946,
            10950
          ],
          "representative_frame": 10946,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 91
    },
    {
      "second": 365,
      "time_range": [
        365,
        365.999
      ],
      "frame_range": [
        10951,
        10980
      ],
      "unified_description": "3-second scene including a person wearing a black shirt and hat, as well as other objects",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:17",
        "processing_time": 2.6,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10965,
          "frame_range": [
            10961,
            10965
          ],
          "description": "a man in a black shirt and hat is sitting on a chair",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.94
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10951,
            10955
          ],
          "representative_frame": 10951,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7669503092765808,
              "bbox": [
                111.24230194091797,
                3.5926198959350586,
                508.0286865234375,
                355.3357849121094
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10956,
            10960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10961,
            10965
          ],
          "representative_frame": 10961,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3621191084384918,
              "bbox": [
                135.356689453125,
                47.309085845947266,
                504.76470947265625,
                355.19915771484375
              ]
            },
            {
              "track_id": 889,
              "class_id": 12,
              "class_name": "parking meter",
              "confidence": 0.7723560333251953,
              "bbox": [
                119.36782836914062,
                39.537044525146484,
                397.98651123046875,
                290.7414245605469
              ]
            }
          ],
          "unique_tracks": [
            817,
            889
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            10966,
            10970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            10971,
            10975
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5118089318275452,
              "bbox": [
                102.42072296142578,
                75.35630798339844,
                430.6497497558594,
                355.30572509765625
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            10976,
            10980
          ],
          "representative_frame": 10976,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 91
    },
    {
      "second": 366,
      "time_range": [
        366,
        366.999
      ],
      "frame_range": [
        10981,
        11010
      ],
      "unified_description": "1-second scene with a man in a black jacket and hat holding a fish, shot using action camera mounted on backpack. The resulting video exhibits some lens distortion, wide-angle perspective, and minor camera movements.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:18",
        "processing_time": 3.22,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 10995,
          "frame_range": [
            10991,
            10995
          ],
          "description": "a man in a black jacket and hat holding a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            10981,
            10985
          ],
          "representative_frame": 10981,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4853050112724304,
              "bbox": [
                119.33928680419922,
                43.1008415222168,
                501.509033203125,
                354.8948974609375
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            10986,
            10990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            10991,
            10995
          ],
          "representative_frame": 10991,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9336573481559753,
              "bbox": [
                118.9020767211914,
                14.531681060791016,
                529.0586547851562,
                355.051513671875
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            10996,
            11000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11001,
            11005
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9211333990097046,
              "bbox": [
                108.39002227783203,
                3.3506224155426025,
                528.2628173828125,
                355.2920837402344
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            11006,
            11010
          ],
          "representative_frame": 11006,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 91
    },
    {
      "second": 367,
      "time_range": [
        367,
        367.999
      ],
      "frame_range": [
        11011,
        11040
      ],
      "unified_description": "\nThe image depicts a man standing outside in the rain wearing a raincoat. He is under an umbrella to shield himself from the downpour. The scene also captures several other people nearby, with some of them holding umbrellas as well. Overall, this image conveys a typical rainy day scenario featuring multiple individuals.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:21",
        "processing_time": 3.37,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11025,
          "frame_range": [
            11021,
            11025
          ],
          "description": "a man in a raincoat is standing in the rain",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.63
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11011,
            11015
          ],
          "representative_frame": 11011,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.918021023273468,
              "bbox": [
                99.30799102783203,
                0.0,
                519.9581298828125,
                354.33526611328125
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            11016,
            11020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11021,
            11025
          ],
          "representative_frame": 11021,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9197555780410767,
              "bbox": [
                106.81240844726562,
                0.0,
                525.7180786132812,
                353.9190368652344
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            11026,
            11030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11031,
            11035
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9265498518943787,
              "bbox": [
                178.6087188720703,
                0.0,
                589.6483154296875,
                354.900634765625
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            11036,
            11040
          ],
          "representative_frame": 11036,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 91
    },
    {
      "second": 368,
      "time_range": [
        368,
        368.999
      ],
      "frame_range": [
        11041,
        11070
      ],
      "unified_description": "1-second scene showing a man standing on the shore of a lake. The camera's perspective is from the man's point of view, indicating that he may be the one filming the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:22",
        "processing_time": 4.15,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11055,
          "frame_range": [
            11051,
            11055
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.35
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11041,
            11045
          ],
          "representative_frame": 11041,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9433459639549255,
              "bbox": [
                196.50608825683594,
                0.0,
                599.846435546875,
                355.2619934082031
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            11046,
            11050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11051,
            11055
          ],
          "representative_frame": 11051,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9512458443641663,
              "bbox": [
                207.14952087402344,
                0.0,
                604.3739013671875,
                355.16351318359375
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            11056,
            11060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11061,
            11065
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9399713277816772,
              "bbox": [
                230.66845703125,
                0.0,
                623.023681640625,
                355.477783203125
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            11066,
            11070
          ],
          "representative_frame": 11066,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 92
    },
    {
      "second": 369,
      "time_range": [
        369,
        369.999
      ],
      "frame_range": [
        11071,
        11100
      ],
      "unified_description": "1-second scene with a man fishing on the shore of a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:23",
        "processing_time": 3.63,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11085,
          "frame_range": [
            11081,
            11085
          ],
          "description": "a man is fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.82
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11071,
            11075
          ],
          "representative_frame": 11071,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9360645413398743,
              "bbox": [
                257.8963623046875,
                0.0,
                640.0,
                355.40814208984375
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            11076,
            11080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11081,
            11085
          ],
          "representative_frame": 11081,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9556828141212463,
              "bbox": [
                264.6008605957031,
                9.924976348876953,
                635.0354614257812,
                355.2919006347656
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            11086,
            11090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11091,
            11095
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9555571675300598,
              "bbox": [
                268.9734802246094,
                13.36418628692627,
                631.85009765625,
                355.3532409667969
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7711185812950134,
              "bbox": [
                0.21293522417545319,
                136.4424285888672,
                75.24373626708984,
                185.8362579345703
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.34698671102523804,
              "bbox": [
                279.5059509277344,
                335.0912170410156,
                315.91021728515625,
                359.7252197265625
              ]
            },
            {
              "track_id": 897,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3103838264942169,
              "bbox": [
                259.1762390136719,
                310.54046630859375,
                291.6416320800781,
                336.13702392578125
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            11096,
            11100
          ],
          "representative_frame": 11096,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 92
    },
    {
      "second": 370,
      "time_range": [
        370,
        370.999
      ],
      "frame_range": [
        11101,
        11130
      ],
      "unified_description": "1-second scene featuring a man fishing at the shore of a lake. The camera is mounted on a tripod providing stable footage.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:25",
        "processing_time": 2.58,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11115,
          "frame_range": [
            11111,
            11115
          ],
          "description": "a man is fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.09
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11101,
            11105
          ],
          "representative_frame": 11101,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9548997282981873,
              "bbox": [
                265.2374572753906,
                13.213659286499023,
                626.0316162109375,
                355.5110778808594
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7850949764251709,
              "bbox": [
                0.23991206288337708,
                136.48545837402344,
                75.18587493896484,
                185.82284545898438
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.40738382935523987,
              "bbox": [
                279.4852600097656,
                335.0727844238281,
                315.8844909667969,
                359.7029724121094
              ]
            },
            {
              "track_id": 897,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.28213033080101013,
              "bbox": [
                259.1725769042969,
                310.405029296875,
                291.88067626953125,
                336.197265625
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            11106,
            11110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11111,
            11115
          ],
          "representative_frame": 11111,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.951168954372406,
              "bbox": [
                257.5920104980469,
                12.014034271240234,
                619.0042114257812,
                355.5528564453125
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7996688485145569,
              "bbox": [
                0.28021517395973206,
                136.53445434570312,
                75.14012145996094,
                185.81309509277344
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4824729263782501,
              "bbox": [
                279.4702453613281,
                335.0794982910156,
                315.8744812011719,
                359.7135314941406
              ]
            },
            {
              "track_id": 897,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.19046230614185333,
              "bbox": [
                259.1611022949219,
                310.3372802734375,
                291.9450988769531,
                336.19244384765625
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            11116,
            11120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11121,
            11125
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9541647434234619,
              "bbox": [
                255.5268096923828,
                11.485993385314941,
                616.4081420898438,
                355.346923828125
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.786287784576416,
              "bbox": [
                0.2665521204471588,
                136.5121307373047,
                75.1748275756836,
                185.8211669921875
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5533209443092346,
              "bbox": [
                279.583740234375,
                335.1697692871094,
                315.7986755371094,
                359.6714782714844
              ]
            },
            {
              "track_id": 897,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.28327032923698425,
              "bbox": [
                259.0694885253906,
                310.57781982421875,
                291.81927490234375,
                336.41912841796875
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            11126,
            11130
          ],
          "representative_frame": 11126,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 92
    },
    {
      "second": 371,
      "time_range": [
        371,
        371.999
      ],
      "frame_range": [
        11131,
        11160
      ],
      "unified_description": "4 tracks, 6 groups",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:27",
        "processing_time": 2.3,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11145,
          "frame_range": [
            11141,
            11145
          ],
          "description": "a man in a raincoat is sitting on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.15
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11131,
            11135
          ],
          "representative_frame": 11131,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9483879208564758,
              "bbox": [
                256.7948303222656,
                17.979965209960938,
                611.140380859375,
                355.2398986816406
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8032763600349426,
              "bbox": [
                0.29953211545944214,
                136.53904724121094,
                75.1784896850586,
                185.82391357421875
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6259741187095642,
              "bbox": [
                279.5335693359375,
                335.13665771484375,
                315.8419189453125,
                359.6946716308594
              ]
            },
            {
              "track_id": 897,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.35937249660491943,
              "bbox": [
                259.0836181640625,
                310.65411376953125,
                291.8834228515625,
                336.5455017089844
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            11136,
            11140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11141,
            11145
          ],
          "representative_frame": 11141,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9501150846481323,
              "bbox": [
                253.16127014160156,
                20.624727249145508,
                605.9680786132812,
                355.2243347167969
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7816102504730225,
              "bbox": [
                0.30461469292640686,
                136.58128356933594,
                75.15287780761719,
                185.83937072753906
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4121650159358978,
              "bbox": [
                279.4824523925781,
                335.1518859863281,
                315.7789306640625,
                359.6920166015625
              ]
            },
            {
              "track_id": 897,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.20099098980426788,
              "bbox": [
                259.084716796875,
                310.68609619140625,
                291.6144104003906,
                336.364013671875
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            11146,
            11150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11151,
            11155
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9540660977363586,
              "bbox": [
                266.94219970703125,
                21.384002685546875,
                616.2764892578125,
                355.43914794921875
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8023146986961365,
              "bbox": [
                0.31876614689826965,
                136.61476135253906,
                75.10942840576172,
                185.825927734375
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.40817010402679443,
              "bbox": [
                279.48858642578125,
                335.1401672363281,
                315.7843322753906,
                359.6710205078125
              ]
            },
            {
              "track_id": 897,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.24865764379501343,
              "bbox": [
                259.1242370605469,
                310.6463317871094,
                291.57745361328125,
                336.26043701171875
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            11156,
            11160
          ],
          "representative_frame": 11156,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 92
    },
    {
      "second": 372,
      "time_range": [
        372,
        372.999
      ],
      "frame_range": [
        11161,
        11190
      ],
      "unified_description": "3rd person's POV of a man fishing near a lake with a house in the background",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:27",
        "processing_time": 2.41,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11175,
          "frame_range": [
            11171,
            11175
          ],
          "description": "a man is fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.41
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11161,
            11165
          ],
          "representative_frame": 11161,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9532361626625061,
              "bbox": [
                271.4189147949219,
                23.42005157470703,
                616.8328247070312,
                355.5340270996094
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7746192812919617,
              "bbox": [
                0.3913367688655853,
                136.7425994873047,
                75.02674865722656,
                185.8328094482422
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4379895031452179,
              "bbox": [
                279.5041198730469,
                335.1488037109375,
                315.76251220703125,
                359.64501953125
              ]
            },
            {
              "track_id": 897,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.24055899679660797,
              "bbox": [
                259.21160888671875,
                310.6946716308594,
                291.7008056640625,
                336.3485412597656
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            11166,
            11170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11171,
            11175
          ],
          "representative_frame": 11171,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9559878706932068,
              "bbox": [
                273.88140869140625,
                22.645278930664062,
                617.8043823242188,
                355.508056640625
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7818349599838257,
              "bbox": [
                0.38675397634506226,
                136.7978057861328,
                74.99259185791016,
                185.85308837890625
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5074126124382019,
              "bbox": [
                279.4666748046875,
                335.13873291015625,
                315.8055114746094,
                359.6853332519531
              ]
            },
            {
              "track_id": 897,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.28551337122917175,
              "bbox": [
                259.2377624511719,
                310.72503662109375,
                291.7284851074219,
                336.39105224609375
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            11176,
            11180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11181,
            11185
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9498446583747864,
              "bbox": [
                273.11492919921875,
                14.760897636413574,
                622.5400390625,
                355.489013671875
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7893516421318054,
              "bbox": [
                0.38178595900535583,
                136.80416870117188,
                74.99159240722656,
                185.84474182128906
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5936069488525391,
              "bbox": [
                279.37298583984375,
                335.0969543457031,
                315.8222961425781,
                359.7131652832031
              ]
            },
            {
              "track_id": 897,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.30636975169181824,
              "bbox": [
                259.1427917480469,
                310.62322998046875,
                291.613037109375,
                336.2750549316406
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            11186,
            11190
          ],
          "representative_frame": 11186,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 93
    },
    {
      "second": 373,
      "time_range": [
        373,
        373.999
      ],
      "frame_range": [
        11191,
        11220
      ],
      "unified_description": "2 people, 2 bodies of water, 3 fish, 1 car, 1 backpack, 1 hand holding a fishing rod, 1 wide-angle perspective",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:29",
        "processing_time": 2.88,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11205,
          "frame_range": [
            11201,
            11205
          ],
          "description": "a man is sitting on the ground with a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.75
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11191,
            11195
          ],
          "representative_frame": 11191,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9661457538604736,
              "bbox": [
                274.0584716796875,
                5.754051685333252,
                632.9392700195312,
                355.7486267089844
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7490244507789612,
              "bbox": [
                0.16438338160514832,
                136.29417419433594,
                75.32231140136719,
                185.7158203125
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5193432569503784,
              "bbox": [
                279.45843505859375,
                335.1507263183594,
                315.81304931640625,
                359.6916198730469
              ]
            },
            {
              "track_id": 897,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.22887086868286133,
              "bbox": [
                259.3151550292969,
                310.69781494140625,
                291.7163391113281,
                336.3004150390625
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            11196,
            11200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11201,
            11205
          ],
          "representative_frame": 11201,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9591403603553772,
              "bbox": [
                269.6455383300781,
                1.4771878719329834,
                633.8329467773438,
                355.06256103515625
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7252597212791443,
              "bbox": [
                0.163648322224617,
                136.24224853515625,
                75.307861328125,
                185.66168212890625
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6008639931678772,
              "bbox": [
                279.4952392578125,
                335.1929626464844,
                315.82537841796875,
                359.7045593261719
              ]
            },
            {
              "track_id": 897,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2600916624069214,
              "bbox": [
                259.3154296875,
                310.62030029296875,
                291.52252197265625,
                336.0543518066406
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            11206,
            11210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11211,
            11215
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9517188668251038,
              "bbox": [
                265.8946228027344,
                0.0,
                633.2843017578125,
                354.7046813964844
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5972214341163635,
              "bbox": [
                0.20208722352981567,
                136.48167419433594,
                74.96923828125,
                185.63807678222656
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5169515013694763,
              "bbox": [
                279.3992919921875,
                335.0243225097656,
                315.9161376953125,
                359.6851501464844
              ]
            },
            {
              "track_id": 897,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3018541932106018,
              "bbox": [
                259.62078857421875,
                310.8118591308594,
                291.9791259765625,
                336.4609069824219
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            11216,
            11220
          ],
          "representative_frame": 11216,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 93
    },
    {
      "second": 374,
      "time_range": [
        374,
        374.999
      ],
      "frame_range": [
        11221,
        11250
      ],
      "unified_description": "1-second scene with a man holding a fish in his hand",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:30",
        "processing_time": 2.32,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11235,
          "frame_range": [
            11231,
            11235
          ],
          "description": "a man is holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.42
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11221,
            11225
          ],
          "representative_frame": 11221,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9534336924552917,
              "bbox": [
                262.2434387207031,
                0.0,
                632.1409912109375,
                354.45733642578125
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.600861668586731,
              "bbox": [
                0.3574490249156952,
                136.83621215820312,
                74.94650268554688,
                185.8294677734375
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5134488344192505,
              "bbox": [
                279.3478698730469,
                334.9925231933594,
                315.89306640625,
                359.7025146484375
              ]
            },
            {
              "track_id": 897,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2601052522659302,
              "bbox": [
                259.79473876953125,
                310.8785095214844,
                292.083251953125,
                336.5519104003906
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            11226,
            11230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11231,
            11235
          ],
          "representative_frame": 11231,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9506794214248657,
              "bbox": [
                258.2277526855469,
                0.0,
                630.7838134765625,
                354.5716552734375
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5960308313369751,
              "bbox": [
                0.35603955388069153,
                136.94149780273438,
                74.93767547607422,
                185.8951416015625
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5214937925338745,
              "bbox": [
                279.3729248046875,
                334.9560852050781,
                315.9009704589844,
                359.68072509765625
              ]
            },
            {
              "track_id": 897,
              "class_id": 32,
              "class_name": "sports ball",
              "confidence": 0.46955424547195435,
              "bbox": [
                259.93011474609375,
                310.6369934082031,
                291.99383544921875,
                336.1790771484375
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            11236,
            11240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11241,
            11245
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9436329007148743,
              "bbox": [
                262.7571105957031,
                6.625978469848633,
                630.5928955078125,
                355.3518371582031
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6301549673080444,
              "bbox": [
                0.3817773461341858,
                136.97691345214844,
                75.00243377685547,
                185.92625427246094
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.46096915006637573,
              "bbox": [
                279.39654541015625,
                334.9406433105469,
                315.9500732421875,
                359.6964416503906
              ]
            },
            {
              "track_id": 897,
              "class_id": 32,
              "class_name": "sports ball",
              "confidence": 0.4640774726867676,
              "bbox": [
                259.8731689453125,
                310.5121765136719,
                291.9542236328125,
                336.1297302246094
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            11246,
            11250
          ],
          "representative_frame": 11246,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 93
    },
    {
      "second": 375,
      "time_range": [
        375,
        375.999
      ],
      "frame_range": [
        11251,
        11280
      ],
      "unified_description": "30 FPS camera, stable mount, wide-angle lens, outdoor setting, action camera.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:31",
        "processing_time": 2.63,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11265,
          "frame_range": [
            11261,
            11265
          ],
          "description": "a man squats on a rock in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.47
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11251,
            11255
          ],
          "representative_frame": 11251,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9568485617637634,
              "bbox": [
                305.22174072265625,
                19.711355209350586,
                640.0,
                355.8183898925781
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7440190315246582,
              "bbox": [
                0.36668092012405396,
                136.95208740234375,
                75.10863494873047,
                185.9615936279297
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2784542739391327,
              "bbox": [
                279.40771484375,
                334.94354248046875,
                315.90325927734375,
                359.670654296875
              ]
            },
            {
              "track_id": 897,
              "class_id": 32,
              "class_name": "sports ball",
              "confidence": 0.28162530064582825,
              "bbox": [
                260.0269775390625,
                310.50921630859375,
                291.9172668457031,
                335.9656982421875
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            11256,
            11260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11261,
            11265
          ],
          "representative_frame": 11261,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9479904174804688,
              "bbox": [
                319.6650695800781,
                11.00375747680664,
                640.0,
                355.6510314941406
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7737545371055603,
              "bbox": [
                0.4236796200275421,
                136.91653442382812,
                75.08736419677734,
                185.8322296142578
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.26846936345100403,
              "bbox": [
                279.4177551269531,
                334.9163818359375,
                315.8700866699219,
                359.61785888671875
              ]
            },
            {
              "track_id": 897,
              "class_id": 32,
              "class_name": "sports ball",
              "confidence": 0.4192071855068207,
              "bbox": [
                260.09710693359375,
                310.4957580566406,
                291.86444091796875,
                335.815673828125
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            11266,
            11270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11271,
            11275
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9462416172027588,
              "bbox": [
                333.81878662109375,
                11.731508255004883,
                640.0,
                355.1927185058594
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7084985375404358,
              "bbox": [
                0.45703837275505066,
                136.89205932617188,
                75.14923095703125,
                185.7803497314453
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.40337586402893066,
              "bbox": [
                279.3903503417969,
                334.89453125,
                315.8238830566406,
                359.58917236328125
              ]
            },
            {
              "track_id": 897,
              "class_id": 32,
              "class_name": "sports ball",
              "confidence": 0.41525331139564514,
              "bbox": [
                260.0932312011719,
                310.4775695800781,
                291.84796142578125,
                335.7591857910156
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            11276,
            11280
          ],
          "representative_frame": 11276,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 93
    },
    {
      "second": 376,
      "time_range": [
        376,
        376.999
      ],
      "frame_range": [
        11281,
        11310
      ],
      "unified_description": "\nBased on image descriptions and object detections, provide a detailed description of this 1-second scene:\n\n1. A man is fishing on the shore of a lake:\n   - The man is holding a fishing rod.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:33",
        "processing_time": 3.25,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11295,
          "frame_range": [
            11291,
            11295
          ],
          "description": "a man is fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.7
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11281,
            11285
          ],
          "representative_frame": 11281,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9438738226890564,
              "bbox": [
                347.1812438964844,
                30.641355514526367,
                640.0,
                355.0924377441406
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.743200957775116,
              "bbox": [
                0.44947758316993713,
                136.87338256835938,
                75.23738098144531,
                185.7810821533203
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4494810998439789,
              "bbox": [
                279.3062438964844,
                334.82763671875,
                315.8760070800781,
                359.63775634765625
              ]
            },
            {
              "track_id": 897,
              "class_id": 32,
              "class_name": "sports ball",
              "confidence": 0.33372753858566284,
              "bbox": [
                260.0680236816406,
                310.4676513671875,
                292.00244140625,
                335.8849182128906
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            11286,
            11290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11291,
            11295
          ],
          "representative_frame": 11291,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8593136668205261,
              "bbox": [
                354.6012878417969,
                44.83404541015625,
                640.0,
                355.2916564941406
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.713066577911377,
              "bbox": [
                0.4204016923904419,
                136.8680419921875,
                75.29866790771484,
                185.80050659179688
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.258241206407547,
              "bbox": [
                279.5105285644531,
                334.8370361328125,
                315.8434753417969,
                359.4886169433594
              ]
            },
            {
              "track_id": 897,
              "class_id": 32,
              "class_name": "sports ball",
              "confidence": 0.5836319327354431,
              "bbox": [
                260.17962646484375,
                310.45550537109375,
                291.9449768066406,
                335.71258544921875
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            11296,
            11300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11301,
            11305
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9173325300216675,
              "bbox": [
                342.7783203125,
                55.05055618286133,
                632.853515625,
                355.3481140136719
              ]
            },
            {
              "track_id": 895,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7348945140838623,
              "bbox": [
                0.24800105392932892,
                136.8837127685547,
                75.33911895751953,
                185.94741821289062
              ]
            },
            {
              "track_id": 896,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.44988635182380676,
              "bbox": [
                279.5120849609375,
                334.8638000488281,
                315.836669921875,
                359.5139465332031
              ]
            },
            {
              "track_id": 897,
              "class_id": 32,
              "class_name": "sports ball",
              "confidence": 0.5697453618049622,
              "bbox": [
                260.17230224609375,
                310.4554748535156,
                292.0146789550781,
                335.76116943359375
              ]
            }
          ],
          "unique_tracks": [
            817,
            895,
            896,
            897
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            11306,
            11310
          ],
          "representative_frame": 11306,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 94
    },
    {
      "second": 377,
      "time_range": [
        377,
        377.999
      ],
      "frame_range": [
        11311,
        11340
      ],
      "unified_description": "1-second scene with a man in a raincoat holding a fish, shot using a GoPro camera.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:34",
        "processing_time": 2.5,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11325,
          "frame_range": [
            11321,
            11325
          ],
          "description": "a man in a raincoat is holding a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.39
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11311,
            11315
          ],
          "representative_frame": 11311,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9257432818412781,
              "bbox": [
                196.2074737548828,
                19.612316131591797,
                523.3632202148438,
                355.4853210449219
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            11316,
            11320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11321,
            11325
          ],
          "representative_frame": 11321,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9378687739372253,
              "bbox": [
                142.93740844726562,
                10.222297668457031,
                483.5877685546875,
                355.70465087890625
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            11326,
            11330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11331,
            11335
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9410068988800049,
              "bbox": [
                120.60445404052734,
                5.128307819366455,
                469.9539489746094,
                355.852294921875
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            11336,
            11340
          ],
          "representative_frame": 11336,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 94
    },
    {
      "second": 378,
      "time_range": [
        378,
        378.999
      ],
      "frame_range": [
        11341,
        11370
      ],
      "unified_description": "1-second scene with a man in a raincoat holding a fish in front of a building. The image also contains several other objects and people, as well as various camera artifacts.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:35",
        "processing_time": 3.08,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11355,
          "frame_range": [
            11351,
            11355
          ],
          "description": "a man in a raincoat is holding a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.31
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11341,
            11345
          ],
          "representative_frame": 11341,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9472729563713074,
              "bbox": [
                123.6132583618164,
                1.3613481521606445,
                479.0783386230469,
                356.18798828125
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            11346,
            11350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11351,
            11355
          ],
          "representative_frame": 11351,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9452520608901978,
              "bbox": [
                123.3488540649414,
                0.5480998754501343,
                482.2863464355469,
                356.1169738769531
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            11356,
            11360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11361,
            11365
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9303993582725525,
              "bbox": [
                59.8762321472168,
                0.0,
                403.0384216308594,
                355.5569152832031
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            11366,
            11370
          ],
          "representative_frame": 11366,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 94
    },
    {
      "second": 379,
      "time_range": [
        379,
        379.999
      ],
      "frame_range": [
        11371,
        11400
      ],
      "unified_description": "\nIn the image, there is a man fishing on a lake using a fishing rod. The camera perspective appears to be first-person, giving a sense that the viewer is experiencing the scene from the fisherman's point of view. The camera positioning seems stable, and the video has been produced with some artistic choices, such as panning, which adds movement to the otherwise still image. The overall effect is an engaging and immersive experience for the viewer, capturing the essence of a fishing trip.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:38",
        "processing_time": 4.38,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11385,
          "frame_range": [
            11381,
            11385
          ],
          "description": "a man fishing on a lake with a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.69
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11371,
            11375
          ],
          "representative_frame": 11371,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9150090217590332,
              "bbox": [
                57.15031433105469,
                0.0,
                383.93212890625,
                355.65765380859375
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            11376,
            11380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11381,
            11385
          ],
          "representative_frame": 11381,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9415884017944336,
              "bbox": [
                77.16162872314453,
                0.0,
                386.3169250488281,
                352.7917175292969
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            11386,
            11390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11391,
            11395
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            11396,
            11400
          ],
          "representative_frame": 11396,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 94
    },
    {
      "second": 380,
      "time_range": [
        380,
        380.999
      ],
      "frame_range": [
        11401,
        11430
      ],
      "unified_description": "1 second video of a man fishing with a fishing rod in the water. The image contains the following objects/people and actions:\n\n- A man standing outdoors near the water with a fishing rod.\n- There is also a backpack in the scene, possibly belonging to the man fishing.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:39",
        "processing_time": 3.71,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11415,
          "frame_range": [
            11411,
            11415
          ],
          "description": "a man fishing in the water with a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.02
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11401,
            11405
          ],
          "representative_frame": 11401,
          "detections": [
            {
              "track_id": 910,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9189815521240234,
              "bbox": [
                288.79754638671875,
                85.02640533447266,
                349.3733215332031,
                254.27474975585938
              ]
            }
          ],
          "unique_tracks": [
            910
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            11406,
            11410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11411,
            11415
          ],
          "representative_frame": 11411,
          "detections": [
            {
              "track_id": 910,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9058921337127686,
              "bbox": [
                286.281005859375,
                84.71087646484375,
                347.25054931640625,
                254.12399291992188
              ]
            }
          ],
          "unique_tracks": [
            910
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            11416,
            11420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11421,
            11425
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 910,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8983739614486694,
              "bbox": [
                282.7742919921875,
                84.9051284790039,
                343.4124755859375,
                253.198974609375
              ]
            }
          ],
          "unique_tracks": [
            910
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            11426,
            11430
          ],
          "representative_frame": 11426,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 95
    },
    {
      "second": 381,
      "time_range": [
        381,
        381.999
      ],
      "frame_range": [
        11431,
        11460
      ],
      "unified_description": "\nThe image depicts a man standing next to a body of water holding a fishing rod. The camera captures this scene from a first-person perspective, providing an immersive view of the moment. The man is wearing a backpack, which can be seen clearly in the upper right portion of the image. The fishing rod appears to be in motion as the man casts his line, adding a sense of action and anticipation for a catch to this scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:41",
        "processing_time": 4.76,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11445,
          "frame_range": [
            11441,
            11445
          ],
          "description": "a man fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11431,
            11435
          ],
          "representative_frame": 11431,
          "detections": [
            {
              "track_id": 910,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9023870229721069,
              "bbox": [
                278.45501708984375,
                85.04010009765625,
                338.25970458984375,
                251.6864776611328
              ]
            }
          ],
          "unique_tracks": [
            910
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            11436,
            11440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11441,
            11445
          ],
          "representative_frame": 11441,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            11446,
            11450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11451,
            11455
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8456389904022217,
              "bbox": [
                330.3619689941406,
                4.466894626617432,
                428.4659118652344,
                298.26544189453125
              ]
            }
          ],
          "unique_tracks": [
            911
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            11456,
            11460
          ],
          "representative_frame": 11456,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 95
    },
    {
      "second": 382,
      "time_range": [
        382,
        382.999
      ],
      "frame_range": [
        11461,
        11490
      ],
      "unified_description": "\n\nFirst-person perspective showing a man fishing with a rod. The scene takes place by the water, possibly in an outdoor or nature setting. There may be additional elements in the background, but the primary focus is on the person fishing.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:42",
        "processing_time": 3.76,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11475,
          "frame_range": [
            11471,
            11475
          ],
          "description": "a man fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11461,
            11465
          ],
          "representative_frame": 11461,
          "detections": [
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8715048432350159,
              "bbox": [
                328.350830078125,
                4.57496976852417,
                426.16326904296875,
                297.0898132324219
              ]
            }
          ],
          "unique_tracks": [
            911
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            11466,
            11470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11471,
            11475
          ],
          "representative_frame": 11471,
          "detections": [
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8655949831008911,
              "bbox": [
                327.39349365234375,
                4.664185523986816,
                425.8038330078125,
                298.3608093261719
              ]
            }
          ],
          "unique_tracks": [
            911
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            11476,
            11480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11481,
            11485
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8648166060447693,
              "bbox": [
                327.9309387207031,
                4.713720321655273,
                426.4916687011719,
                298.0626525878906
              ]
            }
          ],
          "unique_tracks": [
            911
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            11486,
            11490
          ],
          "representative_frame": 11486,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 95
    },
    {
      "second": 383,
      "time_range": [
        383,
        383.999
      ],
      "frame_range": [
        11491,
        11520
      ],
      "unified_description": "1-second scene featuring a man fishing in the water with a rod",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:43",
        "processing_time": 2.72,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11505,
          "frame_range": [
            11501,
            11505
          ],
          "description": "a man fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.99
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11491,
            11495
          ],
          "representative_frame": 11491,
          "detections": [
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8750287294387817,
              "bbox": [
                327.71856689453125,
                4.857004165649414,
                426.9034729003906,
                299.1270446777344
              ]
            }
          ],
          "unique_tracks": [
            911
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            11496,
            11500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11501,
            11505
          ],
          "representative_frame": 11501,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9245143532752991,
              "bbox": [
                0.0,
                0.0,
                279.76361083984375,
                351.65765380859375
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            11506,
            11510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11511,
            11515
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9073358178138733,
              "bbox": [
                0.0,
                0.0,
                245.24850463867188,
                354.44378662109375
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            11516,
            11520
          ],
          "representative_frame": 11516,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 95
    },
    {
      "second": 384,
      "time_range": [
        384,
        384.999
      ],
      "frame_range": [
        11521,
        11550
      ],
      "unified_description": "1-second scene with a man fishing on a lake with a fishing rod",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:45",
        "processing_time": 2.34,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11535,
          "frame_range": [
            11531,
            11535
          ],
          "description": "a man fishing on a lake with a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.06
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11521,
            11525
          ],
          "representative_frame": 11521,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8598629236221313,
              "bbox": [
                0.0,
                0.20478396117687225,
                207.2735595703125,
                353.4334716796875
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            11526,
            11530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11531,
            11535
          ],
          "representative_frame": 11531,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8574622273445129,
              "bbox": [
                0.0,
                0.6844422221183777,
                181.47059631347656,
                353.7207946777344
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            11536,
            11540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11541,
            11545
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8924872279167175,
              "bbox": [
                0.0,
                1.2966598272323608,
                164.097900390625,
                355.12237548828125
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            11546,
            11550
          ],
          "representative_frame": 11546,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 96
    },
    {
      "second": 385,
      "time_range": [
        385,
        385.999
      ],
      "frame_range": [
        11551,
        11580
      ],
      "unified_description": "1-second scene featuring a man who is fishing on a lake with mountains in the background",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:46",
        "processing_time": 2.41,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11565,
          "frame_range": [
            11561,
            11565
          ],
          "description": "a man is fishing on a lake with mountains in the background",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.59
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11551,
            11555
          ],
          "representative_frame": 11551,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8633410930633545,
              "bbox": [
                0.0,
                1.2025353908538818,
                136.85250854492188,
                354.1263122558594
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            11556,
            11560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11561,
            11565
          ],
          "representative_frame": 11561,
          "detections": [
            {
              "track_id": 817,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7360228896141052,
              "bbox": [
                0.0,
                3.862089157104492,
                120.60753631591797,
                354.2998046875
              ]
            }
          ],
          "unique_tracks": [
            817
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            11566,
            11570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11571,
            11575
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            11576,
            11580
          ],
          "representative_frame": 11576,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 96
    },
    {
      "second": 386,
      "time_range": [
        386,
        386.999
      ],
      "frame_range": [
        11581,
        11610
      ],
      "unified_description": "1-second scene with an overcast sky, a building with a fence on top, and two people walking past it.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:47",
        "processing_time": 3.0,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11595,
          "frame_range": [
            11591,
            11595
          ],
          "description": "a fish is swimming in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.29
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11581,
            11585
          ],
          "representative_frame": 11581,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            11586,
            11590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11591,
            11595
          ],
          "representative_frame": 11591,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            11596,
            11600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11601,
            11605
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            11606,
            11610
          ],
          "representative_frame": 11606,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 96
    },
    {
      "second": 387,
      "time_range": [
        387,
        387.999
      ],
      "frame_range": [
        11611,
        11640
      ],
      "unified_description": "\nWhen describing the content of the image, it is helpful to use sentences that start with \"In this scene, ... or other objects are visible.\" When describing technical details, sentences like \"The camera was mounted on a tripod\" or \"A wide-angle lens was used for the recording\" can be useful.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:49",
        "processing_time": 3.52,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11625,
          "frame_range": [
            11621,
            11625
          ],
          "description": "a person standing on a rock with their feet up",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.71
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11611,
            11615
          ],
          "representative_frame": 11611,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            11616,
            11620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11621,
            11625
          ],
          "representative_frame": 11621,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            11626,
            11630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11631,
            11635
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            11636,
            11640
          ],
          "representative_frame": 11636,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 96
    },
    {
      "second": 388,
      "time_range": [
        388,
        388.999
      ],
      "frame_range": [
        11641,
        11670
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:50",
        "processing_time": 2.11,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11655,
          "frame_range": [
            11651,
            11655
          ],
          "description": "a fish is swimming in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.97
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11641,
            11645
          ],
          "representative_frame": 11641,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            11646,
            11650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11651,
            11655
          ],
          "representative_frame": 11651,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            11656,
            11660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11661,
            11665
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            11666,
            11670
          ],
          "representative_frame": 11666,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 97
    },
    {
      "second": 389,
      "time_range": [
        389,
        389.999
      ],
      "frame_range": [
        11671,
        11700
      ],
      "unified_description": "1-second scene that includes two men standing in the water with a net",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:51",
        "processing_time": 2.43,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11685,
          "frame_range": [
            11681,
            11685
          ],
          "description": "two men are standing in the water with a net",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.1
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11671,
            11675
          ],
          "representative_frame": 11671,
          "detections": [
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8916926980018616,
              "bbox": [
                302.8691101074219,
                1.0202417373657227,
                418.1556701660156,
                261.0402526855469
              ]
            }
          ],
          "unique_tracks": [
            911
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            11676,
            11680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11681,
            11685
          ],
          "representative_frame": 11681,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9229323863983154,
              "bbox": [
                35.30448532104492,
                0.9826294183731079,
                266.4342346191406,
                339.50640869140625
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9272872805595398,
              "bbox": [
                454.16705322265625,
                0.47038573026657104,
                631.6168823242188,
                264.5058288574219
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8554585576057434,
              "bbox": [
                296.327880859375,
                0.9403074383735657,
                427.0228576660156,
                259.98468017578125
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            11686,
            11690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11691,
            11695
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9435636401176453,
              "bbox": [
                71.24385070800781,
                0.3248084485530853,
                303.4058837890625,
                339.15032958984375
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9406819939613342,
              "bbox": [
                452.5731201171875,
                0.5998454093933105,
                631.3091430664062,
                268.02313232421875
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8203539252281189,
              "bbox": [
                287.4562683105469,
                0.49335017800331116,
                428.3269348144531,
                265.9493713378906
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            11696,
            11700
          ],
          "representative_frame": 11696,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 97
    },
    {
      "second": 390,
      "time_range": [
        390,
        390.999
      ],
      "frame_range": [
        11701,
        11730
      ],
      "unified_description": "2 men in the water with their feet in the water",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:52",
        "processing_time": 2.28,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11715,
          "frame_range": [
            11711,
            11715
          ],
          "description": "two men are standing in the water with their feet in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.13
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11701,
            11705
          ],
          "representative_frame": 11701,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.945314884185791,
              "bbox": [
                87.81404113769531,
                4.58206033706665,
                317.7907409667969,
                338.98040771484375
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9240666627883911,
              "bbox": [
                460.9698181152344,
                1.0798720121383667,
                640.0,
                272.009765625
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8525367975234985,
              "bbox": [
                273.81793212890625,
                0.5963550209999084,
                416.1462097167969,
                261.9757080078125
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            11706,
            11710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11711,
            11715
          ],
          "representative_frame": 11711,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9326264262199402,
              "bbox": [
                96.55242919921875,
                16.6411190032959,
                319.25311279296875,
                338.7615661621094
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9341734051704407,
              "bbox": [
                465.9814453125,
                1.1294374465942383,
                640.0,
                272.34271240234375
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6279139518737793,
              "bbox": [
                263.03643798828125,
                0.5992993712425232,
                400.3791809082031,
                253.08311462402344
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            11716,
            11720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11721,
            11725
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8829355239868164,
              "bbox": [
                100.19569396972656,
                21.52165985107422,
                321.080078125,
                339.1379699707031
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.936220645904541,
              "bbox": [
                467.1556091308594,
                1.0886220932006836,
                640.0,
                275.3699645996094
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6492910385131836,
              "bbox": [
                258.4742431640625,
                7.805627346038818,
                400.57269287109375,
                271.9530944824219
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            11726,
            11730
          ],
          "representative_frame": 11726,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 97
    },
    {
      "second": 391,
      "time_range": [
        391,
        391.999
      ],
      "frame_range": [
        11731,
        11760
      ],
      "unified_description": "2 men by a lake with handheld cameras capturing their adventures",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:53",
        "processing_time": 2.42,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11745,
          "frame_range": [
            11741,
            11745
          ],
          "description": "two men are standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.02
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11731,
            11735
          ],
          "representative_frame": 11731,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8967260718345642,
              "bbox": [
                101.5068130493164,
                29.543331146240234,
                317.830078125,
                339.37884521484375
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9328193068504333,
              "bbox": [
                465.97747802734375,
                1.1402322053909302,
                640.0,
                276.6380310058594
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.88201504945755,
              "bbox": [
                258.6921081542969,
                14.220268249511719,
                402.9060974121094,
                285.62420654296875
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            11736,
            11740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11741,
            11745
          ],
          "representative_frame": 11741,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9110592603683472,
              "bbox": [
                147.4482421875,
                72.69307708740234,
                328.4833679199219,
                328.427978515625
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9338754415512085,
              "bbox": [
                411.6638488769531,
                0.8872818946838379,
                597.8196411132812,
                292.6353454589844
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6041746139526367,
              "bbox": [
                270.16461181640625,
                24.748647689819336,
                412.7618713378906,
                292.23126220703125
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            11746,
            11750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11751,
            11755
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8966328501701355,
              "bbox": [
                160.75538635253906,
                87.91866302490234,
                331.9475402832031,
                326.6717834472656
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9401108026504517,
              "bbox": [
                394.04425048828125,
                0.912848174571991,
                582.5928955078125,
                298.67095947265625
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7480117082595825,
              "bbox": [
                273.8133239746094,
                28.83831214904785,
                416.6150817871094,
                295.9740905761719
              ]
            },
            {
              "track_id": 922,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3654847741127014,
              "bbox": [
                272.9813232421875,
                29.12653160095215,
                420.7362060546875,
                296.27911376953125
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911,
            922
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            11756,
            11760
          ],
          "representative_frame": 11756,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 97
    },
    {
      "second": 392,
      "time_range": [
        392,
        392.999
      ],
      "frame_range": [
        11761,
        11790
      ],
      "unified_description": "\n2D or 3D? 3D",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:54",
        "processing_time": 2.33,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11775,
          "frame_range": [
            11771,
            11775
          ],
          "description": "two men are standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.7
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11761,
            11765
          ],
          "representative_frame": 11761,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9198853373527527,
              "bbox": [
                165.17071533203125,
                91.81706237792969,
                333.4524841308594,
                323.4207763671875
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9395787715911865,
              "bbox": [
                389.0667724609375,
                0.7889609336853027,
                577.4371337890625,
                300.60711669921875
              ]
            },
            {
              "track_id": 911,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.37271544337272644,
              "bbox": [
                274.1065979003906,
                24.455833435058594,
                417.76593017578125,
                292.740966796875
              ]
            },
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3967803418636322,
              "bbox": [
                273.0968933105469,
                22.495847702026367,
                422.32928466796875,
                292.4736328125
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911,
            922
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            11766,
            11770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11771,
            11775
          ],
          "representative_frame": 11771,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8477391004562378,
              "bbox": [
                162.28976440429688,
                92.37944030761719,
                334.6466064453125,
                327.44659423828125
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9272509813308716,
              "bbox": [
                388.5116882324219,
                0.6227967143058777,
                575.6133422851562,
                301.0663146972656
              ]
            },
            {
              "track_id": 911,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.18147914111614227,
              "bbox": [
                276.20172119140625,
                11.037569046020508,
                414.6213684082031,
                266.18426513671875
              ]
            },
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6114152669906616,
              "bbox": [
                276.5386962890625,
                6.685934543609619,
                417.2226257324219,
                260.5164489746094
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911,
            922
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            11776,
            11780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11781,
            11785
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9352542757987976,
              "bbox": [
                157.16807556152344,
                92.06209564208984,
                338.3028869628906,
                337.65380859375
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9200438261032104,
              "bbox": [
                391.3736267089844,
                0.3889828324317932,
                576.9780883789062,
                301.2986145019531
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.39557158946990967,
              "bbox": [
                280.3269958496094,
                4.255699634552002,
                423.80474853515625,
                258.87225341796875
              ]
            },
            {
              "track_id": 922,
              "class_id": 17,
              "class_name": "horse",
              "confidence": 0.45780208706855774,
              "bbox": [
                282.4020080566406,
                0.16747896373271942,
                424.8439636230469,
                253.87408447265625
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911,
            922
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            11786,
            11790
          ],
          "representative_frame": 11786,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 98
    },
    {
      "second": 393,
      "time_range": [
        393,
        393.999
      ],
      "frame_range": [
        11791,
        11820
      ],
      "unified_description": "3 people are in the image - a man, a boy, and another person. They are standing in the water with some distance between them. The camera is positioned above them, possibly on a tripod or mounted camera.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:56",
        "processing_time": 2.9,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11805,
          "frame_range": [
            11801,
            11805
          ],
          "description": "a man and a boy are standing in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11791,
            11795
          ],
          "representative_frame": 11791,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9326696395874023,
              "bbox": [
                154.7610321044922,
                92.40892028808594,
                339.3546447753906,
                340.80731201171875
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8317606449127197,
              "bbox": [
                396.17706298828125,
                0.6229351758956909,
                580.0737915039062,
                301.3507385253906
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6471984386444092,
              "bbox": [
                264.3841552734375,
                2.1335744857788086,
                404.4527893066406,
                246.59072875976562
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            11796,
            11800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11801,
            11805
          ],
          "representative_frame": 11801,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9428755044937134,
              "bbox": [
                159.9754180908203,
                92.92195892333984,
                349.15167236328125,
                343.4270324707031
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9445855021476746,
              "bbox": [
                400.58746337890625,
                0.8574308753013611,
                583.497314453125,
                301.2991027832031
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7605076432228088,
              "bbox": [
                261.21453857421875,
                0.93929523229599,
                411.2124328613281,
                260.30877685546875
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            11806,
            11810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11811,
            11815
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.935943603515625,
              "bbox": [
                157.3997802734375,
                91.6430435180664,
                349.5925598144531,
                344.41265869140625
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9308068156242371,
              "bbox": [
                414.91156005859375,
                0.9273088574409485,
                597.0173950195312,
                300.81231689453125
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.812036395072937,
              "bbox": [
                271.4428405761719,
                0.6327568292617798,
                423.1025085449219,
                257.7124328613281
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            11816,
            11820
          ],
          "representative_frame": 11816,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 98
    },
    {
      "second": 394,
      "time_range": [
        394,
        394.999
      ],
      "frame_range": [
        11821,
        11850
      ],
      "unified_description": "30 seconds left",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:56",
        "processing_time": 2.2,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11835,
          "frame_range": [
            11831,
            11835
          ],
          "description": "two men are standing in the water with their hands",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.13
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11821,
            11825
          ],
          "representative_frame": 11821,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9430204033851624,
              "bbox": [
                154.48306274414062,
                90.56950378417969,
                348.7397766113281,
                344.4430236816406
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9357002377510071,
              "bbox": [
                427.06988525390625,
                0.8542680144309998,
                610.0870971679688,
                299.5349426269531
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.770891010761261,
              "bbox": [
                267.8110656738281,
                0.16454608738422394,
                422.4130554199219,
                261.0936584472656
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            11826,
            11830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11831,
            11835
          ],
          "representative_frame": 11831,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9338980913162231,
              "bbox": [
                149.98223876953125,
                90.62928009033203,
                344.8514709472656,
                343.9103088378906
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9235008358955383,
              "bbox": [
                442.9162902832031,
                0.62770015001297,
                623.9091186523438,
                296.04315185546875
              ]
            },
            {
              "track_id": 911,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.6158254742622375,
              "bbox": [
                266.2579650878906,
                3.684058427810669,
                422.70599365234375,
                269.64410400390625
              ]
            },
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6110846400260925,
              "bbox": [
                270.09271240234375,
                3.1585607528686523,
                421.283203125,
                273.2019348144531
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911,
            922
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            11836,
            11840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11841,
            11845
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9070338010787964,
              "bbox": [
                109.49042510986328,
                31.98475456237793,
                338.13818359375,
                341.3601989746094
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9486461877822876,
              "bbox": [
                421.7762451171875,
                0.5858750343322754,
                598.1658325195312,
                294.387939453125
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2988685369491577,
              "bbox": [
                248.98416137695312,
                9.28111743927002,
                414.4947814941406,
                285.89434814453125
              ]
            },
            {
              "track_id": 922,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.18850013613700867,
              "bbox": [
                251.95999145507812,
                8.525373458862305,
                410.9671936035156,
                286.94891357421875
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911,
            922
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            11846,
            11850
          ],
          "representative_frame": 11846,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 98
    },
    {
      "second": 395,
      "time_range": [
        395,
        395.999
      ],
      "frame_range": [
        11851,
        11880
      ],
      "unified_description": "\n(This scene takes place at a beach by the ocean with two people standing near the water. There are four main objects in the scene: a skateboard, a backpack, and two handbags. Additionally, there is one bird flying overhead. The camera captures this moment, possibly as part of a video production.)",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:21:59",
        "processing_time": 3.7,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11865,
          "frame_range": [
            11861,
            11865
          ],
          "description": "two people standing on a beach next to a body of water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.0
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11851,
            11855
          ],
          "representative_frame": 11851,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9167669415473938,
              "bbox": [
                94.11396026611328,
                11.384038925170898,
                329.1238708496094,
                342.6061706542969
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9362360835075378,
              "bbox": [
                413.6287536621094,
                0.6555566787719727,
                587.4322509765625,
                295.5853271484375
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.27217215299606323,
              "bbox": [
                243.85601806640625,
                10.038631439208984,
                420.05889892578125,
                305.9275207519531
              ]
            },
            {
              "track_id": 922,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.24359655380249023,
              "bbox": [
                246.28199768066406,
                9.106369972229004,
                415.4851989746094,
                305.19482421875
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911,
            922
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            11856,
            11860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11861,
            11865
          ],
          "representative_frame": 11861,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8029777407646179,
              "bbox": [
                85.68211364746094,
                8.892873764038086,
                313.60821533203125,
                343.170166015625
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9334365725517273,
              "bbox": [
                411.2625427246094,
                0.621922492980957,
                582.71533203125,
                296.65533447265625
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5417464375495911,
              "bbox": [
                242.75958251953125,
                5.407006740570068,
                416.88421630859375,
                295.2601013183594
              ]
            },
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.18989667296409607,
              "bbox": [
                197.75755310058594,
                6.162083148956299,
                388.7382507324219,
                324.6327819824219
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911,
            922
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            11866,
            11870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11871,
            11875
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9138801097869873,
              "bbox": [
                89.08716583251953,
                17.363460540771484,
                305.1790466308594,
                344.2495422363281
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9304613471031189,
              "bbox": [
                412.0977478027344,
                0.6985754370689392,
                580.8558349609375,
                296.96368408203125
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7608945965766907,
              "bbox": [
                260.4053039550781,
                1.8367853164672852,
                424.39056396484375,
                272.3180236816406
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            11876,
            11880
          ],
          "representative_frame": 11876,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 98
    },
    {
      "second": 396,
      "time_range": [
        396,
        396.999
      ],
      "frame_range": [
        11881,
        11910
      ],
      "unified_description": "3 people standing by a lake. The image was captured using a wide-angle lens which gives a distorted view of the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:00",
        "processing_time": 2.56,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11895,
          "frame_range": [
            11891,
            11895
          ],
          "description": "three people are standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.59
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11881,
            11885
          ],
          "representative_frame": 11881,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9410296082496643,
              "bbox": [
                90.76567077636719,
                17.990760803222656,
                299.7100524902344,
                344.1396484375
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9019548892974854,
              "bbox": [
                414.82568359375,
                0.8024442195892334,
                579.4730224609375,
                293.9619140625
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8878624439239502,
              "bbox": [
                276.45947265625,
                0.8885661363601685,
                444.0663146972656,
                270.0767822265625
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            11886,
            11890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11891,
            11895
          ],
          "representative_frame": 11891,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9218584895133972,
              "bbox": [
                85.5283203125,
                5.495509624481201,
                296.4512939453125,
                344.71636962890625
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.918353796005249,
              "bbox": [
                416.02032470703125,
                0.7055435180664062,
                579.337890625,
                295.6025695800781
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5491191744804382,
              "bbox": [
                272.625,
                0.7114613056182861,
                440.8621826171875,
                268.4351501464844
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            11896,
            11900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11901,
            11905
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9306081533432007,
              "bbox": [
                76.93318176269531,
                0.8773521184921265,
                286.3360595703125,
                344.0882263183594
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9266383647918701,
              "bbox": [
                417.99169921875,
                0.7773532867431641,
                581.5394897460938,
                300.7080383300781
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5211369395256042,
              "bbox": [
                259.91790771484375,
                0.19583763182163239,
                431.2160949707031,
                273.18597412109375
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            11906,
            11910
          ],
          "representative_frame": 11906,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 99
    },
    {
      "second": 397,
      "time_range": [
        397,
        397.999
      ],
      "frame_range": [
        11911,
        11940
      ],
      "unified_description": "3 people standing in the ocean at low tide. The camera was mounted on a backpack.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:01",
        "processing_time": 2.67,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11925,
          "frame_range": [
            11921,
            11925
          ],
          "description": "three people are standing in the water with their feet in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.8
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11911,
            11915
          ],
          "representative_frame": 11911,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9074000716209412,
              "bbox": [
                78.38835144042969,
                0.0,
                286.57275390625,
                343.20318603515625
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9348909258842468,
              "bbox": [
                423.68475341796875,
                0.7257531881332397,
                583.7683715820312,
                297.8434753417969
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7433818578720093,
              "bbox": [
                289.7093200683594,
                0.26474782824516296,
                449.91094970703125,
                268.1805419921875
              ]
            },
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.576193630695343,
              "bbox": [
                230.055908203125,
                1.7721314430236816,
                385.35540771484375,
                267.694580078125
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911,
            922
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            11916,
            11920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11921,
            11925
          ],
          "representative_frame": 11921,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9299399852752686,
              "bbox": [
                78.20956420898438,
                0.0,
                285.0462341308594,
                343.9520568847656
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9274265170097351,
              "bbox": [
                429.7196960449219,
                0.5767050981521606,
                588.1812133789062,
                296.9344177246094
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9258671998977661,
              "bbox": [
                275.0616760253906,
                0.41433092951774597,
                434.5260009765625,
                265.35711669921875
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            11926,
            11930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11931,
            11935
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8895964622497559,
              "bbox": [
                78.22567749023438,
                0.0,
                282.89630126953125,
                344.0650329589844
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9123352766036987,
              "bbox": [
                437.3839111328125,
                0.7709552049636841,
                596.6826782226562,
                297.429443359375
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7172524333000183,
              "bbox": [
                251.6116943359375,
                0.6171571016311646,
                416.59063720703125,
                264.61578369140625
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            11936,
            11940
          ],
          "representative_frame": 11936,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 99
    },
    {
      "second": 398,
      "time_range": [
        398,
        398.999
      ],
      "frame_range": [
        11941,
        11970
      ],
      "unified_description": "2 men standing in water, one closer to camera, another farther away, water between them, no visible boats or other objects, overall scene suggests a natural outdoor setting",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:02",
        "processing_time": 2.97,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11955,
          "frame_range": [
            11951,
            11955
          ],
          "description": "two men are standing in the water with their feet in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.88
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11941,
            11945
          ],
          "representative_frame": 11941,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9379304647445679,
              "bbox": [
                86.17607879638672,
                0.0,
                288.6483459472656,
                343.6958923339844
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9132644534111023,
              "bbox": [
                464.2570495605469,
                0.8615501523017883,
                621.95654296875,
                292.92840576171875
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8963719606399536,
              "bbox": [
                253.56637573242188,
                0.7341524958610535,
                417.5907897949219,
                263.4420166015625
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            11946,
            11950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11951,
            11955
          ],
          "representative_frame": 11951,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9319080114364624,
              "bbox": [
                97.78732299804688,
                0.0,
                296.8496398925781,
                344.14312744140625
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9553647637367249,
              "bbox": [
                475.365234375,
                0.7597307562828064,
                640.0,
                325.1644592285156
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.861325204372406,
              "bbox": [
                261.2056884765625,
                0.6852087378501892,
                423.4061279296875,
                263.7267761230469
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            11956,
            11960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11961,
            11965
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8961713314056396,
              "bbox": [
                106.96705627441406,
                0.0,
                298.1006774902344,
                334.358642578125
              ]
            },
            {
              "track_id": 920,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8765456080436707,
              "bbox": [
                483.29998779296875,
                0.6943214535713196,
                640.0,
                346.16351318359375
              ]
            },
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.715910017490387,
              "bbox": [
                275.7704772949219,
                0.9489026069641113,
                436.2411193847656,
                262.7897644042969
              ]
            }
          ],
          "unique_tracks": [
            919,
            920,
            911
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            11966,
            11970
          ],
          "representative_frame": 11966,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 99
    },
    {
      "second": 399,
      "time_range": [
        399,
        399.999
      ],
      "frame_range": [
        11971,
        12000
      ],
      "unified_description": "3D Video Analyis Tool (3DAV Analyis tool)",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:04",
        "processing_time": 2.37,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 11985,
          "frame_range": [
            11981,
            11985
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.49
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            11971,
            11975
          ],
          "representative_frame": 11971,
          "detections": [
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.43191468715667725,
              "bbox": [
                274.6295166015625,
                1.6114863157272339,
                470.08795166015625,
                324.51568603515625
              ]
            }
          ],
          "unique_tracks": [
            911
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            11976,
            11980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11981,
            11985
          ],
          "representative_frame": 11981,
          "detections": [
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4659360945224762,
              "bbox": [
                272.6479797363281,
                0.8863804936408997,
                477.3636169433594,
                341.3193359375
              ]
            },
            {
              "track_id": 934,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.35111895203590393,
              "bbox": [
                152.76304626464844,
                1.2775084972381592,
                475.98846435546875,
                351.36505126953125
              ]
            },
            {
              "track_id": 936,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.41074037551879883,
              "bbox": [
                158.97555541992188,
                10.48987102508545,
                302.20172119140625,
                172.34698486328125
              ]
            }
          ],
          "unique_tracks": [
            911,
            934,
            936
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            11986,
            11990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            11991,
            11995
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 911,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3249655067920685,
              "bbox": [
                279.6567077636719,
                0.43152934312820435,
                477.1978759765625,
                336.7313537597656
              ]
            },
            {
              "track_id": 934,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.58592289686203,
              "bbox": [
                153.27789306640625,
                1.1428959369659424,
                462.4287414550781,
                336.19915771484375
              ]
            },
            {
              "track_id": 936,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.14518411457538605,
              "bbox": [
                145.83580017089844,
                4.715839862823486,
                345.2994689941406,
                230.88526916503906
              ]
            }
          ],
          "unique_tracks": [
            911,
            934,
            936
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            11996,
            12000
          ],
          "representative_frame": 11996,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 99
    },
    {
      "second": 400,
      "time_range": [
        400,
        400.999
      ],
      "frame_range": [
        12001,
        12030
      ],
      "unified_description": "1-second scene with 2 main objects, 6 groups of objects, and technical details such as camera perspective, field of view, lens characteristics, etc.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:05",
        "processing_time": 2.92,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12015,
          "frame_range": [
            12011,
            12015
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.4
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12001,
            12005
          ],
          "representative_frame": 12001,
          "detections": [
            {
              "track_id": 934,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9181002974510193,
              "bbox": [
                167.64736938476562,
                1.0389389991760254,
                470.9034423828125,
                332.2367858886719
              ]
            }
          ],
          "unique_tracks": [
            934
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12006,
            12010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12011,
            12015
          ],
          "representative_frame": 12011,
          "detections": [
            {
              "track_id": 934,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5439559817314148,
              "bbox": [
                190.99017333984375,
                1.0020970106124878,
                490.9926452636719,
                331.29052734375
              ]
            }
          ],
          "unique_tracks": [
            934
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            12016,
            12020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12021,
            12025
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 934,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8905298113822937,
              "bbox": [
                277.7039794921875,
                128.95489501953125,
                432.5978698730469,
                280.2682800292969
              ]
            },
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.888116717338562,
              "bbox": [
                274.1981201171875,
                0.3301720917224884,
                402.8229064941406,
                192.6447296142578
              ]
            }
          ],
          "unique_tracks": [
            934,
            922
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            12026,
            12030
          ],
          "representative_frame": 12026,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 100
    },
    {
      "second": 401,
      "time_range": [
        401,
        401.999
      ],
      "frame_range": [
        12031,
        12060
      ],
      "unified_description": "\n\nIn this scene, there is a man holding a fish in his hands. The camera perspective appears to be first-person, suggesting that it might have been mounted on the person's head or held close to their body. The image also contains other people and objects, like a backpack which could belong to one of the individuals in the scene. The overall setting indicates an outdoor environment where people are engaging in various activities.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:07",
        "processing_time": 4.02,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12045,
          "frame_range": [
            12041,
            12045
          ],
          "description": "a man holding a fish in his hands",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.65
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12031,
            12035
          ],
          "representative_frame": 12031,
          "detections": [
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8950108289718628,
              "bbox": [
                277.8411560058594,
                0.5660878419876099,
                421.8543395996094,
                199.7357177734375
              ]
            },
            {
              "track_id": 911,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.9334248304367065,
              "bbox": [
                307.2522888183594,
                166.04974365234375,
                439.3872375488281,
                334.5032958984375
              ]
            }
          ],
          "unique_tracks": [
            922,
            911
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            12036,
            12040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12041,
            12045
          ],
          "representative_frame": 12041,
          "detections": [
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9071587920188904,
              "bbox": [
                279.4713439941406,
                0.6582939028739929,
                428.4704895019531,
                192.18450927734375
              ]
            }
          ],
          "unique_tracks": [
            922
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            12046,
            12050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12051,
            12055
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8842863440513611,
              "bbox": [
                277.0401306152344,
                0.8478615880012512,
                431.7765197753906,
                188.20091247558594
              ]
            },
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.6049125790596008,
              "bbox": [
                195.19627380371094,
                170.76577758789062,
                540.1746215820312,
                277.41204833984375
              ]
            },
            {
              "track_id": 936,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.6157629489898682,
              "bbox": [
                285.97125244140625,
                166.09188842773438,
                445.0260314941406,
                328.8603210449219
              ]
            }
          ],
          "unique_tracks": [
            922,
            943,
            936
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            12056,
            12060
          ],
          "representative_frame": 12056,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 100
    },
    {
      "second": 402,
      "time_range": [
        402,
        402.999
      ],
      "frame_range": [
        12061,
        12090
      ],
      "unified_description": "30 second video showing a man holding a fish in his hands",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:08",
        "processing_time": 2.39,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12075,
          "frame_range": [
            12071,
            12075
          ],
          "description": "a man holding a fish in his hands",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.91
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12061,
            12065
          ],
          "representative_frame": 12061,
          "detections": [
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3541465103626251,
              "bbox": [
                271.65301513671875,
                0.7548063397407532,
                435.2986145019531,
                191.65777587890625
              ]
            },
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8199713826179504,
              "bbox": [
                218.92308044433594,
                180.57237243652344,
                511.8243408203125,
                270.5854797363281
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5439081192016602,
              "bbox": [
                198.65267944335938,
                0.686501145362854,
                352.8213195800781,
                199.56361389160156
              ]
            }
          ],
          "unique_tracks": [
            922,
            943,
            919
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            12066,
            12070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12071,
            12075
          ],
          "representative_frame": 12071,
          "detections": [
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.652521014213562,
              "bbox": [
                264.5464782714844,
                0.8657656311988831,
                438.2643737792969,
                198.94871520996094
              ]
            },
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.9305967092514038,
              "bbox": [
                151.1775360107422,
                189.11634826660156,
                575.857421875,
                320.5515441894531
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.543039858341217,
              "bbox": [
                162.67715454101562,
                1.0489991903305054,
                328.0243225097656,
                201.6738739013672
              ]
            }
          ],
          "unique_tracks": [
            922,
            943,
            919
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            12076,
            12080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12081,
            12085
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8585564494132996,
              "bbox": [
                259.7289733886719,
                0.8625134825706482,
                437.90887451171875,
                199.37521362304688
              ]
            },
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.9007880687713623,
              "bbox": [
                122.66709899902344,
                183.6483612060547,
                601.8428344726562,
                333.47344970703125
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7152167558670044,
              "bbox": [
                153.59326171875,
                0.5973639488220215,
                325.0014953613281,
                195.76431274414062
              ]
            },
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5324564576148987,
              "bbox": [
                0.0,
                177.54306030273438,
                99.115478515625,
                357.0841979980469
              ]
            }
          ],
          "unique_tracks": [
            922,
            943,
            919,
            946
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            12086,
            12090
          ],
          "representative_frame": 12086,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 100
    },
    {
      "second": 403,
      "time_range": [
        403,
        403.999
      ],
      "frame_range": [
        12091,
        12120
      ],
      "unified_description": "1-second scene, showing a man holding a fish in his hands, taken with a shaky camera, wide-angle lens, and possibly other objects/people present in the background.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:09",
        "processing_time": 2.87,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12105,
          "frame_range": [
            12101,
            12105
          ],
          "description": "a man holding a fish in his hands",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.86
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12091,
            12095
          ],
          "representative_frame": 12091,
          "detections": [
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.44816598296165466,
              "bbox": [
                257.2254943847656,
                1.0236424207687378,
                439.0382995605469,
                199.7995147705078
              ]
            },
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.9181148409843445,
              "bbox": [
                119.57325744628906,
                185.001953125,
                602.1900634765625,
                337.6062316894531
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5528766512870789,
              "bbox": [
                184.5510711669922,
                0.8747754096984863,
                374.2711486816406,
                197.5193634033203
              ]
            },
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5005162954330444,
              "bbox": [
                0.0,
                169.1246795654297,
                102.8758773803711,
                357.8267822265625
              ]
            }
          ],
          "unique_tracks": [
            922,
            943,
            919,
            946
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            12096,
            12100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12101,
            12105
          ],
          "representative_frame": 12101,
          "detections": [
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.12706787884235382,
              "bbox": [
                263.1551818847656,
                0.8070038557052612,
                444.36785888671875,
                196.8279571533203
              ]
            },
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.9030271768569946,
              "bbox": [
                112.43359375,
                177.16114807128906,
                614.7584838867188,
                338.5537414550781
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6797793507575989,
              "bbox": [
                201.70196533203125,
                0.9091566205024719,
                401.4057922363281,
                194.72276306152344
              ]
            },
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6299303770065308,
              "bbox": [
                0.0,
                163.5457305908203,
                104.9444808959961,
                357.983642578125
              ]
            },
            {
              "track_id": 947,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3761410713195801,
              "bbox": [
                0.0,
                312.13153076171875,
                78.2944564819336,
                359.4364013671875
              ]
            }
          ],
          "unique_tracks": [
            922,
            943,
            919,
            946,
            947
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            12106,
            12110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12111,
            12115
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.45858272910118103,
              "bbox": [
                261.38232421875,
                0.9530689120292664,
                443.503173828125,
                194.2132110595703
              ]
            },
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.7550972104072571,
              "bbox": [
                130.8346710205078,
                185.2015838623047,
                599.35693359375,
                337.75341796875
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4525723159313202,
              "bbox": [
                200.47203063964844,
                1.1135356426239014,
                410.7212829589844,
                193.1533660888672
              ]
            },
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6505200266838074,
              "bbox": [
                0.0,
                159.3538055419922,
                106.51348114013672,
                357.4729919433594
              ]
            },
            {
              "track_id": 947,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4231867790222168,
              "bbox": [
                0.0,
                307.1229553222656,
                83.41094970703125,
                359.4133605957031
              ]
            }
          ],
          "unique_tracks": [
            922,
            943,
            919,
            946,
            947
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            12116,
            12120
          ],
          "representative_frame": 12116,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 100
    },
    {
      "second": 404,
      "time_range": [
        404,
        404.999
      ],
      "frame_range": [
        12121,
        12150
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:10",
        "processing_time": 2.08,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12135,
          "frame_range": [
            12131,
            12135
          ],
          "description": "a man holding a fish in his hands",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.08
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12121,
            12125
          ],
          "representative_frame": 12121,
          "detections": [
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6177038550376892,
              "bbox": [
                259.75372314453125,
                0.9887244701385498,
                447.59576416015625,
                198.0623016357422
              ]
            },
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8923863172531128,
              "bbox": [
                136.28907775878906,
                183.07949829101562,
                601.8241577148438,
                337.2585144042969
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.40473005175590515,
              "bbox": [
                175.86659240722656,
                1.0352461338043213,
                392.1868591308594,
                197.5785369873047
              ]
            },
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7149309515953064,
              "bbox": [
                0.0,
                160.53640747070312,
                102.59191131591797,
                357.3363037109375
              ]
            },
            {
              "track_id": 947,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3791058361530304,
              "bbox": [
                0.0,
                304.932861328125,
                84.1893310546875,
                359.2225341796875
              ]
            }
          ],
          "unique_tracks": [
            922,
            943,
            919,
            946,
            947
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            12126,
            12130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12131,
            12135
          ],
          "representative_frame": 12131,
          "detections": [
            {
              "track_id": 922,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.10321862250566483,
              "bbox": [
                269.6438903808594,
                0.8730441927909851,
                447.9964294433594,
                185.33628845214844
              ]
            },
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8850065469741821,
              "bbox": [
                171.28033447265625,
                166.5735626220703,
                564.742431640625,
                296.1516418457031
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8103844523429871,
              "bbox": [
                193.48033142089844,
                1.134682059288025,
                408.7372741699219,
                186.20957946777344
              ]
            },
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6860756278038025,
              "bbox": [
                0.0,
                161.5877227783203,
                102.21349334716797,
                356.9801330566406
              ]
            },
            {
              "track_id": 947,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2436869591474533,
              "bbox": [
                0.0,
                302.67376708984375,
                85.1720199584961,
                359.3236999511719
              ]
            }
          ],
          "unique_tracks": [
            922,
            943,
            919,
            946,
            947
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            12136,
            12140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12141,
            12145
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.9143938422203064,
              "bbox": [
                163.2901153564453,
                130.56700134277344,
                547.4283447265625,
                256.934814453125
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8485100269317627,
              "bbox": [
                202.49522399902344,
                1.0058526992797852,
                399.5040588378906,
                156.26669311523438
              ]
            },
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7309240102767944,
              "bbox": [
                0.0,
                159.01731872558594,
                106.53968048095703,
                357.51239013671875
              ]
            },
            {
              "track_id": 947,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3730149269104004,
              "bbox": [
                0.5129930973052979,
                302.5249328613281,
                95.13709259033203,
                359.5820617675781
              ]
            }
          ],
          "unique_tracks": [
            943,
            919,
            946,
            947
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            12146,
            12150
          ],
          "representative_frame": 12146,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 101
    },
    {
      "second": 405,
      "time_range": [
        405,
        405.999
      ],
      "frame_range": [
        12151,
        12180
      ],
      "unified_description": "1-second scene with a man holding up a fish in his hand. The camera is positioned above, mounted on top of his head, or attached to his body-mounted. The camera has wide-angle lens characteristics, possibly showing some distortion. The image appears to have been taken outdoors, as the man seems to be moving with the fish.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:12",
        "processing_time": 3.51,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12165,
          "frame_range": [
            12161,
            12165
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.01
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12151,
            12155
          ],
          "representative_frame": 12151,
          "detections": [
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8766014575958252,
              "bbox": [
                183.60324096679688,
                129.01370239257812,
                524.9407958984375,
                239.69766235351562
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7475961446762085,
              "bbox": [
                188.8560333251953,
                1.1004774570465088,
                392.1010437011719,
                149.2368621826172
              ]
            },
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5050248503684998,
              "bbox": [
                3.29929256439209,
                160.36187744140625,
                113.95506286621094,
                356.9414978027344
              ]
            },
            {
              "track_id": 947,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.343160480260849,
              "bbox": [
                8.752938270568848,
                299.6543884277344,
                108.95336151123047,
                359.25665283203125
              ]
            },
            {
              "track_id": 948,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4578302204608917,
              "bbox": [
                135.76559448242188,
                0.9244629144668579,
                440.2452392578125,
                314.9299011230469
              ]
            }
          ],
          "unique_tracks": [
            943,
            919,
            946,
            947,
            948
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            12156,
            12160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12161,
            12165
          ],
          "representative_frame": 12161,
          "detections": [
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8487934470176697,
              "bbox": [
                170.9711151123047,
                112.95860290527344,
                540.8229370117188,
                233.0901336669922
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8401418328285217,
              "bbox": [
                182.70297241210938,
                1.054069995880127,
                397.921142578125,
                149.4261474609375
              ]
            },
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6831570863723755,
              "bbox": [
                13.30187702178955,
                170.96414184570312,
                120.3403549194336,
                356.2077331542969
              ]
            },
            {
              "track_id": 947,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3637933135032654,
              "bbox": [
                19.079797744750977,
                301.6486511230469,
                119.08407592773438,
                359.336669921875
              ]
            },
            {
              "track_id": 948,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.13616709411144257,
              "bbox": [
                136.5400848388672,
                1.2769383192062378,
                451.1643371582031,
                325.7915344238281
              ]
            }
          ],
          "unique_tracks": [
            943,
            919,
            946,
            947,
            948
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            12166,
            12170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12171,
            12175
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8331392407417297,
              "bbox": [
                195.6958770751953,
                127.03952026367188,
                517.6596069335938,
                229.09420776367188
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6821277737617493,
              "bbox": [
                178.33480834960938,
                1.0449072122573853,
                402.4371337890625,
                148.670166015625
              ]
            },
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7274566292762756,
              "bbox": [
                17.995141983032227,
                182.08468627929688,
                122.26449584960938,
                357.1136779785156
              ]
            },
            {
              "track_id": 947,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.24570398032665253,
              "bbox": [
                25.42043685913086,
                308.90240478515625,
                117.72594451904297,
                359.7812194824219
              ]
            },
            {
              "track_id": 948,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4534453749656677,
              "bbox": [
                134.21058654785156,
                1.1116313934326172,
                449.04296875,
                325.6680908203125
              ]
            }
          ],
          "unique_tracks": [
            943,
            919,
            946,
            947,
            948
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            12176,
            12180
          ],
          "representative_frame": 12176,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 101
    },
    {
      "second": 406,
      "time_range": [
        406,
        406.999
      ],
      "frame_range": [
        12181,
        12210
      ],
      "unified_description": "1-second scene with a man holdinging a fish in his hand",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:12",
        "processing_time": 2.88,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12195,
          "frame_range": [
            12191,
            12195
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.6
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12181,
            12185
          ],
          "representative_frame": 12181,
          "detections": [
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8060550093650818,
              "bbox": [
                202.36911010742188,
                131.4095001220703,
                508.5513000488281,
                226.6009521484375
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7150766253471375,
              "bbox": [
                178.3195343017578,
                0.8406194448471069,
                409.99560546875,
                148.69476318359375
              ]
            },
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8057799339294434,
              "bbox": [
                15.88998794555664,
                177.5680389404297,
                125.18569946289062,
                357.2496643066406
              ]
            },
            {
              "track_id": 947,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.1587374061346054,
              "bbox": [
                27.28887939453125,
                313.4713134765625,
                115.80609893798828,
                359.95123291015625
              ]
            },
            {
              "track_id": 948,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.34735721349716187,
              "bbox": [
                138.4878387451172,
                1.292992353439331,
                453.84521484375,
                326.725341796875
              ]
            }
          ],
          "unique_tracks": [
            943,
            919,
            946,
            947,
            948
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            12186,
            12190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12191,
            12195
          ],
          "representative_frame": 12191,
          "detections": [
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.843788206577301,
              "bbox": [
                194.81936645507812,
                131.7437744140625,
                511.7152099609375,
                229.14874267578125
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7792651653289795,
              "bbox": [
                173.0088348388672,
                0.8367149233818054,
                410.8062744140625,
                147.89923095703125
              ]
            },
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.741373598575592,
              "bbox": [
                13.594393730163574,
                176.66604614257812,
                125.01741027832031,
                356.5881652832031
              ]
            },
            {
              "track_id": 947,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.11637936532497406,
              "bbox": [
                18.474502563476562,
                308.3955383300781,
                118.70771026611328,
                360.0
              ]
            },
            {
              "track_id": 948,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.38045912981033325,
              "bbox": [
                149.05929565429688,
                1.1376838684082031,
                439.1315002441406,
                298.62750244140625
              ]
            }
          ],
          "unique_tracks": [
            943,
            919,
            946,
            947,
            948
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            12196,
            12200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12201,
            12205
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8848353624343872,
              "bbox": [
                191.3635711669922,
                128.23019409179688,
                512.3222045898438,
                226.0496063232422
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6076945066452026,
              "bbox": [
                162.749267578125,
                0.7663450837135315,
                408.7941589355469,
                148.42605590820312
              ]
            },
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7943233251571655,
              "bbox": [
                9.346263885498047,
                176.0937042236328,
                122.4376449584961,
                356.91754150390625
              ]
            },
            {
              "track_id": 947,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.1358083188533783,
              "bbox": [
                11.265387535095215,
                303.4449768066406,
                121.06193542480469,
                359.480712890625
              ]
            },
            {
              "track_id": 948,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4055285155773163,
              "bbox": [
                132.71141052246094,
                1.1083658933639526,
                439.53680419921875,
                315.4123840332031
              ]
            }
          ],
          "unique_tracks": [
            943,
            919,
            946,
            947,
            948
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            12206,
            12210
          ],
          "representative_frame": 12206,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 101
    },
    {
      "second": 407,
      "time_range": [
        407,
        407.999
      ],
      "frame_range": [
        12211,
        12240
      ],
      "unified_description": "\nFirst-person view from an action camera mounted on a person's head who is walking through a city street. There are several objects and people visible in the image, such as a man holding a fish in his hand. The scene also includes elements of the surrounding urban environment.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:14",
        "processing_time": 3.31,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12225,
          "frame_range": [
            12221,
            12225
          ],
          "description": "a man is holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.8
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12211,
            12215
          ],
          "representative_frame": 12211,
          "detections": [
            {
              "track_id": 943,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8578320741653442,
              "bbox": [
                192.71893310546875,
                126.12644958496094,
                509.12762451171875,
                221.3618621826172
              ]
            },
            {
              "track_id": 919,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6637211441993713,
              "bbox": [
                165.44065856933594,
                0.5961001515388489,
                413.2187194824219,
                146.4856414794922
              ]
            },
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6283068656921387,
              "bbox": [
                2.516732931137085,
                173.5994415283203,
                116.97700500488281,
                357.15496826171875
              ]
            },
            {
              "track_id": 947,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.21294234693050385,
              "bbox": [
                0.0,
                296.197509765625,
                121.47053527832031,
                359.4432373046875
              ]
            },
            {
              "track_id": 948,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5611017942428589,
              "bbox": [
                130.13961791992188,
                1.0617011785507202,
                447.755615234375,
                328.365478515625
              ]
            }
          ],
          "unique_tracks": [
            943,
            919,
            946,
            947,
            948
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            12216,
            12220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12221,
            12225
          ],
          "representative_frame": 12221,
          "detections": [
            {
              "track_id": 946,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.1685246229171753,
              "bbox": [
                4.082329750061035,
                200.9029083251953,
                102.42121887207031,
                356.9996032714844
              ]
            },
            {
              "track_id": 948,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.47082141041755676,
              "bbox": [
                182.39341735839844,
                0.42060327529907227,
                479.03082275390625,
                299.17047119140625
              ]
            }
          ],
          "unique_tracks": [
            946,
            948
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            12226,
            12230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12231,
            12235
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 948,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8461471199989319,
              "bbox": [
                271.47711181640625,
                1.0326554775238037,
                602.421630859375,
                336.4095458984375
              ]
            }
          ],
          "unique_tracks": [
            948
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12236,
            12240
          ],
          "representative_frame": 12236,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 101
    },
    {
      "second": 408,
      "time_range": [
        408,
        408.999
      ],
      "frame_range": [
        12241,
        12270
      ],
      "unified_description": "\nA man with a fish on a hook is standing in front of a crowd of people. The camera capturing the event is mounted on a tripod, providing a stable view of the scene. The image shows the man holding up the fish with satisfaction, as others watch on with interest.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:17",
        "processing_time": 3.12,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12255,
          "frame_range": [
            12251,
            12255
          ],
          "description": "a man is holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.33
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12241,
            12245
          ],
          "representative_frame": 12241,
          "detections": [
            {
              "track_id": 948,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.22492602467536926,
              "bbox": [
                292.5064392089844,
                1.628788948059082,
                634.1874389648438,
                349.216796875
              ]
            }
          ],
          "unique_tracks": [
            948
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12246,
            12250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12251,
            12255
          ],
          "representative_frame": 12251,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            12256,
            12260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12261,
            12265
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            12266,
            12270
          ],
          "representative_frame": 12266,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 102
    },
    {
      "second": 409,
      "time_range": [
        409,
        409.999
      ],
      "frame_range": [
        12271,
        12300
      ],
      "unified_description": "1-second scene showing a man standing on a cliff with ocean waves crashing below. The camera is mounted on a tripod providing stable footage.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:17",
        "processing_time": 3.55,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12285,
          "frame_range": [
            12281,
            12285
          ],
          "description": "a person is standing on a rock in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.35
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12271,
            12275
          ],
          "representative_frame": 12271,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            12276,
            12280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12281,
            12285
          ],
          "representative_frame": 12281,
          "detections": [
            {
              "track_id": 948,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.8233508467674255,
              "bbox": [
                338.7979431152344,
                1.965221643447876,
                584.2132568359375,
                233.04322814941406
              ]
            }
          ],
          "unique_tracks": [
            948
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            12286,
            12290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12291,
            12295
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 948,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6839505434036255,
              "bbox": [
                360.45947265625,
                37.801143646240234,
                600.016357421875,
                255.22573852539062
              ]
            }
          ],
          "unique_tracks": [
            948
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12296,
            12300
          ],
          "representative_frame": 12296,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 102
    },
    {
      "second": 410,
      "time_range": [
        410,
        410.999
      ],
      "frame_range": [
        12301,
        12330
      ],
      "unified_description": "1-second scene where a person is walking on a path that also includes other people, objects and natural outdoor lighting.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:18",
        "processing_time": 3.13,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12315,
          "frame_range": [
            12311,
            12315
          ],
          "description": "a person is walking on a path",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.53
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12301,
            12305
          ],
          "representative_frame": 12301,
          "detections": [
            {
              "track_id": 948,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.35649728775024414,
              "bbox": [
                410.54412841796875,
                81.75923156738281,
                597.1990966796875,
                240.04177856445312
              ]
            }
          ],
          "unique_tracks": [
            948
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12306,
            12310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12311,
            12315
          ],
          "representative_frame": 12311,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            12316,
            12320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12321,
            12325
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            12326,
            12330
          ],
          "representative_frame": 12326,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 102
    },
    {
      "second": 411,
      "time_range": [
        411,
        411.999
      ],
      "frame_range": [
        12331,
        12360
      ],
      "unified_description": "1-second scene: A small fish swimming in the water",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:20",
        "processing_time": 2.27,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12345,
          "frame_range": [
            12341,
            12345
          ],
          "description": "a small fish swimming in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.78
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12331,
            12335
          ],
          "representative_frame": 12331,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            12336,
            12340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12341,
            12345
          ],
          "representative_frame": 12341,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            12346,
            12350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12351,
            12355
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            12356,
            12360
          ],
          "representative_frame": 12356,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 102
    },
    {
      "second": 412,
      "time_range": [
        412,
        412.999
      ],
      "frame_range": [
        12361,
        12390
      ],
      "unified_description": "360 degrees first-person perspective shot of a man standing in the water, with his feet in the water. The camera is mounted on a tripod, providing stable footage.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:22",
        "processing_time": 2.74,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12375,
          "frame_range": [
            12371,
            12375
          ],
          "description": "a man is standing in the water with his feet in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.48
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12361,
            12365
          ],
          "representative_frame": 12361,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            12366,
            12370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12371,
            12375
          ],
          "representative_frame": 12371,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            12376,
            12380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12381,
            12385
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            12386,
            12390
          ],
          "representative_frame": 12386,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 103
    },
    {
      "second": 413,
      "time_range": [
        413,
        413.999
      ],
      "frame_range": [
        12391,
        12420
      ],
      "unified_description": "3rd person perspective camera on a persons body capturing their outdoor activities.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:22",
        "processing_time": 2.75,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12405,
          "frame_range": [
            12401,
            12405
          ],
          "description": "a man is standing in the water with his feet in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.23
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12391,
            12395
          ],
          "representative_frame": 12391,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            12396,
            12400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12401,
            12405
          ],
          "representative_frame": 12401,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            12406,
            12410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12411,
            12415
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            12416,
            12420
          ],
          "representative_frame": 12416,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 103
    },
    {
      "second": 414,
      "time_range": [
        414,
        414.999
      ],
      "frame_range": [
        12421,
        12450
      ],
      "unified_description": "1-second scene with a man fishing in the water",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:23",
        "processing_time": 2.37,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12435,
          "frame_range": [
            12431,
            12435
          ],
          "description": "a man is fishing in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12421,
            12425
          ],
          "representative_frame": 12421,
          "detections": [
            {
              "track_id": 962,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9214028120040894,
              "bbox": [
                4.4122819900512695,
                8.534875869750977,
                485.86376953125,
                355.5207824707031
              ]
            }
          ],
          "unique_tracks": [
            962
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12426,
            12430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12431,
            12435
          ],
          "representative_frame": 12431,
          "detections": [
            {
              "track_id": 962,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9366846680641174,
              "bbox": [
                12.096413612365723,
                6.240378379821777,
                495.1866760253906,
                354.824951171875
              ]
            }
          ],
          "unique_tracks": [
            962
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            12436,
            12440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12441,
            12445
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 962,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9290103912353516,
              "bbox": [
                6.54652214050293,
                1.657086968421936,
                496.2515563964844,
                355.3695068359375
              ]
            }
          ],
          "unique_tracks": [
            962
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12446,
            12450
          ],
          "representative_frame": 12446,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 103
    },
    {
      "second": 415,
      "time_range": [
        415,
        415.999
      ],
      "frame_range": [
        12451,
        12480
      ],
      "unified_description": "5-second scene showing man standing next to river, reeling in his line, with fish visible in water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:25",
        "processing_time": 2.49,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12465,
          "frame_range": [
            12461,
            12465
          ],
          "description": "a man is fishing on the river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.18
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12451,
            12455
          ],
          "representative_frame": 12451,
          "detections": [
            {
              "track_id": 962,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9313098788261414,
              "bbox": [
                8.937603950500488,
                0.0,
                500.4054870605469,
                355.4239196777344
              ]
            },
            {
              "track_id": 964,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6550584435462952,
              "bbox": [
                421.996826171875,
                200.53562927246094,
                459.8194274902344,
                269.18145751953125
              ]
            }
          ],
          "unique_tracks": [
            962,
            964
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            12456,
            12460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12461,
            12465
          ],
          "representative_frame": 12461,
          "detections": [
            {
              "track_id": 962,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9455447196960449,
              "bbox": [
                14.153524398803711,
                0.0,
                504.50543212890625,
                355.4831848144531
              ]
            },
            {
              "track_id": 964,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7606724500656128,
              "bbox": [
                424.855224609375,
                200.86300659179688,
                462.1231689453125,
                268.58673095703125
              ]
            }
          ],
          "unique_tracks": [
            962,
            964
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            12466,
            12470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12471,
            12475
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 943,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9371401071548462,
              "bbox": [
                0.0,
                25.747360229492188,
                629.9320678710938,
                286.8373107910156
              ]
            }
          ],
          "unique_tracks": [
            943
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12476,
            12480
          ],
          "representative_frame": 12476,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 103
    },
    {
      "second": 416,
      "time_range": [
        416,
        416.999
      ],
      "frame_range": [
        12481,
        12510
      ],
      "unified_description": "1-second scene where a man is fishing in the water with a rod. The image contains a total of 2 unique tracks.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:26",
        "processing_time": 2.77,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12495,
          "frame_range": [
            12491,
            12495
          ],
          "description": "a man fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.44
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12481,
            12485
          ],
          "representative_frame": 12481,
          "detections": [
            {
              "track_id": 965,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6330925226211548,
              "bbox": [
                7.994848251342773,
                130.91758728027344,
                42.681365966796875,
                223.82305908203125
              ]
            }
          ],
          "unique_tracks": [
            965
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12486,
            12490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12491,
            12495
          ],
          "representative_frame": 12491,
          "detections": [
            {
              "track_id": 965,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5158767104148865,
              "bbox": [
                6.961627960205078,
                129.2787322998047,
                43.3553466796875,
                227.05538940429688
              ]
            },
            {
              "track_id": 966,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9217578172683716,
              "bbox": [
                226.8941192626953,
                22.378643035888672,
                356.94805908203125,
                291.0577392578125
              ]
            }
          ],
          "unique_tracks": [
            965,
            966
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            12496,
            12500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12501,
            12505
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 965,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5152073502540588,
              "bbox": [
                7.184463024139404,
                128.76246643066406,
                43.7056884765625,
                227.30528259277344
              ]
            },
            {
              "track_id": 966,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9256077408790588,
              "bbox": [
                220.86163330078125,
                22.244691848754883,
                350.0965881347656,
                290.8054504394531
              ]
            }
          ],
          "unique_tracks": [
            965,
            966
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            12506,
            12510
          ],
          "representative_frame": 12506,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 104
    },
    {
      "second": 417,
      "time_range": [
        417,
        417.999
      ],
      "frame_range": [
        12511,
        12540
      ],
      "unified_description": "2 people are standing in the background, 1 person is fishing, there's a dog in the scene, the camera is mounted on a backpack, and the image has a wide-angle perspective.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:27",
        "processing_time": 3.61,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12525,
          "frame_range": [
            12521,
            12525
          ],
          "description": "a man fishing on a lake with a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.12
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12511,
            12515
          ],
          "representative_frame": 12511,
          "detections": [
            {
              "track_id": 965,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.45170581340789795,
              "bbox": [
                7.964227199554443,
                126.66844177246094,
                45.194862365722656,
                227.8182373046875
              ]
            },
            {
              "track_id": 966,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9049480557441711,
              "bbox": [
                212.1490478515625,
                24.145273208618164,
                339.3638000488281,
                291.2141418457031
              ]
            }
          ],
          "unique_tracks": [
            965,
            966
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            12516,
            12520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12521,
            12525
          ],
          "representative_frame": 12521,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            12526,
            12530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12531,
            12535
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 970,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9022635817527771,
              "bbox": [
                86.71990203857422,
                124.20619201660156,
                192.7272491455078,
                352.24261474609375
              ]
            }
          ],
          "unique_tracks": [
            970
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12536,
            12540
          ],
          "representative_frame": 12536,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 104
    },
    {
      "second": 418,
      "time_range": [
        418,
        418.999
      ],
      "frame_range": [
        12541,
        12570
      ],
      "unified_description": "1-second scene including a man fishing in the water near a mountain, with object detections summary covering both content and technical aspects of the video.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:29",
        "processing_time": 2.63,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12555,
          "frame_range": [
            12551,
            12555
          ],
          "description": "a man is fishing in the water near a mountain",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.91
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12541,
            12545
          ],
          "representative_frame": 12541,
          "detections": [
            {
              "track_id": 970,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.774127185344696,
              "bbox": [
                93.1593017578125,
                126.11869812011719,
                194.93692016601562,
                345.769287109375
              ]
            }
          ],
          "unique_tracks": [
            970
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12546,
            12550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12551,
            12555
          ],
          "representative_frame": 12551,
          "detections": [
            {
              "track_id": 970,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9189651608467102,
              "bbox": [
                94.23255157470703,
                124.18043518066406,
                200.5841064453125,
                353.9425964355469
              ]
            }
          ],
          "unique_tracks": [
            970
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            12556,
            12560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12561,
            12565
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 970,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9246941208839417,
              "bbox": [
                102.34172058105469,
                123.49021911621094,
                210.10304260253906,
                356.079345703125
              ]
            }
          ],
          "unique_tracks": [
            970
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12566,
            12570
          ],
          "representative_frame": 12566,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 104
    },
    {
      "second": 419,
      "time_range": [
        419,
        419.999
      ],
      "frame_range": [
        12571,
        12600
      ],
      "unified_description": "1-second scene including a person fishing in a river and a backpack nearby. The scene is captured using a camera with a wide-angle lens, mounted on a tripod, showing some distortion.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:30",
        "processing_time": 2.92,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12585,
          "frame_range": [
            12581,
            12585
          ],
          "description": "a man fishing on the river with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12571,
            12575
          ],
          "representative_frame": 12571,
          "detections": [
            {
              "track_id": 970,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9209869503974915,
              "bbox": [
                103.54610443115234,
                130.40003967285156,
                210.458251953125,
                357.6304626464844
              ]
            }
          ],
          "unique_tracks": [
            970
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12576,
            12580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12581,
            12585
          ],
          "representative_frame": 12581,
          "detections": [
            {
              "track_id": 962,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8854832649230957,
              "bbox": [
                270.41461181640625,
                17.705965042114258,
                640.0,
                354.3382873535156
              ]
            }
          ],
          "unique_tracks": [
            962
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            12586,
            12590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12591,
            12595
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 962,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9325268864631653,
              "bbox": [
                323.766357421875,
                6.189958572387695,
                640.0,
                345.7720947265625
              ]
            }
          ],
          "unique_tracks": [
            962
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12596,
            12600
          ],
          "representative_frame": 12596,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 104
    },
    {
      "second": 420,
      "time_range": [
        420,
        420.999
      ],
      "frame_range": [
        12601,
        12630
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:30",
        "processing_time": 2.23,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12615,
          "frame_range": [
            12611,
            12615
          ],
          "description": "a man is standing on the shore of a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.68
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12601,
            12605
          ],
          "representative_frame": 12601,
          "detections": [
            {
              "track_id": 962,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8999824523925781,
              "bbox": [
                394.8292236328125,
                2.446855068206787,
                640.0,
                314.7936706542969
              ]
            }
          ],
          "unique_tracks": [
            962
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12606,
            12610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12611,
            12615
          ],
          "representative_frame": 12611,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            12616,
            12620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12621,
            12625
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 971,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.715599536895752,
              "bbox": [
                571.8282470703125,
                109.31846618652344,
                636.863037109375,
                276.9215087890625
              ]
            }
          ],
          "unique_tracks": [
            971
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12626,
            12630
          ],
          "representative_frame": 12626,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 105
    },
    {
      "second": 421,
      "time_range": [
        421,
        421.999
      ],
      "frame_range": [
        12631,
        12660
      ],
      "unified_description": "1-second scene, shot with a wide-angle lens, capturing a man standing in the water near a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:32",
        "processing_time": 2.51,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12645,
          "frame_range": [
            12641,
            12645
          ],
          "description": "a man is standing in the water near a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.79
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12631,
            12635
          ],
          "representative_frame": 12631,
          "detections": [
            {
              "track_id": 971,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5375531315803528,
              "bbox": [
                568.3046875,
                114.76141357421875,
                636.9677124023438,
                291.4324645996094
              ]
            }
          ],
          "unique_tracks": [
            971
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12636,
            12640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12641,
            12645
          ],
          "representative_frame": 12641,
          "detections": [
            {
              "track_id": 971,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7148895263671875,
              "bbox": [
                569.0822143554688,
                134.42221069335938,
                634.7830200195312,
                302.5917663574219
              ]
            }
          ],
          "unique_tracks": [
            971
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            12646,
            12650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12651,
            12655
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 971,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6881610751152039,
              "bbox": [
                574.2244873046875,
                145.3658905029297,
                635.7977905273438,
                302.28472900390625
              ]
            }
          ],
          "unique_tracks": [
            971
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12656,
            12660
          ],
          "representative_frame": 12656,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 105
    },
    {
      "second": 422,
      "time_range": [
        422,
        422.999
      ],
      "frame_range": [
        12661,
        12690
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:34",
        "processing_time": 2.1,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12675,
          "frame_range": [
            12671,
            12675
          ],
          "description": "a person is holding a fish in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.21
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12661,
            12665
          ],
          "representative_frame": 12661,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            12666,
            12670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12671,
            12675
          ],
          "representative_frame": 12671,
          "detections": [
            {
              "track_id": 970,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7704377770423889,
              "bbox": [
                124.95731353759766,
                242.91331481933594,
                197.16444396972656,
                357.3136901855469
              ]
            }
          ],
          "unique_tracks": [
            970
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            12676,
            12680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12681,
            12685
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 966,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9060583710670471,
              "bbox": [
                81.70500946044922,
                170.82460021972656,
                201.63658142089844,
                355.1309814453125
              ]
            }
          ],
          "unique_tracks": [
            966
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12686,
            12690
          ],
          "representative_frame": 12686,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 105
    },
    {
      "second": 423,
      "time_range": [
        423,
        423.999
      ],
      "frame_range": [
        12691,
        12720
      ],
      "unified_description": "\n(Based on the image descriptions and object detections from above)",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:34",
        "processing_time": 2.51,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12705,
          "frame_range": [
            12701,
            12705
          ],
          "description": "a person holding a small fish in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.19
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12691,
            12695
          ],
          "representative_frame": 12691,
          "detections": [
            {
              "track_id": 943,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9315568804740906,
              "bbox": [
                0.0,
                84.85448455810547,
                435.6896057128906,
                352.0807189941406
              ]
            }
          ],
          "unique_tracks": [
            943
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12696,
            12700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12701,
            12705
          ],
          "representative_frame": 12701,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            12706,
            12710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12711,
            12715
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 973,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7296276092529297,
              "bbox": [
                109.51897430419922,
                0.12058715522289276,
                321.03009033203125,
                167.897216796875
              ]
            }
          ],
          "unique_tracks": [
            973
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12716,
            12720
          ],
          "representative_frame": 12716,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 105
    },
    {
      "second": 424,
      "time_range": [
        424,
        424.999
      ],
      "frame_range": [
        12721,
        12750
      ],
      "unified_description": "1-second scene including a person walking by a river, shot with a fisheye lens creating distortion in the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:36",
        "processing_time": 2.76,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12735,
          "frame_range": [
            12731,
            12735
          ],
          "description": "a man is walking along a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.53
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12721,
            12725
          ],
          "representative_frame": 12721,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            12726,
            12730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12731,
            12735
          ],
          "representative_frame": 12731,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            12736,
            12740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12741,
            12745
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            12746,
            12750
          ],
          "representative_frame": 12746,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 106
    },
    {
      "second": 425,
      "time_range": [
        425,
        425.999
      ],
      "frame_range": [
        12751,
        12780
      ],
      "unified_description": "4 people, 3 cars, 2 boats, 1 airplane",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:37",
        "processing_time": 2.35,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12765,
          "frame_range": [
            12761,
            12765
          ],
          "description": "a man is standing on the edge of a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.33
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12751,
            12755
          ],
          "representative_frame": 12751,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            12756,
            12760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12761,
            12765
          ],
          "representative_frame": 12761,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            12766,
            12770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12771,
            12775
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            12776,
            12780
          ],
          "representative_frame": 12776,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 106
    },
    {
      "second": 426,
      "time_range": [
        426,
        426.999
      ],
      "frame_range": [
        12781,
        12810
      ],
      "unified_description": "\n\nBased on these image descriptions and object detections, provide a detailed description of the scene:\n\n1. A man is standing on the beach with his feet in the water. The camera captures this moment as the man appears to be enjoying the ocean view. Nearby, a dog can also be spotted by the water, possibly accompanying its owner. \n\nThe video is taken from a first-person perspective, providing an immersive experience for the viewer. The wide-angle lens of the camera captures not only the man and the dog but also the beautiful beach scenery, making it an ideal representation of a relaxing day at the seashore.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:40",
        "processing_time": 4.8,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12795,
          "frame_range": [
            12791,
            12795
          ],
          "description": "a man is standing on the beach with his feet in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.52
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12781,
            12785
          ],
          "representative_frame": 12781,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            12786,
            12790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12791,
            12795
          ],
          "representative_frame": 12791,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            12796,
            12800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12801,
            12805
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            12806,
            12810
          ],
          "representative_frame": 12806,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 106
    },
    {
      "second": 427,
      "time_range": [
        427,
        427.999
      ],
      "frame_range": [
        12811,
        12840
      ],
      "unified_description": "30 second video showing a person outside, possibly near water, with a fishing pole in their hand.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:41",
        "processing_time": 4.72,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12825,
          "frame_range": [
            12821,
            12825
          ],
          "description": "a man fishing on a lake with a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.68
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12811,
            12815
          ],
          "representative_frame": 12811,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            12816,
            12820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12821,
            12825
          ],
          "representative_frame": 12821,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            12826,
            12830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12831,
            12835
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 974,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8297407627105713,
              "bbox": [
                357.3246765136719,
                78.60157012939453,
                501.8819274902344,
                354.36773681640625
              ]
            }
          ],
          "unique_tracks": [
            974
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12836,
            12840
          ],
          "representative_frame": 12836,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 106
    },
    {
      "second": 428,
      "time_range": [
        428,
        428.999
      ],
      "frame_range": [
        12841,
        12870
      ],
      "unified_description": "\n\nThis is a video recording of a young boy fishing on the shore of a lake. The camera perspective appears to be first-person, indicating that it may have been taken using a head-mounted or body-mounted camera. The image captures details such as the body of water, the bank of the lake, and possibly some surrounding scenery. It is likely that this video was captured during daylight hours, providing ample light for a clear recording.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:43",
        "processing_time": 5.1,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12855,
          "frame_range": [
            12851,
            12855
          ],
          "description": "a young boy fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.83
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12841,
            12845
          ],
          "representative_frame": 12841,
          "detections": [
            {
              "track_id": 974,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6506072282791138,
              "bbox": [
                361.5093078613281,
                78.2098617553711,
                508.26837158203125,
                355.516357421875
              ]
            }
          ],
          "unique_tracks": [
            974
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12846,
            12850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12851,
            12855
          ],
          "representative_frame": 12851,
          "detections": [
            {
              "track_id": 974,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9418031573295593,
              "bbox": [
                334.40545654296875,
                81.26944732666016,
                480.83343505859375,
                357.7213134765625
              ]
            }
          ],
          "unique_tracks": [
            974
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            12856,
            12860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12861,
            12865
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 974,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9352626204490662,
              "bbox": [
                338.39703369140625,
                85.79678344726562,
                482.909423828125,
                358.4290771484375
              ]
            }
          ],
          "unique_tracks": [
            974
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12866,
            12870
          ],
          "representative_frame": 12866,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 107
    },
    {
      "second": 429,
      "time_range": [
        429,
        429.999
      ],
      "frame_range": [
        12871,
        12900
      ],
      "unified_description": "\n\nA first-person perspective shows a man fishing in a lake. The scene includes a fishing rod held by the person, the water body, some people nearby, and possibly nearby objects like a backpack or a boat. The camera positioning appears to be a body-mounted one, providing an immersive view of the environment.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:45",
        "processing_time": 3.48,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12885,
          "frame_range": [
            12881,
            12885
          ],
          "description": "a man fishing on a lake with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.32
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12871,
            12875
          ],
          "representative_frame": 12871,
          "detections": [
            {
              "track_id": 974,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9260829091072083,
              "bbox": [
                356.5150451660156,
                93.9354248046875,
                498.26220703125,
                358.9829406738281
              ]
            }
          ],
          "unique_tracks": [
            974
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12876,
            12880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12881,
            12885
          ],
          "representative_frame": 12881,
          "detections": [
            {
              "track_id": 974,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9146579504013062,
              "bbox": [
                421.7366027832031,
                101.94744873046875,
                559.1588134765625,
                358.2273864746094
              ]
            }
          ],
          "unique_tracks": [
            974
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            12886,
            12890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12891,
            12895
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 974,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9384490251541138,
              "bbox": [
                471.9744567871094,
                83.6240005493164,
                618.7902221679688,
                357.06072998046875
              ]
            }
          ],
          "unique_tracks": [
            974
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12896,
            12900
          ],
          "representative_frame": 12896,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 107
    },
    {
      "second": 430,
      "time_range": [
        430,
        430.999
      ],
      "frame_range": [
        12901,
        12930
      ],
      "unified_description": "\n1st person perspective showing a man in a hoodie standing by the water. The camera is stable and capturing the scene with no distortion.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:46",
        "processing_time": 3.65,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12915,
          "frame_range": [
            12911,
            12915
          ],
          "description": "a man in a hoodie is standing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.45
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12901,
            12905
          ],
          "representative_frame": 12901,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            12906,
            12910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12911,
            12915
          ],
          "representative_frame": 12911,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7242353558540344,
              "bbox": [
                264.955810546875,
                98.61967468261719,
                507.5181579589844,
                356.39990234375
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            12916,
            12920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12921,
            12925
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9197415113449097,
              "bbox": [
                239.6382293701172,
                52.95644760131836,
                524.77978515625,
                356.6227111816406
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12926,
            12930
          ],
          "representative_frame": 12926,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 107
    },
    {
      "second": 431,
      "time_range": [
        431,
        431.999
      ],
      "frame_range": [
        12931,
        12960
      ],
      "unified_description": "2 frames from a video showing a man standing on a beach",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:47",
        "processing_time": 2.4,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12945,
          "frame_range": [
            12941,
            12945
          ],
          "description": "a man standing on a beach next to a body of water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12931,
            12935
          ],
          "representative_frame": 12931,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9392400979995728,
              "bbox": [
                246.82345581054688,
                54.33443069458008,
                530.9937744140625,
                356.6268310546875
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12936,
            12940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12941,
            12945
          ],
          "representative_frame": 12941,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9008359909057617,
              "bbox": [
                269.3141174316406,
                59.71294403076172,
                548.7202758789062,
                355.8548889160156
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            12946,
            12950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12951,
            12955
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 978,
              "class_id": 17,
              "class_name": "horse",
              "confidence": 0.13246610760688782,
              "bbox": [
                223.9417724609375,
                15.060888290405273,
                546.7666015625,
                354.8122863769531
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12956,
            12960
          ],
          "representative_frame": 12956,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 107
    },
    {
      "second": 432,
      "time_range": [
        432,
        432.999
      ],
      "frame_range": [
        12961,
        12990
      ],
      "unified_description": "3D model of a scene with objects and people in it.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:49",
        "processing_time": 2.33,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 12975,
          "frame_range": [
            12971,
            12975
          ],
          "description": "a man in a black jacket is holding a knife",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.53
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12961,
            12965
          ],
          "representative_frame": 12961,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9172111749649048,
              "bbox": [
                165.70388793945312,
                0.32529541850090027,
                508.628662109375,
                354.1192321777344
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12966,
            12970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            12971,
            12975
          ],
          "representative_frame": 12971,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8733434677124023,
              "bbox": [
                174.73660278320312,
                4.681138038635254,
                519.21923828125,
                354.8619384765625
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            12976,
            12980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            12981,
            12985
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 978,
              "class_id": 20,
              "class_name": "elephant",
              "confidence": 0.12662850320339203,
              "bbox": [
                202.9203338623047,
                23.172119140625,
                541.2587890625,
                353.9800109863281
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            12986,
            12990
          ],
          "representative_frame": 12986,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 108
    },
    {
      "second": 433,
      "time_range": [
        433,
        433.999
      ],
      "frame_range": [
        12991,
        13020
      ],
      "unified_description": "\nThe image descriptions will be used to generate a written report from the assistant.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:50",
        "processing_time": 2.38,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13005,
          "frame_range": [
            13001,
            13005
          ],
          "description": "a man is standing in the back of a truck",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.63
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            12991,
            12995
          ],
          "representative_frame": 12991,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8464680910110474,
              "bbox": [
                151.69956970214844,
                5.197279453277588,
                525.09814453125,
                352.3700866699219
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            12996,
            13000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13001,
            13005
          ],
          "representative_frame": 13001,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7217274904251099,
              "bbox": [
                131.5797576904297,
                0.0,
                528.1198120117188,
                351.4490661621094
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            13006,
            13010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13011,
            13015
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.17267835140228271,
              "bbox": [
                137.3334197998047,
                0.0,
                551.4321899414062,
                354.0606994628906
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            13016,
            13020
          ],
          "representative_frame": 13016,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 108
    },
    {
      "second": 434,
      "time_range": [
        434,
        434.999
      ],
      "frame_range": [
        13021,
        13050
      ],
      "unified_description": "10-second scene including a person, a tent, and multiple bags",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:51",
        "processing_time": 2.53,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13035,
          "frame_range": [
            13031,
            13035
          ],
          "description": "a man is standing in a tent with many bags",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.45
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13021,
            13025
          ],
          "representative_frame": 13021,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            13026,
            13030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13031,
            13035
          ],
          "representative_frame": 13031,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8171871900558472,
              "bbox": [
                151.64158630371094,
                47.48293685913086,
                461.354736328125,
                326.6738586425781
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            13036,
            13040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13041,
            13045
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 988,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3740072250366211,
              "bbox": [
                54.15955352783203,
                194.9499053955078,
                167.19149780273438,
                286.8789367675781
              ]
            },
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8575024604797363,
              "bbox": [
                167.5626983642578,
                61.596702575683594,
                437.9029235839844,
                315.0567626953125
              ]
            }
          ],
          "unique_tracks": [
            988,
            978
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            13046,
            13050
          ],
          "representative_frame": 13046,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 108
    },
    {
      "second": 435,
      "time_range": [
        435,
        435.999
      ],
      "frame_range": [
        13051,
        13080
      ],
      "unified_description": "1-second scene with a man sitting under an outdoor tent. There are other objects in the vicinity, making the scene look lively. The camera is positioned in such a way that it captures the subject well without any distortion or artifacts.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:53",
        "processing_time": 3.03,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13065,
          "frame_range": [
            13061,
            13065
          ],
          "description": "a man is sitting under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.55
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13051,
            13055
          ],
          "representative_frame": 13051,
          "detections": [
            {
              "track_id": 988,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.23911520838737488,
              "bbox": [
                57.197601318359375,
                190.836669921875,
                175.9792022705078,
                287.5563659667969
              ]
            },
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8692996501922607,
              "bbox": [
                140.8657989501953,
                80.8747787475586,
                397.2486267089844,
                325.8446350097656
              ]
            }
          ],
          "unique_tracks": [
            988,
            978
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            13056,
            13060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13061,
            13065
          ],
          "representative_frame": 13061,
          "detections": [
            {
              "track_id": 988,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5051177144050598,
              "bbox": [
                56.88478088378906,
                188.864990234375,
                177.8140411376953,
                287.5562438964844
              ]
            },
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8730164170265198,
              "bbox": [
                128.61183166503906,
                85.26100158691406,
                379.61865234375,
                328.8659362792969
              ]
            }
          ],
          "unique_tracks": [
            988,
            978
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            13066,
            13070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13071,
            13075
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 988,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.18791964650154114,
              "bbox": [
                57.66881561279297,
                188.64178466796875,
                177.3187713623047,
                286.5862121582031
              ]
            },
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9033918976783752,
              "bbox": [
                147.36940002441406,
                81.12261199951172,
                396.79217529296875,
                330.2083740234375
              ]
            }
          ],
          "unique_tracks": [
            988,
            978
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            13076,
            13080
          ],
          "representative_frame": 13076,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 108
    },
    {
      "second": 436,
      "time_range": [
        436,
        436.999
      ],
      "frame_range": [
        13081,
        13110
      ],
      "unified_description": "2 men are relaxing under an umbrella in the outdoor setting. The camera is panning between different subjects in the scene, capturing various elements for the viewer to enjoy.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:54",
        "processing_time": 2.76,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13095,
          "frame_range": [
            13091,
            13095
          ],
          "description": "two men sitting under a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.19
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13081,
            13085
          ],
          "representative_frame": 13081,
          "detections": [
            {
              "track_id": 988,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2354881316423416,
              "bbox": [
                57.340763092041016,
                188.7622833251953,
                178.71932983398438,
                288.4452819824219
              ]
            },
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9115305542945862,
              "bbox": [
                155.08493041992188,
                76.82079315185547,
                403.71734619140625,
                331.3266296386719
              ]
            },
            {
              "track_id": 992,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5649937391281128,
              "bbox": [
                150.77674865722656,
                111.72471618652344,
                231.9789276123047,
                296.28466796875
              ]
            }
          ],
          "unique_tracks": [
            988,
            978,
            992
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            13086,
            13090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13091,
            13095
          ],
          "representative_frame": 13091,
          "detections": [
            {
              "track_id": 988,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2003394216299057,
              "bbox": [
                59.3348388671875,
                188.6815948486328,
                176.0420379638672,
                284.76141357421875
              ]
            },
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.881600558757782,
              "bbox": [
                162.2861785888672,
                75.16718292236328,
                406.5269470214844,
                331.9007263183594
              ]
            },
            {
              "track_id": 992,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.38611480593681335,
              "bbox": [
                156.39248657226562,
                115.73429870605469,
                234.6495819091797,
                292.8719787597656
              ]
            }
          ],
          "unique_tracks": [
            988,
            978,
            992
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            13096,
            13100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13101,
            13105
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 988,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3399012088775635,
              "bbox": [
                59.112953186035156,
                188.14695739746094,
                177.73556518554688,
                286.156982421875
              ]
            },
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8189592957496643,
              "bbox": [
                159.97219848632812,
                70.27647399902344,
                401.4414367675781,
                332.16375732421875
              ]
            },
            {
              "track_id": 992,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5004533529281616,
              "bbox": [
                156.72914123535156,
                106.82730102539062,
                241.92352294921875,
                299.88787841796875
              ]
            }
          ],
          "unique_tracks": [
            988,
            978,
            992
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            13106,
            13110
          ],
          "representative_frame": 13106,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 109
    },
    {
      "second": 437,
      "time_range": [
        437,
        437.999
      ],
      "frame_range": [
        13111,
        13140
      ],
      "unified_description": "\nA man sitting under a canopy outside with a group of people nearby. The image is captured using a fisheye lens, which gives it a characteristic distorted appearance. There are also some objects and people standing around in various positions, making the scene look busy and lively.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:56",
        "processing_time": 4.09,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13125,
          "frame_range": [
            13121,
            13125
          ],
          "description": "a man is sitting under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.88
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13111,
            13115
          ],
          "representative_frame": 13111,
          "detections": [
            {
              "track_id": 988,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.33020180463790894,
              "bbox": [
                59.246978759765625,
                186.43133544921875,
                178.25303649902344,
                285.1381530761719
              ]
            },
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8537053465843201,
              "bbox": [
                163.03445434570312,
                72.60161590576172,
                395.8677673339844,
                332.50439453125
              ]
            },
            {
              "track_id": 992,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2053162008523941,
              "bbox": [
                158.6361541748047,
                96.75933074951172,
                234.3448486328125,
                267.2919006347656
              ]
            }
          ],
          "unique_tracks": [
            988,
            978,
            992
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            13116,
            13120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13121,
            13125
          ],
          "representative_frame": 13121,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6552769541740417,
              "bbox": [
                147.1842803955078,
                72.44429016113281,
                375.6506042480469,
                332.54034423828125
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            13126,
            13130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13131,
            13135
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9061574935913086,
              "bbox": [
                146.70559692382812,
                72.66021728515625,
                369.58782958984375,
                332.63555908203125
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            13136,
            13140
          ],
          "representative_frame": 13136,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 109
    },
    {
      "second": 438,
      "time_range": [
        438,
        438.999
      ],
      "frame_range": [
        13141,
        13170
      ],
      "unified_description": "3-second scene showing a man under a tent in an outdoor setting.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:56",
        "processing_time": 2.83,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13155,
          "frame_range": [
            13151,
            13155
          ],
          "description": "a man is sitting under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.55
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13141,
            13145
          ],
          "representative_frame": 13141,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7995761632919312,
              "bbox": [
                155.90272521972656,
                76.44799041748047,
                369.97900390625,
                333.1321105957031
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            13146,
            13150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13151,
            13155
          ],
          "representative_frame": 13151,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8772068619728088,
              "bbox": [
                152.9651336669922,
                78.35052490234375,
                362.3879089355469,
                333.3594665527344
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            13156,
            13160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13161,
            13165
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7498247623443604,
              "bbox": [
                158.53956604003906,
                79.33975982666016,
                364.16815185546875,
                332.98065185546875
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            13166,
            13170
          ],
          "representative_frame": 13166,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 109
    },
    {
      "second": 439,
      "time_range": [
        439,
        439.999
      ],
      "frame_range": [
        13171,
        13200
      ],
      "unified_description": "2 people in scene, one inside a large grey tent. The camera is positioned on a tripod providing a stable view. Lighting appears to be natural outdoor lighting, and there are no visible technical artifacts.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:58",
        "processing_time": 2.92,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13185,
          "frame_range": [
            13181,
            13185
          ],
          "description": "a man is sitting under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13171,
            13175
          ],
          "representative_frame": 13171,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8452633023262024,
              "bbox": [
                167.5212860107422,
                81.097900390625,
                368.2020263671875,
                332.7388000488281
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            13176,
            13180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13181,
            13185
          ],
          "representative_frame": 13181,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8119087815284729,
              "bbox": [
                174.72080993652344,
                81.43067169189453,
                372.0002746582031,
                332.6814880371094
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            13186,
            13190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13191,
            13195
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.765457808971405,
              "bbox": [
                175.4889678955078,
                79.5569076538086,
                373.9112243652344,
                332.994140625
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            13196,
            13200
          ],
          "representative_frame": 13196,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 109
    },
    {
      "second": 440,
      "time_range": [
        440,
        440.999
      ],
      "frame_range": [
        13201,
        13230
      ],
      "unified_description": "3rd person's view of a crowded market with various objects and people in it.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:22:59",
        "processing_time": 2.39,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13215,
          "frame_range": [
            13211,
            13215
          ],
          "description": "a man is sitting under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.31
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13201,
            13205
          ],
          "representative_frame": 13201,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6527347564697266,
              "bbox": [
                182.5415802001953,
                78.33956909179688,
                380.7557678222656,
                333.51300048828125
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            13206,
            13210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13211,
            13215
          ],
          "representative_frame": 13211,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8232709169387817,
              "bbox": [
                181.4221649169922,
                78.46639251708984,
                377.86553955078125,
                333.68829345703125
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            13216,
            13220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13221,
            13225
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7695767879486084,
              "bbox": [
                183.0511932373047,
                80.57727813720703,
                375.7667541503906,
                333.3269958496094
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            13226,
            13230
          ],
          "representative_frame": 13226,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 110
    },
    {
      "second": 441,
      "time_range": [
        441,
        441.999
      ],
      "frame_range": [
        13231,
        13260
      ],
      "unified_description": "1-second scene featuring a person and a dog in a tent.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:00",
        "processing_time": 2.48,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13245,
          "frame_range": [
            13241,
            13245
          ],
          "description": "a man is sitting in a tent with a dog",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.32
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13231,
            13235
          ],
          "representative_frame": 13231,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8874138593673706,
              "bbox": [
                127.86713409423828,
                63.876583099365234,
                347.83526611328125,
                346.01507568359375
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            13236,
            13240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13241,
            13245
          ],
          "representative_frame": 13241,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8720919489860535,
              "bbox": [
                115.50828552246094,
                69.7435531616211,
                342.143310546875,
                350.2308654785156
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            13246,
            13250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13251,
            13255
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7747992873191833,
              "bbox": [
                92.03532409667969,
                73.66788482666016,
                318.1172790527344,
                352.3045349121094
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            13256,
            13260
          ],
          "representative_frame": 13256,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 110
    },
    {
      "second": 442,
      "time_range": [
        442,
        442.999
      ],
      "frame_range": [
        13261,
        13290
      ],
      "unified_description": "10-second scene featuring a man sitting in a tent with a camera mounted on his helmet. The image shows an overhead view of the tent and the man inside. The camera is capturing the scene from a first-person perspective, making it seem like the viewer is experiencing the scene from the man's point of view. There are no other people or objects visible in the image, just the man and the tent.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:02",
        "processing_time": 3.68,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13275,
          "frame_range": [
            13271,
            13275
          ],
          "description": "a man is sitting in a tent with a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13261,
            13265
          ],
          "representative_frame": 13261,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6147156953811646,
              "bbox": [
                101.15269470214844,
                76.63671875,
                333.7427062988281,
                352.92474365234375
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            13266,
            13270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13271,
            13275
          ],
          "representative_frame": 13271,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5647124648094177,
              "bbox": [
                101.185302734375,
                75.61206817626953,
                340.04632568359375,
                352.2693176269531
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            13276,
            13280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13281,
            13285
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8115922808647156,
              "bbox": [
                153.7560272216797,
                26.17947006225586,
                458.253662109375,
                353.9811096191406
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            13286,
            13290
          ],
          "representative_frame": 13286,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 110
    },
    {
      "second": 443,
      "time_range": [
        443,
        443.999
      ],
      "frame_range": [
        13291,
        13320
      ],
      "unified_description": "1-second scene where a man is pitching a tent with a fire, along with several other objects. The image contains multiple groups and objects, making it an action-packed scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:04",
        "processing_time": 2.98,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13305,
          "frame_range": [
            13301,
            13305
          ],
          "description": "a man is putting a tent with a fire",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.33
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13291,
            13295
          ],
          "representative_frame": 13291,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7994141578674316,
              "bbox": [
                168.04689025878906,
                8.126700401306152,
                510.9443359375,
                354.0561828613281
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            13296,
            13300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13301,
            13305
          ],
          "representative_frame": 13301,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8653944730758667,
              "bbox": [
                110.23052215576172,
                1.3207167387008667,
                460.3036193847656,
                355.22283935546875
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            13306,
            13310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13311,
            13315
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.49168699979782104,
              "bbox": [
                103.78491973876953,
                0.0,
                463.3255310058594,
                355.5035400390625
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            13316,
            13320
          ],
          "representative_frame": 13316,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 110
    },
    {
      "second": 444,
      "time_range": [
        444,
        444.999
      ],
      "frame_range": [
        13321,
        13350
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:04",
        "processing_time": 2.79,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13335,
          "frame_range": [
            13331,
            13335
          ],
          "description": "a man is sleeping under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13321,
            13325
          ],
          "representative_frame": 13321,
          "detections": [
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6513839960098267,
              "bbox": [
                127.28491973876953,
                67.0799560546875,
                376.2908935546875,
                300.9998779296875
              ]
            }
          ],
          "unique_tracks": [
            978
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            13326,
            13330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13331,
            13335
          ],
          "representative_frame": 13331,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            13336,
            13340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13341,
            13345
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            13346,
            13350
          ],
          "representative_frame": 13346,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 111
    },
    {
      "second": 445,
      "time_range": [
        445,
        445.999
      ],
      "frame_range": [
        13351,
        13380
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:05",
        "processing_time": 2.1,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13365,
          "frame_range": [
            13361,
            13365
          ],
          "description": "a man sleeping under a tent with a dog",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.91
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13351,
            13355
          ],
          "representative_frame": 13351,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            13356,
            13360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13361,
            13365
          ],
          "representative_frame": 13361,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            13366,
            13370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13371,
            13375
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            13376,
            13380
          ],
          "representative_frame": 13376,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 111
    },
    {
      "second": 446,
      "time_range": [
        446,
        446.999
      ],
      "frame_range": [
        13381,
        13410
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:07",
        "processing_time": 2.11,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13395,
          "frame_range": [
            13391,
            13395
          ],
          "description": "a man is sleeping under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.11
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13381,
            13385
          ],
          "representative_frame": 13381,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            13386,
            13390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13391,
            13395
          ],
          "representative_frame": 13391,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            13396,
            13400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13401,
            13405
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            13406,
            13410
          ],
          "representative_frame": 13406,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 111
    },
    {
      "second": 447,
      "time_range": [
        447,
        447.999
      ],
      "frame_range": [
        13411,
        13440
      ],
      "unified_description": "1-second scene featuring a tent with a sleeping bag and a sleeping bag. Camera perspective is first-person, mounted on a backpack. The camera captures the scene with natural outdoor lighting, making it appear vibrant and detailed.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:08",
        "processing_time": 3.15,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13425,
          "frame_range": [
            13421,
            13425
          ],
          "description": "a tent with a sleeping bag and a sleeping bag",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.21
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13411,
            13415
          ],
          "representative_frame": 13411,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            13416,
            13420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13421,
            13425
          ],
          "representative_frame": 13421,
          "detections": [
            {
              "track_id": 1001,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.41932862997055054,
              "bbox": [
                550.0258178710938,
                167.77151489257812,
                639.2664794921875,
                300.8078918457031
              ]
            },
            {
              "track_id": 1003,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3685573935508728,
              "bbox": [
                0.0,
                1.0799834728240967,
                200.41375732421875,
                149.0034637451172
              ]
            }
          ],
          "unique_tracks": [
            1001,
            1003
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            13426,
            13430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13431,
            13435
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1001,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.17335981130599976,
              "bbox": [
                551.3348388671875,
                167.93048095703125,
                640.0,
                303.1891784667969
              ]
            },
            {
              "track_id": 1003,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.34391194581985474,
              "bbox": [
                0.0,
                1.0288888216018677,
                195.80908203125,
                147.40884399414062
              ]
            }
          ],
          "unique_tracks": [
            1001,
            1003
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            13436,
            13440
          ],
          "representative_frame": 13436,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 111
    },
    {
      "second": 448,
      "time_range": [
        448,
        448.999
      ],
      "frame_range": [
        13441,
        13470
      ],
      "unified_description": "1-second scene featuring a person camping in the woods",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:08",
        "processing_time": 2.42,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13455,
          "frame_range": [
            13451,
            13455
          ],
          "description": "a person is camping in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.56
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13441,
            13445
          ],
          "representative_frame": 13441,
          "detections": [
            {
              "track_id": 1001,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.525238037109375,
              "bbox": [
                547.9429931640625,
                160.20431518554688,
                640.0,
                302.0442199707031
              ]
            },
            {
              "track_id": 1003,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.31119921803474426,
              "bbox": [
                0.0,
                1.0093649625778198,
                192.1422119140625,
                144.50863647460938
              ]
            }
          ],
          "unique_tracks": [
            1001,
            1003
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            13446,
            13450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13451,
            13455
          ],
          "representative_frame": 13451,
          "detections": [
            {
              "track_id": 1001,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.4245757460594177,
              "bbox": [
                547.6119384765625,
                154.73011779785156,
                640.0,
                302.4258117675781
              ]
            },
            {
              "track_id": 1003,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2601320445537567,
              "bbox": [
                0.0,
                1.2087358236312866,
                190.68212890625,
                142.79795837402344
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8490642309188843,
              "bbox": [
                6.081761360168457,
                215.4270782470703,
                316.6627502441406,
                356.7704772949219
              ]
            }
          ],
          "unique_tracks": [
            1001,
            1003,
            1004
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            13456,
            13460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13461,
            13465
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1001,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.18444406986236572,
              "bbox": [
                548.4282836914062,
                149.49266052246094,
                640.0,
                301.7902526855469
              ]
            },
            {
              "track_id": 1003,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.19557757675647736,
              "bbox": [
                0.0,
                1.1392953395843506,
                178.903076171875,
                135.2858123779297
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8122493028640747,
              "bbox": [
                0.0,
                210.50880432128906,
                320.1228942871094,
                356.807861328125
              ]
            }
          ],
          "unique_tracks": [
            1001,
            1003,
            1004
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            13466,
            13470
          ],
          "representative_frame": 13466,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 112
    },
    {
      "second": 449,
      "time_range": [
        449,
        449.999
      ],
      "frame_range": [
        13471,
        13500
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:10",
        "processing_time": 2.06,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13485,
          "frame_range": [
            13481,
            13485
          ],
          "description": "a person is camping in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.8
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13471,
            13475
          ],
          "representative_frame": 13471,
          "detections": [
            {
              "track_id": 1001,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.12360288202762604,
              "bbox": [
                550.1898803710938,
                149.5924835205078,
                640.0,
                300.38702392578125
              ]
            },
            {
              "track_id": 1003,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.15911810100078583,
              "bbox": [
                0.0,
                1.2440869808197021,
                174.5819091796875,
                132.1151885986328
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6443634629249573,
              "bbox": [
                0.0,
                209.9769287109375,
                314.604248046875,
                356.69879150390625
              ]
            }
          ],
          "unique_tracks": [
            1001,
            1003,
            1004
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            13476,
            13480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13481,
            13485
          ],
          "representative_frame": 13481,
          "detections": [
            {
              "track_id": 1003,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2556449770927429,
              "bbox": [
                0.0,
                1.2441319227218628,
                174.62550354003906,
                131.66322326660156
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8727166056632996,
              "bbox": [
                0.0,
                197.45742797851562,
                340.3096618652344,
                356.61932373046875
              ]
            }
          ],
          "unique_tracks": [
            1003,
            1004
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            13486,
            13490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13491,
            13495
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1003,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.23936238884925842,
              "bbox": [
                0.0,
                1.355222225189209,
                176.34141540527344,
                133.14308166503906
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8676738142967224,
              "bbox": [
                2.4950828552246094,
                197.3565216064453,
                352.1673889160156,
                356.7193603515625
              ]
            }
          ],
          "unique_tracks": [
            1003,
            1004
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            13496,
            13500
          ],
          "representative_frame": 13496,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 112
    },
    {
      "second": 450,
      "time_range": [
        450,
        450.999
      ],
      "frame_range": [
        13501,
        13530
      ],
      "unified_description": "\nBased on these image descriptions, the scene takes place outside with a group of people standing around, one person holding a backpack. The camera perspective is first-person and mounted on a person's body. The field of view is wide-angle showing many objects simultaneously, and the camera movement is stable.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:13",
        "processing_time": 3.23,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13515,
          "frame_range": [
            13511,
            13515
          ],
          "description": "a person is holding a backpack in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.54
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13501,
            13505
          ],
          "representative_frame": 13501,
          "detections": [
            {
              "track_id": 1003,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.20357640087604523,
              "bbox": [
                1.2070329189300537,
                0.9711254239082336,
                182.48118591308594,
                135.43484497070312
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9170789122581482,
              "bbox": [
                0.0,
                183.44667053222656,
                368.9813232421875,
                357.0306701660156
              ]
            },
            {
              "track_id": 1005,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.41602906584739685,
              "bbox": [
                1.963667392730713,
                196.1578826904297,
                133.59121704101562,
                303.7806396484375
              ]
            }
          ],
          "unique_tracks": [
            1003,
            1004,
            1005
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            13506,
            13510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13511,
            13515
          ],
          "representative_frame": 13511,
          "detections": [
            {
              "track_id": 1003,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.31117841601371765,
              "bbox": [
                0.23862095177173615,
                0.9202015995979309,
                183.27308654785156,
                136.78904724121094
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8299326300621033,
              "bbox": [
                9.766162872314453,
                203.98060607910156,
                346.7699890136719,
                356.94427490234375
              ]
            },
            {
              "track_id": 1005,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4098607301712036,
              "bbox": [
                1.7712984085083008,
                195.92105102539062,
                133.94833374023438,
                303.9443054199219
              ]
            }
          ],
          "unique_tracks": [
            1003,
            1004,
            1005
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            13516,
            13520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13521,
            13525
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1003,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.1144239604473114,
              "bbox": [
                1.2239793539047241,
                1.2613816261291504,
                183.89459228515625,
                136.7178497314453
              ]
            },
            {
              "track_id": 1005,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2506295144557953,
              "bbox": [
                2.204047679901123,
                195.87017822265625,
                134.24761962890625,
                303.67510986328125
              ]
            }
          ],
          "unique_tracks": [
            1003,
            1005
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            13526,
            13530
          ],
          "representative_frame": 13526,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 112
    },
    {
      "second": 451,
      "time_range": [
        451,
        451.999
      ],
      "frame_range": [
        13531,
        13560
      ],
      "unified_description": "\n(Please provide a body-mounted camera perspective if the content description includes first-person POV)",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:14",
        "processing_time": 3.88,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13545,
          "frame_range": [
            13541,
            13545
          ],
          "description": "a man is laying down in the shade",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.16
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13531,
            13535
          ],
          "representative_frame": 13531,
          "detections": [
            {
              "track_id": 1003,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.209160715341568,
              "bbox": [
                0.0,
                1.486618995666504,
                185.5968017578125,
                140.12840270996094
              ]
            },
            {
              "track_id": 1005,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.17985105514526367,
              "bbox": [
                2.319732904434204,
                196.81178283691406,
                133.7303924560547,
                303.953857421875
              ]
            }
          ],
          "unique_tracks": [
            1003,
            1005
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            13536,
            13540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13541,
            13545
          ],
          "representative_frame": 13541,
          "detections": [
            {
              "track_id": 1003,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.20283950865268707,
              "bbox": [
                0.0,
                1.0265092849731445,
                193.01905822753906,
                144.89315795898438
              ]
            },
            {
              "track_id": 1005,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.19112545251846313,
              "bbox": [
                3.382436752319336,
                196.53138732910156,
                138.0746612548828,
                306.06793212890625
              ]
            }
          ],
          "unique_tracks": [
            1003,
            1005
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            13546,
            13550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13551,
            13555
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1003,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.21204978227615356,
              "bbox": [
                1.1494256258010864,
                1.0174341201782227,
                210.96278381347656,
                156.824462890625
              ]
            },
            {
              "track_id": 1005,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.1261405199766159,
              "bbox": [
                17.678131103515625,
                195.26475524902344,
                147.7551727294922,
                300.46307373046875
              ]
            },
            {
              "track_id": 978,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4114592671394348,
              "bbox": [
                101.03823852539062,
                9.153705596923828,
                306.66583251953125,
                186.66680908203125
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4881446063518524,
              "bbox": [
                0.0,
                187.7162628173828,
                365.0368347167969,
                355.6066589355469
              ]
            }
          ],
          "unique_tracks": [
            1003,
            1005,
            978,
            1004
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            13556,
            13560
          ],
          "representative_frame": 13556,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 112
    },
    {
      "second": 452,
      "time_range": [
        452,
        452.999
      ],
      "frame_range": [
        13561,
        13590
      ],
      "unified_description": "3rd person perspective with camera mounted on top of a backpack. The scene is set in an outdoor camping setting.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:14",
        "processing_time": 3.8,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13575,
          "frame_range": [
            13571,
            13575
          ],
          "description": "a man sleeping in a tent with a sleeping bag",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.72
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13561,
            13565
          ],
          "representative_frame": 13561,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            13566,
            13570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13571,
            13575
          ],
          "representative_frame": 13571,
          "detections": [
            {
              "track_id": 1010,
              "class_id": 59,
              "class_name": "bed",
              "confidence": 0.4988722801208496,
              "bbox": [
                319.044189453125,
                80.41545867919922,
                640.0,
                352.8733215332031
              ]
            },
            {
              "track_id": 1005,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6664549112319946,
              "bbox": [
                0.0,
                160.50303649902344,
                189.4801788330078,
                346.7545471191406
              ]
            }
          ],
          "unique_tracks": [
            1010,
            1005
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            13576,
            13580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13581,
            13585
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1010,
              "class_id": 17,
              "class_name": "horse",
              "confidence": 0.1098487451672554,
              "bbox": [
                233.20765686035156,
                80.04447174072266,
                568.0175170898438,
                348.8245544433594
              ]
            }
          ],
          "unique_tracks": [
            1010
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            13586,
            13590
          ],
          "representative_frame": 13586,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 113
    },
    {
      "second": 453,
      "time_range": [
        453,
        453.999
      ],
      "frame_range": [
        13591,
        13620
      ],
      "unified_description": "1-second scene that includes a man with a sleeping bag under a tent in an outdoor setting",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:17",
        "processing_time": 2.44,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13605,
          "frame_range": [
            13601,
            13605
          ],
          "description": "a man is putting a sleeping bag under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.59
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13591,
            13595
          ],
          "representative_frame": 13591,
          "detections": [
            {
              "track_id": 1010,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6384140849113464,
              "bbox": [
                214.585693359375,
                89.24869537353516,
                532.9200439453125,
                340.192138671875
              ]
            },
            {
              "track_id": 1011,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.7024925947189331,
              "bbox": [
                145.7202606201172,
                263.83404541015625,
                169.80474853515625,
                300.33245849609375
              ]
            },
            {
              "track_id": 1001,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5137968063354492,
              "bbox": [
                562.6544189453125,
                127.67237091064453,
                623.3970947265625,
                211.76683044433594
              ]
            }
          ],
          "unique_tracks": [
            1010,
            1011,
            1001
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            13596,
            13600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13601,
            13605
          ],
          "representative_frame": 13601,
          "detections": [
            {
              "track_id": 1010,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6510888338088989,
              "bbox": [
                201.64547729492188,
                89.47600555419922,
                534.3719482421875,
                346.86993408203125
              ]
            },
            {
              "track_id": 1011,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.6060183644294739,
              "bbox": [
                145.43539428710938,
                263.746826171875,
                169.4105682373047,
                300.08795166015625
              ]
            }
          ],
          "unique_tracks": [
            1010,
            1011
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            13606,
            13610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13611,
            13615
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1010,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8070359826087952,
              "bbox": [
                209.00010681152344,
                99.945556640625,
                541.9871826171875,
                352.6787109375
              ]
            },
            {
              "track_id": 1011,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5637648105621338,
              "bbox": [
                145.31594848632812,
                263.8173522949219,
                169.18202209472656,
                300.00341796875
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4901503622531891,
              "bbox": [
                10.667715072631836,
                107.60499572753906,
                510.80718994140625,
                354.8255310058594
              ]
            }
          ],
          "unique_tracks": [
            1010,
            1011,
            1004
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            13616,
            13620
          ],
          "representative_frame": 13616,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 113
    },
    {
      "second": 454,
      "time_range": [
        454,
        454.999
      ],
      "frame_range": [
        13621,
        13650
      ],
      "unified_description": "52 objects were detected in this image, including a man and a dog inside tents.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:18",
        "processing_time": 2.52,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13635,
          "frame_range": [
            13631,
            13635
          ],
          "description": "a man is sleeping in a tent with a dog",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.67
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13621,
            13625
          ],
          "representative_frame": 13621,
          "detections": [
            {
              "track_id": 1010,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7914820313453674,
              "bbox": [
                132.01585388183594,
                90.12501525878906,
                472.2080993652344,
                353.88336181640625
              ]
            },
            {
              "track_id": 1011,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5026831030845642,
              "bbox": [
                145.4927978515625,
                263.9368591308594,
                169.19610595703125,
                299.8861999511719
              ]
            },
            {
              "track_id": 1001,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8048385977745056,
              "bbox": [
                555.4234619140625,
                129.5184326171875,
                625.9835815429688,
                220.7879638671875
              ]
            }
          ],
          "unique_tracks": [
            1010,
            1011,
            1001
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            13626,
            13630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13631,
            13635
          ],
          "representative_frame": 13631,
          "detections": [
            {
              "track_id": 1010,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.890407383441925,
              "bbox": [
                76.84346771240234,
                97.06231689453125,
                364.693115234375,
                322.6207275390625
              ]
            },
            {
              "track_id": 1004,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5309181809425354,
              "bbox": [
                0.0,
                26.54496192932129,
                632.7008666992188,
                351.9903564453125
              ]
            }
          ],
          "unique_tracks": [
            1010,
            1004
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            13636,
            13640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13641,
            13645
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1010,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.908799946308136,
              "bbox": [
                62.623252868652344,
                98.8813247680664,
                372.8715515136719,
                345.1539306640625
              ]
            },
            {
              "track_id": 1017,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4088464379310608,
              "bbox": [
                346.48895263671875,
                155.00694274902344,
                461.0055847167969,
                225.58309936523438
              ]
            },
            {
              "track_id": 1019,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4949854910373688,
              "bbox": [
                358.50335693359375,
                194.6439666748047,
                601.3436889648438,
                356.7567443847656
              ]
            },
            {
              "track_id": 1004,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6160293817520142,
              "bbox": [
                0.0,
                8.030330657958984,
                640.0,
                351.73175048828125
              ]
            }
          ],
          "unique_tracks": [
            1010,
            1017,
            1019,
            1004
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            13646,
            13650
          ],
          "representative_frame": 13646,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 113
    },
    {
      "second": 455,
      "time_range": [
        455,
        455.999
      ],
      "frame_range": [
        13651,
        13680
      ],
      "unified_description": "\nBased on these descriptions, the image depicts an outdoor scene with people, objects and animals present. There is a man sitting in a tent with a dog and possibly other people nearby. The camera perspective appears to be first-person or POV, indicating that the video may have been taken using a body-mounted or head-mounted camera. The image may have been captured for various purposes, such as a vlog, documentary, or action camera footage.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:20",
        "processing_time": 4.37,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13665,
          "frame_range": [
            13661,
            13665
          ],
          "description": "a man is sitting in a tent with a dog",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.22
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13651,
            13655
          ],
          "representative_frame": 13651,
          "detections": [
            {
              "track_id": 1010,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8461729288101196,
              "bbox": [
                62.74016189575195,
                100.62393951416016,
                374.6383056640625,
                351.9157409667969
              ]
            },
            {
              "track_id": 1017,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3995770812034607,
              "bbox": [
                345.2886657714844,
                154.91729736328125,
                460.8764343261719,
                226.23182678222656
              ]
            },
            {
              "track_id": 1019,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.39644327759742737,
              "bbox": [
                358.8569030761719,
                195.0662384033203,
                601.2252807617188,
                356.7489318847656
              ]
            },
            {
              "track_id": 1004,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5979545712471008,
              "bbox": [
                0.0,
                0.44339320063591003,
                640.0,
                352.8296813964844
              ]
            },
            {
              "track_id": 1020,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.40251412987709045,
              "bbox": [
                559.2631225585938,
                229.21356201171875,
                575.6593017578125,
                283.44439697265625
              ]
            }
          ],
          "unique_tracks": [
            1010,
            1017,
            1019,
            1004,
            1020
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            13656,
            13660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13661,
            13665
          ],
          "representative_frame": 13661,
          "detections": [
            {
              "track_id": 1010,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7905611395835876,
              "bbox": [
                67.63618469238281,
                100.28009796142578,
                377.8704833984375,
                354.5343933105469
              ]
            },
            {
              "track_id": 1017,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.39225339889526367,
              "bbox": [
                344.6178283691406,
                154.85411071777344,
                460.7457275390625,
                226.6335906982422
              ]
            },
            {
              "track_id": 1019,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.48663192987442017,
              "bbox": [
                358.9870300292969,
                195.5161590576172,
                601.0155639648438,
                356.77825927734375
              ]
            },
            {
              "track_id": 1004,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5295472741127014,
              "bbox": [
                0.0,
                0.0,
                640.0,
                353.1182861328125
              ]
            },
            {
              "track_id": 1020,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.38743045926094055,
              "bbox": [
                559.2998657226562,
                229.29754638671875,
                575.5134887695312,
                282.749755859375
              ]
            }
          ],
          "unique_tracks": [
            1010,
            1017,
            1019,
            1004,
            1020
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            13666,
            13670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13671,
            13675
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1010,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8578134775161743,
              "bbox": [
                69.37364196777344,
                99.81657409667969,
                376.7594299316406,
                355.5345153808594
              ]
            },
            {
              "track_id": 1017,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.39231249690055847,
              "bbox": [
                345.04052734375,
                154.8226318359375,
                461.1793518066406,
                226.7450714111328
              ]
            },
            {
              "track_id": 1019,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4962545335292816,
              "bbox": [
                358.5857238769531,
                195.58998107910156,
                600.8499755859375,
                356.7900085449219
              ]
            },
            {
              "track_id": 1004,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5530107617378235,
              "bbox": [
                0.0,
                0.0,
                640.0,
                353.2361145019531
              ]
            },
            {
              "track_id": 1020,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.39009320735931396,
              "bbox": [
                559.1676025390625,
                229.311767578125,
                575.6891479492188,
                283.573974609375
              ]
            }
          ],
          "unique_tracks": [
            1010,
            1017,
            1019,
            1004,
            1020
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            13676,
            13680
          ],
          "representative_frame": 13676,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 113
    },
    {
      "second": 456,
      "time_range": [
        456,
        456.999
      ],
      "frame_range": [
        13681,
        13710
      ],
      "unified_description": "50 frames captured from this video.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:20",
        "processing_time": 2.5,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13695,
          "frame_range": [
            13691,
            13695
          ],
          "description": "a man is sleeping in the tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.69
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13681,
            13685
          ],
          "representative_frame": 13681,
          "detections": [
            {
              "track_id": 1010,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.1059553325176239,
              "bbox": [
                27.930130004882812,
                134.64816284179688,
                293.7755126953125,
                355.7787780761719
              ]
            },
            {
              "track_id": 1019,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8024064898490906,
              "bbox": [
                246.66981506347656,
                71.05777740478516,
                640.0,
                353.7978515625
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4811916947364807,
              "bbox": [
                11.022416114807129,
                26.167591094970703,
                640.0,
                353.6904602050781
              ]
            }
          ],
          "unique_tracks": [
            1010,
            1019,
            1004
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            13686,
            13690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13691,
            13695
          ],
          "representative_frame": 13691,
          "detections": [
            {
              "track_id": 1019,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8095578551292419,
              "bbox": [
                219.17091369628906,
                38.45252990722656,
                640.0,
                352.5648193359375
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.41427621245384216,
              "bbox": [
                24.757944107055664,
                41.224178314208984,
                633.211669921875,
                354.25750732421875
              ]
            }
          ],
          "unique_tracks": [
            1019,
            1004
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            13696,
            13700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13701,
            13705
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1019,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7222484350204468,
              "bbox": [
                213.98431396484375,
                31.615568161010742,
                640.0,
                351.9272155761719
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.42983168363571167,
              "bbox": [
                20.83186149597168,
                58.46990203857422,
                594.4965209960938,
                353.4486083984375
              ]
            }
          ],
          "unique_tracks": [
            1019,
            1004
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            13706,
            13710
          ],
          "representative_frame": 13706,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 114
    },
    {
      "second": 457,
      "time_range": [
        457,
        457.999
      ],
      "frame_range": [
        13711,
        13740
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:21",
        "processing_time": 2.11,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13725,
          "frame_range": [
            13721,
            13725
          ],
          "description": "a man sleeping in a tent with an umbrella",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.99
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13711,
            13715
          ],
          "representative_frame": 13711,
          "detections": [
            {
              "track_id": 1019,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7144263386726379,
              "bbox": [
                216.8207550048828,
                32.90571594238281,
                640.0,
                351.5180358886719
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5935219526290894,
              "bbox": [
                18.51165771484375,
                59.732173919677734,
                592.155517578125,
                353.5677490234375
              ]
            },
            {
              "track_id": 1021,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.3994658887386322,
              "bbox": [
                0.0,
                1.4009430408477783,
                640.0,
                159.50572204589844
              ]
            }
          ],
          "unique_tracks": [
            1019,
            1004,
            1021
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            13716,
            13720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13721,
            13725
          ],
          "representative_frame": 13721,
          "detections": [
            {
              "track_id": 1019,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5713503956794739,
              "bbox": [
                223.62513732910156,
                39.56044006347656,
                640.0,
                351.7330322265625
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46938151121139526,
              "bbox": [
                24.613126754760742,
                65.15973663330078,
                592.6060791015625,
                354.3639221191406
              ]
            },
            {
              "track_id": 1021,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.4516564607620239,
              "bbox": [
                0.0,
                1.6583658456802368,
                640.0,
                166.55654907226562
              ]
            }
          ],
          "unique_tracks": [
            1019,
            1004,
            1021
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            13726,
            13730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13731,
            13735
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1019,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7248802185058594,
              "bbox": [
                225.12844848632812,
                40.14601516723633,
                640.0,
                351.92633056640625
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.47124722599983215,
              "bbox": [
                34.381690979003906,
                67.2099838256836,
                602.3297729492188,
                353.6944274902344
              ]
            },
            {
              "track_id": 1021,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.39838242530822754,
              "bbox": [
                0.0,
                1.9163167476654053,
                640.0,
                165.0288848876953
              ]
            }
          ],
          "unique_tracks": [
            1019,
            1004,
            1021
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            13736,
            13740
          ],
          "representative_frame": 13736,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 114
    },
    {
      "second": 458,
      "time_range": [
        458,
        458.999
      ],
      "frame_range": [
        13741,
        13770
      ],
      "unified_description": "\n\nOverall, this scene shows a person and a dog inside a tent, with some objects in the background, like a backpack. The camera is mounted on a tripod, providing stable footage of the man and his canine companion as they rest together within their temporary shelter.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:26",
        "processing_time": 3.57,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13755,
          "frame_range": [
            13751,
            13755
          ],
          "description": "a man is sleeping in a tent with a dog",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.11
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13741,
            13745
          ],
          "representative_frame": 13741,
          "detections": [
            {
              "track_id": 1019,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.22274257242679596,
              "bbox": [
                227.65249633789062,
                42.7095832824707,
                640.0,
                352.4273986816406
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.22122827172279358,
              "bbox": [
                33.009925842285156,
                64.0578842163086,
                611.0149536132812,
                353.4864807128906
              ]
            },
            {
              "track_id": 1021,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.2866729199886322,
              "bbox": [
                0.3520972728729248,
                1.420792579650879,
                628.9356079101562,
                147.6754608154297
              ]
            }
          ],
          "unique_tracks": [
            1019,
            1004,
            1021
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            13746,
            13750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13751,
            13755
          ],
          "representative_frame": 13751,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.37732675671577454,
              "bbox": [
                0.0,
                68.08512878417969,
                561.3992309570312,
                354.29827880859375
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            13756,
            13760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13761,
            13765
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.42377540469169617,
              "bbox": [
                0.0,
                60.360538482666016,
                554.6914672851562,
                354.3446044921875
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            13766,
            13770
          ],
          "representative_frame": 13766,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 114
    },
    {
      "second": 459,
      "time_range": [
        459,
        459.999
      ],
      "frame_range": [
        13771,
        13800
      ],
      "unified_description": "1-second scene with a man standing in the grass",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:24",
        "processing_time": 2.29,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13785,
          "frame_range": [
            13781,
            13785
          ],
          "description": "a man is standing in the grass",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.72
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13771,
            13775
          ],
          "representative_frame": 13771,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46779292821884155,
              "bbox": [
                1.2291525602340698,
                23.502286911010742,
                627.550048828125,
                353.1312255859375
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            13776,
            13780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13781,
            13785
          ],
          "representative_frame": 13781,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            13786,
            13790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13791,
            13795
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            13796,
            13800
          ],
          "representative_frame": 13796,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 114
    },
    {
      "second": 460,
      "time_range": [
        460,
        460.999
      ],
      "frame_range": [
        13801,
        13830
      ],
      "unified_description": "3rd person perspective with a main subject and supporting objects in the frame.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:26",
        "processing_time": 3.48,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13815,
          "frame_range": [
            13811,
            13815
          ],
          "description": "a man in a suit and tie standing in front of a black background",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13801,
            13805
          ],
          "representative_frame": 13801,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            13806,
            13810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13811,
            13815
          ],
          "representative_frame": 13811,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            13816,
            13820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13821,
            13825
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6841460466384888,
              "bbox": [
                20.841388702392578,
                25.21224021911621,
                604.6268920898438,
                351.0879821777344
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            13826,
            13830
          ],
          "representative_frame": 13826,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 115
    },
    {
      "second": 461,
      "time_range": [
        461,
        461.999
      ],
      "frame_range": [
        13831,
        13860
      ],
      "unified_description": "10-second videos require a more detailed description to ensure accurate annotation. Please see the Image Descriptions above.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:28",
        "processing_time": 2.53,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13845,
          "frame_range": [
            13841,
            13845
          ],
          "description": "a man in a tent with a dog",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13831,
            13835
          ],
          "representative_frame": 13831,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8887822031974792,
              "bbox": [
                30.699302673339844,
                31.765899658203125,
                576.198974609375,
                352.1270751953125
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            13836,
            13840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13841,
            13845
          ],
          "representative_frame": 13841,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8674118518829346,
              "bbox": [
                33.14847183227539,
                23.813636779785156,
                565.9332885742188,
                353.06890869140625
              ]
            },
            {
              "track_id": 1019,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.39759767055511475,
              "bbox": [
                148.1216583251953,
                15.824257850646973,
                627.90576171875,
                352.81268310546875
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1019
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            13846,
            13850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13851,
            13855
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1019,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9143708348274231,
              "bbox": [
                106.16213989257812,
                13.248570442199707,
                562.7675170898438,
                353.5309753417969
              ]
            }
          ],
          "unique_tracks": [
            1019
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            13856,
            13860
          ],
          "representative_frame": 13856,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 115
    },
    {
      "second": 462,
      "time_range": [
        462,
        462.999
      ],
      "frame_range": [
        13861,
        13890
      ],
      "unified_description": "1-second scene featuring a man and a baby in a tent, captured using a fisheye lens that results in distortion.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:29",
        "processing_time": 2.58,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13875,
          "frame_range": [
            13871,
            13875
          ],
          "description": "a man in a tent with a baby",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.07
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13861,
            13865
          ],
          "representative_frame": 13861,
          "detections": [
            {
              "track_id": 1019,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9062027335166931,
              "bbox": [
                107.78784942626953,
                19.993572235107422,
                536.2413330078125,
                353.9086608886719
              ]
            }
          ],
          "unique_tracks": [
            1019
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            13866,
            13870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13871,
            13875
          ],
          "representative_frame": 13871,
          "detections": [
            {
              "track_id": 1019,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9067911505699158,
              "bbox": [
                111.60025787353516,
                7.758242607116699,
                536.2440795898438,
                353.9455871582031
              ]
            }
          ],
          "unique_tracks": [
            1019
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            13876,
            13880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13881,
            13885
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4487791657447815,
              "bbox": [
                83.57522583007812,
                84.51981353759766,
                548.0670166015625,
                353.1617431640625
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            13886,
            13890
          ],
          "representative_frame": 13886,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 115
    },
    {
      "second": 463,
      "time_range": [
        463,
        463.999
      ],
      "frame_range": [
        13891,
        13920
      ],
      "unified_description": "1-second scene where a man is sleeping in a tent with a dog. The camera is positioned above the sleeping man, capturing the entire scene including the bed, the tent roof, and the dog lying next to him.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:30",
        "processing_time": 3.32,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13905,
          "frame_range": [
            13901,
            13905
          ],
          "description": "a man sleeping in a tent with a dog",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.08
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13891,
            13895
          ],
          "representative_frame": 13891,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.360603928565979,
              "bbox": [
                79.18744659423828,
                89.0816650390625,
                559.0706787109375,
                353.60870361328125
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            13896,
            13900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13901,
            13905
          ],
          "representative_frame": 13901,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.36124497652053833,
              "bbox": [
                71.83494567871094,
                88.9605712890625,
                570.1705322265625,
                353.8143005371094
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            13906,
            13910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13911,
            13915
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5287021398544312,
              "bbox": [
                59.223426818847656,
                87.49858856201172,
                572.8599243164062,
                353.424560546875
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            13916,
            13920
          ],
          "representative_frame": 13916,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 115
    },
    {
      "second": 464,
      "time_range": [
        464,
        464.999
      ],
      "frame_range": [
        13921,
        13950
      ],
      "unified_description": "3rd person perspective, camera positioned on tripod, wide-angle lens, stable camera positioning, action camera (GoPro-style), documentary style production, indoor lighting, natural outdoor lighting, frame composed to include a person sleeping in a tent with a blanket.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:32",
        "processing_time": 3.42,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13935,
          "frame_range": [
            13931,
            13935
          ],
          "description": "a person sleeping in a tent with a blanket",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.65
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13921,
            13925
          ],
          "representative_frame": 13921,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.47382333874702454,
              "bbox": [
                30.409685134887695,
                80.79645538330078,
                559.1217651367188,
                352.92376708984375
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            13926,
            13930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13931,
            13935
          ],
          "representative_frame": 13931,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.37375202775001526,
              "bbox": [
                38.112056732177734,
                85.91773223876953,
                565.910888671875,
                352.4360656738281
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            13936,
            13940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13941,
            13945
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6944887638092041,
              "bbox": [
                105.82266998291016,
                110.03251647949219,
                589.2681884765625,
                353.6700744628906
              ]
            },
            {
              "track_id": 1019,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.7276932001113892,
              "bbox": [
                109.22967529296875,
                0.0,
                484.37115478515625,
                269.479248046875
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1019
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            13946,
            13950
          ],
          "representative_frame": 13946,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 116
    },
    {
      "second": 465,
      "time_range": [
        465,
        465.999
      ],
      "frame_range": [
        13951,
        13980
      ],
      "unified_description": "\n\n1. Content Description - What is happening in the scene:\n   - Objects, people, actions, and location: A man is holding an umbrella while walking, which implies that there might be rain, or he is trying to protect himself from sun, wind, snow or other weather conditions. The presence of an umbrella also suggests a need for some form of shelter, indicating the possibility of inclement weather.\n   - Visual details (colors, positions, movements): Since there's only one unique track, it might be difficult to confidently determine additional details about the scene, such as the color of the umbrella, or other objects that might be present but not captured well in the image.\n   - Camera perspective and technical details: Based on the single unique track, we can infer that the camera is likely mounted either on a person's body (POV) or on a tripod, capturing the man as he walks with his umbrella. However, without more information, it's challenging to determine additional camera specifications or settings.\n   - Video production style and characterstics: Since there's only one unique track, it might be an issue of resource constraints, limiting the possibility of a more polished or stylish video production.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:37",
        "processing_time": 6.87,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13965,
          "frame_range": [
            13961,
            13965
          ],
          "description": "a man is holding an umbrella while walking",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13951,
            13955
          ],
          "representative_frame": 13951,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2853221595287323,
              "bbox": [
                96.8730239868164,
                89.57202911376953,
                617.2901611328125,
                354.8170471191406
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            13956,
            13960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13961,
            13965
          ],
          "representative_frame": 13961,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7309136390686035,
              "bbox": [
                84.17950439453125,
                82.30032348632812,
                607.9154052734375,
                355.1307678222656
              ]
            },
            {
              "track_id": 1036,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.3817400336265564,
              "bbox": [
                0.0,
                18.5477294921875,
                290.44561767578125,
                264.6524353027344
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1036
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            13966,
            13970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            13971,
            13975
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.876415491104126,
              "bbox": [
                74.51920318603516,
                69.38865661621094,
                610.6992797851562,
                355.301513671875
              ]
            },
            {
              "track_id": 1036,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.33613312244415283,
              "bbox": [
                0.11488623917102814,
                23.37775421142578,
                285.56634521484375,
                263.7872314453125
              ]
            },
            {
              "track_id": 1019,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.5313926935195923,
              "bbox": [
                125.61192321777344,
                0.24098768830299377,
                514.6013793945312,
                246.3781280517578
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1036,
            1019
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            13976,
            13980
          ],
          "representative_frame": 13976,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 116
    },
    {
      "second": 466,
      "time_range": [
        466,
        466.999
      ],
      "frame_range": [
        13981,
        14010
      ],
      "unified_description": "1-second scene, with a person holding an umbrella as the main subject",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:38",
        "processing_time": 6.26,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 13995,
          "frame_range": [
            13991,
            13995
          ],
          "description": "a man is holding an umbrella while walking",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.9
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            13981,
            13985
          ],
          "representative_frame": 13981,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8772984743118286,
              "bbox": [
                68.70631408691406,
                59.78997039794922,
                610.0482177734375,
                355.4186096191406
              ]
            },
            {
              "track_id": 1036,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.6718726754188538,
              "bbox": [
                0.0,
                26.012300491333008,
                278.9426574707031,
                263.1513977050781
              ]
            },
            {
              "track_id": 1019,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.196129709482193,
              "bbox": [
                110.83845520019531,
                0.43146276473999023,
                536.146240234375,
                247.9279327392578
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1036,
            1019
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            13986,
            13990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            13991,
            13995
          ],
          "representative_frame": 13991,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7338932156562805,
              "bbox": [
                35.5408935546875,
                42.06390380859375,
                598.348388671875,
                355.2987365722656
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            13996,
            14000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14001,
            14005
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7071549892425537,
              "bbox": [
                42.55598449707031,
                37.950618743896484,
                602.9068603515625,
                354.9908447265625
              ]
            },
            {
              "track_id": 1036,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.32334211468696594,
              "bbox": [
                0.0,
                22.526992797851562,
                274.6457824707031,
                260.3788146972656
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1036
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            14006,
            14010
          ],
          "representative_frame": 14006,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 116
    },
    {
      "second": 467,
      "time_range": [
        467,
        467.999
      ],
      "frame_range": [
        14011,
        14040
      ],
      "unified_description": "\nA man is standing next to a brown tent with a backpack leaning against it. The scene appears to be outdoors during daytime. The camera is positioned in such a way that it captures the entire area.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:39",
        "processing_time": 6.43,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14025,
          "frame_range": [
            14021,
            14025
          ],
          "description": "a man is standing next to a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.65
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14011,
            14015
          ],
          "representative_frame": 14011,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9482163190841675,
              "bbox": [
                0.0,
                33.936553955078125,
                531.3720092773438,
                355.1826171875
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            14016,
            14020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14021,
            14025
          ],
          "representative_frame": 14021,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9233960509300232,
              "bbox": [
                0.0,
                29.461769104003906,
                486.65814208984375,
                354.81500244140625
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            14026,
            14030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14031,
            14035
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.945701539516449,
              "bbox": [
                0.0,
                9.787088394165039,
                461.507568359375,
                354.93597412109375
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            14036,
            14040
          ],
          "representative_frame": 14036,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 116
    },
    {
      "second": 468,
      "time_range": [
        468,
        468.999
      ],
      "frame_range": [
        14041,
        14070
      ],
      "unified_description": "\n\nIn the image, a man is standing in an outdoor setting with a tent and a dog nearby. The camera used to capture this scene is mounted on a tripod, providing stable footage. There are several other objects visible in the background that give context to the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:42",
        "processing_time": 3.12,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14055,
          "frame_range": [
            14051,
            14055
          ],
          "description": "a man standing next to a tent with a dog",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.56
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14041,
            14045
          ],
          "representative_frame": 14041,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.24345874786376953,
              "bbox": [
                0.0,
                2.543152093887329,
                483.2726745605469,
                354.3388977050781
              ]
            },
            {
              "track_id": 1036,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7849563360214233,
              "bbox": [
                0.0,
                3.2360217571258545,
                351.1593322753906,
                347.48443603515625
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1036
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            14046,
            14050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14051,
            14055
          ],
          "representative_frame": 14051,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.36042916774749756,
              "bbox": [
                0.0,
                0.0,
                492.0843505859375,
                354.3450927734375
              ]
            },
            {
              "track_id": 1036,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7725629806518555,
              "bbox": [
                0.0,
                0.8132065534591675,
                362.9743957519531,
                356.43585205078125
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1036
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            14056,
            14060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14061,
            14065
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            14066,
            14070
          ],
          "representative_frame": 14066,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 117
    },
    {
      "second": 469,
      "time_range": [
        469,
        469.999
      ],
      "frame_range": [
        14071,
        14100
      ],
      "unified_description": "\nThese descriptions help understand what is happening in the scene and how it was captured on camera.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:42",
        "processing_time": 3.08,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14085,
          "frame_range": [
            14081,
            14085
          ],
          "description": "a man fishing on a lake with a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.71
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14071,
            14075
          ],
          "representative_frame": 14071,
          "detections": [
            {
              "track_id": 1041,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8925135135650635,
              "bbox": [
                312.60491943359375,
                112.1530990600586,
                373.9920959472656,
                330.3325500488281
              ]
            }
          ],
          "unique_tracks": [
            1041
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            14076,
            14080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14081,
            14085
          ],
          "representative_frame": 14081,
          "detections": [
            {
              "track_id": 1041,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8902257680892944,
              "bbox": [
                317.42205810546875,
                113.29653930664062,
                378.7471923828125,
                330.6634826660156
              ]
            }
          ],
          "unique_tracks": [
            1041
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            14086,
            14090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14091,
            14095
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1041,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9211997389793396,
              "bbox": [
                329.653564453125,
                114.7535400390625,
                391.6290283203125,
                331.29217529296875
              ]
            }
          ],
          "unique_tracks": [
            1041
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            14096,
            14100
          ],
          "representative_frame": 14096,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 117
    },
    {
      "second": 470,
      "time_range": [
        470,
        470.999
      ],
      "frame_range": [
        14101,
        14130
      ],
      "unified_description": "\n\nIn this outdoor scene, a man is standing next to a lake, holding a fishing rod in his hand as he casts his line into the water. The surrounding area is relatively flat and unobstructed, allowing for an unencumbered view of the man and the lake.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:44",
        "processing_time": 4.19,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14115,
          "frame_range": [
            14111,
            14115
          ],
          "description": "a man fishing on a lake with a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.93
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14101,
            14105
          ],
          "representative_frame": 14101,
          "detections": [
            {
              "track_id": 1041,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9226117134094238,
              "bbox": [
                333.17828369140625,
                114.70746612548828,
                396.1263732910156,
                331.1121826171875
              ]
            }
          ],
          "unique_tracks": [
            1041
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            14106,
            14110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14111,
            14115
          ],
          "representative_frame": 14111,
          "detections": [
            {
              "track_id": 1042,
              "class_id": 32,
              "class_name": "sports ball",
              "confidence": 0.3654073476791382,
              "bbox": [
                266.9491271972656,
                313.4815673828125,
                281.0898132324219,
                327.3874206542969
              ]
            }
          ],
          "unique_tracks": [
            1042
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            14116,
            14120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14121,
            14125
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1042,
              "class_id": 32,
              "class_name": "sports ball",
              "confidence": 0.3421071171760559,
              "bbox": [
                266.85308837890625,
                312.8586730957031,
                281.41650390625,
                327.17767333984375
              ]
            },
            {
              "track_id": 1043,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8927028179168701,
              "bbox": [
                212.83743286132812,
                96.46556091308594,
                286.0495910644531,
                312.4070129394531
              ]
            }
          ],
          "unique_tracks": [
            1042,
            1043
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            14126,
            14130
          ],
          "representative_frame": 14126,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 117
    },
    {
      "second": 471,
      "time_range": [
        471,
        471.999
      ],
      "frame_range": [
        14131,
        14160
      ],
      "unified_description": "\nIn this scene, there is a man fishing on a lake. The camera is positioned in such a way that it captures not only the man but also the surrounding area, including an overhead view of him. This image description indicates the main focus is the fishing activity, and additional details like the lake's calm surface, nearby objects, or other people might be present as well.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:47",
        "processing_time": 3.51,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14145,
          "frame_range": [
            14141,
            14145
          ],
          "description": "a man fishing on a lake with a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.53
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14131,
            14135
          ],
          "representative_frame": 14131,
          "detections": [
            {
              "track_id": 1042,
              "class_id": 32,
              "class_name": "sports ball",
              "confidence": 0.3241528570652008,
              "bbox": [
                266.80377197265625,
                312.6534118652344,
                281.5428466796875,
                327.14239501953125
              ]
            },
            {
              "track_id": 1043,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9094327688217163,
              "bbox": [
                216.49176025390625,
                105.30679321289062,
                287.1156311035156,
                312.52850341796875
              ]
            }
          ],
          "unique_tracks": [
            1042,
            1043
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            14136,
            14140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14141,
            14145
          ],
          "representative_frame": 14141,
          "detections": [
            {
              "track_id": 1042,
              "class_id": 32,
              "class_name": "sports ball",
              "confidence": 0.2775169610977173,
              "bbox": [
                266.80194091796875,
                312.6139831542969,
                281.5190124511719,
                327.0772399902344
              ]
            },
            {
              "track_id": 1043,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9159277081489563,
              "bbox": [
                220.4445037841797,
                113.96205139160156,
                288.99627685546875,
                312.4930114746094
              ]
            }
          ],
          "unique_tracks": [
            1042,
            1043
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            14146,
            14150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14151,
            14155
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1042,
              "class_id": 32,
              "class_name": "sports ball",
              "confidence": 0.26133349537849426,
              "bbox": [
                266.8174133300781,
                312.6653747558594,
                281.492919921875,
                327.0789489746094
              ]
            },
            {
              "track_id": 1043,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9168695211410522,
              "bbox": [
                224.1634521484375,
                134.00656127929688,
                287.3525085449219,
                312.15582275390625
              ]
            }
          ],
          "unique_tracks": [
            1042,
            1043
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            14156,
            14160
          ],
          "representative_frame": 14156,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 117
    },
    {
      "second": 472,
      "time_range": [
        472,
        472.999
      ],
      "frame_range": [
        14161,
        14190
      ],
      "unified_description": "365 words",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:47",
        "processing_time": 3.23,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14175,
          "frame_range": [
            14171,
            14175
          ],
          "description": "a person holding a metal object in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.39
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14161,
            14165
          ],
          "representative_frame": 14161,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            14166,
            14170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14171,
            14175
          ],
          "representative_frame": 14171,
          "detections": [
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8295223712921143,
              "bbox": [
                358.4114990234375,
                218.13760375976562,
                616.7186889648438,
                356.54888916015625
              ]
            }
          ],
          "unique_tracks": [
            1044
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            14176,
            14180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14181,
            14185
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8555133938789368,
              "bbox": [
                353.50537109375,
                199.42868041992188,
                634.1030883789062,
                349.7667236328125
              ]
            }
          ],
          "unique_tracks": [
            1044
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            14186,
            14190
          ],
          "representative_frame": 14186,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 118
    },
    {
      "second": 473,
      "time_range": [
        473,
        473.999
      ],
      "frame_range": [
        14191,
        14220
      ],
      "unified_description": "1-second scene showing a person with a fish in their hand. The camera perspective is first-person, which creates an immersive experience for viewers. The image has been stabilized to reduce shaking, and the field of view captures a wide area, allowing more details to be seen at once.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:49",
        "processing_time": 4.16,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14205,
          "frame_range": [
            14201,
            14205
          ],
          "description": "a person holding a fish in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.62
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14191,
            14195
          ],
          "representative_frame": 14191,
          "detections": [
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9230520129203796,
              "bbox": [
                348.36328125,
                191.88507080078125,
                640.0,
                351.9305114746094
              ]
            }
          ],
          "unique_tracks": [
            1044
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            14196,
            14200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14201,
            14205
          ],
          "representative_frame": 14201,
          "detections": [
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9036573767662048,
              "bbox": [
                359.66558837890625,
                206.91253662109375,
                636.8034057617188,
                355.1981201171875
              ]
            },
            {
              "track_id": 1049,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.7994389533996582,
              "bbox": [
                254.13818359375,
                126.6070556640625,
                376.6212463378906,
                247.8284454345703
              ]
            }
          ],
          "unique_tracks": [
            1044,
            1049
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            14206,
            14210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14211,
            14215
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8808093667030334,
              "bbox": [
                418.8603210449219,
                201.45289611816406,
                628.8587646484375,
                312.9355773925781
              ]
            },
            {
              "track_id": 1049,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8693767786026001,
              "bbox": [
                252.5268096923828,
                125.20417022705078,
                412.4571533203125,
                283.5137634277344
              ]
            }
          ],
          "unique_tracks": [
            1044,
            1049
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            14216,
            14220
          ],
          "representative_frame": 14216,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 118
    },
    {
      "second": 474,
      "time_range": [
        474,
        474.999
      ],
      "frame_range": [
        14221,
        14250
      ],
      "unified_description": "\n\nThe image captures a scene where a person is holding a pot filled with water. The camera's perspective suggests that it is mounted on a backpack, providing a first-person view of the surrounding environment. The photo exhibits some motion blur, possibly indicating that the camera was stabilized using a tripod or other stabilizing method. Other objects and people are also visible in the scene, adding context to the main subject of the person holding the water pot.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:52",
        "processing_time": 3.76,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14235,
          "frame_range": [
            14231,
            14235
          ],
          "description": "a person is holding a pot with water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.66
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14221,
            14225
          ],
          "representative_frame": 14221,
          "detections": [
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8584111928939819,
              "bbox": [
                444.0690612792969,
                200.0974578857422,
                631.28369140625,
                299.01611328125
              ]
            },
            {
              "track_id": 1049,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.9279806017875671,
              "bbox": [
                263.0460205078125,
                123.25184631347656,
                436.4505310058594,
                294.9335632324219
              ]
            }
          ],
          "unique_tracks": [
            1044,
            1049
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            14226,
            14230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14231,
            14235
          ],
          "representative_frame": 14231,
          "detections": [
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8750318288803101,
              "bbox": [
                424.13385009765625,
                218.2517547607422,
                638.4682006835938,
                331.5630187988281
              ]
            },
            {
              "track_id": 1049,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.9602731466293335,
              "bbox": [
                233.09007263183594,
                128.64532470703125,
                427.089111328125,
                320.4644775390625
              ]
            }
          ],
          "unique_tracks": [
            1044,
            1049
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            14236,
            14240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14241,
            14245
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            14246,
            14250
          ],
          "representative_frame": 14246,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 118
    },
    {
      "second": 475,
      "time_range": [
        475,
        475.999
      ],
      "frame_range": [
        14251,
        14280
      ],
      "unified_description": "3rd person camera perspective with a shaky camera positioning. Wide-angle distortion evident in the image suggesting that it might be an action camera setup. The video may be part of a documentary or narrative production, but no specific details about the story or setting are discernible from the image descriptions alone.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:54",
        "processing_time": 5.0,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14265,
          "frame_range": [
            14261,
            14265
          ],
          "description": "a man is setting up a tent in the grass",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.89
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14251,
            14255
          ],
          "representative_frame": 14251,
          "detections": [
            {
              "track_id": 1019,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.5770913362503052,
              "bbox": [
                87.31245422363281,
                0.41654661297798157,
                369.2279052734375,
                122.28083038330078
              ]
            },
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9407480359077454,
              "bbox": [
                245.1669158935547,
                42.08845520019531,
                640.0,
                329.2975158691406
              ]
            }
          ],
          "unique_tracks": [
            1019,
            1044
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            14256,
            14260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14261,
            14265
          ],
          "representative_frame": 14261,
          "detections": [
            {
              "track_id": 1052,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.6181399822235107,
              "bbox": [
                319.5436096191406,
                199.16708374023438,
                369.7619323730469,
                303.76361083984375
              ]
            },
            {
              "track_id": 1053,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5973255038261414,
              "bbox": [
                265.384765625,
                188.04498291015625,
                327.1866455078125,
                246.45448303222656
              ]
            },
            {
              "track_id": 1019,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.68201744556427,
              "bbox": [
                68.01858520507812,
                0.43907618522644043,
                387.1658935546875,
                120.83984375
              ]
            },
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9475656151771545,
              "bbox": [
                214.00277709960938,
                6.4063615798950195,
                640.0,
                330.7782897949219
              ]
            }
          ],
          "unique_tracks": [
            1052,
            1053,
            1019,
            1044
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            14266,
            14270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14271,
            14275
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1052,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5461540818214417,
              "bbox": [
                319.5562438964844,
                199.22483825683594,
                369.75341796875,
                303.768798828125
              ]
            },
            {
              "track_id": 1053,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5403433442115784,
              "bbox": [
                265.45159912109375,
                188.0086212158203,
                327.56207275390625,
                246.71060180664062
              ]
            },
            {
              "track_id": 1019,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.6737088561058044,
              "bbox": [
                55.48418045043945,
                0.46947574615478516,
                399.03839111328125,
                120.33881378173828
              ]
            },
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9504257440567017,
              "bbox": [
                214.32638549804688,
                0.0,
                640.0,
                332.3320617675781
              ]
            },
            {
              "track_id": 1055,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.30967003107070923,
              "bbox": [
                295.34429931640625,
                271.7518615722656,
                389.54229736328125,
                331.72857666015625
              ]
            }
          ],
          "unique_tracks": [
            1052,
            1053,
            1019,
            1044,
            1055
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            14276,
            14280
          ],
          "representative_frame": 14276,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 118
    },
    {
      "second": 476,
      "time_range": [
        476,
        476.999
      ],
      "frame_range": [
        14281,
        14310
      ],
      "unified_description": "1-second scene with a man setting up a tent in the woods",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:54",
        "processing_time": 4.73,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14295,
          "frame_range": [
            14291,
            14295
          ],
          "description": "a man is setting up a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.89
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14281,
            14285
          ],
          "representative_frame": 14281,
          "detections": [
            {
              "track_id": 1052,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.6001878976821899,
              "bbox": [
                319.0478515625,
                196.55172729492188,
                370.5105285644531,
                303.80682373046875
              ]
            },
            {
              "track_id": 1053,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.527921199798584,
              "bbox": [
                265.48028564453125,
                188.041748046875,
                327.5826416015625,
                246.7362060546875
              ]
            },
            {
              "track_id": 1019,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.5673831105232239,
              "bbox": [
                42.25382614135742,
                1.0533908605575562,
                421.38812255859375,
                128.0345458984375
              ]
            },
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9023086428642273,
              "bbox": [
                238.9417266845703,
                0.0,
                640.0,
                332.0589294433594
              ]
            },
            {
              "track_id": 1055,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.22848282754421234,
              "bbox": [
                295.2452087402344,
                271.7376708984375,
                389.5634765625,
                331.7943420410156
              ]
            },
            {
              "track_id": 1056,
              "class_id": 65,
              "class_name": "remote",
              "confidence": 0.301631361246109,
              "bbox": [
                0.14622026681900024,
                276.43267822265625,
                107.23597717285156,
                331.0247802734375
              ]
            }
          ],
          "unique_tracks": [
            1052,
            1053,
            1019,
            1044,
            1055,
            1056
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            14286,
            14290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14291,
            14295
          ],
          "representative_frame": 14291,
          "detections": [
            {
              "track_id": 1052,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4663822650909424,
              "bbox": [
                318.7020263671875,
                194.7521209716797,
                370.9419860839844,
                303.78045654296875
              ]
            },
            {
              "track_id": 1019,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.5262241363525391,
              "bbox": [
                47.279911041259766,
                0.8582448363304138,
                396.93499755859375,
                110.99162292480469
              ]
            },
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9069585204124451,
              "bbox": [
                248.04769897460938,
                0.0,
                640.0,
                330.1007385253906
              ]
            },
            {
              "track_id": 1055,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.14098691940307617,
              "bbox": [
                295.1773681640625,
                271.490234375,
                389.6399841308594,
                331.6366882324219
              ]
            },
            {
              "track_id": 1056,
              "class_id": 65,
              "class_name": "remote",
              "confidence": 0.3514384329319,
              "bbox": [
                0.06709060817956924,
                276.3436584472656,
                107.40924072265625,
                331.06524658203125
              ]
            }
          ],
          "unique_tracks": [
            1052,
            1019,
            1044,
            1055,
            1056
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            14296,
            14300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14301,
            14305
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1052,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2698267996311188,
              "bbox": [
                321.4211730957031,
                206.6415557861328,
                368.34320068359375,
                303.93328857421875
              ]
            },
            {
              "track_id": 1019,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.45380574464797974,
              "bbox": [
                42.664642333984375,
                0.5791566371917725,
                402.5878601074219,
                109.72937774658203
              ]
            },
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8829996585845947,
              "bbox": [
                257.271240234375,
                0.0,
                640.0,
                329.085205078125
              ]
            },
            {
              "track_id": 1055,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.1638273298740387,
              "bbox": [
                294.9865417480469,
                271.4474792480469,
                389.6439514160156,
                331.7184753417969
              ]
            },
            {
              "track_id": 1056,
              "class_id": 65,
              "class_name": "remote",
              "confidence": 0.30996283888816833,
              "bbox": [
                0.013475384563207626,
                276.36688232421875,
                107.39215087890625,
                331.108642578125
              ]
            }
          ],
          "unique_tracks": [
            1052,
            1019,
            1044,
            1055,
            1056
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            14306,
            14310
          ],
          "representative_frame": 14306,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 119
    },
    {
      "second": 477,
      "time_range": [
        477,
        477.999
      ],
      "frame_range": [
        14311,
        14340
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:56",
        "processing_time": 2.1,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14325,
          "frame_range": [
            14321,
            14325
          ],
          "description": "a man is setting up a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.24
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14311,
            14315
          ],
          "representative_frame": 14311,
          "detections": [
            {
              "track_id": 1052,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.16704510152339935,
              "bbox": [
                322.95758056640625,
                213.9954833984375,
                366.8030090332031,
                304.0419006347656
              ]
            },
            {
              "track_id": 1019,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.5669286251068115,
              "bbox": [
                37.250877380371094,
                0.3672756552696228,
                411.1222229003906,
                110.57374572753906
              ]
            },
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9341572523117065,
              "bbox": [
                266.363525390625,
                0.0,
                640.0,
                328.9895324707031
              ]
            },
            {
              "track_id": 1055,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.15630342066287994,
              "bbox": [
                294.89752197265625,
                271.5440368652344,
                389.7650146484375,
                331.96661376953125
              ]
            },
            {
              "track_id": 1056,
              "class_id": 65,
              "class_name": "remote",
              "confidence": 0.35893961787223816,
              "bbox": [
                0.18132369220256805,
                276.38720703125,
                107.16421508789062,
                330.91973876953125
              ]
            },
            {
              "track_id": 1057,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8225783705711365,
              "bbox": [
                290.72808837890625,
                133.04295349121094,
                389.58636474609375,
                199.8040771484375
              ]
            }
          ],
          "unique_tracks": [
            1052,
            1019,
            1044,
            1055,
            1056,
            1057
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            14316,
            14320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14321,
            14325
          ],
          "representative_frame": 14321,
          "detections": [
            {
              "track_id": 1052,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.13575051724910736,
              "bbox": [
                323.1350402832031,
                215.69122314453125,
                366.6619873046875,
                304.25274658203125
              ]
            },
            {
              "track_id": 1019,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.5274672508239746,
              "bbox": [
                34.63584518432617,
                0.31244930624961853,
                412.5164489746094,
                108.9200210571289
              ]
            },
            {
              "track_id": 1044,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9350805878639221,
              "bbox": [
                275.94976806640625,
                0.0,
                640.0,
                328.90277099609375
              ]
            },
            {
              "track_id": 1055,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.10953729599714279,
              "bbox": [
                295.0536193847656,
                271.5123291015625,
                389.6759948730469,
                331.7856750488281
              ]
            },
            {
              "track_id": 1056,
              "class_id": 65,
              "class_name": "remote",
              "confidence": 0.41115128993988037,
              "bbox": [
                0.23780730366706848,
                276.4225769042969,
                107.06999206542969,
                330.8690185546875
              ]
            },
            {
              "track_id": 1057,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.811710000038147,
              "bbox": [
                290.7973937988281,
                134.42437744140625,
                390.12457275390625,
                201.57435607910156
              ]
            }
          ],
          "unique_tracks": [
            1052,
            1019,
            1044,
            1055,
            1056,
            1057
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            14326,
            14330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14331,
            14335
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9461182355880737,
              "bbox": [
                0.0,
                0.6974146366119385,
                394.475830078125,
                352.960693359375
              ]
            }
          ],
          "unique_tracks": [
            1004
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            14336,
            14340
          ],
          "representative_frame": 14336,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 119
    },
    {
      "second": 478,
      "time_range": [
        478,
        478.999
      ],
      "frame_range": [
        14341,
        14370
      ],
      "unified_description": "3rd person POV camera perspective",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:58",
        "processing_time": 2.21,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14355,
          "frame_range": [
            14351,
            14355
          ],
          "description": "a man is setting up a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.54
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14341,
            14345
          ],
          "representative_frame": 14341,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7026979923248291,
              "bbox": [
                482.91741943359375,
                344.23675537109375,
                526.2972412109375,
                359.75677490234375
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.42372605204582214,
              "bbox": [
                376.7768859863281,
                349.6982116699219,
                427.2738952636719,
                359.68603515625
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.36914363503456116,
              "bbox": [
                282.34808349609375,
                222.379150390625,
                374.00457763671875,
                309.6435241699219
              ]
            },
            {
              "track_id": 1063,
              "class_id": 43,
              "class_name": "knife",
              "confidence": 0.3819228410720825,
              "bbox": [
                352.6363830566406,
                256.18670654296875,
                428.6703186035156,
                288.8337097167969
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9528936743736267,
              "bbox": [
                0.0,
                1.2918082475662231,
                371.7621154785156,
                353.6712646484375
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1062,
            1063,
            1004
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            14346,
            14350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14351,
            14355
          ],
          "representative_frame": 14351,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7165497541427612,
              "bbox": [
                482.9169921875,
                344.2473449707031,
                526.2603759765625,
                359.7542724609375
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4325965642929077,
              "bbox": [
                376.79278564453125,
                349.7007141113281,
                427.2861022949219,
                359.68743896484375
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3318655490875244,
              "bbox": [
                282.4004821777344,
                222.41490173339844,
                373.9341125488281,
                309.561279296875
              ]
            },
            {
              "track_id": 1063,
              "class_id": 43,
              "class_name": "knife",
              "confidence": 0.38106590509414673,
              "bbox": [
                352.2698974609375,
                256.11822509765625,
                428.5268859863281,
                288.86083984375
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.941684901714325,
              "bbox": [
                0.0,
                1.220423698425293,
                349.9867248535156,
                352.892578125
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1062,
            1063,
            1004
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            14356,
            14360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14361,
            14365
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6988353133201599,
              "bbox": [
                483.5957336425781,
                344.27587890625,
                526.3362426757812,
                359.55126953125
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4096720516681671,
              "bbox": [
                375.4335021972656,
                349.09442138671875,
                429.1009216308594,
                359.7208557128906
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.44468438625335693,
              "bbox": [
                282.3075256347656,
                222.39459228515625,
                373.9525146484375,
                309.6491394042969
              ]
            },
            {
              "track_id": 1063,
              "class_id": 43,
              "class_name": "knife",
              "confidence": 0.3688218593597412,
              "bbox": [
                352.2909240722656,
                256.0236511230469,
                428.57928466796875,
                288.7835693359375
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9545572400093079,
              "bbox": [
                0.0,
                0.9604725241661072,
                342.0162658691406,
                355.1333923339844
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1062,
            1063,
            1004
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            14366,
            14370
          ],
          "representative_frame": 14366,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 119
    },
    {
      "second": 479,
      "time_range": [
        479,
        479.999
      ],
      "frame_range": [
        14371,
        14400
      ],
      "unified_description": "1-second scene with a man setting up a tent in the woods",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:58",
        "processing_time": 2.43,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14385,
          "frame_range": [
            14381,
            14385
          ],
          "description": "a man is setting up a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.46
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14371,
            14375
          ],
          "representative_frame": 14371,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7735334038734436,
              "bbox": [
                483.2270812988281,
                344.27227783203125,
                526.3751831054688,
                359.6979675292969
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4660671353340149,
              "bbox": [
                375.0306091308594,
                348.90386962890625,
                429.6732177734375,
                359.739501953125
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4177272319793701,
              "bbox": [
                282.27667236328125,
                222.36529541015625,
                374.09716796875,
                309.7922058105469
              ]
            },
            {
              "track_id": 1063,
              "class_id": 43,
              "class_name": "knife",
              "confidence": 0.34478679299354553,
              "bbox": [
                352.9271240234375,
                256.0469055175781,
                429.16021728515625,
                288.8162841796875
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6480697393417358,
              "bbox": [
                0.0,
                1.3091953992843628,
                335.4771423339844,
                353.0757141113281
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1062,
            1063,
            1004
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            14376,
            14380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14381,
            14385
          ],
          "representative_frame": 14381,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6992104649543762,
              "bbox": [
                483.09942626953125,
                344.2743225097656,
                526.410888671875,
                359.76007080078125
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3435654044151306,
              "bbox": [
                374.7932434082031,
                348.86260986328125,
                429.6399841308594,
                359.753662109375
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4666469395160675,
              "bbox": [
                282.23773193359375,
                222.32542419433594,
                374.0172119140625,
                309.71734619140625
              ]
            },
            {
              "track_id": 1063,
              "class_id": 43,
              "class_name": "knife",
              "confidence": 0.34151944518089294,
              "bbox": [
                352.4046630859375,
                255.96896362304688,
                428.82000732421875,
                288.82421875
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9295290112495422,
              "bbox": [
                0.0,
                0.7564504146575928,
                332.85223388671875,
                352.0760498046875
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1062,
            1063,
            1004
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            14386,
            14390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14391,
            14395
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7159762382507324,
              "bbox": [
                483.0150146484375,
                344.22869873046875,
                526.473388671875,
                359.7724609375
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.38157209753990173,
              "bbox": [
                374.8043212890625,
                348.8553161621094,
                429.5675964355469,
                359.74615478515625
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3045932650566101,
              "bbox": [
                282.26641845703125,
                222.34043884277344,
                374.0506896972656,
                309.7448425292969
              ]
            },
            {
              "track_id": 1063,
              "class_id": 43,
              "class_name": "knife",
              "confidence": 0.3544194996356964,
              "bbox": [
                352.0965881347656,
                255.90267944335938,
                428.6279296875,
                288.8212585449219
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9249913692474365,
              "bbox": [
                0.0,
                0.9579615592956543,
                328.91107177734375,
                352.01629638671875
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1062,
            1063,
            1004
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            14396,
            14400
          ],
          "representative_frame": 14396,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 119
    },
    {
      "second": 480,
      "time_range": [
        480,
        480.999
      ],
      "frame_range": [
        14401,
        14430
      ],
      "unified_description": "1-second scene where a man is cooking food in a tent, with many objects simultaneously visible",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:23:59",
        "processing_time": 2.6,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14415,
          "frame_range": [
            14411,
            14415
          ],
          "description": "a man is cooking food in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.66
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14401,
            14405
          ],
          "representative_frame": 14401,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6520389318466187,
              "bbox": [
                483.330810546875,
                344.1512756347656,
                526.6240234375,
                359.6152648925781
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.37130358815193176,
              "bbox": [
                374.6172180175781,
                348.78363037109375,
                429.71832275390625,
                359.7708435058594
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8882516026496887,
              "bbox": [
                0.0,
                0.39150509238243103,
                315.53277587890625,
                352.349853515625
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1004
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            14406,
            14410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14411,
            14415
          ],
          "representative_frame": 14411,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6669861078262329,
              "bbox": [
                483.4382019042969,
                344.10369873046875,
                526.7907104492188,
                359.56744384765625
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4082152545452118,
              "bbox": [
                374.5976257324219,
                348.7597351074219,
                429.7255859375,
                359.781494140625
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9121225476264954,
              "bbox": [
                0.0,
                0.17176567018032074,
                309.1425476074219,
                352.510009765625
              ]
            },
            {
              "track_id": 1070,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.4451886713504791,
              "bbox": [
                216.9608917236328,
                170.95172119140625,
                350.19805908203125,
                270.3863525390625
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1004,
            1070
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            14416,
            14420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14421,
            14425
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6849793791770935,
              "bbox": [
                483.0229797363281,
                344.08978271484375,
                526.5950927734375,
                359.64044189453125
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4281131327152252,
              "bbox": [
                374.65484619140625,
                348.75323486328125,
                429.7195739746094,
                359.794189453125
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9098177552223206,
              "bbox": [
                0.0,
                0.4768620431423187,
                306.2327880859375,
                353.02728271484375
              ]
            },
            {
              "track_id": 1070,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.2510400712490082,
              "bbox": [
                220.59336853027344,
                176.1004638671875,
                351.57501220703125,
                273.675048828125
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1004,
            1070
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            14426,
            14430
          ],
          "representative_frame": 14426,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 120
    },
    {
      "second": 481,
      "time_range": [
        481,
        481.999
      ],
      "frame_range": [
        14431,
        14460
      ],
      "unified_description": "1-second scene with a man in the woods setting up a tent, the field of view is wide-angle showing many objects simultaneously, camera positioning, lens characteristics, video production style and various other technical details.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:02",
        "processing_time": 2.86,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14445,
          "frame_range": [
            14441,
            14445
          ],
          "description": "a man is setting up a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.53
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14431,
            14435
          ],
          "representative_frame": 14431,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7008540034294128,
              "bbox": [
                482.8366394042969,
                343.7979736328125,
                526.909423828125,
                359.54071044921875
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.46076539158821106,
              "bbox": [
                374.7494812011719,
                348.7897644042969,
                429.463134765625,
                359.7880859375
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9470104575157166,
              "bbox": [
                2.316312789916992,
                3.3422229290008545,
                321.2601623535156,
                350.1829833984375
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.41031983494758606,
              "bbox": [
                278.1393127441406,
                223.77711486816406,
                367.86700439453125,
                308.9626770019531
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1004,
            1062
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            14436,
            14440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14441,
            14445
          ],
          "representative_frame": 14441,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7167062759399414,
              "bbox": [
                482.7541198730469,
                343.6654052734375,
                527.0,
                359.4815979003906
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4841368794441223,
              "bbox": [
                374.833740234375,
                348.78656005859375,
                429.3659973144531,
                359.7757568359375
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.954242467880249,
              "bbox": [
                13.020660400390625,
                6.372390270233154,
                327.24847412109375,
                349.60931396484375
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.35552793741226196,
              "bbox": [
                277.68109130859375,
                223.96414184570312,
                367.4483947753906,
                308.9383239746094
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1004,
            1062
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            14446,
            14450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14451,
            14455
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7151733040809631,
              "bbox": [
                482.7552185058594,
                343.6248779296875,
                527.0325317382812,
                359.4631042480469
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4720434248447418,
              "bbox": [
                374.93109130859375,
                348.78857421875,
                429.2610168457031,
                359.7641296386719
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9529079794883728,
              "bbox": [
                17.033512115478516,
                6.032663345336914,
                330.0672912597656,
                349.5056457519531
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.35728955268859863,
              "bbox": [
                277.2848205566406,
                224.0244140625,
                367.3704833984375,
                309.0607604980469
              ]
            },
            {
              "track_id": 1073,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.6429641842842102,
              "bbox": [
                259.22003173828125,
                106.73121643066406,
                306.6227111816406,
                144.3545684814453
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1004,
            1062,
            1073
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            14456,
            14460
          ],
          "representative_frame": 14456,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 120
    },
    {
      "second": 482,
      "time_range": [
        482,
        482.999
      ],
      "frame_range": [
        14461,
        14490
      ],
      "unified_description": "2 people standing in a room for a second. There's also a cup present.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:03",
        "processing_time": 2.55,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14475,
          "frame_range": [
            14471,
            14475
          ],
          "description": "a man is putting a cup in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.13
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14461,
            14465
          ],
          "representative_frame": 14461,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7112534642219543,
              "bbox": [
                482.7601318359375,
                343.6023254394531,
                527.05126953125,
                359.45623779296875
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4652721881866455,
              "bbox": [
                374.9818115234375,
                348.7894592285156,
                429.1634826660156,
                359.76019287109375
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9463857412338257,
              "bbox": [
                18.926509857177734,
                4.975068092346191,
                329.56915283203125,
                347.27044677734375
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.42150068283081055,
              "bbox": [
                277.1741638183594,
                224.04107666015625,
                367.47235107421875,
                309.06524658203125
              ]
            },
            {
              "track_id": 1073,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.49905136227607727,
              "bbox": [
                257.34259033203125,
                101.33454132080078,
                306.3700256347656,
                140.32723999023438
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1004,
            1062,
            1073
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            14466,
            14470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14471,
            14475
          ],
          "representative_frame": 14471,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7122222185134888,
              "bbox": [
                482.7803649902344,
                343.6005859375,
                527.041748046875,
                359.4546813964844
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.46266108751296997,
              "bbox": [
                375.0417785644531,
                348.7922668457031,
                429.0902099609375,
                359.7606201171875
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9435091614723206,
              "bbox": [
                18.949243545532227,
                3.4875881671905518,
                328.99237060546875,
                346.8356628417969
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.40223023295402527,
              "bbox": [
                277.08660888671875,
                224.0404510498047,
                367.5948486328125,
                309.0667724609375
              ]
            },
            {
              "track_id": 1073,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5910685658454895,
              "bbox": [
                256.38763427734375,
                96.75660705566406,
                307.060791015625,
                137.1796875
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1004,
            1062,
            1073
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            14476,
            14480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14481,
            14485
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.729206919670105,
              "bbox": [
                482.98272705078125,
                343.72491455078125,
                527.0361938476562,
                359.4914855957031
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.48774197697639465,
              "bbox": [
                374.9161071777344,
                348.7221984863281,
                428.8327331542969,
                359.6968688964844
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9591018557548523,
              "bbox": [
                51.21058654785156,
                32.202430725097656,
                348.73345947265625,
                352.5960998535156
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.1815817952156067,
              "bbox": [
                277.263916015625,
                224.65408325195312,
                366.93133544921875,
                308.6116027832031
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1004,
            1062
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            14486,
            14490
          ],
          "representative_frame": 14486,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 120
    },
    {
      "second": 483,
      "time_range": [
        483,
        483.999
      ],
      "frame_range": [
        14491,
        14520
      ],
      "unified_description": "1-second scene including a man setting up a tent in the woods",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:03",
        "processing_time": 2.91,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14505,
          "frame_range": [
            14501,
            14505
          ],
          "description": "a man is setting up a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.58
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14491,
            14495
          ],
          "representative_frame": 14491,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7287028431892395,
              "bbox": [
                483.01092529296875,
                343.7500915527344,
                527.0509033203125,
                359.50067138671875
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4598589539527893,
              "bbox": [
                374.86431884765625,
                348.6820983886719,
                428.72991943359375,
                359.6790771484375
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.966928243637085,
              "bbox": [
                58.8755989074707,
                42.337303161621094,
                355.3359375,
                354.9536437988281
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.1833762228488922,
              "bbox": [
                277.1716613769531,
                224.8685760498047,
                366.83282470703125,
                308.5802307128906
              ]
            },
            {
              "track_id": 1074,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.45358964800834656,
              "bbox": [
                379.2979736328125,
                248.96426391601562,
                406.7456970214844,
                280.716552734375
              ]
            },
            {
              "track_id": 1075,
              "class_id": 59,
              "class_name": "bed",
              "confidence": 0.3270241618156433,
              "bbox": [
                298.925048828125,
                139.212890625,
                639.1712036132812,
                344.9952087402344
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1004,
            1062,
            1074,
            1075
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            14496,
            14500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14501,
            14505
          ],
          "representative_frame": 14501,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7305506467819214,
              "bbox": [
                482.8249816894531,
                343.5621032714844,
                527.186767578125,
                359.4526672363281
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4668116271495819,
              "bbox": [
                374.8829650878906,
                348.6640930175781,
                428.6727294921875,
                359.67724609375
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9561202526092529,
              "bbox": [
                61.814334869384766,
                42.23577880859375,
                365.4175720214844,
                355.7537536621094
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.1939506083726883,
              "bbox": [
                276.66802978515625,
                224.20095825195312,
                367.2638244628906,
                308.6451721191406
              ]
            },
            {
              "track_id": 1074,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3773690164089203,
              "bbox": [
                380.38055419921875,
                251.3412322998047,
                405.9502258300781,
                280.8621826171875
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1004,
            1062,
            1074
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            14506,
            14510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14511,
            14515
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7325361371040344,
              "bbox": [
                482.7712707519531,
                343.4810485839844,
                527.2182006835938,
                359.42596435546875
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.43187665939331055,
              "bbox": [
                374.8929138183594,
                348.6521911621094,
                428.6150207519531,
                359.6821594238281
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9608070850372314,
              "bbox": [
                51.49546432495117,
                42.48763656616211,
                356.0586853027344,
                354.0515441894531
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.22899022698402405,
              "bbox": [
                276.7754821777344,
                224.4552764892578,
                367.2826843261719,
                308.5691833496094
              ]
            },
            {
              "track_id": 1074,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.46140000224113464,
              "bbox": [
                380.68048095703125,
                252.52488708496094,
                405.3858337402344,
                280.9352722167969
              ]
            },
            {
              "track_id": 1075,
              "class_id": 59,
              "class_name": "bed",
              "confidence": 0.30193307995796204,
              "bbox": [
                288.5577392578125,
                143.42153930664062,
                620.0494384765625,
                343.1122131347656
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1004,
            1062,
            1074,
            1075
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            14516,
            14520
          ],
          "representative_frame": 14516,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 120
    },
    {
      "second": 484,
      "time_range": [
        484,
        484.999
      ],
      "frame_range": [
        14521,
        14550
      ],
      "unified_description": "3rd person perspective showing a man setting up a tent in the wilderness",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:05",
        "processing_time": 2.31,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14535,
          "frame_range": [
            14531,
            14535
          ],
          "description": "a man is setting up a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.85
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14521,
            14525
          ],
          "representative_frame": 14521,
          "detections": [
            {
              "track_id": 1060,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7113580703735352,
              "bbox": [
                482.77667236328125,
                343.47906494140625,
                527.2345581054688,
                359.45233154296875
              ]
            },
            {
              "track_id": 1061,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.42053359746932983,
              "bbox": [
                374.9826354980469,
                348.6636962890625,
                428.5260314941406,
                359.6831970214844
              ]
            },
            {
              "track_id": 1004,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9596425890922546,
              "bbox": [
                37.70008850097656,
                38.566226959228516,
                345.3169860839844,
                352.92266845703125
              ]
            },
            {
              "track_id": 1062,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.1686890423297882,
              "bbox": [
                276.7679138183594,
                223.92770385742188,
                367.7804870605469,
                308.4291687011719
              ]
            },
            {
              "track_id": 1074,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.37080615758895874,
              "bbox": [
                380.8403625488281,
                252.54434204101562,
                405.6549072265625,
                280.93310546875
              ]
            },
            {
              "track_id": 1075,
              "class_id": 59,
              "class_name": "bed",
              "confidence": 0.3096427023410797,
              "bbox": [
                276.4679870605469,
                133.61097717285156,
                624.1807861328125,
                342.489013671875
              ]
            }
          ],
          "unique_tracks": [
            1060,
            1061,
            1004,
            1062,
            1074,
            1075
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            14526,
            14530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14531,
            14535
          ],
          "representative_frame": 14531,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.6838217377662659,
              "bbox": [
                84.79907989501953,
                14.825202941894531,
                359.9757995605469,
                267.10272216796875
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.909182608127594,
              "bbox": [
                260.0526428222656,
                38.605960845947266,
                640.0,
                348.7362976074219
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1075
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            14536,
            14540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14541,
            14545
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.7608041167259216,
              "bbox": [
                99.6800765991211,
                5.035891056060791,
                371.5606994628906,
                232.9521026611328
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8496938943862915,
              "bbox": [
                266.9328308105469,
                6.686267375946045,
                640.0,
                345.7186584472656
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1075
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            14546,
            14550
          ],
          "representative_frame": 14546,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 121
    },
    {
      "second": 485,
      "time_range": [
        485,
        485.999
      ],
      "frame_range": [
        14551,
        14580
      ],
      "unified_description": "1-second scene showing a person with a camera, no other people seen, daytime outdoor setting, stable camera positioning, wide-angle perspective, documenting a man putting food in a pot.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:07",
        "processing_time": 2.88,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14565,
          "frame_range": [
            14561,
            14565
          ],
          "description": "a man is putting food in a pot",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.52
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14551,
            14555
          ],
          "representative_frame": 14551,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.7653365135192871,
              "bbox": [
                97.88382720947266,
                2.239389181137085,
                381.7688903808594,
                223.17588806152344
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9034202694892883,
              "bbox": [
                272.1089172363281,
                0.0,
                640.0,
                348.57244873046875
              ]
            },
            {
              "track_id": 1076,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3802841603755951,
              "bbox": [
                498.34588623046875,
                317.345703125,
                563.7483520507812,
                359.1549072265625
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1075,
            1076
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            14556,
            14560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14561,
            14565
          ],
          "representative_frame": 14561,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.7845550179481506,
              "bbox": [
                90.24298858642578,
                1.381414771080017,
                389.51171875,
                220.38795471191406
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8956018090248108,
              "bbox": [
                267.39227294921875,
                0.0,
                640.0,
                344.4311218261719
              ]
            },
            {
              "track_id": 1076,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.37667980790138245,
              "bbox": [
                498.29949951171875,
                317.36029052734375,
                563.643310546875,
                359.1378173828125
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1075,
            1076
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            14566,
            14570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14571,
            14575
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.78888338804245,
              "bbox": [
                77.87728881835938,
                0.7795857787132263,
                392.84210205078125,
                220.52210998535156
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9277984499931335,
              "bbox": [
                262.6597595214844,
                0.0,
                640.0,
                339.41326904296875
              ]
            },
            {
              "track_id": 1076,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.25650885701179504,
              "bbox": [
                498.4283447265625,
                317.531982421875,
                563.6732177734375,
                359.2411193847656
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1075,
            1076
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            14576,
            14580
          ],
          "representative_frame": 14576,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 121
    },
    {
      "second": 486,
      "time_range": [
        486,
        486.999
      ],
      "frame_range": [
        14581,
        14610
      ],
      "unified_description": "57-word description generated using speech recognition software.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:08",
        "processing_time": 2.89,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14595,
          "frame_range": [
            14591,
            14595
          ],
          "description": "a man is putting a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.44
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14581,
            14585
          ],
          "representative_frame": 14581,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.8046702742576599,
              "bbox": [
                68.82267761230469,
                0.7099838852882385,
                398.1288757324219,
                221.2279510498047
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9185073971748352,
              "bbox": [
                267.34527587890625,
                0.0,
                640.0,
                335.0739440917969
              ]
            },
            {
              "track_id": 1076,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2526209354400635,
              "bbox": [
                498.7315368652344,
                317.9696960449219,
                563.0841064453125,
                359.0633544921875
              ]
            },
            {
              "track_id": 1078,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3298831582069397,
              "bbox": [
                336.0607604980469,
                230.156494140625,
                419.347900390625,
                303.44720458984375
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1075,
            1076,
            1078
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            14586,
            14590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14591,
            14595
          ],
          "representative_frame": 14591,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.7781660556793213,
              "bbox": [
                61.826080322265625,
                0.6755858659744263,
                404.140869140625,
                221.83746337890625
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9316304922103882,
              "bbox": [
                273.06182861328125,
                0.0,
                640.0,
                337.6615295410156
              ]
            },
            {
              "track_id": 1076,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.288850337266922,
              "bbox": [
                498.73284912109375,
                318.1180419921875,
                562.85498046875,
                359.0203552246094
              ]
            },
            {
              "track_id": 1078,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.29893648624420166,
              "bbox": [
                336.20550537109375,
                229.83615112304688,
                419.8443298339844,
                303.4546203613281
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1075,
            1076,
            1078
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            14596,
            14600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14601,
            14605
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.7210932970046997,
              "bbox": [
                55.59370803833008,
                0.8269466161727905,
                409.7851257324219,
                222.643798828125
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9211704134941101,
              "bbox": [
                309.9964599609375,
                0.0,
                640.0,
                333.67791748046875
              ]
            },
            {
              "track_id": 1076,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.22753939032554626,
              "bbox": [
                499.03936767578125,
                318.0515441894531,
                563.19287109375,
                358.9550476074219
              ]
            },
            {
              "track_id": 1078,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2148604691028595,
              "bbox": [
                335.99053955078125,
                228.0845947265625,
                421.561767578125,
                303.47125244140625
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1075,
            1076,
            1078
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            14606,
            14610
          ],
          "representative_frame": 14606,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 121
    },
    {
      "second": 487,
      "time_range": [
        487,
        487.999
      ],
      "frame_range": [
        14611,
        14640
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:08",
        "processing_time": 2.13,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14625,
          "frame_range": [
            14621,
            14625
          ],
          "description": "a man is cooking food in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.8
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14611,
            14615
          ],
          "representative_frame": 14611,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.7533892393112183,
              "bbox": [
                51.00059509277344,
                0.8990541696548462,
                416.1515197753906,
                223.23550415039062
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8839700818061829,
              "bbox": [
                316.3213806152344,
                0.0,
                640.0,
                348.33782958984375
              ]
            },
            {
              "track_id": 1076,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.27377116680145264,
              "bbox": [
                498.94439697265625,
                317.8585510253906,
                563.4662475585938,
                358.9893798828125
              ]
            },
            {
              "track_id": 1078,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.18345771729946136,
              "bbox": [
                336.001953125,
                227.6585693359375,
                421.89947509765625,
                303.4150390625
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1075,
            1076,
            1078
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            14616,
            14620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14621,
            14625
          ],
          "representative_frame": 14621,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.6352745890617371,
              "bbox": [
                47.23896026611328,
                1.0448296070098877,
                421.3524475097656,
                223.0712890625
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9291353821754456,
              "bbox": [
                324.78839111328125,
                0.0,
                640.0,
                355.8971252441406
              ]
            },
            {
              "track_id": 1076,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.36121422052383423,
              "bbox": [
                499.7038879394531,
                317.97943115234375,
                563.7971801757812,
                358.8475036621094
              ]
            },
            {
              "track_id": 1078,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.14108744263648987,
              "bbox": [
                336.0943603515625,
                227.5692901611328,
                421.9524230957031,
                303.37890625
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1075,
            1076,
            1078
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            14626,
            14630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14631,
            14635
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.6813318133354187,
              "bbox": [
                43.7537727355957,
                1.0191256999969482,
                427.220703125,
                223.3999481201172
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9064918756484985,
              "bbox": [
                341.45782470703125,
                0.0,
                640.0,
                342.346435546875
              ]
            },
            {
              "track_id": 1076,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.20410941541194916,
              "bbox": [
                499.37939453125,
                318.0806579589844,
                563.767333984375,
                359.04241943359375
              ]
            },
            {
              "track_id": 1078,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2795746922492981,
              "bbox": [
                336.0452575683594,
                227.72100830078125,
                421.6932067871094,
                303.4426574707031
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1075,
            1076,
            1078
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            14636,
            14640
          ],
          "representative_frame": 14636,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 121
    },
    {
      "second": 488,
      "time_range": [
        488,
        488.999
      ],
      "frame_range": [
        14641,
        14670
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:12",
        "processing_time": 2.1,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14655,
          "frame_range": [
            14651,
            14655
          ],
          "description": "a man is putting a pot",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.41
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14641,
            14645
          ],
          "representative_frame": 14641,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.6512032151222229,
              "bbox": [
                38.7798957824707,
                0.9311432242393494,
                429.732421875,
                223.28353881835938
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8915418982505798,
              "bbox": [
                347.2505798339844,
                0.0,
                640.0,
                342.2745361328125
              ]
            },
            {
              "track_id": 1076,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.30344608426094055,
              "bbox": [
                498.7071533203125,
                317.63671875,
                563.9105834960938,
                359.1353759765625
              ]
            },
            {
              "track_id": 1078,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2320988029241562,
              "bbox": [
                336.3783264160156,
                227.68263244628906,
                421.9892883300781,
                303.4436950683594
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1075,
            1076,
            1078
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            14646,
            14650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14651,
            14655
          ],
          "representative_frame": 14651,
          "detections": [
            {
              "track_id": 1004,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.7254486680030823,
              "bbox": [
                33.453800201416016,
                1.0061684846878052,
                431.4033203125,
                223.70318603515625
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9434548616409302,
              "bbox": [
                331.71173095703125,
                0.0,
                640.0,
                335.8429870605469
              ]
            },
            {
              "track_id": 1076,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.20659345388412476,
              "bbox": [
                498.6827697753906,
                317.9870910644531,
                563.5392456054688,
                359.20306396484375
              ]
            },
            {
              "track_id": 1078,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5559899806976318,
              "bbox": [
                336.5464172363281,
                229.15069580078125,
                420.5673522949219,
                303.5109558105469
              ]
            }
          ],
          "unique_tracks": [
            1004,
            1075,
            1076,
            1078
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            14656,
            14660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14661,
            14665
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9146438837051392,
              "bbox": [
                367.6142272949219,
                0.0,
                640.0,
                273.23040771484375
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            14666,
            14670
          ],
          "representative_frame": 14666,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 122
    },
    {
      "second": 489,
      "time_range": [
        489,
        489.999
      ],
      "frame_range": [
        14671,
        14700
      ],
      "unified_description": "5 unique objects found in scene with corresponding image descriptions.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:13",
        "processing_time": 2.29,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14685,
          "frame_range": [
            14681,
            14685
          ],
          "description": "a man is putting a cup in the ground",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.84
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14671,
            14675
          ],
          "representative_frame": 14671,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9168496131896973,
              "bbox": [
                383.8944396972656,
                0.0,
                640.0,
                248.63180541992188
              ]
            },
            {
              "track_id": 1088,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5522624254226685,
              "bbox": [
                282.75872802734375,
                79.78939819335938,
                370.53289794921875,
                157.4663848876953
              ]
            },
            {
              "track_id": 1089,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6815589070320129,
              "bbox": [
                337.75421142578125,
                144.9811553955078,
                406.47662353515625,
                187.9576416015625
              ]
            },
            {
              "track_id": 1091,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4842659533023834,
              "bbox": [
                367.1455078125,
                54.86003875732422,
                445.7461853027344,
                143.72207641601562
              ]
            },
            {
              "track_id": 1094,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.513968825340271,
              "bbox": [
                384.7101135253906,
                250.05484008789062,
                444.8569641113281,
                307.17718505859375
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1088,
            1089,
            1091,
            1094
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            14676,
            14680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14681,
            14685
          ],
          "representative_frame": 14681,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9265199899673462,
              "bbox": [
                389.07135009765625,
                0.0,
                640.0,
                241.77365112304688
              ]
            },
            {
              "track_id": 1088,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.581915020942688,
              "bbox": [
                282.7403869628906,
                79.77537536621094,
                370.4814758300781,
                157.42205810546875
              ]
            },
            {
              "track_id": 1089,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6227683424949646,
              "bbox": [
                335.4716491699219,
                143.17628479003906,
                407.796630859375,
                188.41552734375
              ]
            },
            {
              "track_id": 1091,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.468144953250885,
              "bbox": [
                366.5570373535156,
                54.82406997680664,
                446.0407409667969,
                144.63900756835938
              ]
            },
            {
              "track_id": 1094,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4913148283958435,
              "bbox": [
                384.7221984863281,
                250.11793518066406,
                444.84002685546875,
                307.2047424316406
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1088,
            1089,
            1091,
            1094
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            14686,
            14690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14691,
            14695
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9230228662490845,
              "bbox": [
                389.5857849121094,
                0.0,
                640.0,
                240.28578186035156
              ]
            },
            {
              "track_id": 1088,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6226319074630737,
              "bbox": [
                282.6878967285156,
                79.61571502685547,
                370.5868835449219,
                157.4020233154297
              ]
            },
            {
              "track_id": 1089,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5221795439720154,
              "bbox": [
                332.9059753417969,
                142.49046325683594,
                405.5653381347656,
                188.04844665527344
              ]
            },
            {
              "track_id": 1091,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.43028154969215393,
              "bbox": [
                366.12359619140625,
                54.81510543823242,
                445.7985534667969,
                144.77333068847656
              ]
            },
            {
              "track_id": 1094,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4974417984485626,
              "bbox": [
                384.7659912109375,
                250.35263061523438,
                444.73876953125,
                307.2870788574219
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1088,
            1089,
            1091,
            1094
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            14696,
            14700
          ],
          "representative_frame": 14696,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 122
    },
    {
      "second": 490,
      "time_range": [
        490,
        490.999
      ],
      "frame_range": [
        14701,
        14730
      ],
      "unified_description": "1-second scene with a man putting a cup of water in a tent",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:13",
        "processing_time": 2.55,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14715,
          "frame_range": [
            14711,
            14715
          ],
          "description": "a man is putting a cup of water in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.69
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14701,
            14705
          ],
          "representative_frame": 14701,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9528906345367432,
              "bbox": [
                378.5935974121094,
                0.0,
                635.9891357421875,
                242.68075561523438
              ]
            },
            {
              "track_id": 1088,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.508777916431427,
              "bbox": [
                282.4842529296875,
                79.66748046875,
                370.535400390625,
                157.6103973388672
              ]
            },
            {
              "track_id": 1089,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4094105660915375,
              "bbox": [
                330.9842224121094,
                141.6644744873047,
                408.1540222167969,
                190.2911834716797
              ]
            },
            {
              "track_id": 1091,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3942125737667084,
              "bbox": [
                363.82769775390625,
                54.6649284362793,
                444.0608215332031,
                145.4480438232422
              ]
            },
            {
              "track_id": 1094,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7116245031356812,
              "bbox": [
                385.2811279296875,
                251.97227478027344,
                445.5190124511719,
                309.1177978515625
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1088,
            1089,
            1091,
            1094
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            14706,
            14710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14711,
            14715
          ],
          "representative_frame": 14711,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9484038949012756,
              "bbox": [
                372.8116149902344,
                0.0,
                633.1948852539062,
                244.3177947998047
              ]
            },
            {
              "track_id": 1088,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5855613350868225,
              "bbox": [
                282.53619384765625,
                79.7627944946289,
                370.497314453125,
                157.63796997070312
              ]
            },
            {
              "track_id": 1089,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.15811309218406677,
              "bbox": [
                332.33306884765625,
                141.5029754638672,
                405.0938720703125,
                187.46820068359375
              ]
            },
            {
              "track_id": 1091,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.31586578488349915,
              "bbox": [
                363.23291015625,
                54.66546630859375,
                444.7010192871094,
                147.05477905273438
              ]
            },
            {
              "track_id": 1094,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7184299230575562,
              "bbox": [
                385.58056640625,
                252.7908172607422,
                445.6392517089844,
                309.7057189941406
              ]
            },
            {
              "track_id": 1101,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5399982333183289,
              "bbox": [
                354.2156677246094,
                306.538818359375,
                380.9382629394531,
                343.6758728027344
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1088,
            1089,
            1091,
            1094,
            1101
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            14716,
            14720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14721,
            14725
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.954729437828064,
              "bbox": [
                373.0432434082031,
                0.0,
                632.5982055664062,
                242.55540466308594
              ]
            },
            {
              "track_id": 1088,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.38609638810157776,
              "bbox": [
                282.5857849121094,
                79.77076721191406,
                370.504150390625,
                157.61663818359375
              ]
            },
            {
              "track_id": 1089,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.19637031853199005,
              "bbox": [
                330.6689453125,
                141.44863891601562,
                406.3868408203125,
                189.64663696289062
              ]
            },
            {
              "track_id": 1091,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3633415102958679,
              "bbox": [
                363.74456787109375,
                54.520660400390625,
                444.9379577636719,
                146.754638671875
              ]
            },
            {
              "track_id": 1094,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7023695707321167,
              "bbox": [
                385.3516540527344,
                252.73812866210938,
                445.63177490234375,
                309.7964782714844
              ]
            },
            {
              "track_id": 1101,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6371020674705505,
              "bbox": [
                354.17626953125,
                306.548095703125,
                380.94610595703125,
                343.7477722167969
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1088,
            1089,
            1091,
            1094,
            1101
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            14726,
            14730
          ],
          "representative_frame": 14726,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 122
    },
    {
      "second": 491,
      "time_range": [
        491,
        491.999
      ],
      "frame_range": [
        14731,
        14760
      ],
      "unified_description": "\n\nThis is a busy outdoor scene where a man sits in the grass with a tent. There are a few other people in the area, as well as two backpacks nearby. The camera captures this scene from a first-person perspective, providing an immersive view of the surroundings.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:16",
        "processing_time": 3.15,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14745,
          "frame_range": [
            14741,
            14745
          ],
          "description": "a man is sitting in the grass with a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.78
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14731,
            14735
          ],
          "representative_frame": 14731,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9517852663993835,
              "bbox": [
                374.88079833984375,
                0.0,
                634.9799194335938,
                242.9066162109375
              ]
            },
            {
              "track_id": 1088,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5527759194374084,
              "bbox": [
                282.6690673828125,
                79.89090728759766,
                370.4071350097656,
                157.58140563964844
              ]
            },
            {
              "track_id": 1091,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.31288397312164307,
              "bbox": [
                363.9527587890625,
                54.53357696533203,
                444.122802734375,
                145.78619384765625
              ]
            },
            {
              "track_id": 1094,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6898847222328186,
              "bbox": [
                385.54278564453125,
                253.05862426757812,
                445.6529235839844,
                309.8770751953125
              ]
            },
            {
              "track_id": 1101,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5945411324501038,
              "bbox": [
                354.1645202636719,
                306.5376281738281,
                380.96295166015625,
                343.7731628417969
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1088,
            1091,
            1094,
            1101
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            14736,
            14740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14741,
            14745
          ],
          "representative_frame": 14741,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.940671443939209,
              "bbox": [
                381.87353515625,
                0.0,
                633.3993530273438,
                233.64910888671875
              ]
            },
            {
              "track_id": 1088,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5716325640678406,
              "bbox": [
                282.57244873046875,
                79.91956329345703,
                370.3294372558594,
                157.64625549316406
              ]
            },
            {
              "track_id": 1091,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5115926861763,
              "bbox": [
                366.3072509765625,
                54.615684509277344,
                445.9656677246094,
                144.88645935058594
              ]
            },
            {
              "track_id": 1094,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5943846106529236,
              "bbox": [
                385.2482604980469,
                252.9119873046875,
                445.6353759765625,
                309.9359436035156
              ]
            },
            {
              "track_id": 1106,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4630349576473236,
              "bbox": [
                105.95515441894531,
                169.03794860839844,
                221.47140502929688,
                300.4482116699219
              ]
            },
            {
              "track_id": 1089,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.47366055846214294,
              "bbox": [
                334.37139892578125,
                142.51454162597656,
                407.8371276855469,
                189.25692749023438
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1088,
            1091,
            1094,
            1106,
            1089
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            14746,
            14750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14751,
            14755
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9485092163085938,
              "bbox": [
                374.3211669921875,
                0.0,
                629.7944946289062,
                235.41615295410156
              ]
            },
            {
              "track_id": 1088,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6298486590385437,
              "bbox": [
                282.5757751464844,
                79.94536590576172,
                370.3138122558594,
                157.6691131591797
              ]
            },
            {
              "track_id": 1091,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5997225642204285,
              "bbox": [
                366.4841003417969,
                54.59468078613281,
                446.5828552246094,
                145.08676147460938
              ]
            },
            {
              "track_id": 1094,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6902689933776855,
              "bbox": [
                385.19854736328125,
                252.89732360839844,
                445.5898132324219,
                309.8513488769531
              ]
            },
            {
              "track_id": 1106,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5219713449478149,
              "bbox": [
                105.76329040527344,
                168.3519287109375,
                222.47543334960938,
                301.0997009277344
              ]
            },
            {
              "track_id": 1089,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.15742669999599457,
              "bbox": [
                330.0655822753906,
                142.14735412597656,
                405.8730163574219,
                191.01657104492188
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1088,
            1091,
            1094,
            1106,
            1089
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            14756,
            14760
          ],
          "representative_frame": 14756,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 122
    },
    {
      "second": 492,
      "time_range": [
        492,
        492.999
      ],
      "frame_range": [
        14761,
        14790
      ],
      "unified_description": "1-second scene featuring a man digging a hole with a shovel in his backyard. The camera is mounted on a tripod, providing stable footage. This first-person perspective provides an immersive view of the subject at work.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:17",
        "processing_time": 2.96,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14775,
          "frame_range": [
            14771,
            14775
          ],
          "description": "a man is putting a bucket in the ground",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.49
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14761,
            14765
          ],
          "representative_frame": 14761,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9539663791656494,
              "bbox": [
                368.3338317871094,
                0.0,
                629.7706909179688,
                238.96463012695312
              ]
            },
            {
              "track_id": 1088,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6433505415916443,
              "bbox": [
                282.4896240234375,
                79.86408996582031,
                370.28839111328125,
                157.67393493652344
              ]
            },
            {
              "track_id": 1091,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5255447626113892,
              "bbox": [
                366.42437744140625,
                54.501827239990234,
                446.5692138671875,
                144.77865600585938
              ]
            },
            {
              "track_id": 1094,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6614457368850708,
              "bbox": [
                385.1273498535156,
                252.8911895751953,
                445.5484619140625,
                309.8086242675781
              ]
            },
            {
              "track_id": 1106,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5422897934913635,
              "bbox": [
                105.67182922363281,
                168.21664428710938,
                222.8714599609375,
                301.4685974121094
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1088,
            1091,
            1094,
            1106
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            14766,
            14770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14771,
            14775
          ],
          "representative_frame": 14771,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9118182063102722,
              "bbox": [
                360.6379699707031,
                0.0,
                633.2572021484375,
                248.43882751464844
              ]
            },
            {
              "track_id": 1088,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6201748847961426,
              "bbox": [
                282.43023681640625,
                79.7872314453125,
                370.3230285644531,
                157.72239685058594
              ]
            },
            {
              "track_id": 1091,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.391844242811203,
              "bbox": [
                366.9092102050781,
                54.448734283447266,
                446.2013854980469,
                143.36871337890625
              ]
            },
            {
              "track_id": 1094,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7041011452674866,
              "bbox": [
                385.09844970703125,
                252.94113159179688,
                445.5005187988281,
                309.769287109375
              ]
            },
            {
              "track_id": 1106,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5265144109725952,
              "bbox": [
                105.6180191040039,
                168.1079864501953,
                223.03753662109375,
                301.5550537109375
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1088,
            1091,
            1094,
            1106
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            14776,
            14780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14781,
            14785
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9267296195030212,
              "bbox": [
                345.5026550292969,
                0.1376832127571106,
                633.2037963867188,
                261.610595703125
              ]
            },
            {
              "track_id": 1088,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4608776867389679,
              "bbox": [
                275.548583984375,
                79.66990661621094,
                362.1014709472656,
                158.11053466796875
              ]
            },
            {
              "track_id": 1094,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6683613061904907,
              "bbox": [
                385.6509094238281,
                253.60684204101562,
                445.4439697265625,
                309.714111328125
              ]
            },
            {
              "track_id": 1106,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4069584310054779,
              "bbox": [
                106.34536743164062,
                169.61936950683594,
                222.251220703125,
                301.2071838378906
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1088,
            1094,
            1106
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            14786,
            14790
          ],
          "representative_frame": 14786,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 123
    },
    {
      "second": 493,
      "time_range": [
        493,
        493.999
      ],
      "frame_range": [
        14791,
        14820
      ],
      "unified_description": "4 people standing next to each other.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:18",
        "processing_time": 2.92,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14805,
          "frame_range": [
            14801,
            14805
          ],
          "description": "a man is putting a cup of water in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.27
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14791,
            14795
          ],
          "representative_frame": 14791,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.944898247718811,
              "bbox": [
                342.04779052734375,
                0.21274015307426453,
                631.0428466796875,
                261.0240783691406
              ]
            },
            {
              "track_id": 1088,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.33270347118377686,
              "bbox": [
                275.1501159667969,
                79.72177124023438,
                360.09967041015625,
                157.9768524169922
              ]
            },
            {
              "track_id": 1094,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6585442423820496,
              "bbox": [
                385.43145751953125,
                253.2984619140625,
                445.631103515625,
                309.74468994140625
              ]
            },
            {
              "track_id": 1106,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4140876233577728,
              "bbox": [
                106.33281707763672,
                169.55189514160156,
                222.292236328125,
                301.088623046875
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1088,
            1094,
            1106
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            14796,
            14800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14801,
            14805
          ],
          "representative_frame": 14801,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.928081214427948,
              "bbox": [
                338.30511474609375,
                0.5342617034912109,
                629.45166015625,
                261.22113037109375
              ]
            },
            {
              "track_id": 1088,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.33411866426467896,
              "bbox": [
                274.51544189453125,
                79.884521484375,
                358.0884094238281,
                158.32339477539062
              ]
            },
            {
              "track_id": 1094,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7470577359199524,
              "bbox": [
                385.3362121582031,
                253.1839599609375,
                445.7372131347656,
                309.7793273925781
              ]
            },
            {
              "track_id": 1106,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.44713515043258667,
              "bbox": [
                106.07015991210938,
                169.15478515625,
                222.3990020751953,
                301.0155944824219
              ]
            },
            {
              "track_id": 1112,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.48623549938201904,
              "bbox": [
                330.9762878417969,
                180.36260986328125,
                397.7291564941406,
                256.5920104980469
              ]
            },
            {
              "track_id": 1089,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2768420875072479,
              "bbox": [
                336.0677795410156,
                141.9947509765625,
                402.8985900878906,
                184.17129516601562
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1088,
            1094,
            1106,
            1112,
            1089
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            14806,
            14810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14811,
            14815
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4890258014202118,
              "bbox": [
                207.79925537109375,
                0.39157140254974365,
                546.8187866210938,
                278.00628662109375
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            14816,
            14820
          ],
          "representative_frame": 14816,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 123
    },
    {
      "second": 494,
      "time_range": [
        494,
        494.999
      ],
      "frame_range": [
        14821,
        14850
      ],
      "unified_description": "1 second video. A person is puring water into a bowl. The camera perspective is first-person. The scene appears to be indoors with natural lighting.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:20",
        "processing_time": 3.07,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14835,
          "frame_range": [
            14831,
            14835
          ],
          "description": "a person is pouring water into a bowl",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.63
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14821,
            14825
          ],
          "representative_frame": 14821,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6445416808128357,
              "bbox": [
                238.89308166503906,
                7.494986057281494,
                578.7322998046875,
                278.9066162109375
              ]
            },
            {
              "track_id": 1116,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7540518641471863,
              "bbox": [
                397.9655456542969,
                171.52951049804688,
                531.1495971679688,
                286.3977966308594
              ]
            },
            {
              "track_id": 1117,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6654854416847229,
              "bbox": [
                191.48240661621094,
                165.4112091064453,
                414.6380920410156,
                335.3647766113281
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1116,
            1117
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            14826,
            14830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14831,
            14835
          ],
          "representative_frame": 14831,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6772369742393494,
              "bbox": [
                247.15042114257812,
                7.552454948425293,
                593.027587890625,
                277.5174865722656
              ]
            },
            {
              "track_id": 1116,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7350607514381409,
              "bbox": [
                395.3601989746094,
                167.09475708007812,
                528.528564453125,
                281.9892578125
              ]
            },
            {
              "track_id": 1117,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.46538111567497253,
              "bbox": [
                186.43357849121094,
                161.71881103515625,
                409.5580749511719,
                331.8292236328125
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1116,
            1117
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            14836,
            14840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14841,
            14845
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8135312795639038,
              "bbox": [
                284.35943603515625,
                2.6934003829956055,
                579.0720825195312,
                219.43370056152344
              ]
            },
            {
              "track_id": 1116,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6719252467155457,
              "bbox": [
                393.88360595703125,
                162.5087127685547,
                525.2969360351562,
                275.94122314453125
              ]
            },
            {
              "track_id": 1117,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5474799275398254,
              "bbox": [
                167.85714721679688,
                132.18614196777344,
                421.11065673828125,
                326.37554931640625
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1116,
            1117
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            14846,
            14850
          ],
          "representative_frame": 14846,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 123
    },
    {
      "second": 495,
      "time_range": [
        495,
        495.999
      ],
      "frame_range": [
        14851,
        14880
      ],
      "unified_description": "1-second scene showing a man cooking outdoors",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:22",
        "processing_time": 2.29,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14865,
          "frame_range": [
            14861,
            14865
          ],
          "description": "a man cooking food in a pot on the ground",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.81
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14851,
            14855
          ],
          "representative_frame": 14851,
          "detections": [
            {
              "track_id": 1116,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.677842915058136,
              "bbox": [
                381.7777404785156,
                133.18325805664062,
                516.3643188476562,
                249.68838500976562
              ]
            }
          ],
          "unique_tracks": [
            1116
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            14856,
            14860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14861,
            14865
          ],
          "representative_frame": 14861,
          "detections": [
            {
              "track_id": 1116,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.6694616675376892,
              "bbox": [
                382.0082092285156,
                124.29886627197266,
                515.6727905273438,
                240.51161193847656
              ]
            },
            {
              "track_id": 1120,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6405879855155945,
              "bbox": [
                242.94747924804688,
                112.35679626464844,
                358.0397644042969,
                216.70907592773438
              ]
            },
            {
              "track_id": 1124,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3745880126953125,
              "bbox": [
                388.06500244140625,
                124.99559020996094,
                511.0781555175781,
                241.74920654296875
              ]
            },
            {
              "track_id": 1117,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4713422954082489,
              "bbox": [
                133.54481506347656,
                77.90465545654297,
                428.53558349609375,
                306.3953857421875
              ]
            }
          ],
          "unique_tracks": [
            1116,
            1120,
            1124,
            1117
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            14866,
            14870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14871,
            14875
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1116,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3468242585659027,
              "bbox": [
                385.28167724609375,
                121.26219177246094,
                516.7496337890625,
                236.39036560058594
              ]
            },
            {
              "track_id": 1120,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.46902143955230713,
              "bbox": [
                253.30838012695312,
                110.6971664428711,
                360.668701171875,
                207.760498046875
              ]
            },
            {
              "track_id": 1124,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.4309145212173462,
              "bbox": [
                391.8598937988281,
                124.66646575927734,
                512.966796875,
                239.72203063964844
              ]
            },
            {
              "track_id": 1117,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3823744058609009,
              "bbox": [
                134.48789978027344,
                68.90372467041016,
                437.398193359375,
                306.8317565917969
              ]
            }
          ],
          "unique_tracks": [
            1116,
            1120,
            1124,
            1117
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            14876,
            14880
          ],
          "representative_frame": 14876,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 123
    },
    {
      "second": 496,
      "time_range": [
        496,
        496.999
      ],
      "frame_range": [
        14881,
        14910
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:22",
        "processing_time": 2.3,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14895,
          "frame_range": [
            14891,
            14895
          ],
          "description": "a person is putting a pot in the grass",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.62
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14881,
            14885
          ],
          "representative_frame": 14881,
          "detections": [
            {
              "track_id": 1116,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.18371351063251495,
              "bbox": [
                388.7133483886719,
                132.37567138671875,
                506.88134765625,
                235.5149688720703
              ]
            },
            {
              "track_id": 1124,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7897533774375916,
              "bbox": [
                395.0472412109375,
                136.94680786132812,
                502.9081726074219,
                239.0420684814453
              ]
            },
            {
              "track_id": 1117,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.11759331077337265,
              "bbox": [
                121.69268035888672,
                50.50113296508789,
                445.5444030761719,
                309.06201171875
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8911778330802917,
              "bbox": [
                380.7254943847656,
                0.4187370538711548,
                615.9569091796875,
                169.84552001953125
              ]
            }
          ],
          "unique_tracks": [
            1116,
            1124,
            1117,
            1075
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            14886,
            14890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14891,
            14895
          ],
          "representative_frame": 14891,
          "detections": [
            {
              "track_id": 1124,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.477477103471756,
              "bbox": [
                404.685791015625,
                150.20028686523438,
                499.0362548828125,
                238.70375061035156
              ]
            },
            {
              "track_id": 1117,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.7558166980743408,
              "bbox": [
                135.18783569335938,
                54.285884857177734,
                431.5939636230469,
                293.9581604003906
              ]
            },
            {
              "track_id": 1131,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.34439703822135925,
              "bbox": [
                0.0,
                0.8990691900253296,
                397.83935546875,
                102.42928314208984
              ]
            },
            {
              "track_id": 1132,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4563487470149994,
              "bbox": [
                540.6612548828125,
                232.21115112304688,
                640.0,
                357.6743469238281
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9050793051719666,
              "bbox": [
                379.4586486816406,
                6.895822048187256,
                635.1834716796875,
                191.32479858398438
              ]
            }
          ],
          "unique_tracks": [
            1124,
            1117,
            1131,
            1132,
            1075
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            14896,
            14900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14901,
            14905
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1124,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4032549560070038,
              "bbox": [
                410.1626281738281,
                159.7061004638672,
                499.8368835449219,
                242.7467498779297
              ]
            },
            {
              "track_id": 1117,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.43435752391815186,
              "bbox": [
                129.7702178955078,
                62.900115966796875,
                417.91619873046875,
                299.0281677246094
              ]
            },
            {
              "track_id": 1131,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4042918384075165,
              "bbox": [
                0.0,
                0.8526065349578857,
                402.5660705566406,
                105.44216918945312
              ]
            },
            {
              "track_id": 1132,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5044018030166626,
              "bbox": [
                543.5653686523438,
                233.26849365234375,
                640.0,
                358.02911376953125
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8632906079292297,
              "bbox": [
                374.0279846191406,
                14.517468452453613,
                640.0,
                208.7843475341797
              ]
            },
            {
              "track_id": 1133,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.7875580787658691,
              "bbox": [
                0.0,
                114.64350891113281,
                131.54220581054688,
                292.8904113769531
              ]
            }
          ],
          "unique_tracks": [
            1124,
            1117,
            1131,
            1132,
            1075,
            1133
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            14906,
            14910
          ],
          "representative_frame": 14906,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 124
    },
    {
      "second": 497,
      "time_range": [
        497,
        497.999
      ],
      "frame_range": [
        14911,
        14940
      ],
      "unified_description": "\n\nThe image shows a person performing a task outdoors. They are in the process of planting a small sapling. The individual appears focused on their work. Surrounding the scene, various objects can be seen, such as a backpack nearby, possibly holding tools or supplies used for the gardening activity.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:24",
        "processing_time": 3.76,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14925,
          "frame_range": [
            14921,
            14925
          ],
          "description": "a person is putting a pot in the ground",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14911,
            14915
          ],
          "representative_frame": 14911,
          "detections": [
            {
              "track_id": 1117,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.921675443649292,
              "bbox": [
                133.8978729248047,
                68.70858001708984,
                423.7887878417969,
                308.816162109375
              ]
            },
            {
              "track_id": 1131,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.258235901594162,
              "bbox": [
                0.0,
                0.6056098341941833,
                411.1717224121094,
                109.26644897460938
              ]
            },
            {
              "track_id": 1132,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3383249044418335,
              "bbox": [
                549.7258911132812,
                238.29104614257812,
                640.0,
                357.9465026855469
              ]
            },
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8299406170845032,
              "bbox": [
                423.2166748046875,
                8.389147758483887,
                640.0,
                174.5577850341797
              ]
            },
            {
              "track_id": 1133,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.6537087559700012,
              "bbox": [
                0.0,
                117.51837158203125,
                133.021240234375,
                297.7152404785156
              ]
            },
            {
              "track_id": 1116,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.8014724850654602,
              "bbox": [
                390.6275939941406,
                127.34950256347656,
                523.9519653320312,
                245.05560302734375
              ]
            }
          ],
          "unique_tracks": [
            1117,
            1131,
            1132,
            1075,
            1133,
            1116
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            14916,
            14920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14921,
            14925
          ],
          "representative_frame": 14921,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9341134428977966,
              "bbox": [
                298.5367736816406,
                2.6675565242767334,
                640.0,
                273.5417175292969
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            14926,
            14930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14931,
            14935
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9036964774131775,
              "bbox": [
                266.9884948730469,
                0.9084203839302063,
                640.0,
                296.0778503417969
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            14936,
            14940
          ],
          "representative_frame": 14936,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 124
    },
    {
      "second": 498,
      "time_range": [
        498,
        498.999
      ],
      "frame_range": [
        14941,
        14970
      ],
      "unified_description": "360 video showing a man setting up a tent in the woods",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:26",
        "processing_time": 2.51,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14955,
          "frame_range": [
            14951,
            14955
          ],
          "description": "a man is setting up a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.32
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14941,
            14945
          ],
          "representative_frame": 14941,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9171538949012756,
              "bbox": [
                251.0178985595703,
                0.018007170408964157,
                640.0,
                309.277099609375
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            14946,
            14950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14951,
            14955
          ],
          "representative_frame": 14951,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9082247614860535,
              "bbox": [
                245.6144256591797,
                0.0,
                635.127197265625,
                313.7908020019531
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            14956,
            14960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14961,
            14965
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9485092163085938,
              "bbox": [
                240.20944213867188,
                34.65052032470703,
                621.1978759765625,
                344.2557067871094
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            14966,
            14970
          ],
          "representative_frame": 14966,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 124
    },
    {
      "second": 499,
      "time_range": [
        499,
        499.999
      ],
      "frame_range": [
        14971,
        15000
      ],
      "unified_description": "3rd person perspective camera view of a person cooking in a kitchen.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:26",
        "processing_time": 2.38,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 14985,
          "frame_range": [
            14981,
            14985
          ],
          "description": "a man is putting food in a pot",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.9
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            14971,
            14975
          ],
          "representative_frame": 14971,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9473865628242493,
              "bbox": [
                240.117919921875,
                49.15970993041992,
                614.7422485351562,
                355.73138427734375
              ]
            },
            {
              "track_id": 1141,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8187541365623474,
              "bbox": [
                259.16192626953125,
                280.7615051269531,
                342.4723815917969,
                353.1095886230469
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1141
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            14976,
            14980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            14981,
            14985
          ],
          "representative_frame": 14981,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9347439408302307,
              "bbox": [
                244.7268524169922,
                54.64228439331055,
                614.0353393554688,
                359.45416259765625
              ]
            },
            {
              "track_id": 1141,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.398041695356369,
              "bbox": [
                256.56646728515625,
                274.3184814453125,
                346.7204895019531,
                352.6918640136719
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1141
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            14986,
            14990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            14991,
            14995
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9329288601875305,
              "bbox": [
                284.1005859375,
                69.0386962890625,
                632.8152465820312,
                360.0
              ]
            },
            {
              "track_id": 1141,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3739624321460724,
              "bbox": [
                256.0086364746094,
                272.6446533203125,
                347.95355224609375,
                352.67596435546875
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1141
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            14996,
            15000
          ],
          "representative_frame": 14996,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 124
    },
    {
      "second": 500,
      "time_range": [
        500,
        500.999
      ],
      "frame_range": [
        15001,
        15030
      ],
      "unified_description": "30-second videos often include more action, movement or dynamic elements than 1-second videos.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:28",
        "processing_time": 2.68,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15015,
          "frame_range": [
            15011,
            15015
          ],
          "description": "a man is putting food in a bowl",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.65
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15001,
            15005
          ],
          "representative_frame": 15001,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9535269737243652,
              "bbox": [
                315.37225341796875,
                79.24910736083984,
                640.0,
                360.0
              ]
            },
            {
              "track_id": 1141,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3628261089324951,
              "bbox": [
                255.969482421875,
                272.2325744628906,
                348.3966979980469,
                352.81231689453125
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1141
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            15006,
            15010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15011,
            15015
          ],
          "representative_frame": 15011,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9418595433235168,
              "bbox": [
                287.8642883300781,
                28.80808448791504,
                640.0,
                359.41094970703125
              ]
            },
            {
              "track_id": 1141,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4651079475879669,
              "bbox": [
                243.74371337890625,
                247.87722778320312,
                365.0299377441406,
                353.6702575683594
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1141
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            15016,
            15020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15021,
            15025
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9466459155082703,
              "bbox": [
                282.0543518066406,
                10.592044830322266,
                640.0,
                359.2602233886719
              ]
            },
            {
              "track_id": 1141,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6004725694656372,
              "bbox": [
                255.78759765625,
                230.58657836914062,
                360.6417236328125,
                319.3534851074219
              ]
            },
            {
              "track_id": 1146,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6560469269752502,
              "bbox": [
                319.98333740234375,
                330.4381408691406,
                388.6747741699219,
                359.87896728515625
              ]
            },
            {
              "track_id": 1148,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.3451104462146759,
              "bbox": [
                1.300069808959961,
                35.37853240966797,
                374.2535095214844,
                225.45606994628906
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1141,
            1146,
            1148
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            15026,
            15030
          ],
          "representative_frame": 15026,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 125
    },
    {
      "second": 501,
      "time_range": [
        501,
        501.999
      ],
      "frame_range": [
        15031,
        15060
      ],
      "unified_description": "3D model of a person placing something on top of their head",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:30",
        "processing_time": 2.34,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15045,
          "frame_range": [
            15041,
            15045
          ],
          "description": "a man is putting food in a bowl",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.54
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15031,
            15035
          ],
          "representative_frame": 15031,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9484456181526184,
              "bbox": [
                278.58697509765625,
                3.061305046081543,
                640.0,
                360.0
              ]
            },
            {
              "track_id": 1141,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.21712273359298706,
              "bbox": [
                244.87681579589844,
                227.4947509765625,
                361.9532775878906,
                325.8022155761719
              ]
            },
            {
              "track_id": 1146,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.638481855392456,
              "bbox": [
                320.0749206542969,
                330.5108947753906,
                388.5380859375,
                359.8576965332031
              ]
            },
            {
              "track_id": 1148,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.41137775778770447,
              "bbox": [
                0.0,
                34.65912628173828,
                362.8992919921875,
                222.2444610595703
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1141,
            1146,
            1148
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            15036,
            15040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15041,
            15045
          ],
          "representative_frame": 15041,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9434282183647156,
              "bbox": [
                268.64691162109375,
                0.3631453216075897,
                640.0,
                360.0
              ]
            },
            {
              "track_id": 1141,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5387097597122192,
              "bbox": [
                226.18820190429688,
                229.73037719726562,
                359.5390930175781,
                342.3722229003906
              ]
            },
            {
              "track_id": 1146,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6214978098869324,
              "bbox": [
                320.08099365234375,
                330.535888671875,
                388.4570617675781,
                359.84844970703125
              ]
            },
            {
              "track_id": 1148,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.49536001682281494,
              "bbox": [
                0.0,
                36.13196563720703,
                355.2113342285156,
                221.90554809570312
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1141,
            1146,
            1148
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            15046,
            15050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15051,
            15055
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9403114914894104,
              "bbox": [
                255.3072967529297,
                0.0,
                640.0,
                360.0
              ]
            },
            {
              "track_id": 1141,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5465193390846252,
              "bbox": [
                223.44000244140625,
                227.900146484375,
                329.1571350097656,
                314.1036071777344
              ]
            },
            {
              "track_id": 1146,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6461837887763977,
              "bbox": [
                320.11724853515625,
                330.5412902832031,
                388.44281005859375,
                359.83477783203125
              ]
            },
            {
              "track_id": 1148,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.2559521496295929,
              "bbox": [
                0.0,
                33.95367431640625,
                344.90484619140625,
                219.7010498046875
              ]
            },
            {
              "track_id": 1150,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.33013367652893066,
              "bbox": [
                341.3734436035156,
                240.86572265625,
                424.69927978515625,
                330.8285217285156
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1141,
            1146,
            1148,
            1150
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            15056,
            15060
          ],
          "representative_frame": 15056,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 125
    },
    {
      "second": 502,
      "time_range": [
        502,
        502.999
      ],
      "frame_range": [
        15061,
        15090
      ],
      "unified_description": "3rd person camera perspective with field of view showing a man preparing a meal outdoors.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:31",
        "processing_time": 2.59,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15075,
          "frame_range": [
            15071,
            15075
          ],
          "description": "a man is putting food in a pot",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.63
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15061,
            15065
          ],
          "representative_frame": 15061,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9549939036369324,
              "bbox": [
                242.2470245361328,
                0.0,
                627.9278564453125,
                359.9523620605469
              ]
            },
            {
              "track_id": 1141,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8676468133926392,
              "bbox": [
                207.3529510498047,
                222.28091430664062,
                288.11322021484375,
                285.2836608886719
              ]
            },
            {
              "track_id": 1146,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6521157026290894,
              "bbox": [
                320.1617126464844,
                330.5739440917969,
                388.37884521484375,
                359.8199462890625
              ]
            },
            {
              "track_id": 1148,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.3945387601852417,
              "bbox": [
                0.0,
                34.73556900024414,
                330.3362121582031,
                220.9673614501953
              ]
            },
            {
              "track_id": 1150,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2833499014377594,
              "bbox": [
                341.3497314453125,
                241.476318359375,
                423.7508239746094,
                330.5263366699219
              ]
            },
            {
              "track_id": 1151,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7528502345085144,
              "bbox": [
                258.70538330078125,
                273.34149169921875,
                345.643798828125,
                353.0749816894531
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1141,
            1146,
            1148,
            1150,
            1151
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            15066,
            15070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15071,
            15075
          ],
          "representative_frame": 15071,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9511500597000122,
              "bbox": [
                234.08839416503906,
                0.0,
                623.1654052734375,
                360.0
              ]
            },
            {
              "track_id": 1141,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7084649801254272,
              "bbox": [
                188.62353515625,
                235.8441162109375,
                248.099853515625,
                280.3702697753906
              ]
            },
            {
              "track_id": 1146,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6364402770996094,
              "bbox": [
                320.44110107421875,
                330.71527099609375,
                388.50616455078125,
                359.8797302246094
              ]
            },
            {
              "track_id": 1148,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.21118874847888947,
              "bbox": [
                0.0,
                34.636287689208984,
                322.82855224609375,
                220.63735961914062
              ]
            },
            {
              "track_id": 1150,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.22144192457199097,
              "bbox": [
                341.8417663574219,
                241.46148681640625,
                424.03070068359375,
                330.3832702636719
              ]
            },
            {
              "track_id": 1151,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6769858002662659,
              "bbox": [
                259.21942138671875,
                273.6409912109375,
                345.60498046875,
                352.82586669921875
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1141,
            1146,
            1148,
            1150,
            1151
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            15076,
            15080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15081,
            15085
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9545660614967346,
              "bbox": [
                235.96664428710938,
                11.5404634475708,
                615.758544921875,
                359.09173583984375
              ]
            },
            {
              "track_id": 1146,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5830403566360474,
              "bbox": [
                320.6094665527344,
                330.7855529785156,
                388.47344970703125,
                359.8402404785156
              ]
            },
            {
              "track_id": 1148,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.17729085683822632,
              "bbox": [
                0.0,
                33.990604400634766,
                338.268798828125,
                219.5966033935547
              ]
            },
            {
              "track_id": 1150,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.1072341650724411,
              "bbox": [
                339.49530029296875,
                245.32144165039062,
                417.5497131347656,
                330.1202087402344
              ]
            },
            {
              "track_id": 1151,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5337074398994446,
              "bbox": [
                259.397705078125,
                273.6911315917969,
                345.5872802734375,
                352.63726806640625
              ]
            },
            {
              "track_id": 1153,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.35056498646736145,
              "bbox": [
                293.0860290527344,
                227.14425659179688,
                338.5726318359375,
                279.1504211425781
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1146,
            1148,
            1150,
            1151,
            1153
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            15086,
            15090
          ],
          "representative_frame": 15086,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 125
    },
    {
      "second": 503,
      "time_range": [
        503,
        503.999
      ],
      "frame_range": [
        15091,
        15120
      ],
      "unified_description": "1-second scene including a woman laying on a blanket",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:31",
        "processing_time": 2.63,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15105,
          "frame_range": [
            15101,
            15105
          ],
          "description": "a woman laying on a blanket",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.85
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15091,
            15095
          ],
          "representative_frame": 15091,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9243107438087463,
              "bbox": [
                247.37112426757812,
                47.90578079223633,
                596.6704711914062,
                357.2787170410156
              ]
            },
            {
              "track_id": 1146,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.655459463596344,
              "bbox": [
                320.493896484375,
                330.6137390136719,
                388.3377685546875,
                359.6328125
              ]
            },
            {
              "track_id": 1148,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.35016289353370667,
              "bbox": [
                0.0,
                33.937042236328125,
                311.4274597167969,
                218.21566772460938
              ]
            },
            {
              "track_id": 1151,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5454133749008179,
              "bbox": [
                259.2030334472656,
                273.69952392578125,
                345.397216796875,
                352.5883483886719
              ]
            },
            {
              "track_id": 1153,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5333950519561768,
              "bbox": [
                293.53424072265625,
                227.0594482421875,
                339.0252990722656,
                279.0861511230469
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1146,
            1148,
            1151,
            1153
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            15096,
            15100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15101,
            15105
          ],
          "representative_frame": 15101,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2779659628868103,
              "bbox": [
                252.11814880371094,
                50.63951873779297,
                604.3349609375,
                356.72711181640625
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            15106,
            15110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15111,
            15115
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3376350700855255,
              "bbox": [
                255.9805908203125,
                58.11152648925781,
                606.04833984375,
                356.2157287597656
              ]
            },
            {
              "track_id": 1155,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5668557286262512,
              "bbox": [
                290.7160949707031,
                0.42094725370407104,
                375.50390625,
                74.9622573852539
              ]
            },
            {
              "track_id": 1156,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.51701819896698,
              "bbox": [
                200.03721618652344,
                297.1424255371094,
                282.94952392578125,
                359.21038818359375
              ]
            },
            {
              "track_id": 1158,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.40597963333129883,
              "bbox": [
                131.65887451171875,
                283.3451232910156,
                187.32110595703125,
                338.66796875
              ]
            },
            {
              "track_id": 1160,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3533935546875,
              "bbox": [
                92.1579818725586,
                66.19293212890625,
                144.75343322753906,
                132.94241333007812
              ]
            },
            {
              "track_id": 1120,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4964754581451416,
              "bbox": [
                289.9364013671875,
                45.70164489746094,
                475.2728576660156,
                232.5043182373047
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1155,
            1156,
            1158,
            1160,
            1120
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            15116,
            15120
          ],
          "representative_frame": 15116,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 125
    },
    {
      "second": 504,
      "time_range": [
        504,
        504.999
      ],
      "frame_range": [
        15121,
        15150
      ],
      "unified_description": "\n\nIn the image, there is a woman who is laying down in a tent. She appears to be quite comfortable and relaxed as she lays there. The tent seems to be the main focus of the scene, with the woman being the secondary element. Aside from her, no other people or objects are prominently featured in the image. The photo has an artistic quality to it, capturing a moment of tranquility and solitude.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:35",
        "processing_time": 3.84,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15135,
          "frame_range": [
            15131,
            15135
          ],
          "description": "a woman is laying down in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.16
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15121,
            15125
          ],
          "representative_frame": 15121,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 13,
              "class_name": "bench",
              "confidence": 0.2228042334318161,
              "bbox": [
                265.1529541015625,
                81.58100128173828,
                597.433837890625,
                355.99078369140625
              ]
            },
            {
              "track_id": 1155,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7166674733161926,
              "bbox": [
                293.93988037109375,
                0.5116347074508667,
                378.4599304199219,
                74.69013214111328
              ]
            },
            {
              "track_id": 1156,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5792009830474854,
              "bbox": [
                200.33786010742188,
                297.3201904296875,
                283.1498718261719,
                359.2931213378906
              ]
            },
            {
              "track_id": 1158,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5195034146308899,
              "bbox": [
                132.2570343017578,
                283.5213928222656,
                188.04269409179688,
                338.98291015625
              ]
            },
            {
              "track_id": 1160,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3516969382762909,
              "bbox": [
                92.68659210205078,
                66.10649871826172,
                145.0943145751953,
                132.59043884277344
              ]
            },
            {
              "track_id": 1120,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.39344337582588196,
              "bbox": [
                298.6669616699219,
                44.57460403442383,
                474.52984619140625,
                234.704833984375
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1155,
            1156,
            1158,
            1160,
            1120
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            15126,
            15130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15131,
            15135
          ],
          "representative_frame": 15131,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 13,
              "class_name": "bench",
              "confidence": 0.1776983141899109,
              "bbox": [
                268.91796875,
                89.70062255859375,
                599.14111328125,
                355.6155090332031
              ]
            },
            {
              "track_id": 1155,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.17146605253219604,
              "bbox": [
                293.5440368652344,
                0.5327907800674438,
                376.0033874511719,
                72.88626098632812
              ]
            },
            {
              "track_id": 1156,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4370110034942627,
              "bbox": [
                200.4380645751953,
                295.4455871582031,
                284.1251220703125,
                358.1329345703125
              ]
            },
            {
              "track_id": 1158,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.15370430052280426,
              "bbox": [
                133.66061401367188,
                281.2623291015625,
                186.2431640625,
                333.6109619140625
              ]
            },
            {
              "track_id": 1160,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.22393940389156342,
              "bbox": [
                95.71621704101562,
                63.03605270385742,
                147.84146118164062,
                129.10580444335938
              ]
            },
            {
              "track_id": 1120,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6294856071472168,
              "bbox": [
                303.54541015625,
                46.65623474121094,
                469.5170593261719,
                237.60720825195312
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1155,
            1156,
            1158,
            1160,
            1120
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            15136,
            15140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15141,
            15145
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1155,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.42882195115089417,
              "bbox": [
                292.8377990722656,
                0.5887836813926697,
                373.42449951171875,
                71.3389663696289
              ]
            },
            {
              "track_id": 1156,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5012779235839844,
              "bbox": [
                198.98019409179688,
                293.6377258300781,
                284.0691223144531,
                357.43914794921875
              ]
            },
            {
              "track_id": 1158,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.18699583411216736,
              "bbox": [
                132.961669921875,
                278.81536865234375,
                185.09571838378906,
                330.8615417480469
              ]
            },
            {
              "track_id": 1160,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2699906826019287,
              "bbox": [
                96.48860168457031,
                61.58144760131836,
                148.29220581054688,
                127.12197875976562
              ]
            },
            {
              "track_id": 1120,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5827164649963379,
              "bbox": [
                303.31890869140625,
                44.533668518066406,
                464.9148254394531,
                239.16798400878906
              ]
            }
          ],
          "unique_tracks": [
            1155,
            1156,
            1158,
            1160,
            1120
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            15146,
            15150
          ],
          "representative_frame": 15146,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 126
    },
    {
      "second": 505,
      "time_range": [
        505,
        505.999
      ],
      "frame_range": [
        15151,
        15180
      ],
      "unified_description": "1-second scene that includes a tent, a woman, and a man",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:35",
        "processing_time": 3.17,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15165,
          "frame_range": [
            15161,
            15165
          ],
          "description": "a woman laying in a tent with a man",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.61
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15151,
            15155
          ],
          "representative_frame": 15151,
          "detections": [
            {
              "track_id": 1155,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46910926699638367,
              "bbox": [
                297.3075866699219,
                0.6909148097038269,
                380.75244140625,
                73.60183715820312
              ]
            },
            {
              "track_id": 1156,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4385087788105011,
              "bbox": [
                201.86570739746094,
                292.5983581542969,
                286.8420104980469,
                356.4309387207031
              ]
            },
            {
              "track_id": 1158,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.1881367266178131,
              "bbox": [
                135.14283752441406,
                278.2260437011719,
                186.735107421875,
                329.9739685058594
              ]
            },
            {
              "track_id": 1160,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.13225844502449036,
              "bbox": [
                98.2226791381836,
                61.701541900634766,
                149.54144287109375,
                126.50471496582031
              ]
            },
            {
              "track_id": 1120,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5142127275466919,
              "bbox": [
                312.8118591308594,
                48.47665023803711,
                464.79815673828125,
                238.82472229003906
              ]
            }
          ],
          "unique_tracks": [
            1155,
            1156,
            1158,
            1160,
            1120
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            15156,
            15160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15161,
            15165
          ],
          "representative_frame": 15161,
          "detections": [
            {
              "track_id": 1155,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4054344892501831,
              "bbox": [
                299.622314453125,
                0.5679898858070374,
                382.13775634765625,
                72.21745300292969
              ]
            },
            {
              "track_id": 1156,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7594927549362183,
              "bbox": [
                203.47471618652344,
                290.34759521484375,
                288.7738952636719,
                354.5516662597656
              ]
            },
            {
              "track_id": 1158,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.18963508307933807,
              "bbox": [
                137.45263671875,
                276.1990966796875,
                190.33566284179688,
                329.4631652832031
              ]
            },
            {
              "track_id": 1160,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2652606964111328,
              "bbox": [
                99.37318420410156,
                60.93360137939453,
                150.75730895996094,
                125.64739227294922
              ]
            },
            {
              "track_id": 1120,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7759049534797668,
              "bbox": [
                324.9624328613281,
                54.6279411315918,
                465.8555603027344,
                236.2982635498047
              ]
            },
            {
              "track_id": 1075,
              "class_id": 57,
              "class_name": "couch",
              "confidence": 0.4847099781036377,
              "bbox": [
                269.02301025390625,
                86.77040100097656,
                609.3076782226562,
                355.30987548828125
              ]
            }
          ],
          "unique_tracks": [
            1155,
            1156,
            1158,
            1160,
            1120,
            1075
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            15166,
            15170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15171,
            15175
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1155,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.48296770453453064,
              "bbox": [
                296.30218505859375,
                0.5801362991333008,
                378.9627685546875,
                72.46330261230469
              ]
            },
            {
              "track_id": 1156,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6722913384437561,
              "bbox": [
                204.63343811035156,
                290.02880859375,
                289.10919189453125,
                353.75537109375
              ]
            },
            {
              "track_id": 1158,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.29020291566848755,
              "bbox": [
                138.70150756835938,
                276.0747375488281,
                190.7627410888672,
                328.81488037109375
              ]
            },
            {
              "track_id": 1160,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2891881763935089,
              "bbox": [
                98.94692993164062,
                61.07499313354492,
                150.41079711914062,
                125.68682098388672
              ]
            },
            {
              "track_id": 1120,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5041987895965576,
              "bbox": [
                323.9365234375,
                58.473793029785156,
                459.8111267089844,
                238.02951049804688
              ]
            },
            {
              "track_id": 1171,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.34280094504356384,
              "bbox": [
                0.1020561009645462,
                84.66559600830078,
                29.708393096923828,
                122.37556457519531
              ]
            },
            {
              "track_id": 1075,
              "class_id": 57,
              "class_name": "couch",
              "confidence": 0.3462604880332947,
              "bbox": [
                264.1883850097656,
                83.9188461303711,
                613.7073974609375,
                355.1383056640625
              ]
            }
          ],
          "unique_tracks": [
            1155,
            1156,
            1158,
            1160,
            1120,
            1171,
            1075
          ],
          "total_detections": 7
        },
        {
          "group_index": 5,
          "frame_range": [
            15176,
            15180
          ],
          "representative_frame": 15176,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 126
    },
    {
      "second": 506,
      "time_range": [
        506,
        506.999
      ],
      "frame_range": [
        15181,
        15210
      ],
      "unified_description": "4k WIDE ANGLE LENSES WITH DISTORTION AND SHAKY CAMERA FOOTAGE OF TENT CAMPING.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:36",
        "processing_time": 3.97,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15195,
          "frame_range": [
            15191,
            15195
          ],
          "description": "a man and woman are sleeping in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.38
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15181,
            15185
          ],
          "representative_frame": 15181,
          "detections": [
            {
              "track_id": 1155,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3701646029949188,
              "bbox": [
                295.6813049316406,
                0.5539984703063965,
                378.5099792480469,
                72.62297058105469
              ]
            },
            {
              "track_id": 1156,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.480479896068573,
              "bbox": [
                206.118896484375,
                289.7002258300781,
                290.12799072265625,
                353.28460693359375
              ]
            },
            {
              "track_id": 1158,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.34123343229293823,
              "bbox": [
                141.51869201660156,
                276.3521728515625,
                192.55966186523438,
                328.3558654785156
              ]
            },
            {
              "track_id": 1160,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.17125627398490906,
              "bbox": [
                99.42430114746094,
                61.9655647277832,
                151.15695190429688,
                126.64244842529297
              ]
            },
            {
              "track_id": 1120,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5893777012825012,
              "bbox": [
                323.48223876953125,
                61.599693298339844,
                455.1239318847656,
                238.94300842285156
              ]
            },
            {
              "track_id": 1171,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5814399719238281,
              "bbox": [
                0.8555715084075928,
                85.92205047607422,
                30.389896392822266,
                123.49693298339844
              ]
            },
            {
              "track_id": 1075,
              "class_id": 57,
              "class_name": "couch",
              "confidence": 0.2597224712371826,
              "bbox": [
                262.4160461425781,
                85.41278839111328,
                615.57568359375,
                355.1640625
              ]
            }
          ],
          "unique_tracks": [
            1155,
            1156,
            1158,
            1160,
            1120,
            1171,
            1075
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            15186,
            15190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15191,
            15195
          ],
          "representative_frame": 15191,
          "detections": [
            {
              "track_id": 1155,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4237523376941681,
              "bbox": [
                299.70281982421875,
                0.6465316414833069,
                383.9107971191406,
                73.30255889892578
              ]
            },
            {
              "track_id": 1156,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7468992471694946,
              "bbox": [
                208.8765869140625,
                287.45648193359375,
                292.3555603027344,
                350.9060363769531
              ]
            },
            {
              "track_id": 1158,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2742129862308502,
              "bbox": [
                143.69935607910156,
                274.1748046875,
                194.0348358154297,
                325.80950927734375
              ]
            },
            {
              "track_id": 1160,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.23834116756916046,
              "bbox": [
                100.8822250366211,
                62.233577728271484,
                152.68496704101562,
                127.00033569335938
              ]
            },
            {
              "track_id": 1120,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7426818609237671,
              "bbox": [
                325.04229736328125,
                61.328521728515625,
                453.1266174316406,
                236.2526092529297
              ]
            },
            {
              "track_id": 1171,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.48036158084869385,
              "bbox": [
                1.9681379795074463,
                85.92970275878906,
                31.36599349975586,
                123.17909240722656
              ]
            },
            {
              "track_id": 1075,
              "class_id": 57,
              "class_name": "couch",
              "confidence": 0.18614766001701355,
              "bbox": [
                258.8565368652344,
                81.45954132080078,
                620.6200561523438,
                354.7781066894531
              ]
            }
          ],
          "unique_tracks": [
            1155,
            1156,
            1158,
            1160,
            1120,
            1171,
            1075
          ],
          "total_detections": 7
        },
        {
          "group_index": 3,
          "frame_range": [
            15196,
            15200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15201,
            15205
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1155,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.29128849506378174,
              "bbox": [
                300.5232238769531,
                0.41469958424568176,
                384.9429626464844,
                73.1903076171875
              ]
            },
            {
              "track_id": 1156,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.790966808795929,
              "bbox": [
                210.40843200683594,
                286.14117431640625,
                292.14239501953125,
                348.51434326171875
              ]
            },
            {
              "track_id": 1158,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.25945404171943665,
              "bbox": [
                148.6990966796875,
                272.63665771484375,
                197.4586944580078,
                322.4675598144531
              ]
            },
            {
              "track_id": 1160,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.23601442575454712,
              "bbox": [
                102.42451477050781,
                65.12351989746094,
                153.69256591796875,
                129.0760040283203
              ]
            },
            {
              "track_id": 1120,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.574955940246582,
              "bbox": [
                325.43023681640625,
                67.89331817626953,
                447.27227783203125,
                234.22642517089844
              ]
            },
            {
              "track_id": 1171,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4203546643257141,
              "bbox": [
                3.5205743312835693,
                89.9900894165039,
                32.3410758972168,
                126.13627624511719
              ]
            },
            {
              "track_id": 1075,
              "class_id": 13,
              "class_name": "bench",
              "confidence": 0.2972409129142761,
              "bbox": [
                260.6703796386719,
                87.11378479003906,
                620.3548583984375,
                355.2233581542969
              ]
            },
            {
              "track_id": 1176,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.37017539143562317,
              "bbox": [
                176.29080200195312,
                232.63406372070312,
                260.5723571777344,
                300.48944091796875
              ]
            }
          ],
          "unique_tracks": [
            1155,
            1156,
            1158,
            1160,
            1120,
            1171,
            1075,
            1176
          ],
          "total_detections": 8
        },
        {
          "group_index": 5,
          "frame_range": [
            15206,
            15210
          ],
          "representative_frame": 15206,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 126
    },
    {
      "second": 507,
      "time_range": [
        507,
        507.999
      ],
      "frame_range": [
        15211,
        15240
      ],
      "unified_description": "2D scene with multiple subjects, some in motion, others stationary, shot with a wide-angle lens, POV camera perspective",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:39",
        "processing_time": 2.6,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15225,
          "frame_range": [
            15221,
            15225
          ],
          "description": "a woman is laying down in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.52
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15211,
            15215
          ],
          "representative_frame": 15211,
          "detections": [
            {
              "track_id": 1155,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3878428041934967,
              "bbox": [
                300.0281066894531,
                0.3509671986103058,
                385.8426208496094,
                74.00037384033203
              ]
            },
            {
              "track_id": 1156,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7721831202507019,
              "bbox": [
                209.9590606689453,
                285.81048583984375,
                289.9393005371094,
                346.9902648925781
              ]
            },
            {
              "track_id": 1158,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.1694338619709015,
              "bbox": [
                148.96066284179688,
                272.3916015625,
                197.19113159179688,
                321.71160888671875
              ]
            },
            {
              "track_id": 1160,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.194480299949646,
              "bbox": [
                102.8921127319336,
                67.29627227783203,
                154.16908264160156,
                131.2177734375
              ]
            },
            {
              "track_id": 1120,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6959699392318726,
              "bbox": [
                329.62371826171875,
                73.50255584716797,
                450.91448974609375,
                234.7711181640625
              ]
            },
            {
              "track_id": 1171,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3973422348499298,
              "bbox": [
                3.87489914894104,
                92.28305053710938,
                32.90126419067383,
                128.2681884765625
              ]
            },
            {
              "track_id": 1075,
              "class_id": 57,
              "class_name": "couch",
              "confidence": 0.4158763885498047,
              "bbox": [
                256.89324951171875,
                84.05204010009766,
                623.732666015625,
                355.0343017578125
              ]
            },
            {
              "track_id": 1176,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.37780091166496277,
              "bbox": [
                175.59982299804688,
                233.2753143310547,
                258.960693359375,
                300.37640380859375
              ]
            }
          ],
          "unique_tracks": [
            1155,
            1156,
            1158,
            1160,
            1120,
            1171,
            1075,
            1176
          ],
          "total_detections": 8
        },
        {
          "group_index": 1,
          "frame_range": [
            15216,
            15220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15221,
            15225
          ],
          "representative_frame": 15221,
          "detections": [
            {
              "track_id": 1155,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.36037030816078186,
              "bbox": [
                297.306640625,
                0.5677041411399841,
                384.7283935546875,
                75.06004333496094
              ]
            },
            {
              "track_id": 1156,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7689670920372009,
              "bbox": [
                208.62294006347656,
                286.81927490234375,
                287.619140625,
                347.3580322265625
              ]
            },
            {
              "track_id": 1160,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.33513832092285156,
              "bbox": [
                102.08169555664062,
                68.62214660644531,
                153.57484436035156,
                132.7657012939453
              ]
            },
            {
              "track_id": 1120,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.696612536907196,
              "bbox": [
                322.6368713378906,
                73.7402572631836,
                445.7343444824219,
                235.84024047851562
              ]
            },
            {
              "track_id": 1171,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.29096415638923645,
              "bbox": [
                3.304485321044922,
                93.70896911621094,
                32.954498291015625,
                130.10719299316406
              ]
            },
            {
              "track_id": 1075,
              "class_id": 13,
              "class_name": "bench",
              "confidence": 0.33830809593200684,
              "bbox": [
                256.4511413574219,
                86.65563201904297,
                623.6910400390625,
                355.1319274902344
              ]
            },
            {
              "track_id": 1176,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.37976783514022827,
              "bbox": [
                174.47071838378906,
                234.87973022460938,
                256.74481201171875,
                301.0710754394531
              ]
            },
            {
              "track_id": 1180,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4091681241989136,
              "bbox": [
                0.9973412156105042,
                53.23930740356445,
                283.14105224609375,
                333.2568664550781
              ]
            }
          ],
          "unique_tracks": [
            1155,
            1156,
            1160,
            1120,
            1171,
            1075,
            1176,
            1180
          ],
          "total_detections": 8
        },
        {
          "group_index": 3,
          "frame_range": [
            15226,
            15230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15231,
            15235
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1155,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.47833725810050964,
              "bbox": [
                280.63165283203125,
                0.708798348903656,
                392.8333740234375,
                98.39691925048828
              ]
            },
            {
              "track_id": 1156,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7698699235916138,
              "bbox": [
                208.99517822265625,
                288.04144287109375,
                287.3758544921875,
                348.2200012207031
              ]
            },
            {
              "track_id": 1160,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.15311312675476074,
              "bbox": [
                102.3854751586914,
                69.57905578613281,
                154.23776245117188,
                134.18862915039062
              ]
            },
            {
              "track_id": 1120,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5922455787658691,
              "bbox": [
                313.6205749511719,
                66.54898834228516,
                445.5236511230469,
                237.9020233154297
              ]
            },
            {
              "track_id": 1171,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3390892446041107,
              "bbox": [
                2.9715688228607178,
                94.49235534667969,
                33.25630187988281,
                131.29080200195312
              ]
            },
            {
              "track_id": 1075,
              "class_id": 13,
              "class_name": "bench",
              "confidence": 0.5944565534591675,
              "bbox": [
                259.183349609375,
                93.02864837646484,
                621.64013671875,
                354.8617248535156
              ]
            },
            {
              "track_id": 1176,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6384567618370056,
              "bbox": [
                173.70797729492188,
                236.877197265625,
                257.7142333984375,
                304.54827880859375
              ]
            },
            {
              "track_id": 1180,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5721492767333984,
              "bbox": [
                0.0,
                28.454303741455078,
                298.8524169921875,
                334.7140197753906
              ]
            }
          ],
          "unique_tracks": [
            1155,
            1156,
            1160,
            1120,
            1171,
            1075,
            1176,
            1180
          ],
          "total_detections": 8
        },
        {
          "group_index": 5,
          "frame_range": [
            15236,
            15240
          ],
          "representative_frame": 15236,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 126
    },
    {
      "second": 508,
      "time_range": [
        508,
        508.999
      ],
      "frame_range": [
        15241,
        15270
      ],
      "unified_description": "1-second scene with several distinct elements, including a man setting up camping equipment in a wooded area. The camera is held by a person whose movements are also recorded.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:40",
        "processing_time": 2.9,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15255,
          "frame_range": [
            15251,
            15255
          ],
          "description": "a man is putting a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.75
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15241,
            15245
          ],
          "representative_frame": 15241,
          "detections": [
            {
              "track_id": 1155,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4134770333766937,
              "bbox": [
                287.6327209472656,
                0.6957586407661438,
                389.25665283203125,
                88.87456512451172
              ]
            },
            {
              "track_id": 1156,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5575255751609802,
              "bbox": [
                208.87863159179688,
                289.54522705078125,
                286.3468017578125,
                349.1601257324219
              ]
            },
            {
              "track_id": 1160,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.17228537797927856,
              "bbox": [
                102.60040283203125,
                70.8551254272461,
                154.35667419433594,
                135.34327697753906
              ]
            },
            {
              "track_id": 1120,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7788626551628113,
              "bbox": [
                317.4678039550781,
                63.3568229675293,
                450.5845642089844,
                235.82228088378906
              ]
            },
            {
              "track_id": 1171,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3129631280899048,
              "bbox": [
                2.903972625732422,
                96.19322967529297,
                33.28266906738281,
                132.6634063720703
              ]
            },
            {
              "track_id": 1075,
              "class_id": 13,
              "class_name": "bench",
              "confidence": 0.6349532604217529,
              "bbox": [
                260.8345031738281,
                96.05533599853516,
                622.2890014648438,
                354.5198974609375
              ]
            },
            {
              "track_id": 1176,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.31226882338523865,
              "bbox": [
                174.0420379638672,
                238.7288055419922,
                257.3438415527344,
                305.7655334472656
              ]
            },
            {
              "track_id": 1180,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4390797019004822,
              "bbox": [
                0.0,
                33.22820281982422,
                295.15069580078125,
                335.64337158203125
              ]
            }
          ],
          "unique_tracks": [
            1155,
            1156,
            1160,
            1120,
            1171,
            1075,
            1176,
            1180
          ],
          "total_detections": 8
        },
        {
          "group_index": 1,
          "frame_range": [
            15246,
            15250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15251,
            15255
          ],
          "representative_frame": 15251,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9204415678977966,
              "bbox": [
                244.61172485351562,
                37.26172637939453,
                640.0,
                333.0443420410156
              ]
            },
            {
              "track_id": 1180,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.22164127230644226,
              "bbox": [
                50.35597229003906,
                119.52220916748047,
                264.1418762207031,
                326.1534423828125
              ]
            },
            {
              "track_id": 1151,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.44198769330978394,
              "bbox": [
                242.54830932617188,
                279.22296142578125,
                323.6083068847656,
                359.3885192871094
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1180,
            1151
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            15256,
            15260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15261,
            15265
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9193448424339294,
              "bbox": [
                244.01712036132812,
                16.398916244506836,
                640.0,
                325.3052062988281
              ]
            },
            {
              "track_id": 1187,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.8925718665122986,
              "bbox": [
                336.7486572265625,
                272.6584777832031,
                367.93878173828125,
                313.1799621582031
              ]
            },
            {
              "track_id": 1188,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3411288857460022,
              "bbox": [
                102.23831176757812,
                168.59979248046875,
                157.25701904296875,
                237.02203369140625
              ]
            },
            {
              "track_id": 1151,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5717112421989441,
              "bbox": [
                245.41561889648438,
                280.9569396972656,
                320.1954650878906,
                359.5057678222656
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1187,
            1188,
            1151
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            15266,
            15270
          ],
          "representative_frame": 15266,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 127
    },
    {
      "second": 509,
      "time_range": [
        509,
        509.999
      ],
      "frame_range": [
        15271,
        15300
      ],
      "unified_description": "3rd person perspective with a wide field of view camera showing a man putting up a tent in the woods.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:41",
        "processing_time": 3.28,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15285,
          "frame_range": [
            15281,
            15285
          ],
          "description": "a man is putting a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.08
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15271,
            15275
          ],
          "representative_frame": 15271,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9185313582420349,
              "bbox": [
                247.92904663085938,
                8.120083808898926,
                640.0,
                322.206787109375
              ]
            },
            {
              "track_id": 1187,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.8947153687477112,
              "bbox": [
                336.7771911621094,
                272.73046875,
                367.9169616699219,
                313.186279296875
              ]
            },
            {
              "track_id": 1188,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.241890087723732,
              "bbox": [
                102.36685943603516,
                168.1641082763672,
                157.55555725097656,
                236.93321228027344
              ]
            },
            {
              "track_id": 1151,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5395433902740479,
              "bbox": [
                246.80364990234375,
                280.0641784667969,
                318.60150146484375,
                359.5321350097656
              ]
            },
            {
              "track_id": 1191,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.30278855562210083,
              "bbox": [
                1.157174825668335,
                303.8349304199219,
                107.67646789550781,
                359.3370666503906
              ]
            },
            {
              "track_id": 1192,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.32033097743988037,
              "bbox": [
                0.8577141165733337,
                146.5744171142578,
                320.03375244140625,
                322.51043701171875
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1187,
            1188,
            1151,
            1191,
            1192
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            15276,
            15280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15281,
            15285
          ],
          "representative_frame": 15281,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9149811863899231,
              "bbox": [
                253.06082153320312,
                5.13633394241333,
                634.8316650390625,
                321.1687316894531
              ]
            },
            {
              "track_id": 1187,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.8943600654602051,
              "bbox": [
                336.7808837890625,
                272.74249267578125,
                367.91485595703125,
                313.1906433105469
              ]
            },
            {
              "track_id": 1188,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.16456425189971924,
              "bbox": [
                104.08181762695312,
                168.43344116210938,
                159.2304229736328,
                237.30398559570312
              ]
            },
            {
              "track_id": 1151,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5736902952194214,
              "bbox": [
                247.98170471191406,
                279.1480712890625,
                317.3744201660156,
                359.5253601074219
              ]
            },
            {
              "track_id": 1191,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3594324290752411,
              "bbox": [
                0.7862656712532043,
                303.86102294921875,
                107.66156005859375,
                359.5544128417969
              ]
            },
            {
              "track_id": 1192,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.33325886726379395,
              "bbox": [
                0.0,
                143.3855438232422,
                324.33184814453125,
                322.8875732421875
              ]
            },
            {
              "track_id": 1195,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6672523021697998,
              "bbox": [
                285.72723388671875,
                214.31890869140625,
                315.8718566894531,
                251.37734985351562
              ]
            },
            {
              "track_id": 1196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.33592459559440613,
              "bbox": [
                102.22959899902344,
                143.3846893310547,
                318.0667419433594,
                318.0793762207031
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1187,
            1188,
            1151,
            1191,
            1192,
            1195,
            1196
          ],
          "total_detections": 8
        },
        {
          "group_index": 3,
          "frame_range": [
            15286,
            15290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15291,
            15295
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9081335663795471,
              "bbox": [
                257.9200134277344,
                4.198604106903076,
                628.9937744140625,
                320.7559509277344
              ]
            },
            {
              "track_id": 1187,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.8953891396522522,
              "bbox": [
                336.7857360839844,
                272.7403259277344,
                367.919189453125,
                313.18609619140625
              ]
            },
            {
              "track_id": 1151,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5958437919616699,
              "bbox": [
                249.3032989501953,
                279.0892028808594,
                316.0895080566406,
                359.4919128417969
              ]
            },
            {
              "track_id": 1191,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3327678143978119,
              "bbox": [
                0.8757688403129578,
                303.8270263671875,
                107.42156219482422,
                359.33642578125
              ]
            },
            {
              "track_id": 1192,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.41217878460884094,
              "bbox": [
                0.0,
                141.27764892578125,
                324.2778015136719,
                323.4154052734375
              ]
            },
            {
              "track_id": 1195,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6824245452880859,
              "bbox": [
                285.79278564453125,
                214.494140625,
                315.8836669921875,
                251.4271697998047
              ]
            },
            {
              "track_id": 1196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2823561728000641,
              "bbox": [
                100.19802856445312,
                142.38595581054688,
                317.7270202636719,
                318.4809875488281
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1187,
            1151,
            1191,
            1192,
            1195,
            1196
          ],
          "total_detections": 7
        },
        {
          "group_index": 5,
          "frame_range": [
            15296,
            15300
          ],
          "representative_frame": 15296,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 127
    },
    {
      "second": 510,
      "time_range": [
        510,
        510.999
      ],
      "frame_range": [
        15301,
        15330
      ],
      "unified_description": "1-second scene that includes a man cooking food in a tent",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:42",
        "processing_time": 2.32,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15315,
          "frame_range": [
            15311,
            15315
          ],
          "description": "a man is cooking food in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.76
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15301,
            15305
          ],
          "representative_frame": 15301,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9210638403892517,
              "bbox": [
                269.9565124511719,
                13.08582592010498,
                618.1461181640625,
                317.7754211425781
              ]
            },
            {
              "track_id": 1187,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4758274555206299,
              "bbox": [
                337.3739013671875,
                273.9234924316406,
                367.90728759765625,
                313.5438537597656
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1187
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            15306,
            15310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15311,
            15315
          ],
          "representative_frame": 15311,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9252988696098328,
              "bbox": [
                276.3627624511719,
                16.937532424926758,
                611.8338623046875,
                317.5431213378906
              ]
            },
            {
              "track_id": 1187,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.46325188875198364,
              "bbox": [
                337.586181640625,
                274.4189453125,
                367.91546630859375,
                313.7263488769531
              ]
            },
            {
              "track_id": 1197,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.45426055788993835,
              "bbox": [
                220.17506408691406,
                219.30410766601562,
                311.9118957519531,
                296.803955078125
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1187,
            1197
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            15316,
            15320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15321,
            15325
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9249483346939087,
              "bbox": [
                280.52069091796875,
                18.53557777404785,
                607.2469482421875,
                317.8017272949219
              ]
            },
            {
              "track_id": 1187,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4888105094432831,
              "bbox": [
                337.6421203613281,
                274.5985107421875,
                367.9165954589844,
                313.7732849121094
              ]
            },
            {
              "track_id": 1197,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.47482144832611084,
              "bbox": [
                220.3122100830078,
                219.31704711914062,
                312.05413818359375,
                296.80133056640625
              ]
            },
            {
              "track_id": 1199,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4344845116138458,
              "bbox": [
                320.9864501953125,
                241.52978515625,
                361.04351806640625,
                280.8859558105469
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1187,
            1197,
            1199
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            15326,
            15330
          ],
          "representative_frame": 15326,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 127
    },
    {
      "second": 511,
      "time_range": [
        511,
        511.999
      ],
      "frame_range": [
        15331,
        15360
      ],
      "unified_description": "1-second scene that includes a man in a black jacket holding a cup",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:44",
        "processing_time": 2.36,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15345,
          "frame_range": [
            15341,
            15345
          ],
          "description": "a man in a black jacket holding a cup",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.2
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15331,
            15335
          ],
          "representative_frame": 15331,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9258626103401184,
              "bbox": [
                284.07427978515625,
                19.290403366088867,
                603.8724975585938,
                318.2682800292969
              ]
            },
            {
              "track_id": 1187,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6394253969192505,
              "bbox": [
                337.66180419921875,
                274.6460876464844,
                367.9988708496094,
                313.83453369140625
              ]
            },
            {
              "track_id": 1197,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5202321410179138,
              "bbox": [
                220.39178466796875,
                219.33045959472656,
                312.2066955566406,
                296.8446960449219
              ]
            },
            {
              "track_id": 1199,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3583495318889618,
              "bbox": [
                321.4165344238281,
                241.6357421875,
                361.0528564453125,
                280.55938720703125
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1187,
            1197,
            1199
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            15336,
            15340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15341,
            15345
          ],
          "representative_frame": 15341,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.865462064743042,
              "bbox": [
                252.5789031982422,
                5.612388610839844,
                615.2000732421875,
                340.9865417480469
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            15346,
            15350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15351,
            15355
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8852387070655823,
              "bbox": [
                246.93081665039062,
                0.9947948455810547,
                625.478759765625,
                349.4130859375
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            15356,
            15360
          ],
          "representative_frame": 15356,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 127
    },
    {
      "second": 512,
      "time_range": [
        512,
        512.999
      ],
      "frame_range": [
        15361,
        15390
      ],
      "unified_description": "30 second videos require detailed descriptions broken down into easy to understand sentences.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:44",
        "processing_time": 2.48,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15375,
          "frame_range": [
            15371,
            15375
          ],
          "description": "a man in a black jacket is drinking from a cup",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.05
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15361,
            15365
          ],
          "representative_frame": 15361,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.930501401424408,
              "bbox": [
                218.8448944091797,
                0.0,
                611.8887939453125,
                353.34912109375
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            15366,
            15370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15371,
            15375
          ],
          "representative_frame": 15371,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9443755149841309,
              "bbox": [
                218.52850341796875,
                0.0,
                617.58544921875,
                354.8916931152344
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            15376,
            15380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15381,
            15385
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9389426112174988,
              "bbox": [
                219.0987548828125,
                0.0,
                621.9201049804688,
                355.46954345703125
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            15386,
            15390
          ],
          "representative_frame": 15386,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 128
    },
    {
      "second": 513,
      "time_range": [
        513,
        513.999
      ],
      "frame_range": [
        15391,
        15420
      ],
      "unified_description": "5-second scene with a person in the outdoors, standing near the water on rocky terrain.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:46",
        "processing_time": 2.65,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15405,
          "frame_range": [
            15401,
            15405
          ],
          "description": "a man standing on a rocky shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.78
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15391,
            15395
          ],
          "representative_frame": 15391,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9431363344192505,
              "bbox": [
                215.30142211914062,
                0.0,
                621.991943359375,
                355.67193603515625
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            15396,
            15400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15401,
            15405
          ],
          "representative_frame": 15401,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9296677708625793,
              "bbox": [
                280.6159973144531,
                0.0,
                640.0,
                355.64117431640625
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            15406,
            15410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15411,
            15415
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9338175058364868,
              "bbox": [
                307.1850280761719,
                0.0,
                640.0,
                355.8740234375
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            15416,
            15420
          ],
          "representative_frame": 15416,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 128
    },
    {
      "second": 514,
      "time_range": [
        514,
        514.999
      ],
      "frame_range": [
        15421,
        15450
      ],
      "unified_description": "\nThe image depicts a peaceful outdoor scene, with several people dispersed throughout the area. There are two main groups of people - one standing close to the water's edge, and another located farther back in the scene. A total of six individuals can be seen, some of which appear closer together, suggesting they may be interacting or engaged in a shared activity. The camera is mounted on a tripod, providing stable footage, and captures the overall tranquility of the location.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:49",
        "processing_time": 3.86,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15435,
          "frame_range": [
            15431,
            15435
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.35
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15421,
            15425
          ],
          "representative_frame": 15421,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9423916935920715,
              "bbox": [
                316.7135314941406,
                0.0,
                640.0,
                355.3861083984375
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            15426,
            15430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15431,
            15435
          ],
          "representative_frame": 15431,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9467248320579529,
              "bbox": [
                320.1705322265625,
                0.0,
                640.0,
                355.3187255859375
              ]
            },
            {
              "track_id": 1206,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.738924503326416,
              "bbox": [
                360.3402099609375,
                126.24366760253906,
                414.4298400878906,
                190.52536010742188
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1206
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            15436,
            15440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15441,
            15445
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9447231888771057,
              "bbox": [
                319.9314270019531,
                0.0,
                640.0,
                354.50018310546875
              ]
            },
            {
              "track_id": 1206,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.7189583778381348,
              "bbox": [
                354.32586669921875,
                120.80426025390625,
                409.8734130859375,
                186.81478881835938
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1206
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            15446,
            15450
          ],
          "representative_frame": 15446,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 128
    },
    {
      "second": 515,
      "time_range": [
        515,
        515.999
      ],
      "frame_range": [
        15451,
        15480
      ],
      "unified_description": "1-second scene with a man standing next to a lake, seen through a fisheye lens, possibly causing some distortion in the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:50",
        "processing_time": 3.83,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15465,
          "frame_range": [
            15461,
            15465
          ],
          "description": "a man in a black jacket and hat standing next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.62
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15451,
            15455
          ],
          "representative_frame": 15451,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9503561854362488,
              "bbox": [
                319.78094482421875,
                0.0,
                640.0,
                354.683837890625
              ]
            },
            {
              "track_id": 1206,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.49851104617118835,
              "bbox": [
                350.07452392578125,
                117.91072845458984,
                406.0673828125,
                184.4411163330078
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1206
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            15456,
            15460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15461,
            15465
          ],
          "representative_frame": 15461,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9540978074073792,
              "bbox": [
                323.0788269042969,
                0.0,
                640.0,
                354.6973571777344
              ]
            },
            {
              "track_id": 1206,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.5565015077590942,
              "bbox": [
                351.446533203125,
                118.01586151123047,
                407.96099853515625,
                184.98268127441406
              ]
            }
          ],
          "unique_tracks": [
            1075,
            1206
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            15466,
            15470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15471,
            15475
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            15476,
            15480
          ],
          "representative_frame": 15476,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 128
    },
    {
      "second": 516,
      "time_range": [
        516,
        516.999
      ],
      "frame_range": [
        15481,
        15510
      ],
      "unified_description": "360 video of a person fishing in an outdoor setting by a body of water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:50",
        "processing_time": 3.96,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15495,
          "frame_range": [
            15491,
            15495
          ],
          "description": "a man fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.8
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15481,
            15485
          ],
          "representative_frame": 15481,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            15486,
            15490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15491,
            15495
          ],
          "representative_frame": 15491,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            15496,
            15500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15501,
            15505
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            15506,
            15510
          ],
          "representative_frame": 15506,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 129
    },
    {
      "second": 517,
      "time_range": [
        517,
        517.999
      ],
      "frame_range": [
        15511,
        15540
      ],
      "unified_description": "40 seconds of video detailing a man fishing on the shore of a lake. The video has wide-angle distortion and was captured using a GoPro camera.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:53",
        "processing_time": 2.67,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15525,
          "frame_range": [
            15521,
            15525
          ],
          "description": "a man fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.06
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15511,
            15515
          ],
          "representative_frame": 15511,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            15516,
            15520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15521,
            15525
          ],
          "representative_frame": 15521,
          "detections": [
            {
              "track_id": 1192,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8287614583969116,
              "bbox": [
                0.0,
                5.707505702972412,
                324.73822021484375,
                354.82965087890625
              ]
            }
          ],
          "unique_tracks": [
            1192
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            15526,
            15530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15531,
            15535
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1192,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7630283832550049,
              "bbox": [
                0.0,
                0.0,
                374.5061340332031,
                356.1400451660156
              ]
            }
          ],
          "unique_tracks": [
            1192
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            15536,
            15540
          ],
          "representative_frame": 15536,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 129
    },
    {
      "second": 518,
      "time_range": [
        518,
        518.999
      ],
      "frame_range": [
        15541,
        15570
      ],
      "unified_description": "\nThe video captures an outdoor scene with a man in camouflage gear standing on the shore. The camera perspective gives a first-person view, making it seem like the viewer is experiencing the scene from the man's point of view. The footage includes elements such as the ground, water, and potentially other people or objects in the surroundings. The video was likely recorded using a wide-angle lens, capturing a more expansive view of the environment.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:55",
        "processing_time": 3.88,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15555,
          "frame_range": [
            15551,
            15555
          ],
          "description": "a man in camouflage gear is standing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.32
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15541,
            15545
          ],
          "representative_frame": 15541,
          "detections": [
            {
              "track_id": 1192,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8756581544876099,
              "bbox": [
                0.0,
                0.0,
                356.5375671386719,
                355.8078918457031
              ]
            }
          ],
          "unique_tracks": [
            1192
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            15546,
            15550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15551,
            15555
          ],
          "representative_frame": 15551,
          "detections": [
            {
              "track_id": 1192,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.927660346031189,
              "bbox": [
                0.0,
                0.0,
                392.5289306640625,
                356.1014709472656
              ]
            }
          ],
          "unique_tracks": [
            1192
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            15556,
            15560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15561,
            15565
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8778995871543884,
              "bbox": [
                50.75529479980469,
                0.16208118200302124,
                427.554931640625,
                355.6052551269531
              ]
            }
          ],
          "unique_tracks": [
            1196
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            15566,
            15570
          ],
          "representative_frame": 15566,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 129
    },
    {
      "second": 519,
      "time_range": [
        519,
        519.999
      ],
      "frame_range": [
        15571,
        15600
      ],
      "unified_description": "3-second scene from an action camera perspective, showing a man fishing on the shore of a lake. The image is slightly shaky, indicating it may have been captured in a dynamic environment or with an unsteady camera mounting.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:56",
        "processing_time": 4.89,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15585,
          "frame_range": [
            15581,
            15585
          ],
          "description": "a man fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.01
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15571,
            15575
          ],
          "representative_frame": 15571,
          "detections": [
            {
              "track_id": 1196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8318000435829163,
              "bbox": [
                87.32144165039062,
                0.014921831898391247,
                412.55145263671875,
                350.2233581542969
              ]
            }
          ],
          "unique_tracks": [
            1196
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            15576,
            15580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15581,
            15585
          ],
          "representative_frame": 15581,
          "detections": [
            {
              "track_id": 1196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9144941568374634,
              "bbox": [
                115.52377319335938,
                17.2154598236084,
                383.8198547363281,
                335.6753845214844
              ]
            }
          ],
          "unique_tracks": [
            1196
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            15586,
            15590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15591,
            15595
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            15596,
            15600
          ],
          "representative_frame": 15596,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 129
    },
    {
      "second": 520,
      "time_range": [
        520,
        520.999
      ],
      "frame_range": [
        15601,
        15630
      ],
      "unified_description": "4-second scene, showing a man fishing, with a total of 6 unique objects/people visible in the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:57",
        "processing_time": 3.48,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15615,
          "frame_range": [
            15611,
            15615
          ],
          "description": "a man fishing on a lake with a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15601,
            15605
          ],
          "representative_frame": 15601,
          "detections": [
            {
              "track_id": 1208,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9142404794692993,
              "bbox": [
                208.12222290039062,
                60.2618522644043,
                270.8155822753906,
                265.548828125
              ]
            }
          ],
          "unique_tracks": [
            1208
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            15606,
            15610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15611,
            15615
          ],
          "representative_frame": 15611,
          "detections": [
            {
              "track_id": 1208,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9129825830459595,
              "bbox": [
                207.27110290527344,
                59.75959014892578,
                270.0444641113281,
                265.3358154296875
              ]
            }
          ],
          "unique_tracks": [
            1208
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            15616,
            15620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15621,
            15625
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1208,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9211958050727844,
              "bbox": [
                208.03404235839844,
                60.195899963378906,
                270.7276916503906,
                265.2609558105469
              ]
            }
          ],
          "unique_tracks": [
            1208
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            15626,
            15630
          ],
          "representative_frame": 15626,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 130
    },
    {
      "second": 521,
      "time_range": [
        521,
        521.999
      ],
      "frame_range": [
        15631,
        15660
      ],
      "unified_description": "3D camera capturing outdoor scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:24:58",
        "processing_time": 2.22,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15645,
          "frame_range": [
            15641,
            15645
          ],
          "description": "a lake with a mountain in the background",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.94
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15631,
            15635
          ],
          "representative_frame": 15631,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            15636,
            15640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15641,
            15645
          ],
          "representative_frame": 15641,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            15646,
            15650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15651,
            15655
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            15656,
            15660
          ],
          "representative_frame": 15656,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 130
    },
    {
      "second": 522,
      "time_range": [
        522,
        522.999
      ],
      "frame_range": [
        15661,
        15690
      ],
      "unified_description": "1-second scene featuring a man with a fish in his hand, shot using a shaky camera, showing wide-angle distortion and some motion blur.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:00",
        "processing_time": 2.65,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15675,
          "frame_range": [
            15671,
            15675
          ],
          "description": "a person is holding a fish in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.32
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15661,
            15665
          ],
          "representative_frame": 15661,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            15666,
            15670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15671,
            15675
          ],
          "representative_frame": 15671,
          "detections": [
            {
              "track_id": 1075,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9443718791007996,
              "bbox": [
                351.68878173828125,
                120.37093353271484,
                578.6586303710938,
                315.0363464355469
              ]
            }
          ],
          "unique_tracks": [
            1075
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            15676,
            15680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15681,
            15685
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9462553858757019,
              "bbox": [
                283.6011657714844,
                1.1670080423355103,
                559.5689086914062,
                281.83270263671875
              ]
            }
          ],
          "unique_tracks": [
            1196
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            15686,
            15690
          ],
          "representative_frame": 15686,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 130
    },
    {
      "second": 523,
      "time_range": [
        523,
        523.999
      ],
      "frame_range": [
        15691,
        15720
      ],
      "unified_description": "30 seconds of video with various objects and people in it.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:01",
        "processing_time": 2.68,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15705,
          "frame_range": [
            15701,
            15705
          ],
          "description": "a person is holding a fish in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15691,
            15695
          ],
          "representative_frame": 15691,
          "detections": [
            {
              "track_id": 1196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9556078910827637,
              "bbox": [
                313.0013122558594,
                1.1337751150131226,
                566.649658203125,
                217.3112335205078
              ]
            }
          ],
          "unique_tracks": [
            1196
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            15696,
            15700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15701,
            15705
          ],
          "representative_frame": 15701,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            15706,
            15710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15711,
            15715
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            15716,
            15720
          ],
          "representative_frame": 15716,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 130
    },
    {
      "second": 524,
      "time_range": [
        524,
        524.999
      ],
      "frame_range": [
        15721,
        15750
      ],
      "unified_description": "1-second scene that includes a dog walking on the road with its owner, camera positioning, field of view, lens characteristics, video production style, and lighting conditions.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:02",
        "processing_time": 2.99,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15735,
          "frame_range": [
            15731,
            15735
          ],
          "description": "a dog is walking on the road with its owner",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.69
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15721,
            15725
          ],
          "representative_frame": 15721,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            15726,
            15730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15731,
            15735
          ],
          "representative_frame": 15731,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            15736,
            15740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15741,
            15745
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1211,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6267745494842529,
              "bbox": [
                395.50018310546875,
                293.59246826171875,
                634.8934326171875,
                358.7751770019531
              ]
            },
            {
              "track_id": 1212,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.39459455013275146,
              "bbox": [
                394.2019958496094,
                292.44171142578125,
                635.6158447265625,
                359.2126770019531
              ]
            }
          ],
          "unique_tracks": [
            1211,
            1212
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            15746,
            15750
          ],
          "representative_frame": 15746,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 131
    },
    {
      "second": 525,
      "time_range": [
        525,
        525.999
      ],
      "frame_range": [
        15751,
        15780
      ],
      "unified_description": "3rd person perspective camera view",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:04",
        "processing_time": 2.2,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15765,
          "frame_range": [
            15761,
            15765
          ],
          "description": "a dog is walking on the beach with a ball",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.53
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15751,
            15755
          ],
          "representative_frame": 15751,
          "detections": [
            {
              "track_id": 1211,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.352156400680542,
              "bbox": [
                413.65423583984375,
                300.6189270019531,
                627.0166015625,
                358.54998779296875
              ]
            },
            {
              "track_id": 1212,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.13028503954410553,
              "bbox": [
                417.9934997558594,
                302.0832214355469,
                622.50439453125,
                358.40631103515625
              ]
            }
          ],
          "unique_tracks": [
            1211,
            1212
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            15756,
            15760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15761,
            15765
          ],
          "representative_frame": 15761,
          "detections": [
            {
              "track_id": 1211,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.10375877469778061,
              "bbox": [
                446.0132141113281,
                314.43603515625,
                607.7225341796875,
                357.7491760253906
              ]
            }
          ],
          "unique_tracks": [
            1211
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            15766,
            15770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15771,
            15775
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1212,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.7211796045303345,
              "bbox": [
                381.5748291015625,
                275.9850769042969,
                640.0,
                358.0885925292969
              ]
            }
          ],
          "unique_tracks": [
            1212
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            15776,
            15780
          ],
          "representative_frame": 15776,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 131
    },
    {
      "second": 526,
      "time_range": [
        526,
        526.999
      ],
      "frame_range": [
        15781,
        15810
      ],
      "unified_description": "3rd person camera perspective",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:04",
        "processing_time": 2.25,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15795,
          "frame_range": [
            15791,
            15795
          ],
          "description": "a man holding a fish on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.32
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15781,
            15785
          ],
          "representative_frame": 15781,
          "detections": [
            {
              "track_id": 1212,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8764824271202087,
              "bbox": [
                300.5155944824219,
                225.80789184570312,
                640.0,
                358.4100646972656
              ]
            }
          ],
          "unique_tracks": [
            1212
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            15786,
            15790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15791,
            15795
          ],
          "representative_frame": 15791,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            15796,
            15800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15801,
            15805
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4658859372138977,
              "bbox": [
                405.6868591308594,
                1.3858153820037842,
                637.3156127929688,
                351.5365905761719
              ]
            }
          ],
          "unique_tracks": [
            1218
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            15806,
            15810
          ],
          "representative_frame": 15806,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 131
    },
    {
      "second": 527,
      "time_range": [
        527,
        527.999
      ],
      "frame_range": [
        15811,
        15840
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:05",
        "processing_time": 2.1,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15825,
          "frame_range": [
            15821,
            15825
          ],
          "description": "a man holding a fish on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15811,
            15815
          ],
          "representative_frame": 15811,
          "detections": [
            {
              "track_id": 1218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3135989308357239,
              "bbox": [
                403.9352111816406,
                1.4702328443527222,
                634.5795288085938,
                349.78961181640625
              ]
            },
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4886745512485504,
              "bbox": [
                221.2952880859375,
                0.955853283405304,
                632.9013671875,
                239.5994415283203
              ]
            }
          ],
          "unique_tracks": [
            1218,
            1223
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            15816,
            15820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15821,
            15825
          ],
          "representative_frame": 15821,
          "detections": [
            {
              "track_id": 1218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.10417606681585312,
              "bbox": [
                402.8160705566406,
                2.6193976402282715,
                632.1807250976562,
                348.3016357421875
              ]
            },
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4866444766521454,
              "bbox": [
                185.6290740966797,
                0.7354834079742432,
                619.3744506835938,
                251.7204132080078
              ]
            },
            {
              "track_id": 1224,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.45423004031181335,
              "bbox": [
                144.2256622314453,
                135.5091552734375,
                472.9957275390625,
                235.36801147460938
              ]
            }
          ],
          "unique_tracks": [
            1218,
            1223,
            1224
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            15826,
            15830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15831,
            15835
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1218,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.42513012886047363,
              "bbox": [
                452.4530334472656,
                78.56681060791016,
                633.1503295898438,
                350.29083251953125
              ]
            },
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5470936894416809,
              "bbox": [
                199.4242401123047,
                0.9001331329345703,
                620.7985229492188,
                244.23858642578125
              ]
            },
            {
              "track_id": 1224,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.6932809352874756,
              "bbox": [
                147.8639678955078,
                136.30760192871094,
                469.00927734375,
                233.8741455078125
              ]
            },
            {
              "track_id": 1228,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3086947500705719,
              "bbox": [
                397.70849609375,
                1.2004241943359375,
                638.0409545898438,
                237.6420135498047
              ]
            }
          ],
          "unique_tracks": [
            1218,
            1223,
            1224,
            1228
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            15836,
            15840
          ],
          "representative_frame": 15836,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 131
    },
    {
      "second": 528,
      "time_range": [
        528,
        528.999
      ],
      "frame_range": [
        15841,
        15870
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:08",
        "processing_time": 2.07,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15855,
          "frame_range": [
            15851,
            15855
          ],
          "description": "a man holding a fish on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.59
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15841,
            15845
          ],
          "representative_frame": 15841,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.781211793422699,
              "bbox": [
                144.08273315429688,
                0.9690877795219421,
                640.0,
                317.97113037109375
              ]
            },
            {
              "track_id": 1224,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8376526832580566,
              "bbox": [
                149.3245391845703,
                150.63938903808594,
                467.0433044433594,
                247.10321044921875
              ]
            },
            {
              "track_id": 1228,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.38270893692970276,
              "bbox": [
                354.0942687988281,
                1.4197850227355957,
                640.0,
                325.2419128417969
              ]
            }
          ],
          "unique_tracks": [
            1223,
            1224,
            1228
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            15846,
            15850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15851,
            15855
          ],
          "representative_frame": 15851,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6306026577949524,
              "bbox": [
                170.84483337402344,
                0.7774601578712463,
                640.0,
                278.8419494628906
              ]
            },
            {
              "track_id": 1224,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8294050693511963,
              "bbox": [
                140.5812225341797,
                149.3146209716797,
                457.4946594238281,
                245.4804229736328
              ]
            },
            {
              "track_id": 1218,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.44417765736579895,
              "bbox": [
                468.93389892578125,
                111.01997375488281,
                630.6610717773438,
                352.5016784667969
              ]
            }
          ],
          "unique_tracks": [
            1223,
            1224,
            1218
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            15856,
            15860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15861,
            15865
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5048486590385437,
              "bbox": [
                186.26194763183594,
                0.4679080545902252,
                625.0602416992188,
                253.3336944580078
              ]
            },
            {
              "track_id": 1224,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8666471838951111,
              "bbox": [
                132.7691650390625,
                142.28143310546875,
                448.4581298828125,
                237.92404174804688
              ]
            },
            {
              "track_id": 1218,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.25753122568130493,
              "bbox": [
                470.1877746582031,
                113.23430633544922,
                632.1878051757812,
                353.5459289550781
              ]
            },
            {
              "track_id": 1228,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5332962274551392,
              "bbox": [
                252.3386688232422,
                4.34717321395874,
                608.64306640625,
                352.9629211425781
              ]
            }
          ],
          "unique_tracks": [
            1223,
            1224,
            1218,
            1228
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            15866,
            15870
          ],
          "representative_frame": 15866,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 132
    },
    {
      "second": 529,
      "time_range": [
        529,
        529.999
      ],
      "frame_range": [
        15871,
        15900
      ],
      "unified_description": "1-second scene featuring a man holding a fish on the shore",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:08",
        "processing_time": 2.4,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15885,
          "frame_range": [
            15881,
            15885
          ],
          "description": "a man holding a fish on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.57
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15871,
            15875
          ],
          "representative_frame": 15871,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7408151030540466,
              "bbox": [
                199.92581176757812,
                0.533136248588562,
                618.111572265625,
                239.7113800048828
              ]
            },
            {
              "track_id": 1224,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.9027168154716492,
              "bbox": [
                121.90485382080078,
                136.85888671875,
                447.04095458984375,
                235.49642944335938
              ]
            },
            {
              "track_id": 1218,
              "class_id": 43,
              "class_name": "knife",
              "confidence": 0.29908061027526855,
              "bbox": [
                469.9313659667969,
                110.8197021484375,
                634.731689453125,
                354.10125732421875
              ]
            },
            {
              "track_id": 1228,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.10926562547683716,
              "bbox": [
                218.90609741210938,
                5.6841654777526855,
                577.7723999023438,
                350.69122314453125
              ]
            }
          ],
          "unique_tracks": [
            1223,
            1224,
            1218,
            1228
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            15876,
            15880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15881,
            15885
          ],
          "representative_frame": 15881,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7724263668060303,
              "bbox": [
                205.14300537109375,
                0.27473506331443787,
                615.6931762695312,
                233.09556579589844
              ]
            },
            {
              "track_id": 1224,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.7842015624046326,
              "bbox": [
                119.83443450927734,
                135.40927124023438,
                445.48614501953125,
                234.2517547607422
              ]
            },
            {
              "track_id": 1218,
              "class_id": 43,
              "class_name": "knife",
              "confidence": 0.7318556904792786,
              "bbox": [
                471.8844299316406,
                109.92908477783203,
                636.5536499023438,
                352.10107421875
              ]
            }
          ],
          "unique_tracks": [
            1223,
            1224,
            1218
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            15886,
            15890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15891,
            15895
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7344915270805359,
              "bbox": [
                198.72918701171875,
                0.9642518162727356,
                640.0,
                316.0608825683594
              ]
            },
            {
              "track_id": 1224,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.6856878399848938,
              "bbox": [
                121.98995971679688,
                133.93125915527344,
                445.9197692871094,
                232.13092041015625
              ]
            }
          ],
          "unique_tracks": [
            1223,
            1224
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            15896,
            15900
          ],
          "representative_frame": 15896,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 132
    },
    {
      "second": 530,
      "time_range": [
        530,
        530.999
      ],
      "frame_range": [
        15901,
        15930
      ],
      "unified_description": "2-second scene with a man holdinging a fish on the shore. A wide-angle shot capturing all the details.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:09",
        "processing_time": 2.83,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15915,
          "frame_range": [
            15911,
            15915
          ],
          "description": "a man holding a fish on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.45
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15901,
            15905
          ],
          "representative_frame": 15901,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5314290523529053,
              "bbox": [
                133.35150146484375,
                0.8234518766403198,
                640.0,
                340.1549072265625
              ]
            },
            {
              "track_id": 1224,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.5118901133537292,
              "bbox": [
                117.77330017089844,
                127.4271011352539,
                455.1081237792969,
                229.93309020996094
              ]
            },
            {
              "track_id": 1218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6346421837806702,
              "bbox": [
                407.07818603515625,
                24.596275329589844,
                631.9852294921875,
                352.7667236328125
              ]
            }
          ],
          "unique_tracks": [
            1223,
            1224,
            1218
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            15906,
            15910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15911,
            15915
          ],
          "representative_frame": 15911,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7517579197883606,
              "bbox": [
                108.44575500488281,
                0.6147025227546692,
                640.0,
                349.32647705078125
              ]
            },
            {
              "track_id": 1224,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.2289971560239792,
              "bbox": [
                120.0299072265625,
                117.63028717041016,
                462.83746337890625,
                221.9622344970703
              ]
            },
            {
              "track_id": 1218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.38643282651901245,
              "bbox": [
                399.0095520019531,
                6.985861301422119,
                636.0846557617188,
                352.3651428222656
              ]
            }
          ],
          "unique_tracks": [
            1223,
            1224,
            1218
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            15916,
            15920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15921,
            15925
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8777939677238464,
              "bbox": [
                412.4230041503906,
                10.94602108001709,
                592.3417358398438,
                236.4125518798828
              ]
            }
          ],
          "unique_tracks": [
            1218
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            15926,
            15930
          ],
          "representative_frame": 15926,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 132
    },
    {
      "second": 531,
      "time_range": [
        531,
        531.999
      ],
      "frame_range": [
        15931,
        15960
      ],
      "unified_description": "\n\nFirst-person scene: A person is holding a fish in their hand",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:11",
        "processing_time": 2.38,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15945,
          "frame_range": [
            15941,
            15945
          ],
          "description": "a person is holding a fish in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.25
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15931,
            15935
          ],
          "representative_frame": 15931,
          "detections": [
            {
              "track_id": 1218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9224065542221069,
              "bbox": [
                422.286376953125,
                1.7258974313735962,
                569.3302612304688,
                163.51507568359375
              ]
            }
          ],
          "unique_tracks": [
            1218
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            15936,
            15940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15941,
            15945
          ],
          "representative_frame": 15941,
          "detections": [
            {
              "track_id": 1218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8968644142150879,
              "bbox": [
                407.2477722167969,
                0.0,
                556.7161254882812,
                145.01817321777344
              ]
            }
          ],
          "unique_tracks": [
            1218
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            15946,
            15950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15951,
            15955
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8851556777954102,
              "bbox": [
                407.1197204589844,
                0.0,
                574.7698364257812,
                152.10166931152344
              ]
            }
          ],
          "unique_tracks": [
            1218
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            15956,
            15960
          ],
          "representative_frame": 15956,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 132
    },
    {
      "second": 532,
      "time_range": [
        532,
        532.999
      ],
      "frame_range": [
        15961,
        15990
      ],
      "unified_description": " The image captures a man's point of view as he stands on the ground with his feet planted firmly. There is also a backpack visible in the scene, likely belonging to the person. The camera's perspective, field of view, and lens characteristics give a sense of the surrounding environment, adding depth and context to the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:13",
        "processing_time": 3.34,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15975,
          "frame_range": [
            15971,
            15975
          ],
          "description": "a person is standing on the ground with their feet",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.6
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15961,
            15965
          ],
          "representative_frame": 15961,
          "detections": [
            {
              "track_id": 1218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7254987955093384,
              "bbox": [
                405.62005615234375,
                10.34753131866455,
                588.4716186523438,
                168.66661071777344
              ]
            },
            {
              "track_id": 1235,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5149356722831726,
              "bbox": [
                396.1770324707031,
                273.7504577636719,
                640.0,
                357.9898681640625
              ]
            }
          ],
          "unique_tracks": [
            1218,
            1235
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            15966,
            15970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            15971,
            15975
          ],
          "representative_frame": 15971,
          "detections": [
            {
              "track_id": 1218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9151338338851929,
              "bbox": [
                409.2813415527344,
                3.427982807159424,
                591.2535400390625,
                152.3681182861328
              ]
            },
            {
              "track_id": 1235,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.5418532490730286,
              "bbox": [
                381.6309509277344,
                254.10501098632812,
                640.0,
                357.50701904296875
              ]
            }
          ],
          "unique_tracks": [
            1218,
            1235
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            15976,
            15980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            15981,
            15985
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6671696901321411,
              "bbox": [
                239.11769104003906,
                60.77641296386719,
                640.0,
                357.1923522949219
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            15986,
            15990
          ],
          "representative_frame": 15986,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 133
    },
    {
      "second": 533,
      "time_range": [
        533,
        533.999
      ],
      "frame_range": [
        15991,
        16020
      ],
      "unified_description": "5-second descriptions for quick review:\n\n1. The camera is stable, showing a first-person perspective of a person holding a knife.\n2. In the background, there are 6 other people present.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:14",
        "processing_time": 4.35,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16005,
          "frame_range": [
            16001,
            16005
          ],
          "description": "a person is holding a knife in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.05
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            15991,
            15995
          ],
          "representative_frame": 15991,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6857949495315552,
              "bbox": [
                281.1070861816406,
                52.914791107177734,
                640.0,
                354.7377014160156
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            15996,
            16000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16001,
            16005
          ],
          "representative_frame": 16001,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7503161430358887,
              "bbox": [
                281.45379638671875,
                20.230438232421875,
                640.0,
                354.8045959472656
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16006,
            16010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16011,
            16015
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1235,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5968958139419556,
              "bbox": [
                290.3607177734375,
                218.9619598388672,
                640.0,
                356.2427673339844
              ]
            }
          ],
          "unique_tracks": [
            1235
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16016,
            16020
          ],
          "representative_frame": 16016,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 133
    },
    {
      "second": 534,
      "time_range": [
        534,
        534.999
      ],
      "frame_range": [
        16021,
        16050
      ],
      "unified_description": "1-second scene featuring a man fishing on the shore of a lake. The camera captures the man's actions along with the surrounding landscape. The image is slightly shaky, indicating it may have been taken with a handheld or unsteady camera mount.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:16",
        "processing_time": 3.62,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16035,
          "frame_range": [
            16031,
            16035
          ],
          "description": "a man fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.71
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16021,
            16025
          ],
          "representative_frame": 16021,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            16026,
            16030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16031,
            16035
          ],
          "representative_frame": 16031,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.934694230556488,
              "bbox": [
                206.09642028808594,
                4.535837650299072,
                640.0,
                356.8199157714844
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16036,
            16040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16041,
            16045
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9301465749740601,
              "bbox": [
                199.36654663085938,
                1.4892174005508423,
                640.0,
                356.63226318359375
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16046,
            16050
          ],
          "representative_frame": 16046,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 133
    },
    {
      "second": 535,
      "time_range": [
        535,
        535.999
      ],
      "frame_range": [
        16051,
        16080
      ],
      "unified_description": "2nd person perspective, stabilized camera, natural outdoor lighting, no technical artifacts",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:17",
        "processing_time": 2.4,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16065,
          "frame_range": [
            16061,
            16065
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.1
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16051,
            16055
          ],
          "representative_frame": 16051,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9175540208816528,
              "bbox": [
                206.1089324951172,
                0.37256669998168945,
                640.0,
                355.6900634765625
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            16056,
            16060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16061,
            16065
          ],
          "representative_frame": 16061,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9237690567970276,
              "bbox": [
                225.100830078125,
                0.44661200046539307,
                640.0,
                355.9225158691406
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16066,
            16070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16071,
            16075
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9313996434211731,
              "bbox": [
                242.25376892089844,
                0.11679603159427643,
                640.0,
                356.08575439453125
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16076,
            16080
          ],
          "representative_frame": 16076,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 133
    },
    {
      "second": 536,
      "time_range": [
        536,
        536.999
      ],
      "frame_range": [
        16081,
        16110
      ],
      "unified_description": "360 video with a person fishing in the background.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:18",
        "processing_time": 2.29,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16095,
          "frame_range": [
            16091,
            16095
          ],
          "description": "a man fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.94
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16081,
            16085
          ],
          "representative_frame": 16081,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.922053873538971,
              "bbox": [
                247.41036987304688,
                4.751286506652832,
                640.0,
                355.85992431640625
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            16086,
            16090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16091,
            16095
          ],
          "representative_frame": 16091,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9181543588638306,
              "bbox": [
                258.1598815917969,
                2.227956533432007,
                640.0,
                356.38043212890625
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16096,
            16100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16101,
            16105
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9141989350318909,
              "bbox": [
                264.2208557128906,
                0.8742775321006775,
                640.0,
                356.2431640625
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16106,
            16110
          ],
          "representative_frame": 16106,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 134
    },
    {
      "second": 537,
      "time_range": [
        537,
        537.999
      ],
      "frame_range": [
        16111,
        16140
      ],
      "unified_description": "1-second scene that features a man fishing on the water with a boat. The camera is positioned in such a way that it captures the entire scene, showing the outdoor setting, the person's activities, as well as any other surrounding elements.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:19",
        "processing_time": 2.99,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16125,
          "frame_range": [
            16121,
            16125
          ],
          "description": "a man is fishing on the water with a boat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.7
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16111,
            16115
          ],
          "representative_frame": 16111,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9233588576316833,
              "bbox": [
                264.11859130859375,
                0.41975805163383484,
                640.0,
                356.0932922363281
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            16116,
            16120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16121,
            16125
          ],
          "representative_frame": 16121,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9112106561660767,
              "bbox": [
                259.19195556640625,
                10.335199356079102,
                630.9268798828125,
                356.3522033691406
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16126,
            16130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16131,
            16135
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9111068248748779,
              "bbox": [
                257.7419128417969,
                17.742233276367188,
                620.1159057617188,
                355.7278137207031
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16136,
            16140
          ],
          "representative_frame": 16136,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 134
    },
    {
      "second": 538,
      "time_range": [
        538,
        538.999
      ],
      "frame_range": [
        16141,
        16170
      ],
      "unified_description": "\n\nIn the image, there is a person standing on a sandy beach holding a bottle. The camera perspective appears to be first-person, mounted on the person's shoulder. The field of view includes a wide-angle distortion which captures the surrounding environment. There are no other people or objects visible in the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:21",
        "processing_time": 3.6,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16155,
          "frame_range": [
            16151,
            16155
          ],
          "description": "a person is holding a bottle on the beach",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.68
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16141,
            16145
          ],
          "representative_frame": 16141,
          "detections": [
            {
              "track_id": 1223,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9482747316360474,
              "bbox": [
                276.12750244140625,
                7.242161273956299,
                640.0,
                355.5674743652344
              ]
            }
          ],
          "unique_tracks": [
            1223
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            16146,
            16150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16151,
            16155
          ],
          "representative_frame": 16151,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            16156,
            16160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16161,
            16165
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            16166,
            16170
          ],
          "representative_frame": 16166,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 134
    },
    {
      "second": 539,
      "time_range": [
        539,
        539.999
      ],
      "frame_range": [
        16171,
        16200
      ],
      "unified_description": "2 bags on the shore of a lake. A white water bottle is placed in front of one bag. The camera is positioned to capture the beautiful scenery, as well as the action or story involving these two bags.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:22",
        "processing_time": 4.01,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16185,
          "frame_range": [
            16181,
            16185
          ],
          "description": "two bags are on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.62
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16171,
            16175
          ],
          "representative_frame": 16171,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            16176,
            16180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16181,
            16185
          ],
          "representative_frame": 16181,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            16186,
            16190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16191,
            16195
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            16196,
            16200
          ],
          "representative_frame": 16196,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 134
    },
    {
      "second": 540,
      "time_range": [
        540,
        540.999
      ],
      "frame_range": [
        16201,
        16230
      ],
      "unified_description": "\nIn this scene, there's a man standing by the water on the shore of a lake. The camera perspective is POV, providing a first-person experience for the viewer. The image captures the outdoors, showcasing the surrounding environment and its elements.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:24",
        "processing_time": 3.31,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16215,
          "frame_range": [
            16211,
            16215
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.01
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16201,
            16205
          ],
          "representative_frame": 16201,
          "detections": [
            {
              "track_id": 1250,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.849132776260376,
              "bbox": [
                289.9496765136719,
                43.89849853515625,
                407.86737060546875,
                260.69207763671875
              ]
            },
            {
              "track_id": 1251,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.30827420949935913,
              "bbox": [
                165.89251708984375,
                170.7021026611328,
                216.04116821289062,
                200.1947479248047
              ]
            }
          ],
          "unique_tracks": [
            1250,
            1251
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            16206,
            16210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16211,
            16215
          ],
          "representative_frame": 16211,
          "detections": [
            {
              "track_id": 1250,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8690833449363708,
              "bbox": [
                291.5445861816406,
                13.971961975097656,
                424.5419616699219,
                260.35638427734375
              ]
            },
            {
              "track_id": 1251,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.299380362033844,
              "bbox": [
                165.95452880859375,
                170.75343322753906,
                215.58140563964844,
                199.93040466308594
              ]
            }
          ],
          "unique_tracks": [
            1250,
            1251
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            16216,
            16220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16221,
            16225
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1250,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7405568361282349,
              "bbox": [
                306.878662109375,
                0.5368422269821167,
                423.43670654296875,
                217.3751983642578
              ]
            },
            {
              "track_id": 1251,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.30106937885284424,
              "bbox": [
                166.04112243652344,
                170.8770751953125,
                215.60931396484375,
                200.01499938964844
              ]
            },
            {
              "track_id": 1256,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.32105720043182373,
              "bbox": [
                288.913330078125,
                245.21548461914062,
                404.1377868652344,
                324.517333984375
              ]
            }
          ],
          "unique_tracks": [
            1250,
            1251,
            1256
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            16226,
            16230
          ],
          "representative_frame": 16226,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 135
    },
    {
      "second": 541,
      "time_range": [
        541,
        541.999
      ],
      "frame_range": [
        16231,
        16260
      ],
      "unified_description": "3rd person's view of an outdoor scene with a man standing on the shore of a lake, and other objects/persons present in the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:25",
        "processing_time": 2.7,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16245,
          "frame_range": [
            16241,
            16245
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.26
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16231,
            16235
          ],
          "representative_frame": 16231,
          "detections": [
            {
              "track_id": 1250,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.7930753231048584,
              "bbox": [
                313.7713623046875,
                0.0,
                436.9234924316406,
                228.9679718017578
              ]
            },
            {
              "track_id": 1251,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2925177216529846,
              "bbox": [
                165.9726104736328,
                170.90223693847656,
                215.751708984375,
                200.16407775878906
              ]
            },
            {
              "track_id": 1256,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.22831541299819946,
              "bbox": [
                286.1904602050781,
                241.54049682617188,
                407.04962158203125,
                324.822021484375
              ]
            },
            {
              "track_id": 1224,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.909135639667511,
              "bbox": [
                41.316429138183594,
                0.14835521578788757,
                640.0,
                245.3791046142578
              ]
            }
          ],
          "unique_tracks": [
            1250,
            1251,
            1256,
            1224
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            16236,
            16240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16241,
            16245
          ],
          "representative_frame": 16241,
          "detections": [
            {
              "track_id": 1250,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8897921442985535,
              "bbox": [
                301.42034912109375,
                0.0,
                431.98797607421875,
                241.4973907470703
              ]
            },
            {
              "track_id": 1251,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.11519807577133179,
              "bbox": [
                165.9193878173828,
                170.92625427246094,
                215.8845977783203,
                200.3071746826172
              ]
            },
            {
              "track_id": 1256,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.11332742124795914,
              "bbox": [
                278.0994873046875,
                228.73971557617188,
                416.117919921875,
                324.3997802734375
              ]
            }
          ],
          "unique_tracks": [
            1250,
            1251,
            1256
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            16246,
            16250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16251,
            16255
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1250,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9282519221305847,
              "bbox": [
                291.540771484375,
                0.0,
                430.1324768066406,
                255.68202209472656
              ]
            },
            {
              "track_id": 1251,
              "class_id": 35,
              "class_name": "baseball glove",
              "confidence": 0.3150852620601654,
              "bbox": [
                166.07559204101562,
                170.98648071289062,
                215.42233276367188,
                199.96945190429688
              ]
            },
            {
              "track_id": 1256,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.1956336945295334,
              "bbox": [
                276.13671875,
                234.0313720703125,
                406.8455810546875,
                324.41876220703125
              ]
            }
          ],
          "unique_tracks": [
            1250,
            1251,
            1256
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            16256,
            16260
          ],
          "representative_frame": 16256,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 135
    },
    {
      "second": 542,
      "time_range": [
        542,
        542.999
      ],
      "frame_range": [
        16261,
        16290
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:25",
        "processing_time": 2.11,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16275,
          "frame_range": [
            16271,
            16275
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.9
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16261,
            16265
          ],
          "representative_frame": 16261,
          "detections": [
            {
              "track_id": 1250,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9115254282951355,
              "bbox": [
                265.5605773925781,
                36.472469329833984,
                391.07330322265625,
                265.4054260253906
              ]
            }
          ],
          "unique_tracks": [
            1250
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            16266,
            16270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16271,
            16275
          ],
          "representative_frame": 16271,
          "detections": [
            {
              "track_id": 1250,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9079139232635498,
              "bbox": [
                253.88092041015625,
                44.482601165771484,
                378.5011901855469,
                268.42047119140625
              ]
            },
            {
              "track_id": 1259,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.47638413310050964,
              "bbox": [
                28.17693328857422,
                172.43603515625,
                162.7312774658203,
                267.0962829589844
              ]
            },
            {
              "track_id": 1260,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.314125120639801,
              "bbox": [
                133.9074249267578,
                174.63055419921875,
                221.30320739746094,
                255.88839721679688
              ]
            }
          ],
          "unique_tracks": [
            1250,
            1259,
            1260
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            16276,
            16280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16281,
            16285
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1250,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8472575545310974,
              "bbox": [
                244.14710998535156,
                37.56840896606445,
                373.1551513671875,
                268.2640380859375
              ]
            },
            {
              "track_id": 1259,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4885616898536682,
              "bbox": [
                27.00623893737793,
                170.9292449951172,
                163.55014038085938,
                267.0327453613281
              ]
            },
            {
              "track_id": 1260,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.29319337010383606,
              "bbox": [
                133.7886505126953,
                174.4845733642578,
                221.58103942871094,
                256.1401672363281
              ]
            }
          ],
          "unique_tracks": [
            1250,
            1259,
            1260
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            16286,
            16290
          ],
          "representative_frame": 16286,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 135
    },
    {
      "second": 543,
      "time_range": [
        543,
        543.999
      ],
      "frame_range": [
        16291,
        16320
      ],
      "unified_description": "\nAn outdoor scene with a person standing on the shore of a lake. The camera is positioned to capture the man as he stands by the water. The image includes a few other elements, such as a bench and a small bird, adding more depth to the otherwise simple scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:28",
        "processing_time": 3.06,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16305,
          "frame_range": [
            16301,
            16305
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.75
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16291,
            16295
          ],
          "representative_frame": 16291,
          "detections": [
            {
              "track_id": 1250,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8968695402145386,
              "bbox": [
                237.616455078125,
                32.42405700683594,
                370.6672058105469,
                270.2337951660156
              ]
            },
            {
              "track_id": 1259,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4808676838874817,
              "bbox": [
                27.234455108642578,
                171.49383544921875,
                162.75306701660156,
                266.9047546386719
              ]
            },
            {
              "track_id": 1260,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.20967158675193787,
              "bbox": [
                134.61341857910156,
                175.4401092529297,
                221.80728149414062,
                256.5392761230469
              ]
            }
          ],
          "unique_tracks": [
            1250,
            1259,
            1260
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            16296,
            16300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16301,
            16305
          ],
          "representative_frame": 16301,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            16306,
            16310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16311,
            16315
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7399349808692932,
              "bbox": [
                419.6097412109375,
                105.4871826171875,
                519.4072875976562,
                275.51385498046875
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16316,
            16320
          ],
          "representative_frame": 16316,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 135
    },
    {
      "second": 544,
      "time_range": [
        544,
        544.999
      ],
      "frame_range": [
        16321,
        16350
      ],
      "unified_description": "1-second scene with a man standing by a body of water called Lake Tahoe. The camera is mounted on a backpack, capturing the surrounding area which includes a beach, bushes, and a boat in the water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:29",
        "processing_time": 2.91,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16335,
          "frame_range": [
            16331,
            16335
          ],
          "description": "a man is standing near a lake with a tare",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.33
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16321,
            16325
          ],
          "representative_frame": 16321,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6678774952888489,
              "bbox": [
                412.8721008300781,
                103.71913146972656,
                513.927001953125,
                275.97711181640625
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3459238111972809,
              "bbox": [
                352.3988037109375,
                103.8050308227539,
                516.8441772460938,
                276.5970764160156
              ]
            }
          ],
          "unique_tracks": [
            1261,
            1262
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            16326,
            16330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16331,
            16335
          ],
          "representative_frame": 16331,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9252210259437561,
              "bbox": [
                395.7398986816406,
                96.7172622680664,
                499.3219299316406,
                273.4311828613281
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16336,
            16340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16341,
            16345
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9054210186004639,
              "bbox": [
                383.40576171875,
                91.582275390625,
                485.19573974609375,
                265.0197448730469
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16346,
            16350
          ],
          "representative_frame": 16346,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 136
    },
    {
      "second": 545,
      "time_range": [
        545,
        545.999
      ],
      "frame_range": [
        16351,
        16380
      ],
      "unified_description": "3rd person perspective, hand held camera with wide angle lens, no visible tripod or other camera support, outdoor setting with lake, clear day, no additional lenses or filters applied to image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:30",
        "processing_time": 3.74,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16365,
          "frame_range": [
            16361,
            16365
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.19
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16351,
            16355
          ],
          "representative_frame": 16351,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9226229786872864,
              "bbox": [
                373.09185791015625,
                90.54420471191406,
                474.2154235839844,
                262.1454772949219
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            16356,
            16360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16361,
            16365
          ],
          "representative_frame": 16361,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9353200793266296,
              "bbox": [
                363.3071594238281,
                91.8432846069336,
                461.5512390136719,
                257.7306823730469
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16366,
            16370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16371,
            16375
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9347943663597107,
              "bbox": [
                357.5150146484375,
                94.68965911865234,
                453.80523681640625,
                255.79669189453125
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16376,
            16380
          ],
          "representative_frame": 16376,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 136
    },
    {
      "second": 546,
      "time_range": [
        546,
        546.999
      ],
      "frame_range": [
        16381,
        16410
      ],
      "unified_description": "1-second scene featuring a man standing by a lake, possibly taking a picture himself. The image includes multiple objects and people within the frame, as well as various camera perspectives and styles.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:31",
        "processing_time": 3.07,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16395,
          "frame_range": [
            16391,
            16395
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.78
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16381,
            16385
          ],
          "representative_frame": 16381,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9343121647834778,
              "bbox": [
                355.411376953125,
                98.62425231933594,
                449.984130859375,
                255.37008666992188
              ]
            },
            {
              "track_id": 1265,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7205507159233093,
              "bbox": [
                347.5752258300781,
                161.01864624023438,
                414.0643005371094,
                239.80776977539062
              ]
            }
          ],
          "unique_tracks": [
            1261,
            1265
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            16386,
            16390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16391,
            16395
          ],
          "representative_frame": 16391,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9286128282546997,
              "bbox": [
                354.6766052246094,
                103.6435317993164,
                447.5327453613281,
                255.4198455810547
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16396,
            16400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16401,
            16405
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.922971785068512,
              "bbox": [
                354.66400146484375,
                107.86213684082031,
                446.5111389160156,
                255.2363739013672
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16406,
            16410
          ],
          "representative_frame": 16406,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 136
    },
    {
      "second": 547,
      "time_range": [
        547,
        547.999
      ],
      "frame_range": [
        16411,
        16440
      ],
      "unified_description": "1-second scene featuring a man standing by water with objects floating on top. Camera is mounted on a backpack, capturing wide-angle footage.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:33",
        "processing_time": 2.66,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16425,
          "frame_range": [
            16421,
            16425
          ],
          "description": "a person is standing near a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.83
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16411,
            16415
          ],
          "representative_frame": 16411,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9282584190368652,
              "bbox": [
                353.5925598144531,
                111.59758758544922,
                444.6478271484375,
                254.90538024902344
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            16416,
            16420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16421,
            16425
          ],
          "representative_frame": 16421,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8583763241767883,
              "bbox": [
                385.8796081542969,
                100.7142105102539,
                545.521240234375,
                274.38262939453125
              ]
            }
          ],
          "unique_tracks": [
            1262
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16426,
            16430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16431,
            16435
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9126368165016174,
              "bbox": [
                390.591796875,
                102.2056884765625,
                544.1759033203125,
                274.5152893066406
              ]
            }
          ],
          "unique_tracks": [
            1262
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16436,
            16440
          ],
          "representative_frame": 16436,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 136
    },
    {
      "second": 548,
      "time_range": [
        548,
        548.999
      ],
      "frame_range": [
        16441,
        16470
      ],
      "unified_description": "1-second scene where a man is standing by a lake with his fishing pole, and a backpack nearby. The camera was held steady with a tripod.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:34",
        "processing_time": 2.66,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16455,
          "frame_range": [
            16451,
            16455
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.06
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16441,
            16445
          ],
          "representative_frame": 16441,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8929904103279114,
              "bbox": [
                393.99371337890625,
                104.00340270996094,
                542.3915405273438,
                275.3439636230469
              ]
            }
          ],
          "unique_tracks": [
            1262
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            16446,
            16450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16451,
            16455
          ],
          "representative_frame": 16451,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.908279299736023,
              "bbox": [
                396.8052673339844,
                104.48953247070312,
                540.497314453125,
                274.68597412109375
              ]
            }
          ],
          "unique_tracks": [
            1262
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16456,
            16460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16461,
            16465
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9158269166946411,
              "bbox": [
                398.28240966796875,
                104.40476989746094,
                538.72119140625,
                274.7064208984375
              ]
            }
          ],
          "unique_tracks": [
            1262
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16466,
            16470
          ],
          "representative_frame": 16466,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 137
    },
    {
      "second": 549,
      "time_range": [
        549,
        549.999
      ],
      "frame_range": [
        16471,
        16500
      ],
      "unified_description": "1-second scene where a man is throwing a bag into the water with a wide-angle view.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:35",
        "processing_time": 2.63,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16485,
          "frame_range": [
            16481,
            16485
          ],
          "description": "a man is putting a bag into the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.71
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16471,
            16475
          ],
          "representative_frame": 16471,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.441313236951828,
              "bbox": [
                137.6449737548828,
                126.63279724121094,
                421.5234375,
                258.0928039550781
              ]
            },
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.911359429359436,
              "bbox": [
                351.0891418457031,
                81.46746063232422,
                461.2120056152344,
                257.2922058105469
              ]
            }
          ],
          "unique_tracks": [
            1269,
            1261
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            16476,
            16480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16481,
            16485
          ],
          "representative_frame": 16481,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.16042132675647736,
              "bbox": [
                130.92669677734375,
                119.96739959716797,
                429.9643249511719,
                258.8616638183594
              ]
            },
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.925719678401947,
              "bbox": [
                343.6976318359375,
                83.05167388916016,
                452.5234375,
                256.85821533203125
              ]
            }
          ],
          "unique_tracks": [
            1269,
            1261
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            16486,
            16490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16491,
            16495
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9271224141120911,
              "bbox": [
                334.0042724609375,
                85.88320922851562,
                440.6346130371094,
                257.3248596191406
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16496,
            16500
          ],
          "representative_frame": 16496,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 137
    },
    {
      "second": 550,
      "time_range": [
        550,
        550.999
      ],
      "frame_range": [
        16501,
        16530
      ],
      "unified_description": "\n\nVideo of a person placing a boat into the water. The person appears to be wearing a backpack while pushing the boat into the water. There are no other individuals visible in the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:36",
        "processing_time": 2.83,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16515,
          "frame_range": [
            16511,
            16515
          ],
          "description": "a man is putting a canoe into the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.72
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16501,
            16505
          ],
          "representative_frame": 16501,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9285280108451843,
              "bbox": [
                331.14923095703125,
                91.7781982421875,
                434.4753112792969,
                257.855224609375
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            16506,
            16510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16511,
            16515
          ],
          "representative_frame": 16511,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9227675199508667,
              "bbox": [
                331.05487060546875,
                96.74187469482422,
                431.6719970703125,
                257.9801330566406
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16516,
            16520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16521,
            16525
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8432623744010925,
              "bbox": [
                139.18536376953125,
                1.3180009126663208,
                480.87396240234375,
                288.1211242675781
              ]
            }
          ],
          "unique_tracks": [
            1256
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16526,
            16530
          ],
          "representative_frame": 16526,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 137
    },
    {
      "second": 551,
      "time_range": [
        551,
        551.999
      ],
      "frame_range": [
        16531,
        16560
      ],
      "unified_description": "1 second of video showcasing outdoor scene with a man near water with a surfboard nearby.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:37",
        "processing_time": 2.43,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16545,
          "frame_range": [
            16541,
            16545
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.02
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16531,
            16535
          ],
          "representative_frame": 16531,
          "detections": [
            {
              "track_id": 1270,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7551414370536804,
              "bbox": [
                131.95530700683594,
                0.375244140625,
                193.05889892578125,
                175.90304565429688
              ]
            },
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8544931411743164,
              "bbox": [
                147.8164825439453,
                0.0,
                453.9841003417969,
                287.0749206542969
              ]
            }
          ],
          "unique_tracks": [
            1270,
            1256
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            16536,
            16540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16541,
            16545
          ],
          "representative_frame": 16541,
          "detections": [
            {
              "track_id": 1270,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7755884528160095,
              "bbox": [
                131.7823028564453,
                0.08582015335559845,
                192.82508850097656,
                175.3994598388672
              ]
            },
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8944956660270691,
              "bbox": [
                156.01763916015625,
                0.0,
                434.6149597167969,
                286.937255859375
              ]
            }
          ],
          "unique_tracks": [
            1270,
            1256
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            16546,
            16550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16551,
            16555
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1270,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7061689496040344,
              "bbox": [
                131.5004119873047,
                0.0,
                192.5876922607422,
                175.2527313232422
              ]
            },
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7484297156333923,
              "bbox": [
                165.5928497314453,
                0.0,
                423.7727355957031,
                286.9937438964844
              ]
            }
          ],
          "unique_tracks": [
            1270,
            1256
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            16556,
            16560
          ],
          "representative_frame": 16556,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 137
    },
    {
      "second": 552,
      "time_range": [
        552,
        552.999
      ],
      "frame_range": [
        16561,
        16590
      ],
      "unified_description": "5-second scene with a person standing by water. The camera is relatively stable and capturing the scene in wide-angle perspective.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:38",
        "processing_time": 2.7,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16575,
          "frame_range": [
            16571,
            16575
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16561,
            16565
          ],
          "representative_frame": 16561,
          "detections": [
            {
              "track_id": 1270,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.76816725730896,
              "bbox": [
                131.37330627441406,
                0.0,
                192.58914184570312,
                175.44354248046875
              ]
            },
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8887697458267212,
              "bbox": [
                175.13491821289062,
                0.0,
                416.2906494140625,
                287.07550048828125
              ]
            }
          ],
          "unique_tracks": [
            1270,
            1256
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            16566,
            16570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16571,
            16575
          ],
          "representative_frame": 16571,
          "detections": [
            {
              "track_id": 1270,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7272509336471558,
              "bbox": [
                131.26116943359375,
                0.0,
                192.52976989746094,
                175.40867614746094
              ]
            },
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.869848370552063,
              "bbox": [
                183.36959838867188,
                0.0,
                408.050048828125,
                287.5558166503906
              ]
            }
          ],
          "unique_tracks": [
            1270,
            1256
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            16576,
            16580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16581,
            16585
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1270,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8091450929641724,
              "bbox": [
                131.12185668945312,
                0.2778802216053009,
                192.15277099609375,
                174.89749145507812
              ]
            },
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5690770149230957,
              "bbox": [
                196.43943786621094,
                0.0,
                407.3106689453125,
                281.1193542480469
              ]
            }
          ],
          "unique_tracks": [
            1270,
            1256
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            16586,
            16590
          ],
          "representative_frame": 16586,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 138
    },
    {
      "second": 553,
      "time_range": [
        553,
        553.999
      ],
      "frame_range": [
        16591,
        16620
      ],
      "unified_description": "1-second scene with a man standing on the shore of a lake, with two other people nearby, and a backpack on the ground. The camera perspective is from the body of a person wearing a backpack, showing the person's point of view as they look out over the water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:40",
        "processing_time": 3.12,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16605,
          "frame_range": [
            16601,
            16605
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.68
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16591,
            16595
          ],
          "representative_frame": 16591,
          "detections": [
            {
              "track_id": 1270,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7954948544502258,
              "bbox": [
                130.97686767578125,
                0.11864891648292542,
                192.05577087402344,
                174.57858276367188
              ]
            }
          ],
          "unique_tracks": [
            1270
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            16596,
            16600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16601,
            16605
          ],
          "representative_frame": 16601,
          "detections": [
            {
              "track_id": 1270,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6655616164207458,
              "bbox": [
                128.45022583007812,
                0.2040257602930069,
                189.33595275878906,
                175.3717041015625
              ]
            },
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.482143372297287,
              "bbox": [
                177.2485809326172,
                0.0,
                366.84368896484375,
                254.34568786621094
              ]
            }
          ],
          "unique_tracks": [
            1270,
            1256
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            16606,
            16610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16611,
            16615
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 17,
              "class_name": "horse",
              "confidence": 0.18297064304351807,
              "bbox": [
                139.0994110107422,
                0.703453540802002,
                365.5125732421875,
                310.84881591796875
              ]
            }
          ],
          "unique_tracks": [
            1256
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16616,
            16620
          ],
          "representative_frame": 16616,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 138
    },
    {
      "second": 554,
      "time_range": [
        554,
        554.999
      ],
      "frame_range": [
        16621,
        16650
      ],
      "unified_description": "3rd person's view of a person sitting by a lake. The camera is stable (tripod or similar) and capturing the scene with the lake in focus.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:41",
        "processing_time": 2.87,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16635,
          "frame_range": [
            16631,
            16635
          ],
          "description": "a man is sitting on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.87
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16621,
            16625
          ],
          "representative_frame": 16621,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8468927145004272,
              "bbox": [
                338.4811096191406,
                126.60643768310547,
                449.2650451660156,
                292.9749755859375
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            16626,
            16630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16631,
            16635
          ],
          "representative_frame": 16631,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8147388100624084,
              "bbox": [
                335.556640625,
                129.12161254882812,
                450.8262023925781,
                293.8231506347656
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16636,
            16640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16641,
            16645
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.875774621963501,
              "bbox": [
                330.4833068847656,
                129.7991943359375,
                453.0558776855469,
                300.4488220214844
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16646,
            16650
          ],
          "representative_frame": 16646,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 138
    },
    {
      "second": 555,
      "time_range": [
        555,
        555.999
      ],
      "frame_range": [
        16651,
        16680
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:41",
        "processing_time": 2.18,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16665,
          "frame_range": [
            16661,
            16665
          ],
          "description": "a man sitting on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.66
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16651,
            16655
          ],
          "representative_frame": 16651,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8817285895347595,
              "bbox": [
                327.4576721191406,
                129.8089141845703,
                454.5186462402344,
                302.6973876953125
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            16656,
            16660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16661,
            16665
          ],
          "representative_frame": 16661,
          "detections": [
            {
              "track_id": 1261,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8744069337844849,
              "bbox": [
                324.7177429199219,
                123.7716064453125,
                458.2473449707031,
                303.69696044921875
              ]
            }
          ],
          "unique_tracks": [
            1261
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16666,
            16670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16671,
            16675
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9243596196174622,
              "bbox": [
                431.7239685058594,
                120.78330993652344,
                560.237548828125,
                281.6379089355469
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6396209001541138,
              "bbox": [
                98.7572250366211,
                111.97100830078125,
                561.4463500976562,
                329.1174621582031
              ]
            }
          ],
          "unique_tracks": [
            1262,
            1269
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            16676,
            16680
          ],
          "representative_frame": 16676,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 138
    },
    {
      "second": 556,
      "time_range": [
        556,
        556.999
      ],
      "frame_range": [
        16681,
        16710
      ],
      "unified_description": "3rd person perspective showing a man trying to put a raft into the water. The camera is likely mounted on a helmet or body-mounted, giving a first-person view.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:44",
        "processing_time": 2.75,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16695,
          "frame_range": [
            16691,
            16695
          ],
          "description": "a man is putting a raft into the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.79
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16681,
            16685
          ],
          "representative_frame": 16681,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9132704138755798,
              "bbox": [
                432.6041564941406,
                122.94774627685547,
                557.73828125,
                282.2211608886719
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6601856350898743,
              "bbox": [
                99.6304931640625,
                111.86006927490234,
                562.4654541015625,
                330.80859375
              ]
            }
          ],
          "unique_tracks": [
            1262,
            1269
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            16686,
            16690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16691,
            16695
          ],
          "representative_frame": 16691,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8263149261474609,
              "bbox": [
                432.8357849121094,
                124.80818939208984,
                555.3768310546875,
                281.83905029296875
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.679402232170105,
              "bbox": [
                100.7744140625,
                111.88209533691406,
                561.8950805664062,
                331.32635498046875
              ]
            }
          ],
          "unique_tracks": [
            1262,
            1269
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            16696,
            16700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16701,
            16705
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            16706,
            16710
          ],
          "representative_frame": 16706,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 139
    },
    {
      "second": 557,
      "time_range": [
        557,
        557.999
      ],
      "frame_range": [
        16711,
        16740
      ],
      "unified_description": "3D modeler or video editor, please provideke in a text document for proper credit and usage.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:45",
        "processing_time": 2.45,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16725,
          "frame_range": [
            16721,
            16725
          ],
          "description": "a man standing next to a lake with a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.51
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16711,
            16715
          ],
          "representative_frame": 16711,
          "detections": [
            {
              "track_id": 1274,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8723534941673279,
              "bbox": [
                387.4267272949219,
                43.70090866088867,
                458.289794921875,
                216.85284423828125
              ]
            },
            {
              "track_id": 1275,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8213021755218506,
              "bbox": [
                360.4145812988281,
                93.07684326171875,
                387.61376953125,
                150.03179931640625
              ]
            }
          ],
          "unique_tracks": [
            1274,
            1275
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            16716,
            16720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16721,
            16725
          ],
          "representative_frame": 16721,
          "detections": [
            {
              "track_id": 1274,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8763728737831116,
              "bbox": [
                385.6062927246094,
                43.87785339355469,
                456.8208923339844,
                217.70339965820312
              ]
            },
            {
              "track_id": 1275,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8275121450424194,
              "bbox": [
                360.4058837890625,
                93.00856018066406,
                387.5940246582031,
                149.9250946044922
              ]
            }
          ],
          "unique_tracks": [
            1274,
            1275
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            16726,
            16730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16731,
            16735
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1274,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8739187717437744,
              "bbox": [
                386.01953125,
                44.59750747680664,
                456.8798522949219,
                217.31558227539062
              ]
            },
            {
              "track_id": 1275,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8304078578948975,
              "bbox": [
                360.0926513671875,
                93.17766571044922,
                387.1946716308594,
                149.97161865234375
              ]
            }
          ],
          "unique_tracks": [
            1274,
            1275
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            16736,
            16740
          ],
          "representative_frame": 16736,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 139
    },
    {
      "second": 558,
      "time_range": [
        558,
        558.999
      ],
      "frame_range": [
        16741,
        16770
      ],
      "unified_description": "2 people are standing in front of a lake in this image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:46",
        "processing_time": 2.71,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16755,
          "frame_range": [
            16751,
            16755
          ],
          "description": "two people standing on a rocky shore next to a body of water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.57
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16741,
            16745
          ],
          "representative_frame": 16741,
          "detections": [
            {
              "track_id": 1275,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8447818756103516,
              "bbox": [
                368.2472839355469,
                95.82867431640625,
                399.1365966796875,
                160.75289916992188
              ]
            }
          ],
          "unique_tracks": [
            1275
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            16746,
            16750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16751,
            16755
          ],
          "representative_frame": 16751,
          "detections": [
            {
              "track_id": 1275,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8614985942840576,
              "bbox": [
                372.40234375,
                96.0728530883789,
                405.3155212402344,
                165.58087158203125
              ]
            },
            {
              "track_id": 1277,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8445590138435364,
              "bbox": [
                431.0400390625,
                87.02494812011719,
                458.189208984375,
                170.9738311767578
              ]
            },
            {
              "track_id": 1278,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5022709369659424,
              "bbox": [
                351.2194519042969,
                149.18722534179688,
                523.8682250976562,
                201.88031005859375
              ]
            },
            {
              "track_id": 1270,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8763332366943359,
              "bbox": [
                150.34324645996094,
                0.5003458261489868,
                222.69468688964844,
                201.8240966796875
              ]
            }
          ],
          "unique_tracks": [
            1275,
            1277,
            1278,
            1270
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            16756,
            16760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16761,
            16765
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1275,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8153888583183289,
              "bbox": [
                377.06610107421875,
                96.87593841552734,
                409.8674621582031,
                167.02418518066406
              ]
            },
            {
              "track_id": 1277,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8634510040283203,
              "bbox": [
                432.3830871582031,
                86.77261352539062,
                459.453369140625,
                170.2189483642578
              ]
            },
            {
              "track_id": 1278,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5373659133911133,
              "bbox": [
                350.852783203125,
                148.68898010253906,
                525.0186157226562,
                201.85716247558594
              ]
            },
            {
              "track_id": 1270,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9221590757369995,
              "bbox": [
                145.21182250976562,
                0.18801607191562653,
                221.5501251220703,
                202.8118133544922
              ]
            }
          ],
          "unique_tracks": [
            1275,
            1277,
            1278,
            1270
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            16766,
            16770
          ],
          "representative_frame": 16766,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 139
    },
    {
      "second": 559,
      "time_range": [
        559,
        559.999
      ],
      "frame_range": [
        16771,
        16800
      ],
      "unified_description": "360 videos with an equidistant perspective",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:47",
        "processing_time": 2.34,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16785,
          "frame_range": [
            16781,
            16785
          ],
          "description": "two people standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.73
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16771,
            16775
          ],
          "representative_frame": 16771,
          "detections": [
            {
              "track_id": 1275,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7939118146896362,
              "bbox": [
                380.5309753417969,
                97.08181762695312,
                413.06695556640625,
                167.8909912109375
              ]
            },
            {
              "track_id": 1277,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8624792098999023,
              "bbox": [
                432.2537841796875,
                86.57539367675781,
                459.5672607421875,
                170.31423950195312
              ]
            },
            {
              "track_id": 1278,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.49720504879951477,
              "bbox": [
                350.00738525390625,
                148.03167724609375,
                526.1054077148438,
                201.82601928710938
              ]
            },
            {
              "track_id": 1270,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8779764175415039,
              "bbox": [
                155.59706115722656,
                0.08809122443199158,
                230.11441040039062,
                202.75296020507812
              ]
            }
          ],
          "unique_tracks": [
            1275,
            1277,
            1278,
            1270
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            16776,
            16780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16781,
            16785
          ],
          "representative_frame": 16781,
          "detections": [
            {
              "track_id": 1275,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8285464644432068,
              "bbox": [
                381.02294921875,
                96.84947967529297,
                413.3160705566406,
                168.05406188964844
              ]
            },
            {
              "track_id": 1277,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8786217570304871,
              "bbox": [
                429.4033203125,
                86.76130676269531,
                456.8006591796875,
                169.98733520507812
              ]
            },
            {
              "track_id": 1278,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5300450325012207,
              "bbox": [
                350.147216796875,
                148.39259338378906,
                525.4893798828125,
                201.99656677246094
              ]
            },
            {
              "track_id": 1270,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9027183055877686,
              "bbox": [
                156.14141845703125,
                0.02351054921746254,
                230.49786376953125,
                202.702880859375
              ]
            }
          ],
          "unique_tracks": [
            1275,
            1277,
            1278,
            1270
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            16786,
            16790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16791,
            16795
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9242565631866455,
              "bbox": [
                158.1184844970703,
                0.0,
                355.1287536621094,
                274.9495849609375
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9522320032119751,
              "bbox": [
                421.5592956542969,
                4.3848090171813965,
                640.0,
                339.61285400390625
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6292029619216919,
              "bbox": [
                224.31307983398438,
                124.32540130615234,
                553.4364624023438,
                281.5168151855469
              ]
            }
          ],
          "unique_tracks": [
            1256,
            1262,
            1269
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            16796,
            16800
          ],
          "representative_frame": 16796,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 139
    },
    {
      "second": 560,
      "time_range": [
        560,
        560.999
      ],
      "frame_range": [
        16801,
        16830
      ],
      "unified_description": "4 people are in the scene and it has been stabilized for clearer viewing.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:51",
        "processing_time": 4.07,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16815,
          "frame_range": [
            16811,
            16815
          ],
          "description": "a man in a red jacket is standing next to a man in a red jacket",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.12
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16801,
            16805
          ],
          "representative_frame": 16801,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9185702800750732,
              "bbox": [
                162.5789794921875,
                0.16809077560901642,
                354.4413146972656,
                271.9275817871094
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9351846575737,
              "bbox": [
                425.85546875,
                0.0,
                640.0,
                340.4261169433594
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8505855202674866,
              "bbox": [
                233.40328979492188,
                128.42568969726562,
                555.5450439453125,
                284.02325439453125
              ]
            }
          ],
          "unique_tracks": [
            1256,
            1262,
            1269
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            16806,
            16810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16811,
            16815
          ],
          "representative_frame": 16811,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9165744781494141,
              "bbox": [
                167.40689086914062,
                0.3577280640602112,
                357.6612854003906,
                272.9184265136719
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9488627314567566,
              "bbox": [
                427.4451904296875,
                0.0,
                640.0,
                341.31787109375
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.865127444267273,
              "bbox": [
                224.80296325683594,
                124.04064178466797,
                562.64013671875,
                291.37506103515625
              ]
            }
          ],
          "unique_tracks": [
            1256,
            1262,
            1269
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            16816,
            16820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16821,
            16825
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9190654158592224,
              "bbox": [
                181.29489135742188,
                9.592339515686035,
                365.2835693359375,
                273.0036926269531
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9471443295478821,
              "bbox": [
                428.8160705566406,
                0.0,
                640.0,
                341.9428405761719
              ]
            },
            {
              "track_id": 1269,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.2628856301307678,
              "bbox": [
                224.34249877929688,
                123.34574127197266,
                562.1182861328125,
                293.0833435058594
              ]
            }
          ],
          "unique_tracks": [
            1256,
            1262,
            1269
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            16826,
            16830
          ],
          "representative_frame": 16826,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 140
    },
    {
      "second": 561,
      "time_range": [
        561,
        561.999
      ],
      "frame_range": [
        16831,
        16860
      ],
      "unified_description": "\nIn this scene, there is a person standing near a boat. The camera used to capture this image has a wide-angle perspective which allows for a more immersive view of the surrounding area. There are some artifacts present in the image, such as motion blur and lens flare, which may indicate that the camera is moving or that the lighting conditions are challenging. Overall, the video showcases a person's outdoor experience near a boat, with some technical aspects inherent in the capture of this moment.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:51",
        "processing_time": 3.96,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16845,
          "frame_range": [
            16841,
            16845
          ],
          "description": "a man is standing next to a boat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.32
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16831,
            16835
          ],
          "representative_frame": 16831,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9186484217643738,
              "bbox": [
                192.38494873046875,
                30.308320999145508,
                370.5926208496094,
                285.2709655761719
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9516680836677551,
              "bbox": [
                429.6824951171875,
                0.0,
                640.0,
                343.3533020019531
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6042787432670593,
              "bbox": [
                221.75875854492188,
                123.60083770751953,
                560.8381958007812,
                296.5978088378906
              ]
            },
            {
              "track_id": 1284,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.50678950548172,
              "bbox": [
                518.0471801757812,
                15.860376358032227,
                639.0009155273438,
                161.75247192382812
              ]
            }
          ],
          "unique_tracks": [
            1256,
            1262,
            1269,
            1284
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            16836,
            16840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16841,
            16845
          ],
          "representative_frame": 16841,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9117487072944641,
              "bbox": [
                206.4077606201172,
                57.62509536743164,
                383.59686279296875,
                308.4868469238281
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9499515295028687,
              "bbox": [
                430.9441223144531,
                0.0,
                640.0,
                341.88690185546875
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5782963037490845,
              "bbox": [
                207.50180053710938,
                125.48284912109375,
                551.9834594726562,
                302.0248718261719
              ]
            },
            {
              "track_id": 1284,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4896159768104553,
              "bbox": [
                518.2300415039062,
                16.905569076538086,
                637.8172607421875,
                161.07571411132812
              ]
            }
          ],
          "unique_tracks": [
            1256,
            1262,
            1269,
            1284
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            16846,
            16850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16851,
            16855
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8477622866630554,
              "bbox": [
                233.38587951660156,
                88.09552001953125,
                396.601318359375,
                319.0674133300781
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9482869505882263,
              "bbox": [
                430.90191650390625,
                0.0,
                640.0,
                344.9380187988281
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.4035312533378601,
              "bbox": [
                220.30856323242188,
                129.9701385498047,
                550.5146484375,
                300.9150695800781
              ]
            },
            {
              "track_id": 1284,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.47902220487594604,
              "bbox": [
                519.2764282226562,
                16.510799407958984,
                637.3321533203125,
                158.7068328857422
              ]
            }
          ],
          "unique_tracks": [
            1256,
            1262,
            1269,
            1284
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            16856,
            16860
          ],
          "representative_frame": 16856,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 140
    },
    {
      "second": 562,
      "time_range": [
        562,
        562.999
      ],
      "frame_range": [
        16861,
        16890
      ],
      "unified_description": "1-second scene of a man fishing on a small boat, captured with a fisheye lens, giving a wide perspective of the subject and surrounding area.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:52",
        "processing_time": 4.62,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16875,
          "frame_range": [
            16871,
            16875
          ],
          "description": "a man is fishing on a small boat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.89
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16861,
            16865
          ],
          "representative_frame": 16861,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8894637227058411,
              "bbox": [
                265.9121398925781,
                98.2376937866211,
                412.59564208984375,
                312.77362060546875
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9483355283737183,
              "bbox": [
                431.841552734375,
                0.0,
                640.0,
                345.525634765625
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.516934335231781,
              "bbox": [
                229.5035400390625,
                123.13729095458984,
                552.56787109375,
                291.72552490234375
              ]
            },
            {
              "track_id": 1284,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4555519223213196,
              "bbox": [
                518.9276733398438,
                17.049177169799805,
                634.7659912109375,
                156.34803771972656
              ]
            }
          ],
          "unique_tracks": [
            1256,
            1262,
            1269,
            1284
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            16866,
            16870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16871,
            16875
          ],
          "representative_frame": 16871,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6905062198638916,
              "bbox": [
                276.7008361816406,
                106.10920715332031,
                417.2925109863281,
                311.07403564453125
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9454885721206665,
              "bbox": [
                433.9879150390625,
                0.0,
                640.0,
                342.6488037109375
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5232864022254944,
              "bbox": [
                237.05099487304688,
                121.43885803222656,
                551.6319580078125,
                286.7841796875
              ]
            },
            {
              "track_id": 1284,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.48689642548561096,
              "bbox": [
                514.0757446289062,
                18.781213760375977,
                627.5779418945312,
                155.13906860351562
              ]
            }
          ],
          "unique_tracks": [
            1256,
            1262,
            1269,
            1284
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            16876,
            16880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16881,
            16885
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7222663760185242,
              "bbox": [
                284.3831481933594,
                107.90807342529297,
                421.8287658691406,
                302.5310974121094
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.939848005771637,
              "bbox": [
                435.341796875,
                1.4973539113998413,
                640.0,
                341.1934509277344
              ]
            },
            {
              "track_id": 1269,
              "class_id": 20,
              "class_name": "elephant",
              "confidence": 0.27969032526016235,
              "bbox": [
                258.4525146484375,
                121.22809600830078,
                582.191650390625,
                289.8322448730469
              ]
            },
            {
              "track_id": 1284,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3862207531929016,
              "bbox": [
                513.9639892578125,
                19.75788116455078,
                623.6453857421875,
                150.92323303222656
              ]
            }
          ],
          "unique_tracks": [
            1256,
            1262,
            1269,
            1284
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            16886,
            16890
          ],
          "representative_frame": 16886,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 140
    },
    {
      "second": 563,
      "time_range": [
        563,
        563.999
      ],
      "frame_range": [
        16891,
        16920
      ],
      "unified_description": "1-second scene that includes a man standing in the water with a boat, shot using a fisheye lens to capture the wide-angle view.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:55",
        "processing_time": 2.66,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16905,
          "frame_range": [
            16901,
            16905
          ],
          "description": "a man is standing in the water with a boat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.57
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16891,
            16895
          ],
          "representative_frame": 16891,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8451523780822754,
              "bbox": [
                289.34381103515625,
                109.9948959350586,
                418.20526123046875,
                281.3439636230469
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9343271851539612,
              "bbox": [
                436.50616455078125,
                4.057698726654053,
                640.0,
                339.2474060058594
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.21207405626773834,
              "bbox": [
                255.96568298339844,
                130.8373565673828,
                558.393798828125,
                288.87835693359375
              ]
            },
            {
              "track_id": 1284,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4035916328430176,
              "bbox": [
                513.9026489257812,
                20.400243759155273,
                627.9827880859375,
                156.0572052001953
              ]
            }
          ],
          "unique_tracks": [
            1256,
            1262,
            1269,
            1284
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            16896,
            16900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16901,
            16905
          ],
          "representative_frame": 16901,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8560890555381775,
              "bbox": [
                297.8637390136719,
                111.97857666015625,
                426.5782165527344,
                274.7998352050781
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9361770749092102,
              "bbox": [
                437.2612609863281,
                7.6609787940979,
                640.0,
                338.7428283691406
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.39024752378463745,
              "bbox": [
                246.11061096191406,
                120.60850524902344,
                577.5552368164062,
                288.8871765136719
              ]
            },
            {
              "track_id": 1284,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.42307552695274353,
              "bbox": [
                512.8609619140625,
                21.31865882873535,
                629.9326171875,
                159.61572265625
              ]
            }
          ],
          "unique_tracks": [
            1256,
            1262,
            1269,
            1284
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            16906,
            16910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16911,
            16915
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1256,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8261163234710693,
              "bbox": [
                312.33428955078125,
                111.72419738769531,
                437.25433349609375,
                265.7690124511719
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9168506860733032,
              "bbox": [
                436.4442443847656,
                6.9562602043151855,
                640.0,
                342.5567932128906
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6339429020881653,
              "bbox": [
                252.55874633789062,
                117.78546142578125,
                607.0423583984375,
                296.1633605957031
              ]
            },
            {
              "track_id": 1284,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2933752238750458,
              "bbox": [
                511.077880859375,
                20.943614959716797,
                628.0952758789062,
                158.7546844482422
              ]
            }
          ],
          "unique_tracks": [
            1256,
            1262,
            1269,
            1284
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            16916,
            16920
          ],
          "representative_frame": 16916,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 140
    },
    {
      "second": 564,
      "time_range": [
        564,
        564.999
      ],
      "frame_range": [
        16921,
        16950
      ],
      "unified_description": "1-second scene featuring a man and a child in a canoe",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:56",
        "processing_time": 2.54,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16935,
          "frame_range": [
            16931,
            16935
          ],
          "description": "a man and a child are in a canoe",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.6
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16921,
            16925
          ],
          "representative_frame": 16921,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9182876348495483,
              "bbox": [
                434.5529479980469,
                5.353681564331055,
                640.0,
                346.182861328125
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.4531874358654022,
              "bbox": [
                260.9255065917969,
                115.850830078125,
                622.9473876953125,
                297.39605712890625
              ]
            },
            {
              "track_id": 1284,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5152990818023682,
              "bbox": [
                507.4840393066406,
                20.212404251098633,
                625.0380859375,
                158.96939086914062
              ]
            },
            {
              "track_id": 1290,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.5992261171340942,
              "bbox": [
                219.74737548828125,
                212.82135009765625,
                307.7364501953125,
                287.7370300292969
              ]
            },
            {
              "track_id": 1274,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6989395618438721,
              "bbox": [
                392.6637268066406,
                111.3138427734375,
                437.3824462890625,
                205.4352569580078
              ]
            }
          ],
          "unique_tracks": [
            1262,
            1269,
            1284,
            1290,
            1274
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            16926,
            16930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16931,
            16935
          ],
          "representative_frame": 16931,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.920898973941803,
              "bbox": [
                435.3692321777344,
                10.048806190490723,
                640.0,
                346.4180603027344
              ]
            },
            {
              "track_id": 1269,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.48315685987472534,
              "bbox": [
                244.2925262451172,
                115.09994506835938,
                586.2529907226562,
                289.5607604980469
              ]
            },
            {
              "track_id": 1284,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4627615809440613,
              "bbox": [
                506.10968017578125,
                20.98428726196289,
                622.1550903320312,
                157.9658203125
              ]
            },
            {
              "track_id": 1290,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.7555304765701294,
              "bbox": [
                215.07887268066406,
                210.76121520996094,
                297.9271545410156,
                281.3503723144531
              ]
            },
            {
              "track_id": 1274,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6767812967300415,
              "bbox": [
                385.3685607910156,
                111.69878387451172,
                435.4031066894531,
                204.59300231933594
              ]
            }
          ],
          "unique_tracks": [
            1262,
            1269,
            1284,
            1290,
            1274
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            16936,
            16940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16941,
            16945
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9003515839576721,
              "bbox": [
                456.28741455078125,
                2.8897299766540527,
                640.0,
                343.0726623535156
              ]
            }
          ],
          "unique_tracks": [
            1262
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            16946,
            16950
          ],
          "representative_frame": 16946,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 141
    },
    {
      "second": 565,
      "time_range": [
        565,
        565.999
      ],
      "frame_range": [
        16951,
        16980
      ],
      "unified_description": "4 unique objects are detected in this image, including a man, a kay, some water, and potentially some other objects. The camera is mounted on a tripod, providing a stable perspective. The image descriptions suggest that this scene captures outdoor recreational activities such as fishing or boating.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:25:57",
        "processing_time": 3.92,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16965,
          "frame_range": [
            16961,
            16965
          ],
          "description": "a man is fishing in the water with a kay",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16951,
            16955
          ],
          "representative_frame": 16951,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9186954498291016,
              "bbox": [
                462.0819091796875,
                0.3969024121761322,
                640.0,
                341.6357727050781
              ]
            },
            {
              "track_id": 1295,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.31088316440582275,
              "bbox": [
                0.10505560040473938,
                134.2957305908203,
                33.15298080444336,
                184.70059204101562
              ]
            },
            {
              "track_id": 1277,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7487671375274658,
              "bbox": [
                395.0146484375,
                79.75792694091797,
                423.885498046875,
                138.60313415527344
              ]
            },
            {
              "track_id": 1274,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6337167024612427,
              "bbox": [
                375.67431640625,
                117.79999542236328,
                425.4683532714844,
                191.86061096191406
              ]
            }
          ],
          "unique_tracks": [
            1262,
            1295,
            1277,
            1274
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            16956,
            16960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16961,
            16965
          ],
          "representative_frame": 16961,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8521244525909424,
              "bbox": [
                455.5440979003906,
                0.0,
                640.0,
                345.0640869140625
              ]
            },
            {
              "track_id": 1295,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.44667574763298035,
              "bbox": [
                0.0,
                134.14971923828125,
                33.200138092041016,
                185.094970703125
              ]
            },
            {
              "track_id": 1277,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.758441686630249,
              "bbox": [
                391.7249450683594,
                79.29766845703125,
                425.9934997558594,
                135.99842834472656
              ]
            }
          ],
          "unique_tracks": [
            1262,
            1295,
            1277
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            16966,
            16970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            16971,
            16975
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8379314541816711,
              "bbox": [
                462.98712158203125,
                0.0,
                640.0,
                342.7987365722656
              ]
            },
            {
              "track_id": 1295,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.11828330159187317,
              "bbox": [
                0.0,
                134.57647705078125,
                33.32730484008789,
                185.45970153808594
              ]
            },
            {
              "track_id": 1277,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.841722846031189,
              "bbox": [
                391.97412109375,
                77.02864074707031,
                430.7225036621094,
                133.20315551757812
              ]
            },
            {
              "track_id": 1274,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6373531222343445,
              "bbox": [
                375.9830627441406,
                118.63846588134766,
                424.1109924316406,
                177.68450927734375
              ]
            }
          ],
          "unique_tracks": [
            1262,
            1295,
            1277,
            1274
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            16976,
            16980
          ],
          "representative_frame": 16976,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 141
    },
    {
      "second": 566,
      "time_range": [
        566,
        566.999
      ],
      "frame_range": [
        16981,
        17010
      ],
      "unified_description": "1-second scene featuring a man fishing in the water with a kay. This scene is shot using a fisheye lens which gives it a distinct appearance.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:00",
        "processing_time": 2.66,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 16995,
          "frame_range": [
            16991,
            16995
          ],
          "description": "a man is fishing in the water with a kay",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.74
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            16981,
            16985
          ],
          "representative_frame": 16981,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8221808671951294,
              "bbox": [
                459.44403076171875,
                0.0,
                640.0,
                343.049072265625
              ]
            },
            {
              "track_id": 1295,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.38304680585861206,
              "bbox": [
                0.17557363212108612,
                135.01629638671875,
                32.99776840209961,
                185.09336853027344
              ]
            },
            {
              "track_id": 1277,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8012858033180237,
              "bbox": [
                394.17681884765625,
                76.11226654052734,
                435.2629089355469,
                130.43768310546875
              ]
            },
            {
              "track_id": 1274,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5413010716438293,
              "bbox": [
                379.3017883300781,
                111.04027557373047,
                434.4874267578125,
                173.1739044189453
              ]
            }
          ],
          "unique_tracks": [
            1262,
            1295,
            1277,
            1274
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            16986,
            16990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            16991,
            16995
          ],
          "representative_frame": 16991,
          "detections": [
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8570623993873596,
              "bbox": [
                461.908935546875,
                0.0,
                636.41748046875,
                342.1402282714844
              ]
            },
            {
              "track_id": 1295,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.4226815104484558,
              "bbox": [
                0.07589118182659149,
                135.10223388671875,
                32.66331481933594,
                184.85292053222656
              ]
            },
            {
              "track_id": 1277,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8207870721817017,
              "bbox": [
                398.12530517578125,
                75.85885620117188,
                438.9725036621094,
                126.01150512695312
              ]
            },
            {
              "track_id": 1274,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.48880070447921753,
              "bbox": [
                386.8549499511719,
                115.0106430053711,
                437.4283752441406,
                165.240966796875
              ]
            }
          ],
          "unique_tracks": [
            1262,
            1295,
            1277,
            1274
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            16996,
            17000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17001,
            17005
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            17006,
            17010
          ],
          "representative_frame": 17006,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 141
    },
    {
      "second": 567,
      "time_range": [
        567,
        567.999
      ],
      "frame_range": [
        17011,
        17040
      ],
      "unified_description": "\nFrom top to bottom, the image captures a man wearing a life jacket as he pulls a boat into the water. There is no indication that this scene takes place at night, but it does show that there might be additional people involved in the process. Additionally, there are some interesting camera perspective and technical details that add character to the video.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:01",
        "processing_time": 3.62,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17025,
          "frame_range": [
            17021,
            17025
          ],
          "description": "a man in a life jacket is pulling a boat into the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.06
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17011,
            17015
          ],
          "representative_frame": 17011,
          "detections": [
            {
              "track_id": 1299,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9327982664108276,
              "bbox": [
                38.54752731323242,
                0.04966430738568306,
                164.79843139648438,
                325.43365478515625
              ]
            },
            {
              "track_id": 1300,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7608731389045715,
              "bbox": [
                269.43585205078125,
                58.177589416503906,
                333.42578125,
                248.05613708496094
              ]
            },
            {
              "track_id": 1301,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.531665563583374,
              "bbox": [
                162.1797332763672,
                106.4074478149414,
                474.7685852050781,
                209.9031219482422
              ]
            },
            {
              "track_id": 1302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4902038872241974,
              "bbox": [
                592.3782958984375,
                146.96041870117188,
                603.411376953125,
                159.6405029296875
              ]
            },
            {
              "track_id": 1303,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5406962633132935,
              "bbox": [
                567.9609985351562,
                153.5350341796875,
                612.826416015625,
                167.5869903564453
              ]
            }
          ],
          "unique_tracks": [
            1299,
            1300,
            1301,
            1302,
            1303
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            17016,
            17020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17021,
            17025
          ],
          "representative_frame": 17021,
          "detections": [
            {
              "track_id": 1299,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9215235114097595,
              "bbox": [
                74.64362335205078,
                9.341994285583496,
                190.29147338867188,
                307.0820617675781
              ]
            },
            {
              "track_id": 1300,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5867153406143188,
              "bbox": [
                288.4093017578125,
                71.19795227050781,
                347.4945068359375,
                245.1858673095703
              ]
            },
            {
              "track_id": 1301,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.5189670920372009,
              "bbox": [
                170.8818359375,
                114.01229858398438,
                512.5380859375,
                227.84996032714844
              ]
            },
            {
              "track_id": 1302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5358570218086243,
              "bbox": [
                591.7734375,
                146.1746826171875,
                603.4158935546875,
                159.56617736816406
              ]
            },
            {
              "track_id": 1303,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5775198340415955,
              "bbox": [
                568.5241088867188,
                154.190185546875,
                611.4650268554688,
                167.6471710205078
              ]
            }
          ],
          "unique_tracks": [
            1299,
            1300,
            1301,
            1302,
            1303
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            17026,
            17030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17031,
            17035
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1299,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8878164291381836,
              "bbox": [
                93.35041046142578,
                19.753498077392578,
                201.3468475341797,
                297.59259033203125
              ]
            },
            {
              "track_id": 1300,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.1699114292860031,
              "bbox": [
                302.14404296875,
                96.4261245727539,
                348.5023498535156,
                231.58021545410156
              ]
            },
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7512056827545166,
              "bbox": [
                238.14988708496094,
                157.89303588867188,
                486.770751953125,
                240.44163513183594
              ]
            },
            {
              "track_id": 1302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.517733633518219,
              "bbox": [
                590.6082153320312,
                145.66708374023438,
                602.4652709960938,
                159.36875915527344
              ]
            },
            {
              "track_id": 1303,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6331708431243896,
              "bbox": [
                566.9945678710938,
                153.6782684326172,
                612.6305541992188,
                168.0433349609375
              ]
            }
          ],
          "unique_tracks": [
            1299,
            1300,
            1301,
            1302,
            1303
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            17036,
            17040
          ],
          "representative_frame": 17036,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 141
    },
    {
      "second": 568,
      "time_range": [
        568,
        568.999
      ],
      "frame_range": [
        17041,
        17070
      ],
      "unified_description": "1-second scene with a man is standing in the water with a kay",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:02",
        "processing_time": 3.62,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17055,
          "frame_range": [
            17051,
            17055
          ],
          "description": "a man is standing in the water with a kay",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.85
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17041,
            17045
          ],
          "representative_frame": 17041,
          "detections": [
            {
              "track_id": 1299,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9150634407997131,
              "bbox": [
                107.40970611572266,
                33.36414337158203,
                203.14784240722656,
                279.4551086425781
              ]
            },
            {
              "track_id": 1300,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4736872911453247,
              "bbox": [
                306.2054748535156,
                106.33165740966797,
                354.1263427734375,
                243.27566528320312
              ]
            },
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5828900933265686,
              "bbox": [
                256.43927001953125,
                167.20004272460938,
                502.37103271484375,
                249.18565368652344
              ]
            },
            {
              "track_id": 1302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5322077870368958,
              "bbox": [
                589.615234375,
                145.69300842285156,
                601.9869995117188,
                159.92263793945312
              ]
            },
            {
              "track_id": 1303,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.3723416328430176,
              "bbox": [
                567.9544067382812,
                154.00698852539062,
                610.4915771484375,
                167.47100830078125
              ]
            }
          ],
          "unique_tracks": [
            1299,
            1300,
            1301,
            1302,
            1303
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            17046,
            17050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17051,
            17055
          ],
          "representative_frame": 17051,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.46565958857536316,
              "bbox": [
                256.86248779296875,
                172.83541870117188,
                521.95263671875,
                262.4796142578125
              ]
            },
            {
              "track_id": 1303,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6210798025131226,
              "bbox": [
                563.9681396484375,
                154.87130737304688,
                608.8148803710938,
                168.96730041503906
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1303
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            17056,
            17060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17061,
            17065
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5112049579620361,
              "bbox": [
                260.88897705078125,
                177.4027099609375,
                521.4705810546875,
                266.83270263671875
              ]
            },
            {
              "track_id": 1303,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5429349541664124,
              "bbox": [
                564.4923706054688,
                155.7094268798828,
                604.8816528320312,
                168.11248779296875
              ]
            },
            {
              "track_id": 1314,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8003222942352295,
              "bbox": [
                345.0668640136719,
                116.54011535644531,
                426.67486572265625,
                274.936279296875
              ]
            },
            {
              "track_id": 1315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7130005359649658,
              "bbox": [
                572.45947265625,
                145.0715789794922,
                583.361328125,
                159.87757873535156
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1303,
            1314,
            1315
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            17066,
            17070
          ],
          "representative_frame": 17066,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 142
    },
    {
      "second": 569,
      "time_range": [
        569,
        569.999
      ],
      "frame_range": [
        17071,
        17100
      ],
      "unified_description": "1-second scene with a man fishing in a river and a backpack on the shore nearby. The camera is stable, using a wide-angle lens to capture the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:03",
        "processing_time": 2.78,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17085,
          "frame_range": [
            17081,
            17085
          ],
          "description": "a man is fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.02
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17071,
            17075
          ],
          "representative_frame": 17071,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.4651744067668915,
              "bbox": [
                246.97537231445312,
                174.6584014892578,
                516.4974975585938,
                268.34259033203125
              ]
            },
            {
              "track_id": 1303,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5494271516799927,
              "bbox": [
                562.54345703125,
                155.1421661376953,
                604.6541748046875,
                167.8781280517578
              ]
            },
            {
              "track_id": 1314,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8533561825752258,
              "bbox": [
                345.5102233886719,
                116.50767517089844,
                426.9234924316406,
                274.4681396484375
              ]
            },
            {
              "track_id": 1315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6178881525993347,
              "bbox": [
                572.7544555664062,
                145.85467529296875,
                582.8672485351562,
                159.5706329345703
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1303,
            1314,
            1315
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            17076,
            17080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17081,
            17085
          ],
          "representative_frame": 17081,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7500660419464111,
              "bbox": [
                255.78013610839844,
                179.68487548828125,
                500.3079528808594,
                265.0871887207031
              ]
            },
            {
              "track_id": 1303,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5756814479827881,
              "bbox": [
                560.3136596679688,
                154.7554473876953,
                605.9595336914062,
                168.41152954101562
              ]
            },
            {
              "track_id": 1314,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8770235180854797,
              "bbox": [
                345.6678771972656,
                116.44083404541016,
                427.2605285644531,
                274.7176818847656
              ]
            },
            {
              "track_id": 1315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5665120482444763,
              "bbox": [
                572.0147705078125,
                145.26551818847656,
                582.6490478515625,
                159.69766235351562
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1303,
            1314,
            1315
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            17086,
            17090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17091,
            17095
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            17096,
            17100
          ],
          "representative_frame": 17096,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 142
    },
    {
      "second": 570,
      "time_range": [
        570,
        570.999
      ],
      "frame_range": [
        17101,
        17130
      ],
      "unified_description": "3rd person perspective with a camera mounted on top of a helmet. The scene shows a man paddling in a kay on the water with several other objects around him.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:05",
        "processing_time": 2.72,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17115,
          "frame_range": [
            17111,
            17115
          ],
          "description": "a man in a kay is on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.25
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17101,
            17105
          ],
          "representative_frame": 17101,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6495428085327148,
              "bbox": [
                114.9723129272461,
                2.221522808074951,
                599.264404296875,
                280.2538146972656
              ]
            }
          ],
          "unique_tracks": [
            1269
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            17106,
            17110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17111,
            17115
          ],
          "representative_frame": 17111,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8140659928321838,
              "bbox": [
                59.9686393737793,
                0.0,
                561.6475219726562,
                319.3433532714844
              ]
            }
          ],
          "unique_tracks": [
            1269
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            17116,
            17120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17121,
            17125
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.24279609322547913,
              "bbox": [
                31.651865005493164,
                6.404754638671875,
                525.341064453125,
                340.9826965332031
              ]
            }
          ],
          "unique_tracks": [
            1269
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            17126,
            17130
          ],
          "representative_frame": 17126,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 142
    },
    {
      "second": 571,
      "time_range": [
        571,
        571.999
      ],
      "frame_range": [
        17131,
        17160
      ],
      "unified_description": "40 second descriptions for each image, single paragraph including relevant details and context.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:06",
        "processing_time": 2.8,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17145,
          "frame_range": [
            17141,
            17145
          ],
          "description": "a man in a red shirt is holding a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.17
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17131,
            17135
          ],
          "representative_frame": 17131,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            17136,
            17140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17141,
            17145
          ],
          "representative_frame": 17141,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8215208053588867,
              "bbox": [
                43.65119171142578,
                0.44638681411743164,
                547.4999389648438,
                351.02325439453125
              ]
            }
          ],
          "unique_tracks": [
            1269
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            17146,
            17150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17151,
            17155
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.917048454284668,
              "bbox": [
                70.54265594482422,
                0.15430930256843567,
                562.3248901367188,
                353.6900329589844
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3997979164123535,
              "bbox": [
                440.27349853515625,
                0.0,
                627.483154296875,
                354.74652099609375
              ]
            }
          ],
          "unique_tracks": [
            1269,
            1262
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            17156,
            17160
          ],
          "representative_frame": 17156,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 142
    },
    {
      "second": 572,
      "time_range": [
        572,
        572.999
      ],
      "frame_range": [
        17161,
        17190
      ],
      "unified_description": "\n\n(Optional) Metadata: Title, creator, date/time, location, weather conditions, etc.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:07",
        "processing_time": 2.67,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17175,
          "frame_range": [
            17171,
            17175
          ],
          "description": "a young boy in a life jacket is fishing",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.62
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17161,
            17165
          ],
          "representative_frame": 17161,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9316961169242859,
              "bbox": [
                98.8482666015625,
                0.16309019923210144,
                573.2166137695312,
                354.2538757324219
              ]
            },
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5425358414649963,
              "bbox": [
                397.6844787597656,
                0.803271472454071,
                640.0,
                203.6667022705078
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.416707307100296,
              "bbox": [
                439.5364685058594,
                0.8347207903862,
                629.834228515625,
                354.0944519042969
              ]
            }
          ],
          "unique_tracks": [
            1269,
            1328,
            1262
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            17166,
            17170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17171,
            17175
          ],
          "representative_frame": 17171,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9209067821502686,
              "bbox": [
                81.04776000976562,
                0.795890212059021,
                544.42529296875,
                355.0979309082031
              ]
            },
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5107553005218506,
              "bbox": [
                371.4727478027344,
                0.2523684799671173,
                640.0,
                213.9423828125
              ]
            },
            {
              "track_id": 1262,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3315480947494507,
              "bbox": [
                425.11798095703125,
                0.3242942690849304,
                605.8468627929688,
                324.27783203125
              ]
            }
          ],
          "unique_tracks": [
            1269,
            1328,
            1262
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            17176,
            17180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17181,
            17185
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8459029197692871,
              "bbox": [
                65.10013580322266,
                0.49056264758110046,
                524.285400390625,
                355.990234375
              ]
            },
            {
              "track_id": 1262,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.12564925849437714,
              "bbox": [
                415.755126953125,
                8.837713241577148,
                590.4510498046875,
                297.78375244140625
              ]
            }
          ],
          "unique_tracks": [
            1269,
            1262
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            17186,
            17190
          ],
          "representative_frame": 17186,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 143
    },
    {
      "second": 573,
      "time_range": [
        573,
        573.999
      ],
      "frame_range": [
        17191,
        17220
      ],
      "unified_description": "\n\nIn one second, a young boy is seen riding his kayak on the water. The image captures this exciting moment with the kayak prominently visible in the foreground. There are a few other objects in the background, but they are not as distinct or clearly visible as the primary subject.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:10",
        "processing_time": 3.24,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17205,
          "frame_range": [
            17201,
            17205
          ],
          "description": "a young boy in a kayakle is seen in this image",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17191,
            17195
          ],
          "representative_frame": 17191,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.896100640296936,
              "bbox": [
                53.80924606323242,
                0.364433616399765,
                513.2013549804688,
                355.5473937988281
              ]
            },
            {
              "track_id": 1329,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.34659940004348755,
              "bbox": [
                0.0,
                4.735681056976318,
                632.0203857421875,
                348.2875061035156
              ]
            }
          ],
          "unique_tracks": [
            1269,
            1329
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            17196,
            17200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17201,
            17205
          ],
          "representative_frame": 17201,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.913948118686676,
              "bbox": [
                80.11880493164062,
                0.3065267503261566,
                538.6068115234375,
                355.5561218261719
              ]
            },
            {
              "track_id": 1329,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.14074622094631195,
              "bbox": [
                0.0,
                7.97673225402832,
                633.4055786132812,
                353.6642150878906
              ]
            }
          ],
          "unique_tracks": [
            1269,
            1329
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            17206,
            17210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17211,
            17215
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9299914836883545,
              "bbox": [
                189.34463500976562,
                81.09687042236328,
                505.2449645996094,
                323.1955871582031
              ]
            },
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8074368834495544,
              "bbox": [
                153.33963012695312,
                230.96646118164062,
                524.5140991210938,
                359.11669921875
              ]
            },
            {
              "track_id": 1303,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7157751321792603,
              "bbox": [
                535.057861328125,
                147.7670135498047,
                608.0783081054688,
                169.2163848876953
              ]
            }
          ],
          "unique_tracks": [
            1269,
            1301,
            1303
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            17216,
            17220
          ],
          "representative_frame": 17216,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 143
    },
    {
      "second": 574,
      "time_range": [
        574,
        574.999
      ],
      "frame_range": [
        17221,
        17250
      ],
      "unified_description": "\n\n1. A man in a kayak paddles on a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:11",
        "processing_time": 3.42,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17235,
          "frame_range": [
            17231,
            17235
          ],
          "description": "a man in a kayak paddles on a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.83
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17221,
            17225
          ],
          "representative_frame": 17221,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9153538942337036,
              "bbox": [
                253.73744201660156,
                105.31378173828125,
                509.7671813964844,
                299.69354248046875
              ]
            },
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8313838243484497,
              "bbox": [
                153.16256713867188,
                222.1175079345703,
                552.3549194335938,
                360.0
              ]
            }
          ],
          "unique_tracks": [
            1269,
            1301
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            17226,
            17230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17231,
            17235
          ],
          "representative_frame": 17231,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.906875491142273,
              "bbox": [
                269.6632995605469,
                115.69878387451172,
                507.0899963378906,
                295.1273193359375
              ]
            },
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7972044944763184,
              "bbox": [
                147.01014709472656,
                218.3623809814453,
                557.1768188476562,
                360.0
              ]
            }
          ],
          "unique_tracks": [
            1269,
            1301
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            17236,
            17240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17241,
            17245
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1269,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8530939817428589,
              "bbox": [
                273.58050537109375,
                122.73150634765625,
                506.09954833984375,
                297.4631652832031
              ]
            },
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7229266166687012,
              "bbox": [
                147.37393188476562,
                217.09747314453125,
                557.7294921875,
                360.0
              ]
            }
          ],
          "unique_tracks": [
            1269,
            1301
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            17246,
            17250
          ],
          "representative_frame": 17246,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 143
    },
    {
      "second": 575,
      "time_range": [
        575,
        575.999
      ],
      "frame_range": [
        17251,
        17280
      ],
      "unified_description": "2 people in boats on the water",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:11",
        "processing_time": 3.36,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17265,
          "frame_range": [
            17261,
            17265
          ],
          "description": "two people in kays paddling on a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.18
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17251,
            17255
          ],
          "representative_frame": 17251,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8481983542442322,
              "bbox": [
                123.39958190917969,
                208.9916229248047,
                551.3673095703125,
                360.0
              ]
            }
          ],
          "unique_tracks": [
            1301
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            17256,
            17260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17261,
            17265
          ],
          "representative_frame": 17261,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8433640003204346,
              "bbox": [
                113.9050064086914,
                203.8542022705078,
                551.1199340820312,
                360.0
              ]
            },
            {
              "track_id": 1340,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8321343064308167,
              "bbox": [
                31.478425979614258,
                141.57965087890625,
                85.21092224121094,
                190.98033142089844
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1340
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            17266,
            17270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17271,
            17275
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8462427258491516,
              "bbox": [
                105.83109283447266,
                198.4139404296875,
                550.7130737304688,
                360.0
              ]
            },
            {
              "track_id": 1340,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8618080019950867,
              "bbox": [
                20.51754379272461,
                141.1333770751953,
                72.37773132324219,
                188.65591430664062
              ]
            },
            {
              "track_id": 1343,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.45195263624191284,
              "bbox": [
                0.0,
                178.47024536132812,
                96.45035552978516,
                238.35055541992188
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1340,
            1343
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            17276,
            17280
          ],
          "representative_frame": 17276,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 143
    },
    {
      "second": 576,
      "time_range": [
        576,
        576.999
      ],
      "frame_range": [
        17281,
        17310
      ],
      "unified_description": "2 people are in the scene, they appear to be rowing a boat",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:14",
        "processing_time": 2.45,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17295,
          "frame_range": [
            17291,
            17295
          ],
          "description": "two people in kays paddling on a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.59
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17281,
            17285
          ],
          "representative_frame": 17281,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8543754816055298,
              "bbox": [
                91.81031799316406,
                189.14889526367188,
                550.6362915039062,
                359.9499206542969
              ]
            },
            {
              "track_id": 1340,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8480780720710754,
              "bbox": [
                5.5812907218933105,
                142.8225555419922,
                58.22779846191406,
                190.933349609375
              ]
            },
            {
              "track_id": 1343,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.4484812319278717,
              "bbox": [
                0.0,
                181.4984130859375,
                92.678466796875,
                243.5183563232422
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1340,
            1343
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            17286,
            17290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17291,
            17295
          ],
          "representative_frame": 17291,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8568838238716125,
              "bbox": [
                125.77949523925781,
                203.80621337890625,
                546.37646484375,
                360.0
              ]
            },
            {
              "track_id": 1340,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8604456782341003,
              "bbox": [
                0.0,
                146.28363037109375,
                49.17387390136719,
                195.1785888671875
              ]
            },
            {
              "track_id": 1343,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5656151175498962,
              "bbox": [
                0.0,
                186.58074951171875,
                91.42868041992188,
                254.64549255371094
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1340,
            1343
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            17296,
            17300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17301,
            17305
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8418576717376709,
              "bbox": [
                128.7836151123047,
                205.67190551757812,
                542.7113037109375,
                360.0
              ]
            },
            {
              "track_id": 1340,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6081072092056274,
              "bbox": [
                0.0,
                148.9933624267578,
                47.72388458251953,
                208.57730102539062
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1340
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            17306,
            17310
          ],
          "representative_frame": 17306,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 144
    },
    {
      "second": 577,
      "time_range": [
        577,
        577.999
      ],
      "frame_range": [
        17311,
        17340
      ],
      "unified_description": "1 second video showing a person in a kayak, with a stable camera positioning, wide-angle perspective, and natural outdoor lighting.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:17",
        "processing_time": 2.62,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17325,
          "frame_range": [
            17321,
            17325
          ],
          "description": "a person in a kayak pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 3.91
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17311,
            17315
          ],
          "representative_frame": 17311,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7333595752716064,
              "bbox": [
                108.55744934082031,
                192.83670043945312,
                547.443359375,
                359.40716552734375
              ]
            }
          ],
          "unique_tracks": [
            1301
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            17316,
            17320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17321,
            17325
          ],
          "representative_frame": 17321,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8042505979537964,
              "bbox": [
                120.30134582519531,
                193.1816864013672,
                555.3792724609375,
                360.0
              ]
            }
          ],
          "unique_tracks": [
            1301
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            17326,
            17330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17331,
            17335
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8539762496948242,
              "bbox": [
                112.90599060058594,
                197.95115661621094,
                534.5196533203125,
                360.0
              ]
            }
          ],
          "unique_tracks": [
            1301
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            17336,
            17340
          ],
          "representative_frame": 17336,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 144
    },
    {
      "second": 578,
      "time_range": [
        578,
        578.999
      ],
      "frame_range": [
        17341,
        17370
      ],
      "unified_description": "1 second video - Content Description:\nA person in a kayak, with a wide-angle view showing a small portion of the kayaker's surroundings.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:18",
        "processing_time": 3.29,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17355,
          "frame_range": [
            17351,
            17355
          ],
          "description": "a person in a kayak pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 3.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17341,
            17345
          ],
          "representative_frame": 17341,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8366038203239441,
              "bbox": [
                117.0097885131836,
                202.4011993408203,
                525.6243896484375,
                360.0
              ]
            }
          ],
          "unique_tracks": [
            1301
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            17346,
            17350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17351,
            17355
          ],
          "representative_frame": 17351,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8783404231071472,
              "bbox": [
                123.93651580810547,
                210.6221466064453,
                513.6502685546875,
                360.0
              ]
            },
            {
              "track_id": 1350,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4240337014198303,
              "bbox": [
                242.46112060546875,
                131.35047912597656,
                369.8892517089844,
                313.91754150390625
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1350
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            17356,
            17360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17361,
            17365
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8546255826950073,
              "bbox": [
                126.07955932617188,
                212.0106658935547,
                512.6359252929688,
                360.0
              ]
            },
            {
              "track_id": 1350,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.800390362739563,
              "bbox": [
                246.81365966796875,
                124.76558685302734,
                374.6588134765625,
                307.7074279785156
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1350
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            17366,
            17370
          ],
          "representative_frame": 17366,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 144
    },
    {
      "second": 579,
      "time_range": [
        579,
        579.999
      ],
      "frame_range": [
        17371,
        17400
      ],
      "unified_description": "1 second video of a person in a kayak with a paddle, stable camera positioning, and a wide-angle perspective showing surrounding environment, vegetation, water, and sky.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:20",
        "processing_time": 3.12,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17385,
          "frame_range": [
            17381,
            17385
          ],
          "description": "a person in a kayak pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.97
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17371,
            17375
          ],
          "representative_frame": 17371,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8896345496177673,
              "bbox": [
                117.82779693603516,
                198.38662719726562,
                533.2652587890625,
                359.56134033203125
              ]
            },
            {
              "track_id": 1350,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6160052418708801,
              "bbox": [
                250.64590454101562,
                114.07041931152344,
                380.91729736328125,
                300.4357604980469
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1350
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            17376,
            17380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17381,
            17385
          ],
          "representative_frame": 17381,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.861497163772583,
              "bbox": [
                128.69468688964844,
                204.7823486328125,
                527.7293701171875,
                359.4465637207031
              ]
            },
            {
              "track_id": 1350,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.549127459526062,
              "bbox": [
                254.5829620361328,
                116.5107650756836,
                385.6246032714844,
                303.6240539550781
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1350
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            17386,
            17390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17391,
            17395
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.7554647326469421,
              "bbox": [
                129.7419891357422,
                219.56752014160156,
                483.8331298828125,
                358.1174621582031
              ]
            },
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9079755544662476,
              "bbox": [
                116.81851959228516,
                67.59852600097656,
                468.3868713378906,
                355.0698547363281
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1328
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            17396,
            17400
          ],
          "representative_frame": 17396,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 144
    },
    {
      "second": 580,
      "time_range": [
        580,
        580.999
      ],
      "frame_range": [
        17401,
        17430
      ],
      "unified_description": "3rd person perspective camera, stable on a tripod, capturing outdoor scene with a man fishing in a kayak on the water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:21",
        "processing_time": 2.6,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17415,
          "frame_range": [
            17411,
            17415
          ],
          "description": "a man in a kay is fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.0
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17401,
            17405
          ],
          "representative_frame": 17401,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.7462975978851318,
              "bbox": [
                130.95668029785156,
                235.17514038085938,
                445.2641296386719,
                358.2861328125
              ]
            },
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.916982889175415,
              "bbox": [
                118.25556945800781,
                72.90982055664062,
                451.0331726074219,
                358.18914794921875
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1328
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            17406,
            17410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17411,
            17415
          ],
          "representative_frame": 17411,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.6423102617263794,
              "bbox": [
                128.06744384765625,
                233.74159240722656,
                444.5224304199219,
                358.3805847167969
              ]
            },
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9067152142524719,
              "bbox": [
                128.6527862548828,
                78.62696075439453,
                445.31890869140625,
                359.3568115234375
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1328
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            17416,
            17420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17421,
            17425
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.7821421027183533,
              "bbox": [
                122.94707489013672,
                228.32826232910156,
                449.5103454589844,
                358.266845703125
              ]
            },
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8993062376976013,
              "bbox": [
                132.56544494628906,
                78.63282012939453,
                438.8920593261719,
                359.1880798339844
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1328
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            17426,
            17430
          ],
          "representative_frame": 17426,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 145
    },
    {
      "second": 581,
      "time_range": [
        581,
        581.999
      ],
      "frame_range": [
        17431,
        17460
      ],
      "unified_description": "\nThe image depicts a person kayaking and fishing in a body of water. The camera is mounted on the kayaker's backpack, providing a first-person perspective of the scene. This video showcases the kayaker's adventure, surrounding environment, and fishing experience.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:26:23",
        "processing_time": 3.17,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17445,
          "frame_range": [
            17441,
            17445
          ],
          "description": "a man in a kay is fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.2
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17431,
            17435
          ],
          "representative_frame": 17431,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5711392760276794,
              "bbox": [
                122.0396957397461,
                229.86740112304688,
                442.23089599609375,
                358.30615234375
              ]
            },
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9218747019767761,
              "bbox": [
                129.59007263183594,
                76.49876403808594,
                429.1678161621094,
                359.15972900390625
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1328
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            17436,
            17440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17441,
            17445
          ],
          "representative_frame": 17441,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.7263472676277161,
              "bbox": [
                118.14300537109375,
                222.26065063476562,
                452.5196533203125,
                357.801513671875
              ]
            },
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9109706878662109,
              "bbox": [
                133.9535675048828,
                75.63451385498047,
                427.036376953125,
                358.8082275390625
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1328
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            17446,
            17450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17451,
            17455
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.11203606426715851,
              "bbox": [
                152.24911499023438,
                232.96380615234375,
                472.2460021972656,
                358.5417785644531
              ]
            },
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9473332762718201,
              "bbox": [
                122.23089599609375,
                69.00016784667969,
                424.53167724609375,
                358.78057861328125
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1328
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            17456,
            17460
          ],
          "representative_frame": 17456,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 145
    },
    {
      "second": 583,
      "time_range": [
        583,
        583.999
      ],
      "frame_range": [
        17491,
        17520
      ],
      "unified_description": "\nA camera captures the image of a man in a kayak, while he's fishing on a river with the water visible in the background.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:23",
        "processing_time": 61.26,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17505,
          "frame_range": [
            17501,
            17505
          ],
          "description": "a man in a kay is fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.79
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17491,
            17495
          ],
          "representative_frame": 17491,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 30,
              "class_name": "skis",
              "confidence": 0.7383139729499817,
              "bbox": [
                224.85011291503906,
                241.66378784179688,
                537.9725952148438,
                358.232666015625
              ]
            },
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9278465509414673,
              "bbox": [
                116.65035247802734,
                66.64984893798828,
                423.72100830078125,
                357.608154296875
              ]
            },
            {
              "track_id": 1358,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.4056232273578644,
              "bbox": [
                326.234619140625,
                100.91275787353516,
                369.61346435546875,
                120.9144287109375
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1328,
            1358
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            17496,
            17500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17501,
            17505
          ],
          "representative_frame": 17501,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.2462058663368225,
              "bbox": [
                236.9486846923828,
                233.3604278564453,
                564.2378540039062,
                358.4627380371094
              ]
            },
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9399369359016418,
              "bbox": [
                125.87926483154297,
                67.30882263183594,
                434.3056335449219,
                357.6305847167969
              ]
            },
            {
              "track_id": 1358,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.17780625820159912,
              "bbox": [
                330.9891052246094,
                103.55120849609375,
                374.74420166015625,
                123.72262573242188
              ]
            },
            {
              "track_id": 1368,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6417747735977173,
              "bbox": [
                339.4946594238281,
                82.24459838867188,
                366.13323974609375,
                106.58218383789062
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1328,
            1358,
            1368
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            17506,
            17510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17511,
            17515
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9428682923316956,
              "bbox": [
                127.28244018554688,
                59.020484924316406,
                444.6423645019531,
                357.4019775390625
              ]
            },
            {
              "track_id": 1358,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.49856632947921753,
              "bbox": [
                336.3839416503906,
                102.96424865722656,
                385.2939758300781,
                125.66127014160156
              ]
            },
            {
              "track_id": 1368,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6722599267959595,
              "bbox": [
                344.78607177734375,
                81.97828674316406,
                370.9751892089844,
                105.91621398925781
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1358,
            1368
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            17516,
            17520
          ],
          "representative_frame": 17516,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 145
    },
    {
      "second": 584,
      "time_range": [
        584,
        584.999
      ],
      "frame_range": [
        17521,
        17550
      ],
      "unified_description": "1-second scene featuring a man paddling on a kayak in a large body of water. The camera is mounted on a backpack, providing an interesting perspective as the kayaker navigates across the lake. There are a few other objects and people in the vicinity, indicating that this could be a recreational area or a popular spot for outdoor activities.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:25",
        "processing_time": 61.02,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17535,
          "frame_range": [
            17531,
            17535
          ],
          "description": "a man in a kayak pad pad on a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.06
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17521,
            17525
          ],
          "representative_frame": 17521,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9540630578994751,
              "bbox": [
                125.18638610839844,
                63.79729080200195,
                438.23291015625,
                357.7279968261719
              ]
            },
            {
              "track_id": 1358,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.3545921742916107,
              "bbox": [
                339.94500732421875,
                102.86689758300781,
                391.1845397949219,
                126.81262969970703
              ]
            },
            {
              "track_id": 1368,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6658207774162292,
              "bbox": [
                349.5806884765625,
                81.8302993774414,
                379.4307861328125,
                109.14466857910156
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1358,
            1368
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            17526,
            17530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17531,
            17535
          ],
          "representative_frame": 17531,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9446567893028259,
              "bbox": [
                122.03599548339844,
                68.04947662353516,
                431.7834167480469,
                357.5928955078125
              ]
            }
          ],
          "unique_tracks": [
            1328
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            17536,
            17540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17541,
            17545
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9421188235282898,
              "bbox": [
                124.80585479736328,
                67.43490600585938,
                437.18731689453125,
                357.50537109375
              ]
            },
            {
              "track_id": 1369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7395084500312805,
              "bbox": [
                373.3823547363281,
                88.09796142578125,
                410.1424865722656,
                118.89216613769531
              ]
            },
            {
              "track_id": 1358,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7407914400100708,
              "bbox": [
                358.4726257324219,
                112.13163757324219,
                413.14208984375,
                137.87124633789062
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1369,
            1358
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            17546,
            17550
          ],
          "representative_frame": 17546,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 146
    },
    {
      "second": 585,
      "time_range": [
        585,
        585.999
      ],
      "frame_range": [
        17551,
        17580
      ],
      "unified_description": "\n\n1st second camera perspective looking out over a calm lake with trees in the distance. A man is in a kayak on the water, fishing. The camera is mounted on a backpack, providing a first-person perspective. The scene is captured in wide-angle view, showing the surrounding area and the man's position in relation to the other objects.\n\nAdditionally, there are several other people scattered around the lake, likely also participating in various outdoor activities.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:27",
        "processing_time": 3.82,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17565,
          "frame_range": [
            17561,
            17565
          ],
          "description": "a man in a kayak fishing on a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.37
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17551,
            17555
          ],
          "representative_frame": 17551,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9394132494926453,
              "bbox": [
                126.03804016113281,
                59.13725280761719,
                448.2113037109375,
                357.38775634765625
              ]
            },
            {
              "track_id": 1369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7357508540153503,
              "bbox": [
                379.6376647949219,
                88.05416870117188,
                418.2658386230469,
                120.42576599121094
              ]
            },
            {
              "track_id": 1358,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6267450451850891,
              "bbox": [
                365.8757629394531,
                113.1611328125,
                425.2635498046875,
                141.57791137695312
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1369,
            1358
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            17556,
            17560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17561,
            17565
          ],
          "representative_frame": 17561,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9449160099029541,
              "bbox": [
                117.0709457397461,
                58.37942886352539,
                440.1803283691406,
                357.2613830566406
              ]
            },
            {
              "track_id": 1369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7229062914848328,
              "bbox": [
                385.22540283203125,
                89.22486114501953,
                423.70074462890625,
                121.5454330444336
              ]
            },
            {
              "track_id": 1358,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6292919516563416,
              "bbox": [
                370.74725341796875,
                114.42216491699219,
                430.90594482421875,
                143.49972534179688
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1369,
            1358
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            17566,
            17570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17571,
            17575
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9404219388961792,
              "bbox": [
                113.34429168701172,
                58.667850494384766,
                436.5318603515625,
                357.1753845214844
              ]
            },
            {
              "track_id": 1369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6738117337226868,
              "bbox": [
                386.9267578125,
                88.85934448242188,
                428.4444885253906,
                123.70793914794922
              ]
            },
            {
              "track_id": 1358,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6955434679985046,
              "bbox": [
                372.4620056152344,
                113.25518035888672,
                436.70965576171875,
                144.3455047607422
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1369,
            1358
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            17576,
            17580
          ],
          "representative_frame": 17576,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 146
    },
    {
      "second": 586,
      "time_range": [
        586,
        586.999
      ],
      "frame_range": [
        17581,
        17610
      ],
      "unified_description": "1-second scene featuring a person in a boat on the water, with three other objects nearby.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:28",
        "processing_time": 3.62,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17595,
          "frame_range": [
            17591,
            17595
          ],
          "description": "a man in a kay is fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.22
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17581,
            17585
          ],
          "representative_frame": 17581,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9294745326042175,
              "bbox": [
                111.5083236694336,
                51.90205764770508,
                440.2442932128906,
                356.4389343261719
              ]
            },
            {
              "track_id": 1369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6089043021202087,
              "bbox": [
                395.8951110839844,
                87.76795196533203,
                437.3269958496094,
                122.85309600830078
              ]
            },
            {
              "track_id": 1358,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7862699627876282,
              "bbox": [
                376.81927490234375,
                111.77091217041016,
                444.0422058105469,
                143.8944091796875
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1369,
            1358
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            17586,
            17590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17591,
            17595
          ],
          "representative_frame": 17591,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9264480471611023,
              "bbox": [
                111.95687866210938,
                55.835391998291016,
                434.9613037109375,
                356.4761657714844
              ]
            },
            {
              "track_id": 1369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.49120935797691345,
              "bbox": [
                405.0999755859375,
                87.72949981689453,
                445.22064208984375,
                121.82583618164062
              ]
            },
            {
              "track_id": 1358,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6299420595169067,
              "bbox": [
                380.9279479980469,
                110.85506439208984,
                455.0964660644531,
                146.10243225097656
              ]
            },
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.42318567633628845,
              "bbox": [
                244.8490753173828,
                230.40896606445312,
                565.216552734375,
                357.8065490722656
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1369,
            1358,
            1301
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            17596,
            17600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17601,
            17605
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9322956800460815,
              "bbox": [
                119.32015991210938,
                61.0885009765625,
                437.8859558105469,
                356.4355773925781
              ]
            },
            {
              "track_id": 1369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5725043416023254,
              "bbox": [
                416.7587585449219,
                87.34916687011719,
                460.17816162109375,
                124.22958374023438
              ]
            },
            {
              "track_id": 1358,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6978060007095337,
              "bbox": [
                389.50640869140625,
                111.41460418701172,
                465.443359375,
                147.0974884033203
              ]
            },
            {
              "track_id": 1301,
              "class_id": 30,
              "class_name": "skis",
              "confidence": 0.4711538553237915,
              "bbox": [
                266.1878967285156,
                236.69525146484375,
                562.373291015625,
                358.1758117675781
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1369,
            1358,
            1301
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            17606,
            17610
          ],
          "representative_frame": 17606,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 146
    },
    {
      "second": 587,
      "time_range": [
        587,
        587.999
      ],
      "frame_range": [
        17611,
        17640
      ],
      "unified_description": "3rd person in a canoe on the water, stable camera mounted on a backpack, wide-angle perspective, action camera style.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:29",
        "processing_time": 3.21,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17625,
          "frame_range": [
            17621,
            17625
          ],
          "description": "a person in a kay boat on a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.62
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17611,
            17615
          ],
          "representative_frame": 17611,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6417033076286316,
              "bbox": [
                161.05743408203125,
                82.70088958740234,
                423.57843017578125,
                326.73126220703125
              ]
            },
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5801162719726562,
              "bbox": [
                158.0156707763672,
                214.13467407226562,
                516.171875,
                358.5189514160156
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1301
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            17616,
            17620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17621,
            17625
          ],
          "representative_frame": 17621,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7443117499351501,
              "bbox": [
                186.34927368164062,
                92.01033782958984,
                426.7212829589844,
                316.922119140625
              ]
            },
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6326716542243958,
              "bbox": [
                121.9476318359375,
                205.2812957763672,
                507.4587097167969,
                358.2184753417969
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1301
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            17626,
            17630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17631,
            17635
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.37069636583328247,
              "bbox": [
                204.1348876953125,
                86.25838470458984,
                437.579833984375,
                306.9054870605469
              ]
            },
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7201334238052368,
              "bbox": [
                106.52228546142578,
                200.1211395263672,
                508.7838439941406,
                357.9999084472656
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1301
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            17636,
            17640
          ],
          "representative_frame": 17636,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 146
    },
    {
      "second": 588,
      "time_range": [
        588,
        588.999
      ],
      "frame_range": [
        17641,
        17670
      ],
      "unified_description": "1-second scene featuring a person in a kayak with a wide-angle lens capturing the action.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:34",
        "processing_time": 2.5,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17655,
          "frame_range": [
            17651,
            17655
          ],
          "description": "a person in a kayak pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 4.33
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17641,
            17645
          ],
          "representative_frame": 17641,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.25833091139793396,
              "bbox": [
                215.18978881835938,
                88.10789489746094,
                449.85614013671875,
                311.82073974609375
              ]
            },
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5688740611076355,
              "bbox": [
                118.59381866455078,
                202.66696166992188,
                516.7662963867188,
                358.02734375
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1301
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            17646,
            17650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17651,
            17655
          ],
          "representative_frame": 17651,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6010627150535583,
              "bbox": [
                217.2748565673828,
                92.04553985595703,
                449.46051025390625,
                314.8922119140625
              ]
            },
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7649919390678406,
              "bbox": [
                93.66405487060547,
                189.59779357910156,
                524.2740478515625,
                358.2200012207031
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1301
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            17656,
            17660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17661,
            17665
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1328,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6342390179634094,
              "bbox": [
                190.9812774658203,
                82.56693267822266,
                414.2320861816406,
                304.22100830078125
              ]
            },
            {
              "track_id": 1301,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7988235354423523,
              "bbox": [
                77.71971893310547,
                182.24598693847656,
                523.628662109375,
                356.88470458984375
              ]
            }
          ],
          "unique_tracks": [
            1328,
            1301
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            17666,
            17670
          ],
          "representative_frame": 17666,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 147
    },
    {
      "second": 589,
      "time_range": [
        589,
        589.999
      ],
      "frame_range": [
        17671,
        17700
      ],
      "unified_description": "1-second scene with a person in a kayak on a river. A wide-angle perspective shows the person paddling, along with other objects in the surroundings, giving context to the setting and activities taking place.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:36",
        "processing_time": 3.28,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17685,
          "frame_range": [
            17681,
            17685
          ],
          "description": "a person in a kayak pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 4.58
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17671,
            17675
          ],
          "representative_frame": 17671,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            17676,
            17680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17681,
            17685
          ],
          "representative_frame": 17681,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6928471922874451,
              "bbox": [
                88.03890228271484,
                181.6818389892578,
                510.2742004394531,
                356.790283203125
              ]
            }
          ],
          "unique_tracks": [
            1301
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            17686,
            17690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17691,
            17695
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5478268265724182,
              "bbox": [
                100.88311004638672,
                177.4802703857422,
                508.279296875,
                355.9841003417969
              ]
            }
          ],
          "unique_tracks": [
            1301
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            17696,
            17700
          ],
          "representative_frame": 17696,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 147
    },
    {
      "second": 590,
      "time_range": [
        590,
        590.999
      ],
      "frame_range": [
        17701,
        17730
      ],
      "unified_description": "1-second scene including a person in a kayak, POV camera perspective, wide-angle distortion, lens flare, and other technical details.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:37",
        "processing_time": 3.98,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17715,
          "frame_range": [
            17711,
            17715
          ],
          "description": "a person in a kayak pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 4.04
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17701,
            17705
          ],
          "representative_frame": 17701,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.18876521289348602,
              "bbox": [
                117.72098541259766,
                175.0131378173828,
                511.9975891113281,
                355.77294921875
              ]
            },
            {
              "track_id": 1383,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5336863398551941,
              "bbox": [
                203.79928588867188,
                174.87811279296875,
                352.80438232421875,
                356.4580993652344
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1383
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            17706,
            17710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17711,
            17715
          ],
          "representative_frame": 17711,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4495455324649811,
              "bbox": [
                135.5100860595703,
                176.8123016357422,
                509.28314208984375,
                356.16851806640625
              ]
            },
            {
              "track_id": 1383,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2690486013889313,
              "bbox": [
                212.57998657226562,
                177.64892578125,
                359.67718505859375,
                356.9346923828125
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1383
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            17716,
            17720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17721,
            17725
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7833569049835205,
              "bbox": [
                153.46908569335938,
                177.34854125976562,
                511.126953125,
                356.22705078125
              ]
            },
            {
              "track_id": 1383,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.11098703742027283,
              "bbox": [
                221.03094482421875,
                178.52093505859375,
                365.4248046875,
                354.75640869140625
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1383
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            17726,
            17730
          ],
          "representative_frame": 17726,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 147
    },
    {
      "second": 591,
      "time_range": [
        591,
        591.999
      ],
      "frame_range": [
        17731,
        17760
      ],
      "unified_description": "1-second scene where a man is kayaking in a river with a wide-angle lens",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:38",
        "processing_time": 2.47,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17745,
          "frame_range": [
            17741,
            17745
          ],
          "description": "a person in a kayak pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.71
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17731,
            17735
          ],
          "representative_frame": 17731,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.661125659942627,
              "bbox": [
                158.96401977539062,
                171.0408172607422,
                513.2689819335938,
                355.95916748046875
              ]
            },
            {
              "track_id": 1383,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.1549040526151657,
              "bbox": [
                246.22219848632812,
                170.84605407714844,
                360.82098388671875,
                309.8482666015625
              ]
            }
          ],
          "unique_tracks": [
            1301,
            1383
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            17736,
            17740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17741,
            17745
          ],
          "representative_frame": 17741,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4027925729751587,
              "bbox": [
                161.2190399169922,
                165.96902465820312,
                511.5751953125,
                356.43310546875
              ]
            }
          ],
          "unique_tracks": [
            1301
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            17746,
            17750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17751,
            17755
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2969836890697479,
              "bbox": [
                181.64402770996094,
                164.56939697265625,
                525.2471923828125,
                355.7304382324219
              ]
            }
          ],
          "unique_tracks": [
            1301
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            17756,
            17760
          ],
          "representative_frame": 17756,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 147
    },
    {
      "second": 592,
      "time_range": [
        592,
        592.999
      ],
      "frame_range": [
        17761,
        17790
      ],
      "unified_description": "1-second scene: A person in a kayak on river rapids",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:41",
        "processing_time": 2.66,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17775,
          "frame_range": [
            17771,
            17775
          ],
          "description": "a person in a kayak pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.27
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17761,
            17765
          ],
          "representative_frame": 17761,
          "detections": [
            {
              "track_id": 1392,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.4270375669002533,
              "bbox": [
                558.7786865234375,
                145.8103485107422,
                640.0,
                194.0028839111328
              ]
            }
          ],
          "unique_tracks": [
            1392
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            17766,
            17770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17771,
            17775
          ],
          "representative_frame": 17771,
          "detections": [
            {
              "track_id": 1392,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.26057830452919006,
              "bbox": [
                558.0419921875,
                146.0704803466797,
                638.143310546875,
                193.2649688720703
              ]
            },
            {
              "track_id": 1394,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.41347888112068176,
              "bbox": [
                232.40357971191406,
                171.9884490966797,
                356.2359313964844,
                301.9390869140625
              ]
            }
          ],
          "unique_tracks": [
            1392,
            1394
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            17776,
            17780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17781,
            17785
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1392,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.30428025126457214,
              "bbox": [
                557.1602783203125,
                146.3822021484375,
                637.0098876953125,
                193.3445281982422
              ]
            },
            {
              "track_id": 1394,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2269553393125534,
              "bbox": [
                228.7501983642578,
                172.5533905029297,
                351.2129211425781,
                300.8216552734375
              ]
            },
            {
              "track_id": 1301,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3789774477481842,
              "bbox": [
                187.80389404296875,
                169.95327758789062,
                515.1732177734375,
                355.3692321777344
              ]
            }
          ],
          "unique_tracks": [
            1392,
            1394,
            1301
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            17786,
            17790
          ],
          "representative_frame": 17786,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 148
    },
    {
      "second": 593,
      "time_range": [
        593,
        593.999
      ],
      "frame_range": [
        17791,
        17820
      ],
      "unified_description": "2 men riding kayaks down a river with trees lining the sides.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:40",
        "processing_time": 2.37,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17805,
          "frame_range": [
            17801,
            17805
          ],
          "description": "two people in kays on a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.14
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17791,
            17795
          ],
          "representative_frame": 17791,
          "detections": [
            {
              "track_id": 1392,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.13570564985275269,
              "bbox": [
                555.8577880859375,
                145.2770233154297,
                637.525390625,
                193.24636840820312
              ]
            },
            {
              "track_id": 1394,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3171939551830292,
              "bbox": [
                226.24627685546875,
                170.60952758789062,
                351.12969970703125,
                301.176025390625
              ]
            },
            {
              "track_id": 1301,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.22363872826099396,
              "bbox": [
                191.0023956298828,
                169.70339965820312,
                512.1764526367188,
                354.94781494140625
              ]
            }
          ],
          "unique_tracks": [
            1392,
            1394,
            1301
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            17796,
            17800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17801,
            17805
          ],
          "representative_frame": 17801,
          "detections": [
            {
              "track_id": 1392,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.2662171423435211,
              "bbox": [
                555.151123046875,
                144.4056396484375,
                638.0914916992188,
                193.06585693359375
              ]
            },
            {
              "track_id": 1394,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.24539826810359955,
              "bbox": [
                238.5894317626953,
                168.62503051757812,
                364.5479431152344,
                300.2597961425781
              ]
            },
            {
              "track_id": 1301,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.43079909682273865,
              "bbox": [
                195.1331024169922,
                168.8715362548828,
                510.9800720214844,
                355.2386779785156
              ]
            },
            {
              "track_id": 1396,
              "class_id": 13,
              "class_name": "bench",
              "confidence": 0.33881765604019165,
              "bbox": [
                251.72509765625,
                112.470458984375,
                346.61114501953125,
                136.87130737304688
              ]
            }
          ],
          "unique_tracks": [
            1392,
            1394,
            1301,
            1396
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            17806,
            17810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17811,
            17815
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            17816,
            17820
          ],
          "representative_frame": 17816,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 148
    },
    {
      "second": 594,
      "time_range": [
        594,
        594.999
      ],
      "frame_range": [
        17821,
        17850
      ],
      "unified_description": "\nA man is wearing a blue shirt while paddling a canoe down a wide river. The camera is positioned on his body to capture the scene from his perspective.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:42",
        "processing_time": 3.01,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17835,
          "frame_range": [
            17831,
            17835
          ],
          "description": "a man in a canoe on a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.6
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17821,
            17825
          ],
          "representative_frame": 17821,
          "detections": [
            {
              "track_id": 1399,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.751064121723175,
              "bbox": [
                415.713134765625,
                266.3627624511719,
                564.2982177734375,
                337.9002380371094
              ]
            }
          ],
          "unique_tracks": [
            1399
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            17826,
            17830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17831,
            17835
          ],
          "representative_frame": 17831,
          "detections": [
            {
              "track_id": 1399,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5684515833854675,
              "bbox": [
                402.6664123535156,
                260.4838562011719,
                542.4342651367188,
                326.7099914550781
              ]
            }
          ],
          "unique_tracks": [
            1399
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            17836,
            17840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17841,
            17845
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1399,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6044889688491821,
              "bbox": [
                400.8862609863281,
                250.5306854248047,
                554.6865234375,
                322.1546936035156
              ]
            },
            {
              "track_id": 1402,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.4664297103881836,
              "bbox": [
                365.21337890625,
                211.81411743164062,
                590.4207763671875,
                322.52960205078125
              ]
            },
            {
              "track_id": 1403,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7043095231056213,
              "bbox": [
                487.7138977050781,
                225.02777099609375,
                546.420166015625,
                289.8897399902344
              ]
            }
          ],
          "unique_tracks": [
            1399,
            1402,
            1403
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            17846,
            17850
          ],
          "representative_frame": 17846,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 148
    },
    {
      "second": 595,
      "time_range": [
        595,
        595.999
      ],
      "frame_range": [
        17851,
        17880
      ],
      "unified_description": "1-second scene that includes a man in a canoe on a river with three other people. The camera is stable and uses a wide-angle lens to capture the scene, which may include distortion or artifacts due to its perspective.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:44",
        "processing_time": 2.93,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17865,
          "frame_range": [
            17861,
            17865
          ],
          "description": "a man in a canoe on a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.15
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17851,
            17855
          ],
          "representative_frame": 17851,
          "detections": [
            {
              "track_id": 1402,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.770314633846283,
              "bbox": [
                408.81951904296875,
                243.92295837402344,
                573.065673828125,
                323.5404968261719
              ]
            },
            {
              "track_id": 1403,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7480971813201904,
              "bbox": [
                500.11395263671875,
                225.45716857910156,
                559.565673828125,
                290.9719543457031
              ]
            }
          ],
          "unique_tracks": [
            1402,
            1403
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            17856,
            17860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17861,
            17865
          ],
          "representative_frame": 17861,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            17866,
            17870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17871,
            17875
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1405,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.37659960985183716,
              "bbox": [
                50.60869598388672,
                94.60081481933594,
                563.4998779296875,
                354.9622802734375
              ]
            }
          ],
          "unique_tracks": [
            1405
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            17876,
            17880
          ],
          "representative_frame": 17876,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 148
    },
    {
      "second": 596,
      "time_range": [
        596,
        596.999
      ],
      "frame_range": [
        17881,
        17910
      ],
      "unified_description": "1-second scene where a man is in a green raft on the water. The camera perspective is first person, mounted on a backpack. There are six distinct objects or groups detected in the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:46",
        "processing_time": 3.51,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17895,
          "frame_range": [
            17891,
            17895
          ],
          "description": "a man is in a green raft on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.21
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17881,
            17885
          ],
          "representative_frame": 17881,
          "detections": [
            {
              "track_id": 1405,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.36995929479599,
              "bbox": [
                99.48551177978516,
                112.16838836669922,
                578.8245239257812,
                354.343994140625
              ]
            }
          ],
          "unique_tracks": [
            1405
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            17886,
            17890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17891,
            17895
          ],
          "representative_frame": 17891,
          "detections": [
            {
              "track_id": 1405,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6410043835639954,
              "bbox": [
                139.51722717285156,
                131.2417449951172,
                585.6868286132812,
                355.0909423828125
              ]
            }
          ],
          "unique_tracks": [
            1405
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            17896,
            17900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17901,
            17905
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1405,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9193112850189209,
              "bbox": [
                91.24542999267578,
                33.05775451660156,
                640.0,
                355.9595947265625
              ]
            }
          ],
          "unique_tracks": [
            1405
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            17906,
            17910
          ],
          "representative_frame": 17906,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 149
    },
    {
      "second": 597,
      "time_range": [
        597,
        597.999
      ],
      "frame_range": [
        17911,
        17940
      ],
      "unified_description": "\n\n(1-second scene) (video) (style: action camera)",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:46",
        "processing_time": 3.17,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17925,
          "frame_range": [
            17921,
            17925
          ],
          "description": "a man in a black jacket is holding a blue bag",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.73
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17911,
            17915
          ],
          "representative_frame": 17911,
          "detections": [
            {
              "track_id": 1405,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7145370244979858,
              "bbox": [
                96.00885009765625,
                3.212580919265747,
                640.0,
                355.40533447265625
              ]
            }
          ],
          "unique_tracks": [
            1405
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            17916,
            17920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17921,
            17925
          ],
          "representative_frame": 17921,
          "detections": [
            {
              "track_id": 1405,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8930831551551819,
              "bbox": [
                98.43372344970703,
                0.0,
                640.0,
                355.57733154296875
              ]
            }
          ],
          "unique_tracks": [
            1405
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            17926,
            17930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17931,
            17935
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1405,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9181279540061951,
              "bbox": [
                120.94586944580078,
                0.0,
                640.0,
                355.1692810058594
              ]
            }
          ],
          "unique_tracks": [
            1405
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            17936,
            17940
          ],
          "representative_frame": 17936,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 149
    },
    {
      "second": 598,
      "time_range": [
        598,
        598.999
      ],
      "frame_range": [
        17941,
        17970
      ],
      "unified_description": "3D Camera with image stabilization software applied to the footage",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:48",
        "processing_time": 2.57,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 17955,
          "frame_range": [
            17951,
            17955
          ],
          "description": "a man in a black jacket and hat is standing on a trail",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.29
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17941,
            17945
          ],
          "representative_frame": 17941,
          "detections": [
            {
              "track_id": 1405,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8250409364700317,
              "bbox": [
                150.3507537841797,
                0.0,
                640.0,
                355.1581726074219
              ]
            }
          ],
          "unique_tracks": [
            1405
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            17946,
            17950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17951,
            17955
          ],
          "representative_frame": 17951,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9240099787712097,
              "bbox": [
                179.38137817382812,
                16.061176300048828,
                640.0,
                355.4201354980469
              ]
            }
          ],
          "unique_tracks": [
            1301
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            17956,
            17960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17961,
            17965
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9193764925003052,
              "bbox": [
                216.8610382080078,
                6.662797927856445,
                640.0,
                355.68402099609375
              ]
            }
          ],
          "unique_tracks": [
            1301
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            17966,
            17970
          ],
          "representative_frame": 17966,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 149
    },
    {
      "second": 599,
      "time_range": [
        599,
        599.999
      ],
      "frame_range": [
        17971,
        18000
      ],
      "unified_description": "3D Wide Angle lens; 20 fps; POV perspective; 1 second scene",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-09T19:27:48",
        "processing_time": 2.47,
        "note": "LLaVA processed with text only"
      },
      "blip_descriptions": [],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            17971,
            17975
          ],
          "representative_frame": 17971,
          "detections": [
            {
              "track_id": 1301,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8934766054153442,
              "bbox": [
                247.66119384765625,
                5.229114055633545,
                640.0,
                355.7414245605469
              ]
            }
          ],
          "unique_tracks": [
            1301
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            17976,
            17980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            17981,
            17985
          ],
          "representative_frame": 17981,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            17986,
            17990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            17991,
            17995
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            17996,
            18000
          ],
          "representative_frame": 17996,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 149
    }
  ],
  "transcriptions": [
    {
      "id": 0,
      "time_range": [
        0,
        5
      ],
      "transcription": "Luke here with the Outdoor Boys YouTube channel and welcome to Alaska. Me and my boys are gonna",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 11.33
      }
    },
    {
      "id": 1,
      "time_range": [
        4,
        9
      ],
      "transcription": "Me and my boys are going to be dropped off by a float plane and camp here for the next three days. We're going to be",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 4.57
      }
    },
    {
      "id": 2,
      "time_range": [
        8,
        13
      ],
      "transcription": "We're gonna be fishing for Dolly Vardin, Lake Trout, an Arctic Grailing, hiking.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.45
      }
    },
    {
      "id": 3,
      "time_range": [
        12,
        17
      ],
      "transcription": "Hiking, pack rafting, and exploring the homestead of Dick Prennicky, the original bush",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.44
      }
    },
    {
      "id": 4,
      "time_range": [
        16,
        21
      ],
      "transcription": "the original bush crafting youtuber.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.24
      }
    },
    {
      "id": 5,
      "time_range": [
        20,
        25
      ],
      "transcription": "There's your plane.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.22
      }
    },
    {
      "id": 6,
      "time_range": [
        24,
        29
      ],
      "transcription": "and with the \uc624\ub298\uc740 luckily us",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.22
      }
    },
    {
      "id": 7,
      "time_range": [
        28,
        33
      ],
      "transcription": "Big thanks. Everybody. Nice to see you.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.21
      }
    },
    {
      "id": 8,
      "time_range": [
        32,
        37
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.2
      }
    },
    {
      "id": 9,
      "time_range": [
        36,
        41
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.21
      }
    },
    {
      "id": 10,
      "time_range": [
        40,
        45
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.21
      }
    },
    {
      "id": 11,
      "time_range": [
        44,
        49
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.21
      }
    },
    {
      "id": 12,
      "time_range": [
        48,
        53
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.22
      }
    },
    {
      "id": 13,
      "time_range": [
        52,
        57
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.23
      }
    },
    {
      "id": 14,
      "time_range": [
        56,
        61
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 55.88
      }
    },
    {
      "id": 15,
      "time_range": [
        60,
        65
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.23
      }
    },
    {
      "id": 16,
      "time_range": [
        64,
        69
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.31
      }
    },
    {
      "id": 17,
      "time_range": [
        68,
        73
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.31
      }
    },
    {
      "id": 18,
      "time_range": [
        72,
        77
      ],
      "transcription": "Well guys that's it we're all by our side.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.34
      }
    },
    {
      "id": 19,
      "time_range": [
        76,
        81
      ],
      "transcription": "We're all by ourselves. He's not going to come and get us for three days. Welcome to Twins.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.52
      }
    },
    {
      "id": 20,
      "time_range": [
        80,
        85
      ],
      "transcription": "Welcome to Twin Lakes We had to fly about an hour",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.35
      }
    },
    {
      "id": 21,
      "time_range": [
        84,
        89
      ],
      "transcription": "to fly about an hour and a half in a float plane to get here and this is very much room",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.44
      }
    },
    {
      "id": 22,
      "time_range": [
        88,
        93
      ],
      "transcription": "very much remote Alaskan wilderness. Okay, whether forecast is is gonna be raining on.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.45
      }
    },
    {
      "id": 23,
      "time_range": [
        92,
        97
      ],
      "transcription": "going to be raining on and off so I don't want to find a place to build my shelter.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.46
      }
    },
    {
      "id": 24,
      "time_range": [
        96,
        101
      ],
      "transcription": "All right, you guys like this spot huh?",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.33
      }
    },
    {
      "id": 25,
      "time_range": [
        100,
        105
      ],
      "transcription": "this spot huh let's drop it you guys think you can go grab the other stuff",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.46
      }
    },
    {
      "id": 26,
      "time_range": [
        104,
        109
      ],
      "transcription": "stuff.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.25
      }
    },
    {
      "id": 27,
      "time_range": [
        108,
        113
      ],
      "transcription": "Yes!",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.66
      }
    },
    {
      "id": 28,
      "time_range": [
        112,
        117
      ],
      "transcription": "we walked on. again!",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.28
      }
    },
    {
      "id": 29,
      "time_range": [
        116,
        121
      ],
      "transcription": "Good luck. car engines",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.68
      }
    },
    {
      "id": 30,
      "time_range": [
        120,
        125
      ],
      "transcription": "Tommy, you're going fishing? Grab your bear spray.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.38
      }
    },
    {
      "id": 31,
      "time_range": [
        124,
        129
      ],
      "transcription": "of your bear spray.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.47
      }
    },
    {
      "id": 32,
      "time_range": [
        128,
        133
      ],
      "transcription": "It's nothing toob.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.31
      }
    },
    {
      "id": 33,
      "time_range": [
        132,
        137
      ],
      "transcription": "Come on Yes",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.95
      }
    },
    {
      "id": 34,
      "time_range": [
        136,
        141
      ],
      "transcription": "Get in there. Yes! Hurry, get in the wall! Yes! Yes!",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.51
      }
    },
    {
      "id": 35,
      "time_range": [
        140,
        145
      ],
      "transcription": "Yeah! Oh yeah? Oh, I need to...",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.63
      }
    },
    {
      "id": 36,
      "time_range": [
        144,
        149
      ],
      "transcription": "Let's have line out, let's have line out. That is a chart, that's a dollar.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.64
      }
    },
    {
      "id": 37,
      "time_range": [
        148,
        153
      ],
      "transcription": "That's a Dolly Barton. You ready to eat it for dinner? Yep. Okay. Also I can bonk them.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.61
      }
    },
    {
      "id": 38,
      "time_range": [
        152,
        157
      ],
      "transcription": "Also I can bump behind it. I have a fish blancher now. So that right there, that's a deli varten.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.61
      }
    },
    {
      "id": 39,
      "time_range": [
        156,
        161
      ],
      "transcription": "to Dolly Barton. See how he's got the pink spot? Oh yeah. He's a member of the char family. Okay.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.62
      }
    },
    {
      "id": 40,
      "time_range": [
        160,
        165
      ],
      "transcription": "Okay, there you go. Go, go.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.39
      }
    },
    {
      "id": 41,
      "time_range": [
        164,
        169
      ],
      "transcription": "There you go, there's your dinner buddy. Yeah!",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.4
      }
    },
    {
      "id": 42,
      "time_range": [
        168,
        173
      ],
      "transcription": "Oh, there's a dolly isn't it? Yeah, there's a dolly of art. Nice.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.56
      }
    },
    {
      "id": 43,
      "time_range": [
        172,
        177
      ],
      "transcription": "get away dumb",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.91
      }
    },
    {
      "id": 44,
      "time_range": [
        176,
        181
      ],
      "transcription": "Tom, let me see what you got. You got a dolly.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.45
      }
    },
    {
      "id": 45,
      "time_range": [
        180,
        185
      ],
      "transcription": "Oh, it's another lovely dolly Sharon let this one go. This is weird",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.47
      }
    },
    {
      "id": 46,
      "time_range": [
        184,
        189
      ],
      "transcription": "This one goes, it's we already got a fish.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.43
      }
    },
    {
      "id": 47,
      "time_range": [
        188,
        193
      ],
      "transcription": "it never bind",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.17
      }
    },
    {
      "id": 48,
      "time_range": [
        192,
        197
      ],
      "transcription": "Hey, nice. Alright, we'll get another one.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.42
      }
    },
    {
      "id": 49,
      "time_range": [
        196,
        201
      ],
      "transcription": "Hey Tommy I want to make a",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.36
      }
    },
    {
      "id": 50,
      "time_range": [
        200,
        205
      ],
      "transcription": "Hey Tommy, I'm gonna make lunch, you wanna stay in fish? Yup.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.59
      }
    },
    {
      "id": 51,
      "time_range": [
        204,
        209
      ],
      "transcription": "Tough and dirty.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.15
      }
    },
    {
      "id": 52,
      "time_range": [
        208,
        213
      ],
      "transcription": "Alright, what are with this guy's been eating his stomachs full? Little...",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.55
      }
    },
    {
      "id": 53,
      "time_range": [
        212,
        217
      ],
      "transcription": "little mosquitoes and flies just thousands and thousands of bugs",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.39
      }
    },
    {
      "id": 54,
      "time_range": [
        216,
        221
      ],
      "transcription": "There we go.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.33
      }
    },
    {
      "id": 55,
      "time_range": [
        220,
        225
      ],
      "transcription": "Hmmm... Bye for God- M Fly",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.88
      }
    },
    {
      "id": 56,
      "time_range": [
        224,
        229
      ],
      "transcription": "Hi, forgot.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.33
      }
    },
    {
      "id": 57,
      "time_range": [
        228,
        233
      ],
      "transcription": "I think you're full. That's what chocolate makes. You're a bit like...",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.54
      }
    },
    {
      "id": 58,
      "time_range": [
        232,
        237
      ],
      "transcription": "You're just like That's hot. I just hold it no",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.46
      }
    },
    {
      "id": 59,
      "time_range": [
        236,
        241
      ],
      "transcription": "Just hold it and the warm up your hands first.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.42
      }
    },
    {
      "id": 60,
      "time_range": [
        240,
        245
      ],
      "transcription": "Oh my god. My... My god. Put all your shells in here so we don't attract bears and stuff.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 23.97
      }
    },
    {
      "id": 61,
      "time_range": [
        244,
        249
      ],
      "transcription": "and stuck. Yeah.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.84
      }
    },
    {
      "id": 62,
      "time_range": [
        248,
        253
      ],
      "transcription": "I'm sure you guys are pretty hungry, right? Oh yeah, please.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.52
      }
    },
    {
      "id": 63,
      "time_range": [
        252,
        257
      ],
      "transcription": "please yeah and then at the other bite",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.43
      }
    },
    {
      "id": 64,
      "time_range": [
        256,
        261
      ],
      "transcription": "Don't do it, yeah.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.62
      }
    },
    {
      "id": 65,
      "time_range": [
        260,
        265
      ],
      "transcription": "Okay Pull out So straight over there",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.21
      }
    },
    {
      "id": 66,
      "time_range": [
        264,
        269
      ],
      "transcription": "Put that fish in there.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.4
      }
    },
    {
      "id": 67,
      "time_range": [
        268,
        273
      ],
      "transcription": "fish in the oiling broth.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.4
      }
    },
    {
      "id": 68,
      "time_range": [
        272,
        277
      ],
      "transcription": "Nakpalm",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.17
      }
    },
    {
      "id": 69,
      "time_range": [
        276,
        281
      ],
      "transcription": "Are you ready for some some ramen flavored dolly here?",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.45
      }
    },
    {
      "id": 70,
      "time_range": [
        280,
        285
      ],
      "transcription": "Yeah, that's good. Wing. Dolly tastes a lot like a trowel or something.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.61
      }
    },
    {
      "id": 71,
      "time_range": [
        284,
        289
      ],
      "transcription": "I got a trout or salmon. Yeah. Do you want a little salt on them?",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.59
      }
    },
    {
      "id": 72,
      "time_range": [
        288,
        293
      ],
      "transcription": "Salt there? Oh yeah, little salt and pepper",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.48
      }
    },
    {
      "id": 73,
      "time_range": [
        292,
        297
      ],
      "transcription": "A little salt and pepper is good. Oh. Alright.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.52
      }
    },
    {
      "id": 74,
      "time_range": [
        296,
        301
      ],
      "transcription": "Alright, I'll do some dishes. Ooh!",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.45
      }
    },
    {
      "id": 75,
      "time_range": [
        300,
        305
      ],
      "transcription": "Oh, look at that. That's nice.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.43
      }
    },
    {
      "id": 76,
      "time_range": [
        304,
        309
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.48
      }
    },
    {
      "id": 77,
      "time_range": [
        308,
        313
      ],
      "transcription": "Oh, you got one!",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.39
      }
    },
    {
      "id": 78,
      "time_range": [
        312,
        317
      ],
      "transcription": "What the hell you got one? Good job, Tom! What Tom's doing pretty well, he just landed another dolly...",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.66
      }
    },
    {
      "id": 79,
      "time_range": [
        316,
        321
      ],
      "transcription": "landed another dolly down at the stream.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.45
      }
    },
    {
      "id": 80,
      "time_range": [
        320,
        325
      ],
      "transcription": "Sun's come out and it's beautiful but we've got more rain.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.51
      }
    },
    {
      "id": 81,
      "time_range": [
        324,
        329
      ],
      "transcription": "got more rain coming in about 30 minutes maybe an hour. It's how it is.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.57
      }
    },
    {
      "id": 82,
      "time_range": [
        328,
        333
      ],
      "transcription": "It's how it is if you don't like the weather in Alaska, wait five minutes.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.54
      }
    },
    {
      "id": 83,
      "time_range": [
        332,
        337
      ],
      "transcription": "I am blind. It's really blind.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.46
      }
    },
    {
      "id": 84,
      "time_range": [
        336,
        341
      ],
      "transcription": "Sorry, Narena, get in it. I have no flaws, look angry. Yeah.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.6
      }
    },
    {
      "id": 85,
      "time_range": [
        340,
        345
      ],
      "transcription": "Yeah, it looks like it might rain a little bit.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.51
      }
    },
    {
      "id": 86,
      "time_range": [
        344,
        349
      ],
      "transcription": "Rain's picking up. I think I'm gonna retreat.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.49
      }
    },
    {
      "id": 87,
      "time_range": [
        348,
        353
      ],
      "transcription": "retreat Shanze",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.05
      }
    },
    {
      "id": 88,
      "time_range": [
        352,
        357
      ],
      "transcription": "You're gonna get ready for better, you're gonna wait a little bit. Wait a little bit. You guys wanna have a little...",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.71
      }
    },
    {
      "id": 89,
      "time_range": [
        356,
        361
      ],
      "transcription": "You guys wanna have a little dessert while we wait? Oh yeah, what is it? We got some brownies.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.66
      }
    },
    {
      "id": 90,
      "time_range": [
        360,
        365
      ],
      "transcription": "some brownies. Yes! We're allowed one a day.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.55
      }
    },
    {
      "id": 91,
      "time_range": [
        364,
        369
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.48
      }
    },
    {
      "id": 92,
      "time_range": [
        368,
        373
      ],
      "transcription": "The salmon come up these rivers and into lakes to spawn.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.53
      }
    },
    {
      "id": 93,
      "time_range": [
        372,
        377
      ],
      "transcription": "to spawn and the trout loved to feast on the salmon eggs. So salmon eggs make X.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.61
      }
    },
    {
      "id": 94,
      "time_range": [
        376,
        381
      ],
      "transcription": "Every minute g seem, excellent baby.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.99
      }
    },
    {
      "id": 95,
      "time_range": [
        380,
        385
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.38
      }
    },
    {
      "id": 96,
      "time_range": [
        384,
        389
      ],
      "transcription": "More takes into my eyes\u2026.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.96
      }
    },
    {
      "id": 97,
      "time_range": [
        388,
        393
      ],
      "transcription": "sniper lah Fighting Adam hein he is 8 6 6 6 8 9 9 9 9 9 9 9 6 7 9 9 2",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.81
      }
    },
    {
      "id": 98,
      "time_range": [
        392,
        397
      ],
      "transcription": "He is 18 inches. Now we'll check out his girth. 9 and...",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.59
      }
    },
    {
      "id": 99,
      "time_range": [
        396,
        401
      ],
      "transcription": "9.5 inches round. Here's fat here. And anything.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.62
      }
    },
    {
      "id": 100,
      "time_range": [
        400,
        405
      ],
      "transcription": "You pulled the fin. See? Look at that.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.56
      }
    },
    {
      "id": 101,
      "time_range": [
        404,
        409
      ],
      "transcription": "Look at that that is a beautiful Arctic Grailing. Really a lot of ghosts.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.69
      }
    },
    {
      "id": 102,
      "time_range": [
        408,
        413
      ],
      "transcription": "We're a lot of go this what is",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.5
      }
    },
    {
      "id": 103,
      "time_range": [
        412,
        417
      ],
      "transcription": "That was pretty cool.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.45
      }
    },
    {
      "id": 104,
      "time_range": [
        416,
        421
      ],
      "transcription": "Cool. Yeah, look at that.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.55
      }
    },
    {
      "id": 105,
      "time_range": [
        420,
        425
      ],
      "transcription": "Yeah, look at that nice it we hold this for",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.54
      }
    },
    {
      "id": 106,
      "time_range": [
        424,
        429
      ],
      "transcription": "There you go. There you go. Last number three, tall.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.63
      }
    },
    {
      "id": 107,
      "time_range": [
        428,
        433
      ],
      "transcription": "Last number three, Tom. Number three for me. There you go.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.63
      }
    },
    {
      "id": 108,
      "time_range": [
        432,
        437
      ],
      "transcription": "Hey guys",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.41
      }
    },
    {
      "id": 109,
      "time_range": [
        436,
        441
      ],
      "transcription": "Let's see, it's like that. Oh, my God. Oh, my God.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.83
      }
    },
    {
      "id": 110,
      "time_range": [
        440,
        445
      ],
      "transcription": "ODG Is all",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.22
      }
    },
    {
      "id": 111,
      "time_range": [
        444,
        449
      ],
      "transcription": "It's a little cramped but got three bags set up and I got an emergency bivvy",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.67
      }
    },
    {
      "id": 112,
      "time_range": [
        448,
        453
      ],
      "transcription": "Emergency bivvy around each bag so if a little wind or rain gets under the tarp it won't be a big deal",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.73
      }
    },
    {
      "id": 113,
      "time_range": [
        452,
        457
      ],
      "transcription": "it won't be a big deal.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.5
      }
    },
    {
      "id": 114,
      "time_range": [
        456,
        461
      ],
      "transcription": "Alright guys, it's late. We're going to bed. We're gonna see you guys in the morning.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.7
      }
    },
    {
      "id": 115,
      "time_range": [
        460,
        465
      ],
      "transcription": "in the morning.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.86
      }
    },
    {
      "id": 116,
      "time_range": [
        464,
        469
      ],
      "transcription": "How dashing don't me any?",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.3
      }
    },
    {
      "id": 117,
      "time_range": [
        468,
        473
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.5
      }
    },
    {
      "id": 118,
      "time_range": [
        472,
        477
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.55
      }
    },
    {
      "id": 119,
      "time_range": [
        476,
        481
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.67
      }
    },
    {
      "id": 120,
      "time_range": [
        480,
        485
      ],
      "transcription": "The",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.03
      }
    },
    {
      "id": 121,
      "time_range": [
        484,
        489
      ],
      "transcription": "Here's your hot chocolate. We're gonna hard boil three eggs, and then we're gonna steam three.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.79
      }
    },
    {
      "id": 122,
      "time_range": [
        488,
        493
      ],
      "transcription": "we're gonna steam three eggs. Hey.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.57
      }
    },
    {
      "id": 123,
      "time_range": [
        492,
        497
      ],
      "transcription": "Okay, let's get down here.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.53
      }
    },
    {
      "id": 124,
      "time_range": [
        496,
        501
      ],
      "transcription": "Hey",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.8
      }
    },
    {
      "id": 125,
      "time_range": [
        500,
        505
      ],
      "transcription": "little egg sandwich with a hard boiled egg",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.53
      }
    },
    {
      "id": 126,
      "time_range": [
        504,
        509
      ],
      "transcription": "Oh my goodness. You eat like an anaconda.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.63
      }
    },
    {
      "id": 127,
      "time_range": [
        508,
        513
      ],
      "transcription": "an anaconda.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.53
      }
    },
    {
      "id": 128,
      "time_range": [
        512,
        517
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.59
      }
    },
    {
      "id": 129,
      "time_range": [
        516,
        521
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.48
      }
    },
    {
      "id": 130,
      "time_range": [
        520,
        525
      ],
      "transcription": "Now it looks like a laker.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.59
      }
    },
    {
      "id": 131,
      "time_range": [
        524,
        529
      ],
      "transcription": "Yeah, look at that. Kind of a small average size lake.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.67
      }
    },
    {
      "id": 132,
      "time_range": [
        528,
        533
      ],
      "transcription": "average size lake trout right there they get up to like 30 40 pounds",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.62
      }
    },
    {
      "id": 133,
      "time_range": [
        532,
        537
      ],
      "transcription": "Well, we want to do a little like spl-",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.59
      }
    },
    {
      "id": 134,
      "time_range": [
        536,
        541
      ],
      "transcription": "want to do a little exploring so we're gonna bust the raft out.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.64
      }
    },
    {
      "id": 135,
      "time_range": [
        540,
        545
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.48
      }
    },
    {
      "id": 136,
      "time_range": [
        544,
        549
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.66
      }
    },
    {
      "id": 137,
      "time_range": [
        548,
        553
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.62
      }
    },
    {
      "id": 138,
      "time_range": [
        552,
        557
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.57
      }
    },
    {
      "id": 139,
      "time_range": [
        556,
        561
      ],
      "transcription": "Mind singing",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.57
      }
    },
    {
      "id": 140,
      "time_range": [
        560,
        565
      ],
      "transcription": "You just sit down into the sea. Okay, then put your head.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.68
      }
    },
    {
      "id": 141,
      "time_range": [
        564,
        569
      ],
      "transcription": "And then put real face lines you'll get that.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.13
      }
    },
    {
      "id": 142,
      "time_range": [
        568,
        573
      ],
      "transcription": "Oh",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.88
      }
    },
    {
      "id": 143,
      "time_range": [
        572,
        577
      ],
      "transcription": "Thanks!",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.56
      }
    },
    {
      "id": 144,
      "time_range": [
        576,
        581
      ],
      "transcription": "How you doing Nathan? You okay?",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.68
      }
    },
    {
      "id": 145,
      "time_range": [
        580,
        585
      ],
      "transcription": "You guys want to go see a cool cabin?",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.72
      }
    },
    {
      "id": 146,
      "time_range": [
        584,
        589
      ],
      "transcription": "Where you gonna see Dick Priniky's cabin?",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.69
      }
    },
    {
      "id": 147,
      "time_range": [
        588,
        593
      ],
      "transcription": "maybe we'll move on now?",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.42
      }
    },
    {
      "id": 148,
      "time_range": [
        592,
        597
      ],
      "transcription": "Sorry, how about a need?",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.6
      }
    },
    {
      "id": 149,
      "time_range": [
        596,
        600.0
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.65
      }
    },
    {
      "id": 150,
      "time_range": [
        600,
        600.0
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.39,
        "error": "Video has no audio track or audio extraction failed"
      }
    }
  ]
}