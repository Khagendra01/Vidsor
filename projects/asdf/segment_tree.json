{
  "video": "C:\\Users\\Khage\\Desktop\\Vidagent\\projects\\asdf\\video\\camp_5min.mp4",
  "fps": 30,
  "tracker": "bytetrack",
  "seconds": [
    {
      "second": 0,
      "time_range": [
        0,
        0.999
      ],
      "frame_range": [
        1,
        30
      ],
      "unified_description": "360-degree first-person POV shot showing a man in sunglasses pointing at something off camera. He is standing on a hillside with mountains behind him. The image appears to be slightly shaky, indicating that it was likely taken with a GoPro or similar action camera.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:34",
        "processing_time": 4.73,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 15,
          "frame_range": [
            11,
            15
          ],
          "description": "a man in a green shirt and sunglasses is standing on a mountain",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 4.14
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1,
            5
          ],
          "representative_frame": 1,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9507590532302856,
              "bbox": [
                204.27996826171875,
                28.640380859375,
                467.83856201171875,
                356.35443115234375
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6,
            10
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            11,
            15
          ],
          "representative_frame": 11,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9539904594421387,
              "bbox": [
                200.9285888671875,
                28.712146759033203,
                464.7741394042969,
                356.6958312988281
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            16,
            20
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            21,
            25
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9593721628189087,
              "bbox": [
                194.09121704101562,
                30.067119598388672,
                457.08636474609375,
                356.7889099121094
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            26,
            30
          ],
          "representative_frame": 26,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 0
    },
    {
      "second": 1,
      "time_range": [
        1,
        1.999
      ],
      "frame_range": [
        31,
        60
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:35",
        "processing_time": 5.45,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 45,
          "frame_range": [
            41,
            45
          ],
          "description": "a man in a green shirt and hat is pointing at the camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 4.23
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            31,
            35
          ],
          "representative_frame": 31,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9604988694190979,
              "bbox": [
                185.72994995117188,
                30.24675178527832,
                449.0813903808594,
                356.6740417480469
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            36,
            40
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            41,
            45
          ],
          "representative_frame": 41,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9628799557685852,
              "bbox": [
                179.6627960205078,
                31.858909606933594,
                443.65155029296875,
                356.674072265625
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            46,
            50
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            51,
            55
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9547137022018433,
              "bbox": [
                191.21890258789062,
                30.82033920288086,
                458.150146484375,
                356.30987548828125
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            56,
            60
          ],
          "representative_frame": 56,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 0
    },
    {
      "second": 2,
      "time_range": [
        2,
        2.999
      ],
      "frame_range": [
        61,
        90
      ],
      "unified_description": "360-degree video shot by a man in a green shirt and hat, pointing at the camera as he stands on a mountain top with a beautiful blue lake in the background.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:32",
        "processing_time": 3.13,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 75,
          "frame_range": [
            71,
            75
          ],
          "description": "a man in a green shirt and hat pointing at the camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 3.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            61,
            65
          ],
          "representative_frame": 61,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9500173926353455,
              "bbox": [
                203.93826293945312,
                26.70396614074707,
                476.53582763671875,
                356.08660888671875
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            66,
            70
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            71,
            75
          ],
          "representative_frame": 71,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9538323283195496,
              "bbox": [
                209.8795166015625,
                23.710832595825195,
                487.2662658691406,
                356.1751708984375
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            76,
            80
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            81,
            85
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9561107754707336,
              "bbox": [
                224.47352600097656,
                26.760604858398438,
                500.51483154296875,
                356.1374206542969
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            86,
            90
          ],
          "representative_frame": 86,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 0
    },
    {
      "second": 3,
      "time_range": [
        3,
        3.999
      ],
      "frame_range": [
        91,
        120
      ],
      "unified_description": "\nIn the image, there is a person who appears to be flying a helicopter over a mountainous area. The camera perspective seems to be from within the helicopter, providing a first-person view of the experience. The scene captures the beautiful outdoor environment and the excitement of the flight.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:37",
        "processing_time": 3.48,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 105,
          "frame_range": [
            101,
            105
          ],
          "description": "a man in a helicopter flying over a mountain",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.07
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            91,
            95
          ],
          "representative_frame": 91,
          "detections": [
            {
              "track_id": 1,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.47193643450737,
              "bbox": [
                194.7380828857422,
                31.609464645385742,
                490.82061767578125,
                354.4194030761719
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            96,
            100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            101,
            105
          ],
          "representative_frame": 101,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8430745601654053,
              "bbox": [
                0.0,
                165.96701049804688,
                234.9156494140625,
                357.66070556640625
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            106,
            110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            111,
            115
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8344135284423828,
              "bbox": [
                0.0,
                161.25543212890625,
                237.47085571289062,
                357.37652587890625
              ]
            },
            {
              "track_id": 4,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.36499059200286865,
              "bbox": [
                5.231254577636719,
                20.09417724609375,
                636.9119873046875,
                354.03887939453125
              ]
            }
          ],
          "unique_tracks": [
            3,
            4
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            116,
            120
          ],
          "representative_frame": 116,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 0
    },
    {
      "second": 4,
      "time_range": [
        4,
        4.999
      ],
      "frame_range": [
        121,
        150
      ],
      "unified_description": "\nA small airplane in the water with a writing in the back of it saying Fiji Air.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:38",
        "processing_time": 3.03,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 135,
          "frame_range": [
            131,
            135
          ],
          "description": "a small plane is sitting on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.09
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            121,
            125
          ],
          "representative_frame": 121,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7873885631561279,
              "bbox": [
                2.467545747756958,
                158.8382568359375,
                248.50486755371094,
                357.0202331542969
              ]
            },
            {
              "track_id": 4,
              "class_id": 7,
              "class_name": "truck",
              "confidence": 0.5431358814239502,
              "bbox": [
                3.354332447052002,
                24.57671546936035,
                626.3038330078125,
                354.01153564453125
              ]
            }
          ],
          "unique_tracks": [
            3,
            4
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            126,
            130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            131,
            135
          ],
          "representative_frame": 131,
          "detections": [
            {
              "track_id": 4,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5294943451881409,
              "bbox": [
                5.591200351715088,
                6.318665504455566,
                640.0,
                345.8898010253906
              ]
            }
          ],
          "unique_tracks": [
            4
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            136,
            140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            141,
            145
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 4,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.8670928478240967,
              "bbox": [
                8.87352180480957,
                1.693039059638977,
                636.357177734375,
                333.63336181640625
              ]
            }
          ],
          "unique_tracks": [
            4
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            146,
            150
          ],
          "representative_frame": 146,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 1
    },
    {
      "second": 5,
      "time_range": [
        5,
        5.999
      ],
      "frame_range": [
        151,
        180
      ],
      "unified_description": "1-second video showing a man in an outdoor setting with a tent and water nearby.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:39",
        "processing_time": 3.32,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 165,
          "frame_range": [
            161,
            165
          ],
          "description": "a man is standing near a tent by the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.06
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            151,
            155
          ],
          "representative_frame": 151,
          "detections": [
            {
              "track_id": 4,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.8478488326072693,
              "bbox": [
                40.14228820800781,
                0.08027173578739166,
                603.4263916015625,
                295.53369140625
              ]
            }
          ],
          "unique_tracks": [
            4
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            156,
            160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            161,
            165
          ],
          "representative_frame": 161,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.931973934173584,
              "bbox": [
                0.0,
                10.13897705078125,
                363.3157043457031,
                354.19805908203125
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            166,
            170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            171,
            175
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.829245924949646,
              "bbox": [
                0.0,
                0.0,
                378.255615234375,
                354.0686340332031
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            176,
            180
          ],
          "representative_frame": 176,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 1
    },
    {
      "second": 6,
      "time_range": [
        6,
        6.999
      ],
      "frame_range": [
        181,
        210
      ],
      "unified_description": "30 second timelapse of a man in a grey hoodie, black glasses and cap, standing next to a tree. The image includes several objects: backpack, tent, and two other people in the distance. It is shot in a wide-angle perspective which may cause distortion near the edges of the frame.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:41",
        "processing_time": 3.43,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 195,
          "frame_range": [
            191,
            195
          ],
          "description": "a man is standing next to a tree",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.86
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            181,
            185
          ],
          "representative_frame": 181,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8930047750473022,
              "bbox": [
                0.0,
                0.0,
                420.9224853515625,
                353.85809326171875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            186,
            190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            191,
            195
          ],
          "representative_frame": 191,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9282649755477905,
              "bbox": [
                323.32574462890625,
                82.76326751708984,
                578.5562133789062,
                356.781494140625
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            196,
            200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            201,
            205
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 6,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9323602318763733,
              "bbox": [
                4.4222846031188965,
                79.98775482177734,
                178.65444946289062,
                297.514892578125
              ]
            },
            {
              "track_id": 7,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8692275881767273,
              "bbox": [
                120.25582122802734,
                78.73434448242188,
                241.56735229492188,
                221.86155700683594
              ]
            },
            {
              "track_id": 9,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.36055564880371094,
              "bbox": [
                591.116455078125,
                193.38723754882812,
                608.5519409179688,
                229.3829345703125
              ]
            },
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9152858853340149,
              "bbox": [
                330.4203186035156,
                96.2899169921875,
                578.4588012695312,
                356.8045959472656
              ]
            }
          ],
          "unique_tracks": [
            6,
            7,
            9,
            1
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            206,
            210
          ],
          "representative_frame": 206,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 1
    },
    {
      "second": 7,
      "time_range": [
        7,
        7.999
      ],
      "frame_range": [
        211,
        240
      ],
      "unified_description": "3 men are enjoying a meal together outdoors.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:42",
        "processing_time": 3.16,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 225,
          "frame_range": [
            221,
            225
          ],
          "description": "two people sitting on the ground eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.92
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            211,
            215
          ],
          "representative_frame": 211,
          "detections": [
            {
              "track_id": 6,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9271562099456787,
              "bbox": [
                4.738406658172607,
                80.32447052001953,
                178.5801544189453,
                297.34912109375
              ]
            },
            {
              "track_id": 7,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8400675654411316,
              "bbox": [
                119.3870620727539,
                77.89501953125,
                242.1838836669922,
                222.84059143066406
              ]
            },
            {
              "track_id": 9,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3400264084339142,
              "bbox": [
                591.0966186523438,
                193.36166381835938,
                608.554443359375,
                229.4056396484375
              ]
            },
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9291509389877319,
              "bbox": [
                326.6929626464844,
                95.57341003417969,
                579.859619140625,
                356.73126220703125
              ]
            }
          ],
          "unique_tracks": [
            6,
            7,
            9,
            1
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            216,
            220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            221,
            225
          ],
          "representative_frame": 221,
          "detections": [
            {
              "track_id": 6,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9247143268585205,
              "bbox": [
                4.3079962730407715,
                80.0662841796875,
                178.9336395263672,
                298.0809326171875
              ]
            },
            {
              "track_id": 7,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8589786887168884,
              "bbox": [
                119.35272216796875,
                77.64167785644531,
                242.0414581298828,
                222.49232482910156
              ]
            },
            {
              "track_id": 9,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3422187268733978,
              "bbox": [
                591.098876953125,
                193.37351989746094,
                608.5467529296875,
                229.4010772705078
              ]
            },
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9265065789222717,
              "bbox": [
                323.67669677734375,
                100.79772186279297,
                577.2544555664062,
                356.7384033203125
              ]
            },
            {
              "track_id": 11,
              "class_id": 34,
              "class_name": "baseball bat",
              "confidence": 0.3225689232349396,
              "bbox": [
                486.1221008300781,
                109.23503875732422,
                639.2018432617188,
                161.22732543945312
              ]
            }
          ],
          "unique_tracks": [
            6,
            7,
            9,
            1,
            11
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            226,
            230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            231,
            235
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            236,
            240
          ],
          "representative_frame": 236,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 1
    },
    {
      "second": 8,
      "time_range": [
        8,
        8.999
      ],
      "frame_range": [
        241,
        270
      ],
      "unified_description": "1-second scene featuring a man casting a fishing line from shore while standing on rocks next to boats. One boat is positioned close to the shore and another further away on the right side. The scene captures the man's perspective, providing an immersive view of the outdoors.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:44",
        "processing_time": 3.97,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 255,
          "frame_range": [
            251,
            255
          ],
          "description": "a man fishing on a lake with two boats",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.75
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            241,
            245
          ],
          "representative_frame": 241,
          "detections": [
            {
              "track_id": 12,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9111188054084778,
              "bbox": [
                234.63186645507812,
                117.04703521728516,
                303.3243713378906,
                322.637451171875
              ]
            },
            {
              "track_id": 13,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8304157853126526,
              "bbox": [
                0.0,
                259.26287841796875,
                230.623046875,
                343.9941711425781
              ]
            },
            {
              "track_id": 14,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.751838743686676,
              "bbox": [
                413.3829040527344,
                242.48324584960938,
                584.4465942382812,
                321.5242919921875
              ]
            }
          ],
          "unique_tracks": [
            12,
            13,
            14
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            246,
            250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            251,
            255
          ],
          "representative_frame": 251,
          "detections": [
            {
              "track_id": 12,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9150422811508179,
              "bbox": [
                233.34942626953125,
                117.66963958740234,
                301.96075439453125,
                322.6609802246094
              ]
            },
            {
              "track_id": 13,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8250353336334229,
              "bbox": [
                0.0,
                259.2254943847656,
                230.84445190429688,
                344.1025085449219
              ]
            },
            {
              "track_id": 14,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7433767318725586,
              "bbox": [
                413.5086669921875,
                242.47808837890625,
                584.4810791015625,
                321.4820861816406
              ]
            }
          ],
          "unique_tracks": [
            12,
            13,
            14
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            256,
            260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            261,
            265
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 12,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.91446852684021,
              "bbox": [
                230.76446533203125,
                117.9176254272461,
                299.6139221191406,
                322.5917663574219
              ]
            },
            {
              "track_id": 13,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8414720296859741,
              "bbox": [
                0.0,
                258.9443054199219,
                231.16094970703125,
                344.0950012207031
              ]
            },
            {
              "track_id": 14,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7516250014305115,
              "bbox": [
                414.1439514160156,
                242.90655517578125,
                584.0535888671875,
                321.4108581542969
              ]
            }
          ],
          "unique_tracks": [
            12,
            13,
            14
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            266,
            270
          ],
          "representative_frame": 266,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 2
    },
    {
      "second": 9,
      "time_range": [
        9,
        9.999
      ],
      "frame_range": [
        271,
        300
      ],
      "unified_description": " A person is holding a fish out to the camera and also wearing a green shirt. The camera is positioned in such a way that it seems as if we are looking through the person's hand to see the fish up close.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:45",
        "processing_time": 3.21,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 285,
          "frame_range": [
            281,
            285
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.16
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            271,
            275
          ],
          "representative_frame": 271,
          "detections": [
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6290048956871033,
              "bbox": [
                344.145751953125,
                10.357288360595703,
                640.0,
                336.541748046875
              ]
            }
          ],
          "unique_tracks": [
            1
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            276,
            280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            281,
            285
          ],
          "representative_frame": 281,
          "detections": [
            {
              "track_id": 15,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.7643557786941528,
              "bbox": [
                87.25816345214844,
                111.0964126586914,
                442.3265380859375,
                258.9237365722656
              ]
            },
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8466410636901855,
              "bbox": [
                345.1493835449219,
                2.3944804668426514,
                640.0,
                342.50445556640625
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7455866932868958,
              "bbox": [
                118.17118835449219,
                0.0,
                363.2675476074219,
                195.37974548339844
              ]
            }
          ],
          "unique_tracks": [
            15,
            1,
            3
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            286,
            290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            291,
            295
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 15,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.8417583107948303,
              "bbox": [
                90.37540435791016,
                112.01891326904297,
                421.9374694824219,
                250.15145874023438
              ]
            },
            {
              "track_id": 1,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7874661684036255,
              "bbox": [
                338.8258361816406,
                0.0,
                640.0,
                346.666259765625
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7460663914680481,
              "bbox": [
                119.09014129638672,
                0.0,
                350.3685607910156,
                185.9444122314453
              ]
            }
          ],
          "unique_tracks": [
            15,
            1,
            3
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            296,
            300
          ],
          "representative_frame": 296,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 2
    },
    {
      "second": 10,
      "time_range": [
        10,
        10.999
      ],
      "frame_range": [
        301,
        330
      ],
      "unified_description": "1-second scene featuring a young boy holding a fish while standing on rocks. The camera is positioned overhead, capturing the boy and the fish in the frame.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:47",
        "processing_time": 3.66,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 315,
          "frame_range": [
            311,
            315
          ],
          "description": "a young boy holding a fish on a rock",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.12
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            301,
            305
          ],
          "representative_frame": 301,
          "detections": [
            {
              "track_id": 15,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8303283452987671,
              "bbox": [
                0.0,
                35.35582733154297,
                640.0,
                336.470458984375
              ]
            }
          ],
          "unique_tracks": [
            15
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            306,
            310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            311,
            315
          ],
          "representative_frame": 311,
          "detections": [
            {
              "track_id": 17,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.6782817840576172,
              "bbox": [
                171.94107055664062,
                244.53268432617188,
                520.3787841796875,
                346.28485107421875
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8581926822662354,
              "bbox": [
                111.85317993164062,
                8.231097221374512,
                487.92681884765625,
                332.3021240234375
              ]
            }
          ],
          "unique_tracks": [
            17,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            316,
            320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            321,
            325
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 17,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.5650207996368408,
              "bbox": [
                182.94747924804688,
                256.0105895996094,
                517.5365600585938,
                353.7800598144531
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8131354451179504,
              "bbox": [
                129.02310180664062,
                5.861510276794434,
                519.8340454101562,
                358.677001953125
              ]
            }
          ],
          "unique_tracks": [
            17,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            326,
            330
          ],
          "representative_frame": 326,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 2
    },
    {
      "second": 11,
      "time_range": [
        11,
        11.999
      ],
      "frame_range": [
        331,
        360
      ],
      "unified_description": "360 video from a first person perspective showing a man holding a fish next to a river.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:48",
        "processing_time": 3.59,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 345,
          "frame_range": [
            341,
            345
          ],
          "description": "a man holding a fish in his hands",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.69
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            331,
            335
          ],
          "representative_frame": 331,
          "detections": [
            {
              "track_id": 13,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7444362044334412,
              "bbox": [
                0.0,
                183.04299926757812,
                292.6763000488281,
                356.3812561035156
              ]
            }
          ],
          "unique_tracks": [
            13
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            336,
            340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            341,
            345
          ],
          "representative_frame": 341,
          "detections": [
            {
              "track_id": 18,
              "class_id": 36,
              "class_name": "skateboard",
              "confidence": 0.8482088446617126,
              "bbox": [
                177.2501220703125,
                138.13565063476562,
                539.3565673828125,
                231.2949981689453
              ]
            },
            {
              "track_id": 20,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.445970356464386,
              "bbox": [
                120.88544464111328,
                1.0379120111465454,
                458.90582275390625,
                149.32647705078125
              ]
            },
            {
              "track_id": 6,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7161080241203308,
              "bbox": [
                0.5282527208328247,
                183.80845642089844,
                139.0198516845703,
                356.6011657714844
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4823489487171173,
              "bbox": [
                124.54611206054688,
                4.630040168762207,
                494.0894470214844,
                343.1195983886719
              ]
            }
          ],
          "unique_tracks": [
            18,
            20,
            6,
            3
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            346,
            350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            351,
            355
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            356,
            360
          ],
          "representative_frame": 356,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 2
    },
    {
      "second": 12,
      "time_range": [
        12,
        12.999
      ],
      "frame_range": [
        361,
        390
      ],
      "unified_description": "2 guys hiking in the mountains with a lake in the back ground.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:50",
        "processing_time": 2.75,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 375,
          "frame_range": [
            371,
            375
          ],
          "description": "two people walking up a hill with a lake in the background",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.31
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            361,
            365
          ],
          "representative_frame": 361,
          "detections": [
            {
              "track_id": 21,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8674055337905884,
              "bbox": [
                274.6982727050781,
                135.482421875,
                326.3636169433594,
                243.0889892578125
              ]
            }
          ],
          "unique_tracks": [
            21
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            366,
            370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            371,
            375
          ],
          "representative_frame": 371,
          "detections": [
            {
              "track_id": 21,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8479529619216919,
              "bbox": [
                290.9670104980469,
                136.4116973876953,
                344.7263488769531,
                249.2429656982422
              ]
            }
          ],
          "unique_tracks": [
            21
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            376,
            380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            381,
            385
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9571301341056824,
              "bbox": [
                211.9161834716797,
                5.777378082275391,
                604.2592163085938,
                356.8426818847656
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            386,
            390
          ],
          "representative_frame": 386,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 3
    },
    {
      "second": 13,
      "time_range": [
        13,
        13.999
      ],
      "frame_range": [
        391,
        420
      ],
      "unified_description": "08 Seconds of Video with Object Detection and Description",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:51",
        "processing_time": 2.75,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 405,
          "frame_range": [
            401,
            405
          ],
          "description": "a man in a boat on a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.14
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            391,
            395
          ],
          "representative_frame": 391,
          "detections": [
            {
              "track_id": 25,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8015137910842896,
              "bbox": [
                90.29822540283203,
                161.04348754882812,
                195.7443084716797,
                189.76095581054688
              ]
            },
            {
              "track_id": 26,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6737478375434875,
              "bbox": [
                155.45335388183594,
                143.25021362304688,
                176.78054809570312,
                169.69638061523438
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9418284296989441,
              "bbox": [
                224.48934936523438,
                4.061923027038574,
                624.959228515625,
                358.54296875
              ]
            }
          ],
          "unique_tracks": [
            25,
            26,
            3
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            396,
            400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            401,
            405
          ],
          "representative_frame": 401,
          "detections": [
            {
              "track_id": 25,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8141570091247559,
              "bbox": [
                94.73973846435547,
                160.93006896972656,
                198.24746704101562,
                189.1554412841797
              ]
            },
            {
              "track_id": 26,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6967717409133911,
              "bbox": [
                156.38836669921875,
                142.89794921875,
                178.22039794921875,
                169.87428283691406
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9407411813735962,
              "bbox": [
                238.7548828125,
                3.326655149459839,
                640.0,
                358.72900390625
              ]
            }
          ],
          "unique_tracks": [
            25,
            26,
            3
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            406,
            410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            411,
            415
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9003905057907104,
              "bbox": [
                178.743896484375,
                3.7526447772979736,
                561.3082275390625,
                358.7680969238281
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            416,
            420
          ],
          "representative_frame": 416,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 3
    },
    {
      "second": 14,
      "time_range": [
        14,
        14.999
      ],
      "frame_range": [
        421,
        450
      ],
      "unified_description": "3rd person perspective of a man in a hat looking out of a small hole in a wooden structure while sitting inside of it. The camera is positioned relatively stable, capturing the scene with a wide-angle lens, showing the man's facial expression and the surrounding environment.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:52",
        "processing_time": 3.58,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 435,
          "frame_range": [
            431,
            435
          ],
          "description": "a man in a hat is sitting in a barrel",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.75
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            421,
            425
          ],
          "representative_frame": 421,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.92197185754776,
              "bbox": [
                173.3914031982422,
                3.138709306716919,
                539.2730712890625,
                358.98431396484375
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            426,
            430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            431,
            435
          ],
          "representative_frame": 431,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.933417797088623,
              "bbox": [
                186.55673217773438,
                2.768325090408325,
                535.2510375976562,
                358.3570861816406
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            436,
            440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            441,
            445
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.923451840877533,
              "bbox": [
                162.53793334960938,
                2.8503153324127197,
                503.1936950683594,
                358.2141418457031
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            446,
            450
          ],
          "representative_frame": 446,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 3
    },
    {
      "second": 15,
      "time_range": [
        15,
        15.999
      ],
      "frame_range": [
        451,
        480
      ],
      "unified_description": "3rd person perspective of a man standing outside of a log cabin, holding a coffee cup",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:54",
        "processing_time": 3.36,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 465,
          "frame_range": [
            461,
            465
          ],
          "description": "a man standing in front of a wooden cabin",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.75
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            451,
            455
          ],
          "representative_frame": 451,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8693680763244629,
              "bbox": [
                188.39634704589844,
                6.034997463226318,
                489.5587463378906,
                343.0153503417969
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            456,
            460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            461,
            465
          ],
          "representative_frame": 461,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9088011384010315,
              "bbox": [
                189.1995086669922,
                3.500164747238159,
                471.4242248535156,
                338.1645812988281
              ]
            },
            {
              "track_id": 30,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.44643038511276245,
              "bbox": [
                495.47314453125,
                147.68080139160156,
                540.1699829101562,
                173.1026153564453
              ]
            }
          ],
          "unique_tracks": [
            3,
            30
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            466,
            470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            471,
            475
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9186460375785828,
              "bbox": [
                188.37322998046875,
                2.6713833808898926,
                454.659423828125,
                336.5171813964844
              ]
            },
            {
              "track_id": 30,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3647236227989197,
              "bbox": [
                497.0612487792969,
                149.71730041503906,
                538.7732543945312,
                173.3939208984375
              ]
            }
          ],
          "unique_tracks": [
            3,
            30
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            476,
            480
          ],
          "representative_frame": 476,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 3
    },
    {
      "second": 16,
      "time_range": [
        16,
        16.999
      ],
      "frame_range": [
        481,
        510
      ],
      "unified_description": "3rd person perspective of a man sitting on a stool outside a log cabin with a wide-angle lens used for filming.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:55",
        "processing_time": 3.38,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 495,
          "frame_range": [
            491,
            495
          ],
          "description": "a man is sitting in a chair outside",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.86
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            481,
            485
          ],
          "representative_frame": 481,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8871590495109558,
              "bbox": [
                200.7762908935547,
                21.67636489868164,
                439.8064880371094,
                334.477294921875
              ]
            },
            {
              "track_id": 30,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4400121569633484,
              "bbox": [
                495.9029541015625,
                148.59420776367188,
                539.7811889648438,
                173.48133850097656
              ]
            }
          ],
          "unique_tracks": [
            3,
            30
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            486,
            490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            491,
            495
          ],
          "representative_frame": 491,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7757158279418945,
              "bbox": [
                221.53392028808594,
                67.23560333251953,
                413.34796142578125,
                321.53045654296875
              ]
            },
            {
              "track_id": 30,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.34263381361961365,
              "bbox": [
                496.2203063964844,
                149.9191436767578,
                538.0302734375,
                173.55677795410156
              ]
            }
          ],
          "unique_tracks": [
            3,
            30
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            496,
            500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            501,
            505
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7885887622833252,
              "bbox": [
                240.23910522460938,
                103.81822967529297,
                395.664794921875,
                308.4963073730469
              ]
            },
            {
              "track_id": 30,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2701997458934784,
              "bbox": [
                499.3487854003906,
                153.359375,
                535.307861328125,
                173.4190216064453
              ]
            }
          ],
          "unique_tracks": [
            3,
            30
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            506,
            510
          ],
          "representative_frame": 506,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 4
    },
    {
      "second": 17,
      "time_range": [
        17,
        17.999
      ],
      "frame_range": [
        511,
        540
      ],
      "unified_description": "1-second video showing a man holding a coffee mug outdoors next to a log cabin with a frying pan inside.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:57",
        "processing_time": 2.88,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 525,
          "frame_range": [
            521,
            525
          ],
          "description": "a man sitting on a chair in front of a building",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.68
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            511,
            515
          ],
          "representative_frame": 511,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8524378538131714,
              "bbox": [
                238.87091064453125,
                88.288330078125,
                399.85693359375,
                302.2279968261719
              ]
            },
            {
              "track_id": 30,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.24693694710731506,
              "bbox": [
                498.84844970703125,
                153.158447265625,
                535.3453979492188,
                173.32174682617188
              ]
            },
            {
              "track_id": 38,
              "class_id": 56,
              "class_name": "chair",
              "confidence": 0.37760233879089355,
              "bbox": [
                87.51709747314453,
                151.34776306152344,
                185.6719970703125,
                304.9002685546875
              ]
            }
          ],
          "unique_tracks": [
            3,
            30,
            38
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            516,
            520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            521,
            525
          ],
          "representative_frame": 521,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8379719853401184,
              "bbox": [
                227.46083068847656,
                83.86406707763672,
                409.6244201660156,
                331.02508544921875
              ]
            },
            {
              "track_id": 30,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.28783661127090454,
              "bbox": [
                498.8332214355469,
                152.7891387939453,
                536.0499877929688,
                173.1571044921875
              ]
            },
            {
              "track_id": 38,
              "class_id": 56,
              "class_name": "chair",
              "confidence": 0.3350902199745178,
              "bbox": [
                87.8659439086914,
                151.82127380371094,
                185.64942932128906,
                304.7488098144531
              ]
            },
            {
              "track_id": 39,
              "class_id": 56,
              "class_name": "chair",
              "confidence": 0.3479427993297577,
              "bbox": [
                385.1808776855469,
                2.740344285964966,
                558.3450927734375,
                355.0648498535156
              ]
            }
          ],
          "unique_tracks": [
            3,
            30,
            38,
            39
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            526,
            530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            531,
            535
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            536,
            540
          ],
          "representative_frame": 536,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 4
    },
    {
      "second": 18,
      "time_range": [
        18,
        18.999
      ],
      "frame_range": [
        541,
        570
      ],
      "unified_description": "1-second scene including a large axe stuck in a tree stump",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:25:58",
        "processing_time": 3.19,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 555,
          "frame_range": [
            551,
            555
          ],
          "description": "a large axe is stuck into a tree stump",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.29
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            541,
            545
          ],
          "representative_frame": 541,
          "detections": [
            {
              "track_id": 41,
              "class_id": 10,
              "class_name": "fire hydrant",
              "confidence": 0.34705090522766113,
              "bbox": [
                77.93897247314453,
                53.57273483276367,
                610.8735961914062,
                354.2466125488281
              ]
            }
          ],
          "unique_tracks": [
            41
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            546,
            550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            551,
            555
          ],
          "representative_frame": 551,
          "detections": [
            {
              "track_id": 41,
              "class_id": 13,
              "class_name": "bench",
              "confidence": 0.34419217705726624,
              "bbox": [
                49.495662689208984,
                54.902915954589844,
                580.1690673828125,
                353.39666748046875
              ]
            }
          ],
          "unique_tracks": [
            41
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            556,
            560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            561,
            565
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            566,
            570
          ],
          "representative_frame": 566,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 4
    },
    {
      "second": 19,
      "time_range": [
        19,
        19.999
      ],
      "frame_range": [
        571,
        600
      ],
      "unified_description": "3D view of a mountain scene as seen through a kaleidoscope. A kite is flying over a river near a forest. A person is standing in front of a tree with an axe stuck in it.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:00",
        "processing_time": 4.01,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 585,
          "frame_range": [
            581,
            585
          ],
          "description": "a axe is stuck into a tree stump",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.62
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            571,
            575
          ],
          "representative_frame": 571,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            576,
            580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            581,
            585
          ],
          "representative_frame": 581,
          "detections": [
            {
              "track_id": 3,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.7303178906440735,
              "bbox": [
                232.18661499023438,
                76.84481048583984,
                402.96356201171875,
                298.4319152832031
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            586,
            590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            591,
            595
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.36373913288116455,
              "bbox": [
                229.68482971191406,
                74.96784210205078,
                405.6263122558594,
                295.4705505371094
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            596,
            600
          ],
          "representative_frame": 596,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 4
    },
    {
      "second": 20,
      "time_range": [
        20,
        20.999
      ],
      "frame_range": [
        601,
        630
      ],
      "unified_description": "30 second long black and white photo with red writing that says Outdoor Boys. The image features a large tree stump with a GoPro on top of it.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:02",
        "processing_time": 3.0,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 615,
          "frame_range": [
            611,
            615
          ],
          "description": "a knife is on top of a tree stump",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.42
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            601,
            605
          ],
          "representative_frame": 601,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.4220951795578003,
              "bbox": [
                229.9632568359375,
                74.50051879882812,
                405.5723571777344,
                287.173095703125
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            606,
            610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            611,
            615
          ],
          "representative_frame": 611,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.5173249244689941,
              "bbox": [
                230.40785217285156,
                74.1837387084961,
                405.8936462402344,
                279.9039001464844
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            616,
            620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            621,
            625
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.4418213665485382,
              "bbox": [
                228.93280029296875,
                74.04158782958984,
                408.0507507324219,
                278.71435546875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            626,
            630
          ],
          "representative_frame": 626,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 5
    },
    {
      "second": 21,
      "time_range": [
        21,
        21.999
      ],
      "frame_range": [
        631,
        660
      ],
      "unified_description": "12345",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:03",
        "processing_time": 3.13,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 645,
          "frame_range": [
            641,
            645
          ],
          "description": "the logo for the new logo",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.06
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            631,
            635
          ],
          "representative_frame": 631,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.3371151089668274,
              "bbox": [
                226.37522888183594,
                73.76626586914062,
                410.3453063964844,
                279.9217224121094
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            636,
            640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            641,
            645
          ],
          "representative_frame": 641,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.5020081996917725,
              "bbox": [
                223.80850219726562,
                73.850830078125,
                412.9742736816406,
                282.76055908203125
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            646,
            650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            651,
            655
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.4738010764122009,
              "bbox": [
                222.24342346191406,
                73.86904907226562,
                414.5700378417969,
                283.55902099609375
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            656,
            660
          ],
          "representative_frame": 656,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 5
    },
    {
      "second": 22,
      "time_range": [
        22,
        22.999
      ],
      "frame_range": [
        661,
        690
      ],
      "unified_description": "2 boys are outdoors and are part of the Outdoor Boys group",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:04",
        "processing_time": 3.3,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 675,
          "frame_range": [
            671,
            675
          ],
          "description": "the logo for the new logo",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.52
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            661,
            665
          ],
          "representative_frame": 661,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.4738010764122009,
              "bbox": [
                220.99807739257812,
                73.86750030517578,
                415.8253479003906,
                283.9198303222656
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            666,
            670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            671,
            675
          ],
          "representative_frame": 671,
          "detections": [
            {
              "track_id": 3,
              "class_id": 74,
              "class_name": "clock",
              "confidence": 0.7880275845527649,
              "bbox": [
                223.6882781982422,
                73.69390106201172,
                413.45428466796875,
                274.84442138671875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            676,
            680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            681,
            685
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            686,
            690
          ],
          "representative_frame": 686,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 5
    },
    {
      "second": 23,
      "time_range": [
        23,
        23.999
      ],
      "frame_range": [
        691,
        720
      ],
      "unified_description": "27 seconds of dashcam footage from a drivers perspective in a vehicle.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:05",
        "processing_time": 2.74,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 705,
          "frame_range": [
            701,
            705
          ],
          "description": "a man driving a car on a road",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            691,
            695
          ],
          "representative_frame": 691,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            696,
            700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            701,
            705
          ],
          "representative_frame": 701,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            706,
            710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            711,
            715
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            716,
            720
          ],
          "representative_frame": 716,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 5
    },
    {
      "second": 24,
      "time_range": [
        24,
        24.999
      ],
      "frame_range": [
        721,
        750
      ],
      "unified_description": "3rd person perspective video showing a man driving a vehicle with a young boy seated beside him. The driver is looking at the camera while the child appears to be looking out the window. The car's interior is visible, as well as some of its surroundings. The image likely captures a moment from a road trip or everyday life.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:07",
        "processing_time": 3.65,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 735,
          "frame_range": [
            731,
            735
          ],
          "description": "a man in a car with a child inside",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.16
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            721,
            725
          ],
          "representative_frame": 721,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5361323952674866,
              "bbox": [
                1.7283062934875488,
                0.0,
                639.0068969726562,
                355.7532653808594
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            726,
            730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            731,
            735
          ],
          "representative_frame": 731,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.668205738067627,
              "bbox": [
                3.3491687774658203,
                1.5994490385055542,
                637.8045043945312,
                355.74481201171875
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8908608555793762,
              "bbox": [
                132.87954711914062,
                68.30899810791016,
                401.94036865234375,
                350.9401550292969
              ]
            }
          ],
          "unique_tracks": [
            48,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            736,
            740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            741,
            745
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6371522545814514,
              "bbox": [
                3.642571210861206,
                1.200789213180542,
                637.4706420898438,
                354.995849609375
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9161389470100403,
              "bbox": [
                137.62042236328125,
                45.39576721191406,
                440.6848449707031,
                356.720947265625
              ]
            }
          ],
          "unique_tracks": [
            48,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            746,
            750
          ],
          "representative_frame": 746,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 6
    },
    {
      "second": 25,
      "time_range": [
        25,
        25.999
      ],
      "frame_range": [
        751,
        780
      ],
      "unified_description": "360-degree view of man sitting in a vehicle, possibly talking to someone",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:09",
        "processing_time": 3.99,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 765,
          "frame_range": [
            761,
            765
          ],
          "description": "a man in a black jacket and hat is sitting in a car",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.91
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            751,
            755
          ],
          "representative_frame": 751,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.4150708317756653,
              "bbox": [
                100.39016723632812,
                2.505370855331421,
                640.0,
                354.4175720214844
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9048471450805664,
              "bbox": [
                114.0639877319336,
                18.1608829498291,
                452.50732421875,
                359.5174865722656
              ]
            }
          ],
          "unique_tracks": [
            48,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            756,
            760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            761,
            765
          ],
          "representative_frame": 761,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.934381902217865,
              "bbox": [
                120.8203353881836,
                5.561675548553467,
                453.2113342285156,
                359.4986267089844
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            766,
            770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            771,
            775
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9386749863624573,
              "bbox": [
                131.72007751464844,
                0.3407890796661377,
                450.5264892578125,
                355.9888916015625
              ]
            },
            {
              "track_id": 60,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6706032156944275,
              "bbox": [
                94.05941772460938,
                55.44511795043945,
                113.0194091796875,
                71.58521270751953
              ]
            },
            {
              "track_id": 61,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5133658647537231,
              "bbox": [
                118.87480163574219,
                52.88211441040039,
                139.66920471191406,
                68.05957794189453
              ]
            },
            {
              "track_id": 65,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.46981433033943176,
              "bbox": [
                284.2461853027344,
                194.27967834472656,
                433.0501708984375,
                352.6500549316406
              ]
            }
          ],
          "unique_tracks": [
            3,
            60,
            61,
            65
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            776,
            780
          ],
          "representative_frame": 776,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 6
    },
    {
      "second": 26,
      "time_range": [
        26,
        26.999
      ],
      "frame_range": [
        781,
        810
      ],
      "unified_description": "32 second video showing a person carrying several bags in front of an open market stall on a rainy day.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:10",
        "processing_time": 3.55,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 795,
          "frame_range": [
            791,
            795
          ],
          "description": "a man walking down the street with a bag",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.02
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            781,
            785
          ],
          "representative_frame": 781,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9283356666564941,
              "bbox": [
                145.59022521972656,
                0.0,
                450.6273498535156,
                352.9218444824219
              ]
            },
            {
              "track_id": 60,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6596017479896545,
              "bbox": [
                90.57091522216797,
                58.95198059082031,
                108.48828125,
                74.08747863769531
              ]
            },
            {
              "track_id": 61,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.56939297914505,
              "bbox": [
                115.72232055664062,
                53.03430938720703,
                139.1595458984375,
                69.97315216064453
              ]
            },
            {
              "track_id": 65,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.634682834148407,
              "bbox": [
                299.6012268066406,
                190.01156616210938,
                454.3472900390625,
                355.0867919921875
              ]
            },
            {
              "track_id": 68,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6619961261749268,
              "bbox": [
                9.11666488647461,
                70.63339233398438,
                30.359798431396484,
                88.8972396850586
              ]
            },
            {
              "track_id": 69,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.674278199672699,
              "bbox": [
                61.54948806762695,
                61.78109359741211,
                86.17050170898438,
                79.06307983398438
              ]
            },
            {
              "track_id": 71,
              "class_id": 13,
              "class_name": "bench",
              "confidence": 0.490220844745636,
              "bbox": [
                472.89251708984375,
                95.30583190917969,
                640.0,
                292.7455139160156
              ]
            }
          ],
          "unique_tracks": [
            3,
            60,
            61,
            65,
            68,
            69,
            71
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            786,
            790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            791,
            795
          ],
          "representative_frame": 791,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9449130296707153,
              "bbox": [
                157.0575714111328,
                6.993293285369873,
                448.01336669921875,
                357.0520935058594
              ]
            },
            {
              "track_id": 60,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6823520064353943,
              "bbox": [
                82.06362915039062,
                60.10684585571289,
                103.0902328491211,
                77.66513061523438
              ]
            },
            {
              "track_id": 65,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.4126829206943512,
              "bbox": [
                303.995361328125,
                195.63450622558594,
                453.5994567871094,
                355.38824462890625
              ]
            },
            {
              "track_id": 71,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.15302139520645142,
              "bbox": [
                436.8477478027344,
                38.848140716552734,
                640.0,
                315.5296630859375
              ]
            },
            {
              "track_id": 78,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.5953928828239441,
              "bbox": [
                199.9081268310547,
                143.66114807128906,
                279.33331298828125,
                259.2653503417969
              ]
            }
          ],
          "unique_tracks": [
            3,
            60,
            65,
            71,
            78
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            796,
            800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            801,
            805
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9338885545730591,
              "bbox": [
                146.1367645263672,
                13.502362251281738,
                400.49749755859375,
                334.9223937988281
              ]
            },
            {
              "track_id": 38,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8640209436416626,
              "bbox": [
                83.96177673339844,
                80.1750259399414,
                212.78952026367188,
                299.527587890625
              ]
            },
            {
              "track_id": 48,
              "class_id": 7,
              "class_name": "truck",
              "confidence": 0.4843319356441498,
              "bbox": [
                159.4651641845703,
                1.6919254064559937,
                640.0,
                351.7928771972656
              ]
            }
          ],
          "unique_tracks": [
            3,
            38,
            48
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            806,
            810
          ],
          "representative_frame": 806,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 6
    },
    {
      "second": 27,
      "time_range": [
        27,
        27.999
      ],
      "frame_range": [
        811,
        840
      ],
      "unified_description": "4 unique objects are detected in the image with their respective locations and characteristics.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:11",
        "processing_time": 2.8,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 825,
          "frame_range": [
            821,
            825
          ],
          "description": "a man is getting off the boat and getting off",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.25
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            811,
            815
          ],
          "representative_frame": 811,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9060192704200745,
              "bbox": [
                172.67324829101562,
                18.569948196411133,
                411.0365295410156,
                328.6295471191406
              ]
            },
            {
              "track_id": 86,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8031141757965088,
              "bbox": [
                396.82183837890625,
                0.6285034418106079,
                492.34979248046875,
                143.03598022460938
              ]
            },
            {
              "track_id": 38,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7323946356773376,
              "bbox": [
                72.97857666015625,
                83.37869262695312,
                201.0489501953125,
                310.2547302246094
              ]
            }
          ],
          "unique_tracks": [
            3,
            86,
            38
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            816,
            820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            821,
            825
          ],
          "representative_frame": 821,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8702690005302429,
              "bbox": [
                187.86065673828125,
                22.000181198120117,
                417.9136657714844,
                330.20513916015625
              ]
            },
            {
              "track_id": 86,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8310878276824951,
              "bbox": [
                384.3182373046875,
                1.4211361408233643,
                484.00067138671875,
                150.0093994140625
              ]
            },
            {
              "track_id": 38,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8776016235351562,
              "bbox": [
                58.43954849243164,
                88.04810333251953,
                187.26702880859375,
                316.2081298828125
              ]
            },
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.516939103603363,
              "bbox": [
                50.71964645385742,
                0.7708845138549805,
                631.7314453125,
                338.7986145019531
              ]
            }
          ],
          "unique_tracks": [
            3,
            86,
            38,
            48
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            826,
            830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            831,
            835
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 38,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9424980878829956,
              "bbox": [
                43.04193878173828,
                127.51924896240234,
                179.5804901123047,
                343.0180969238281
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9508558511734009,
              "bbox": [
                119.03192138671875,
                27.619976043701172,
                640.0,
                350.4071350097656
              ]
            }
          ],
          "unique_tracks": [
            38,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            836,
            840
          ],
          "representative_frame": 836,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 6
    },
    {
      "second": 28,
      "time_range": [
        28,
        28.999
      ],
      "frame_range": [
        841,
        870
      ],
      "unified_description": "\nA man wearing sunglasses stands next to a piece of machinery. His head is turned to the side as he looks at something out of frame. The image has several unique elements, including a car that seems to be under repair, possibly by the man himself. There are two other people in the scene, one near the center and another towards the left.\n\nAdditionally, there are two chairs visible in the image, with one situated at the back-left of the scene and another closer to the center.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:14",
        "processing_time": 3.99,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 855,
          "frame_range": [
            851,
            855
          ],
          "description": "a man in a black jacket and hat is fixing a car",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.73
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            841,
            845
          ],
          "representative_frame": 841,
          "detections": [
            {
              "track_id": 38,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.827157199382782,
              "bbox": [
                84.46376037597656,
                162.09722900390625,
                198.41696166992188,
                353.2633972167969
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9153852462768555,
              "bbox": [
                109.2424545288086,
                9.687538146972656,
                640.0,
                353.833740234375
              ]
            }
          ],
          "unique_tracks": [
            38,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            846,
            850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            851,
            855
          ],
          "representative_frame": 851,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8914344906806946,
              "bbox": [
                112.83139038085938,
                3.7557578086853027,
                640.0,
                354.5275573730469
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            856,
            860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            861,
            865
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9392359256744385,
              "bbox": [
                109.31672668457031,
                1.3611606359481812,
                640.0,
                354.145263671875
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            866,
            870
          ],
          "representative_frame": 866,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 7
    },
    {
      "second": 29,
      "time_range": [
        29,
        29.999
      ],
      "frame_range": [
        871,
        900
      ],
      "unified_description": "35 second video of a man sitting inside a small aircraft. The aircraft appears to be a personal helicopter with two seats, one in front and one behind. A young boy is seated behind the man. There are various objects within the scene such as a bottle located towards the right side of the image. Additionally, the camera perspective seems to be first-person, suggesting that the man wearing glasses is the one operating the camera while sitting in the pilot's seat.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:17",
        "processing_time": 5.69,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 885,
          "frame_range": [
            881,
            885
          ],
          "description": "a man in a helicopter with a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.89
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            871,
            875
          ],
          "representative_frame": 871,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8885224461555481,
              "bbox": [
                101.22441864013672,
                1.6924222707748413,
                640.0,
                355.65576171875
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            876,
            880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            881,
            885
          ],
          "representative_frame": 881,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9158449172973633,
              "bbox": [
                209.93768310546875,
                3.290266275405884,
                481.4488830566406,
                353.5797119140625
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            886,
            890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            891,
            895
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9296180009841919,
              "bbox": [
                197.08132934570312,
                0.9266600012779236,
                479.072265625,
                355.56524658203125
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            896,
            900
          ],
          "representative_frame": 896,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 7
    },
    {
      "second": 30,
      "time_range": [
        30,
        30.999
      ],
      "frame_range": [
        901,
        930
      ],
      "unified_description": "\n\nA small airplane with one person on board. The pilot is sitting in the cockpit, which features several control surfaces, such as a steering wheel and multiple buttons and switches. There is also a speedometer visible within the cockpit. The airplane appears to be flying at a relatively low altitude above water, possibly near some trees.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:19",
        "processing_time": 6.34,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 915,
          "frame_range": [
            911,
            915
          ],
          "description": "a man in a boat is driving down the river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.75
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            901,
            905
          ],
          "representative_frame": 901,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9167084097862244,
              "bbox": [
                173.7749786376953,
                0.6344751715660095,
                462.9635009765625,
                356.41326904296875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            906,
            910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            911,
            915
          ],
          "representative_frame": 911,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9266306757926941,
              "bbox": [
                117.78829193115234,
                25.059602737426758,
                405.00054931640625,
                356.99298095703125
              ]
            },
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.4672582149505615,
              "bbox": [
                45.828826904296875,
                0.12883207201957703,
                612.1990966796875,
                358.8778381347656
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            916,
            920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            921,
            925
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.932878315448761,
              "bbox": [
                87.39833068847656,
                33.4404411315918,
                380.7978820800781,
                357.14544677734375
              ]
            },
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.2802688181400299,
              "bbox": [
                37.692298889160156,
                0.006107895635068417,
                610.2054443359375,
                357.6490478515625
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            926,
            930
          ],
          "representative_frame": 926,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 7
    },
    {
      "second": 31,
      "time_range": [
        31,
        31.999
      ],
      "frame_range": [
        931,
        960
      ],
      "unified_description": "1-second scene showing the ocean with a boat and house in the background. The camera is mounted on a tripod for stable footage.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:20",
        "processing_time": 4.19,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 945,
          "frame_range": [
            941,
            945
          ],
          "description": "a boat is in the water near a house",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.29
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            931,
            935
          ],
          "representative_frame": 931,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9381016492843628,
              "bbox": [
                74.5602035522461,
                43.67771530151367,
                370.2759094238281,
                357.2982177734375
              ]
            },
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.4720124900341034,
              "bbox": [
                32.90250778198242,
                0.11531289666891098,
                611.4443359375,
                357.2621765136719
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            936,
            940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            941,
            945
          ],
          "representative_frame": 941,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            946,
            950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            951,
            955
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 98,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.4834085702896118,
              "bbox": [
                0.0,
                154.6630859375,
                305.7347412109375,
                356.6422424316406
              ]
            }
          ],
          "unique_tracks": [
            98
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            956,
            960
          ],
          "representative_frame": 956,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 7
    },
    {
      "second": 32,
      "time_range": [
        32,
        32.999
      ],
      "frame_range": [
        961,
        990
      ],
      "unified_description": "1 second of footage shot with a camera mounted on a person's shoulder capturing the view from inside a boat. There is also a car visible in the background, adding context to the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:21",
        "processing_time": 3.41,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 975,
          "frame_range": [
            971,
            975
          ],
          "description": "a boat is seen from the inside of a boat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.27
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            961,
            965
          ],
          "representative_frame": 961,
          "detections": [
            {
              "track_id": 98,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.3332473933696747,
              "bbox": [
                0.0,
                143.4626007080078,
                308.6209411621094,
                356.62725830078125
              ]
            }
          ],
          "unique_tracks": [
            98
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            966,
            970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            971,
            975
          ],
          "representative_frame": 971,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            976,
            980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            981,
            985
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.766850471496582,
              "bbox": [
                29.810867309570312,
                0.6032494902610779,
                612.0947875976562,
                355.1989440917969
              ]
            },
            {
              "track_id": 98,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8595413565635681,
              "bbox": [
                0.0,
                116.57970428466797,
                305.1280822753906,
                357.4620361328125
              ]
            }
          ],
          "unique_tracks": [
            48,
            98
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            986,
            990
          ],
          "representative_frame": 986,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 8
    },
    {
      "second": 33,
      "time_range": [
        33,
        33.999
      ],
      "frame_range": [
        991,
        1020
      ],
      "unified_description": "\n\nA man is sitting in a small boat or plane cockpit, holding a control or steering wheel. He has a camera mounted on his helmet, capturing his experience as he flies or navigates through the water. The image also features a laptop screen, possibly providing crucial flight information or serving as a visual aid for the pilot. The scene is dynamic and filled with interesting elements, making it an engaging watch for viewers.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:23",
        "processing_time": 3.9,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1005,
          "frame_range": [
            1001,
            1005
          ],
          "description": "a man in a boat with a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.93
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            991,
            995
          ],
          "representative_frame": 991,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.5626766681671143,
              "bbox": [
                39.473079681396484,
                0.8910201191902161,
                622.5177612304688,
                353.84478759765625
              ]
            },
            {
              "track_id": 98,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8841067552566528,
              "bbox": [
                0.0,
                105.11524963378906,
                305.03094482421875,
                357.2315368652344
              ]
            }
          ],
          "unique_tracks": [
            48,
            98
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            996,
            1000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1001,
            1005
          ],
          "representative_frame": 1001,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.592369794845581,
              "bbox": [
                31.42171859741211,
                0.3194715082645416,
                621.2943725585938,
                354.42816162109375
              ]
            },
            {
              "track_id": 98,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.514421284198761,
              "bbox": [
                0.0,
                95.71366119384766,
                307.3730773925781,
                357.53582763671875
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.42377811670303345,
              "bbox": [
                69.52680969238281,
                96.58651733398438,
                342.0187683105469,
                357.86822509765625
              ]
            }
          ],
          "unique_tracks": [
            48,
            98,
            3
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            1006,
            1010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1011,
            1015
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.3662808835506439,
              "bbox": [
                23.776174545288086,
                0.42814701795578003,
                621.1045532226562,
                356.11151123046875
              ]
            },
            {
              "track_id": 98,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7698674201965332,
              "bbox": [
                0.0,
                88.66758728027344,
                301.9595031738281,
                357.4642639160156
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.49235057830810547,
              "bbox": [
                60.82086944580078,
                99.48299407958984,
                350.7794494628906,
                358.5273132324219
              ]
            }
          ],
          "unique_tracks": [
            48,
            98,
            3
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            1016,
            1020
          ],
          "representative_frame": 1016,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 8
    },
    {
      "second": 34,
      "time_range": [
        34,
        34.999
      ],
      "frame_range": [
        1021,
        1050
      ],
      "unified_description": "\n\nA person wearing a ball cap sits at the controls of a helicopter, flying along a river.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:25",
        "processing_time": 3.74,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1035,
          "frame_range": [
            1031,
            1035
          ],
          "description": "a man in a helicopter flying over a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.02
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1021,
            1025
          ],
          "representative_frame": 1021,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.5164409279823303,
              "bbox": [
                19.868118286132812,
                0.9014606475830078,
                620.4977416992188,
                355.7303161621094
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8586081266403198,
              "bbox": [
                62.59945297241211,
                133.7034149169922,
                336.6865234375,
                358.6729431152344
              ]
            }
          ],
          "unique_tracks": [
            48,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1026,
            1030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1031,
            1035
          ],
          "representative_frame": 1031,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.3202051520347595,
              "bbox": [
                16.874223709106445,
                0.7966554164886475,
                621.9468994140625,
                355.7550354003906
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8582004308700562,
              "bbox": [
                66.9483642578125,
                160.7610626220703,
                329.2913513183594,
                358.7542724609375
              ]
            }
          ],
          "unique_tracks": [
            48,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1036,
            1040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1041,
            1045
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.3014465570449829,
              "bbox": [
                15.405102729797363,
                1.222306489944458,
                623.4153442382812,
                355.7214050292969
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8429576754570007,
              "bbox": [
                61.649662017822266,
                164.92901611328125,
                334.30828857421875,
                358.6414794921875
              ]
            }
          ],
          "unique_tracks": [
            48,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1046,
            1050
          ],
          "representative_frame": 1046,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 8
    },
    {
      "second": 35,
      "time_range": [
        35,
        35.999
      ],
      "frame_range": [
        1051,
        1080
      ],
      "unified_description": "1-second scene showing a body of water with an island in the middle, a building on the shoreline, and a few cars and a bus located around the area. The image is captured from an aircraft perspective, providing an aerial view of the landscape below.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:26",
        "processing_time": 4.17,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1065,
          "frame_range": [
            1061,
            1065
          ],
          "description": "a view of a lake from a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1051,
            1055
          ],
          "representative_frame": 1051,
          "detections": [
            {
              "track_id": 48,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.27592402696609497,
              "bbox": [
                14.006561279296875,
                1.0126320123672485,
                624.67724609375,
                355.18359375
              ]
            },
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8524879813194275,
              "bbox": [
                54.07356262207031,
                162.42481994628906,
                342.9205017089844,
                358.5458984375
              ]
            }
          ],
          "unique_tracks": [
            48,
            3
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1056,
            1060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1061,
            1065
          ],
          "representative_frame": 1061,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.6146875023841858,
              "bbox": [
                66.29114532470703,
                76.82581329345703,
                570.31689453125,
                353.5520935058594
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1066,
            1070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1071,
            1075
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.5474815964698792,
              "bbox": [
                46.19620132446289,
                58.97629165649414,
                589.814453125,
                353.027587890625
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1076,
            1080
          ],
          "representative_frame": 1076,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 8
    },
    {
      "second": 36,
      "time_range": [
        36,
        36.999
      ],
      "frame_range": [
        1081,
        1110
      ],
      "unified_description": "1-second scene with a airplane flying over water. The image shows a birds eye view of the plane. There is also a car visible near the water's edge.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:28",
        "processing_time": 3.36,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1095,
          "frame_range": [
            1091,
            1095
          ],
          "description": "a small plane flying over a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.01
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1081,
            1085
          ],
          "representative_frame": 1081,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.5629032850265503,
              "bbox": [
                58.71556091308594,
                80.40958404541016,
                579.9160766601562,
                354.18023681640625
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1086,
            1090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1091,
            1095
          ],
          "representative_frame": 1091,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            1096,
            1100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1101,
            1105
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8985850811004639,
              "bbox": [
                0.0,
                21.137800216674805,
                541.4817504882812,
                355.64813232421875
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1106,
            1110
          ],
          "representative_frame": 1106,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 9
    },
    {
      "second": 37,
      "time_range": [
        37,
        37.999
      ],
      "frame_range": [
        1111,
        1140
      ],
      "unified_description": "10-second video of a person inside a helicopter",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:29",
        "processing_time": 3.07,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1125,
          "frame_range": [
            1121,
            1125
          ],
          "description": "a young boy in a helicopter looking out the window",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.13
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1111,
            1115
          ],
          "representative_frame": 1111,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9227280020713806,
              "bbox": [
                0.0,
                7.687073230743408,
                526.6025390625,
                356.51263427734375
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1116,
            1120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1121,
            1125
          ],
          "representative_frame": 1121,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9215964674949646,
              "bbox": [
                0.0,
                2.3380813598632812,
                516.6975708007812,
                356.5648193359375
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1126,
            1130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1131,
            1135
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.753856897354126,
              "bbox": [
                9.38759708404541,
                55.49750900268555,
                546.1123657226562,
                356.9874572753906
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1136,
            1140
          ],
          "representative_frame": 1136,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 9
    },
    {
      "second": 38,
      "time_range": [
        38,
        38.999
      ],
      "frame_range": [
        1141,
        1170
      ],
      "unified_description": "1-second scene of a plane flying over a body of water on an overcast day. The image was captured using a first-person camera perspective, showing the cockpit view of the plane's instruments and surroundings.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:31",
        "processing_time": 3.26,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1155,
          "frame_range": [
            1151,
            1155
          ],
          "description": "a helicopter flying over a lake with a cloudy sky",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.13
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1141,
            1145
          ],
          "representative_frame": 1141,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.3512002229690552,
              "bbox": [
                61.01176452636719,
                93.76773071289062,
                551.1857299804688,
                356.88507080078125
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1146,
            1150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1151,
            1155
          ],
          "representative_frame": 1151,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.44739195704460144,
              "bbox": [
                72.76004791259766,
                108.74668884277344,
                552.6333618164062,
                356.5766296386719
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1156,
            1160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1161,
            1165
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.6170142292976379,
              "bbox": [
                59.67535400390625,
                95.68132019042969,
                574.2568359375,
                355.6833190917969
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1166,
            1170
          ],
          "representative_frame": 1166,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 9
    },
    {
      "second": 39,
      "time_range": [
        39,
        39.999
      ],
      "frame_range": [
        1171,
        1200
      ],
      "unified_description": "1 second long shot of an airplane flying over a field with a lot of small tracks in it. The plane is seen from the front (cockpit view) showing part of its wing and some of the landscape below.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:32",
        "processing_time": 3.46,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1185,
          "frame_range": [
            1181,
            1185
          ],
          "description": "a view from the cockpit of a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.92
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1171,
            1175
          ],
          "representative_frame": 1171,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            1176,
            1180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1181,
            1185
          ],
          "representative_frame": 1181,
          "detections": [
            {
              "track_id": 110,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.41690513491630554,
              "bbox": [
                292.8946838378906,
                0.555041491985321,
                637.0494995117188,
                352.37982177734375
              ]
            }
          ],
          "unique_tracks": [
            110
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1186,
            1190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1191,
            1195
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 110,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.3636914789676666,
              "bbox": [
                292.40972900390625,
                0.6154557466506958,
                637.025146484375,
                352.8892822265625
              ]
            }
          ],
          "unique_tracks": [
            110
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1196,
            1200
          ],
          "representative_frame": 1196,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 9
    },
    {
      "second": 40,
      "time_range": [
        40,
        40.999
      ],
      "frame_range": [
        1201,
        1230
      ],
      "unified_description": "\nThe image shows the point of view from the cockpit of an airplane flying over a marshy area with many rivers. The airplane's wing is visible in the upper right corner, providing a sense of altitude and perspective. The focus of the image is on the expansive landscape below, which is filled with water channels, showcasing the natural beauty of the wetlands from above. The video has a wide-angle perspective that captures the vastness of the scene, giving viewers a unique, aerial vantage point to appreciate the Earth's landscape.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:35",
        "processing_time": 4.91,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1215,
          "frame_range": [
            1211,
            1215
          ],
          "description": "a view from the cockpit of a plane flying over a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1201,
            1205
          ],
          "representative_frame": 1201,
          "detections": [
            {
              "track_id": 110,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.19763493537902832,
              "bbox": [
                292.353515625,
                0.4169052243232727,
                637.7105712890625,
                353.3702087402344
              ]
            }
          ],
          "unique_tracks": [
            110
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1206,
            1210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1211,
            1215
          ],
          "representative_frame": 1211,
          "detections": [
            {
              "track_id": 110,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.16479744017124176,
              "bbox": [
                294.2779235839844,
                0.6184127330780029,
                638.2315063476562,
                352.0445556640625
              ]
            }
          ],
          "unique_tracks": [
            110
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1216,
            1220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1221,
            1225
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            1226,
            1230
          ],
          "representative_frame": 1226,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 10
    },
    {
      "second": 41,
      "time_range": [
        41,
        41.999
      ],
      "frame_range": [
        1231,
        1260
      ],
      "unified_description": "2 young boys sit side by side in the cockpit of an airplane with red and white jackets. They are wearing headphones and there is a noticeable fisheye effect due to the wide-angle lens used for filming.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:36",
        "processing_time": 4.61,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1245,
          "frame_range": [
            1241,
            1245
          ],
          "description": "two boys are sitting in the cockpit of a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.99
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1231,
            1235
          ],
          "representative_frame": 1231,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            1236,
            1240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1241,
            1245
          ],
          "representative_frame": 1241,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9222798943519592,
              "bbox": [
                0.0,
                116.2364501953125,
                275.8341979980469,
                357.1285705566406
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9311953186988831,
              "bbox": [
                92.98684692382812,
                91.79736328125,
                568.1839599609375,
                357.4235534667969
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1246,
            1250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1251,
            1255
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9162003993988037,
              "bbox": [
                0.0,
                116.398193359375,
                264.5340270996094,
                357.01055908203125
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9334086775779724,
              "bbox": [
                114.43146514892578,
                92.68306732177734,
                548.6998901367188,
                357.2239990234375
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1256,
            1260
          ],
          "representative_frame": 1256,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 10
    },
    {
      "second": 42,
      "time_range": [
        42,
        42.999
      ],
      "frame_range": [
        1261,
        1290
      ],
      "unified_description": "2 boys are sitting in the cockpit of an airplane with red seats. They are wearing headphones that may be connected to a radio communication system. The camera is capturing this moment, possibly for documentation or recreational purposes.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:38",
        "processing_time": 4.46,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1275,
          "frame_range": [
            1271,
            1275
          ],
          "description": "two boys are sitting in the cockpit of a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.11
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1261,
            1265
          ],
          "representative_frame": 1261,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9165599942207336,
              "bbox": [
                0.0,
                117.05638122558594,
                256.6601867675781,
                356.7946472167969
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9363710284233093,
              "bbox": [
                130.09332275390625,
                93.17987823486328,
                532.2091064453125,
                357.2131652832031
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1266,
            1270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1271,
            1275
          ],
          "representative_frame": 1271,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9262441396713257,
              "bbox": [
                0.0,
                115.7444076538086,
                246.1365203857422,
                356.74127197265625
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9312430024147034,
              "bbox": [
                143.14122009277344,
                93.23787689208984,
                519.3408813476562,
                357.1678771972656
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1276,
            1280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1281,
            1285
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9199704527854919,
              "bbox": [
                0.0,
                114.14825439453125,
                246.91700744628906,
                356.81158447265625
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9329484701156616,
              "bbox": [
                153.3035888671875,
                92.64021301269531,
                508.6097412109375,
                357.017578125
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1286,
            1290
          ],
          "representative_frame": 1286,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 10
    },
    {
      "second": 43,
      "time_range": [
        43,
        43.999
      ],
      "frame_range": [
        1291,
        1320
      ],
      "unified_description": "1-second scene featuring a scenic river valley viewed from a plane's cockpit. The image is slightly shaky, which indicates that it was taken during turbulence.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:39",
        "processing_time": 3.43,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1305,
          "frame_range": [
            1301,
            1305
          ],
          "description": "a view from the cockpit of a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.99
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1291,
            1295
          ],
          "representative_frame": 1291,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            1296,
            1300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1301,
            1305
          ],
          "representative_frame": 1301,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            1306,
            1310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1311,
            1315
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            1316,
            1320
          ],
          "representative_frame": 1316,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 10
    },
    {
      "second": 44,
      "time_range": [
        44,
        44.999
      ],
      "frame_range": [
        1321,
        1350
      ],
      "unified_description": "2 men in a helicopter with headphones on",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:40",
        "processing_time": 2.95,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1335,
          "frame_range": [
            1331,
            1335
          ],
          "description": "two men in a helicopter with headphones on",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.0
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1321,
            1325
          ],
          "representative_frame": 1321,
          "detections": [
            {
              "track_id": 110,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9192209243774414,
              "bbox": [
                417.2012939453125,
                92.56139373779297,
                640.0,
                356.3014831542969
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8764417171478271,
              "bbox": [
                14.442312240600586,
                10.900217056274414,
                465.940185546875,
                355.82281494140625
              ]
            }
          ],
          "unique_tracks": [
            110,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1326,
            1330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1331,
            1335
          ],
          "representative_frame": 1331,
          "detections": [
            {
              "track_id": 112,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5043954849243164,
              "bbox": [
                340.8994445800781,
                137.22189331054688,
                424.2740173339844,
                248.43580627441406
              ]
            },
            {
              "track_id": 113,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3878227770328522,
              "bbox": [
                344.1882019042969,
                137.01950073242188,
                429.16375732421875,
                319.9988708496094
              ]
            },
            {
              "track_id": 110,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9163551926612854,
              "bbox": [
                423.7154541015625,
                94.80290222167969,
                640.0,
                356.2933044433594
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9029721617698669,
              "bbox": [
                12.980942726135254,
                1.772546410560608,
                463.076171875,
                355.464599609375
              ]
            }
          ],
          "unique_tracks": [
            112,
            113,
            110,
            48
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            1336,
            1340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1341,
            1345
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 112,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6710883378982544,
              "bbox": [
                336.7621154785156,
                136.35154724121094,
                424.4539489746094,
                253.2394561767578
              ]
            },
            {
              "track_id": 113,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.16370724141597748,
              "bbox": [
                338.6665344238281,
                137.0579071044922,
                429.51025390625,
                332.5461730957031
              ]
            },
            {
              "track_id": 110,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9220518469810486,
              "bbox": [
                426.4121398925781,
                94.60320281982422,
                640.0,
                356.31201171875
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9170253872871399,
              "bbox": [
                31.525888442993164,
                6.236546039581299,
                462.2674865722656,
                355.4123229980469
              ]
            }
          ],
          "unique_tracks": [
            112,
            113,
            110,
            48
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            1346,
            1350
          ],
          "representative_frame": 1346,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 11
    },
    {
      "second": 45,
      "time_range": [
        45,
        45.999
      ],
      "frame_range": [
        1351,
        1380
      ],
      "unified_description": "1-second scene showing the outside of a passenger airplane flying over a green countryside filled with mountains.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:42",
        "processing_time": 2.84,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1365,
          "frame_range": [
            1361,
            1365
          ],
          "description": "a view of a mountain range from a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.02
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1351,
            1355
          ],
          "representative_frame": 1351,
          "detections": [
            {
              "track_id": 112,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.49658113718032837,
              "bbox": [
                342.1280822753906,
                137.4637451171875,
                427.38763427734375,
                251.5376739501953
              ]
            },
            {
              "track_id": 113,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.14951294660568237,
              "bbox": [
                342.6637268066406,
                136.7882843017578,
                432.2254943847656,
                329.7121887207031
              ]
            },
            {
              "track_id": 110,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9331485629081726,
              "bbox": [
                420.6048278808594,
                93.5047836303711,
                640.0,
                356.8887023925781
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9172343611717224,
              "bbox": [
                40.411773681640625,
                1.744468092918396,
                463.7960205078125,
                355.4056701660156
              ]
            },
            {
              "track_id": 114,
              "class_id": 56,
              "class_name": "chair",
              "confidence": 0.4107033908367157,
              "bbox": [
                418.57696533203125,
                188.97328186035156,
                515.5496215820312,
                352.77239990234375
              ]
            }
          ],
          "unique_tracks": [
            112,
            113,
            110,
            48,
            114
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            1356,
            1360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1361,
            1365
          ],
          "representative_frame": 1361,
          "detections": [
            {
              "track_id": 3,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.41937923431396484,
              "bbox": [
                0.0,
                122.24920654296875,
                244.607177734375,
                356.48590087890625
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1366,
            1370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1371,
            1375
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.6339063048362732,
              "bbox": [
                18.27069664001465,
                183.6302490234375,
                219.60891723632812,
                356.525634765625
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1376,
            1380
          ],
          "representative_frame": 1376,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 11
    },
    {
      "second": 46,
      "time_range": [
        46,
        46.999
      ],
      "frame_range": [
        1381,
        1410
      ],
      "unified_description": "3rd person perspective of a plane flying over snowy mountains and green valleys. The camera captures the scenic views from the airplane window, making it an amazing visual experience.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:43",
        "processing_time": 3.21,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1395,
          "frame_range": [
            1391,
            1395
          ],
          "description": "a view from a plane of mountains and clouds",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.91
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1381,
            1385
          ],
          "representative_frame": 1381,
          "detections": [
            {
              "track_id": 3,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.7297350168228149,
              "bbox": [
                0.0,
                93.86195373535156,
                266.9787902832031,
                355.5594787597656
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1386,
            1390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1391,
            1395
          ],
          "representative_frame": 1391,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            1396,
            1400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1401,
            1405
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5099807977676392,
              "bbox": [
                0.0,
                92.57064056396484,
                255.88975524902344,
                355.0616149902344
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1406,
            1410
          ],
          "representative_frame": 1406,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 11
    },
    {
      "second": 47,
      "time_range": [
        47,
        47.999
      ],
      "frame_range": [
        1411,
        1440
      ],
      "unified_description": "1 second long video showing a person flying a plane over a mountain range with wide-angle distortion",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:45",
        "processing_time": 3.53,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1425,
          "frame_range": [
            1421,
            1425
          ],
          "description": "a person flying a small plane over a mountain",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.7
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1411,
            1415
          ],
          "representative_frame": 1411,
          "detections": [
            {
              "track_id": 3,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5152395367622375,
              "bbox": [
                0.0,
                133.23231506347656,
                233.85330200195312,
                355.2611083984375
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1416,
            1420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1421,
            1425
          ],
          "representative_frame": 1421,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            1426,
            1430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1431,
            1435
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            1436,
            1440
          ],
          "representative_frame": 1436,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 11
    },
    {
      "second": 48,
      "time_range": [
        48,
        48.999
      ],
      "frame_range": [
        1441,
        1470
      ],
      "unified_description": "1 second long shot of some plants and snowy mountains seen from above with a fisheye lens giving a wider view of the area.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:46",
        "processing_time": 3.37,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1455,
          "frame_range": [
            1451,
            1455
          ],
          "description": "a view of the mountains from a helicopter",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.85
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1441,
            1445
          ],
          "representative_frame": 1441,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            1446,
            1450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1451,
            1455
          ],
          "representative_frame": 1451,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            1456,
            1460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1461,
            1465
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8041397333145142,
              "bbox": [
                10.794692993164062,
                167.18621826171875,
                220.63255310058594,
                356.5886535644531
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1466,
            1470
          ],
          "representative_frame": 1466,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 12
    },
    {
      "second": 49,
      "time_range": [
        49,
        49.999
      ],
      "frame_range": [
        1471,
        1500
      ],
      "unified_description": " The image features a pilot inside a small plane, flying in front of a beautiful snowy mountain range. The camera's perspective is from within the airplane, providing an immersive experience for the viewer. The pilot seems focused on navigating the aircraft, while the stunning landscape unfolds before him.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:48",
        "processing_time": 3.49,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1485,
          "frame_range": [
            1481,
            1485
          ],
          "description": "a man in a helicopter flying over a mountain range",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.09
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1471,
            1475
          ],
          "representative_frame": 1471,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7743139266967773,
              "bbox": [
                8.116621017456055,
                164.71157836914062,
                223.4063262939453,
                357.06982421875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1476,
            1480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1481,
            1485
          ],
          "representative_frame": 1481,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6361581087112427,
              "bbox": [
                7.244763374328613,
                154.86355590820312,
                235.39974975585938,
                356.99786376953125
              ]
            },
            {
              "track_id": 48,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.5360214710235596,
              "bbox": [
                83.12989044189453,
                1.7215226888656616,
                548.2005004882812,
                354.775390625
              ]
            }
          ],
          "unique_tracks": [
            3,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1486,
            1490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1491,
            1495
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            1496,
            1500
          ],
          "representative_frame": 1496,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 12
    },
    {
      "second": 50,
      "time_range": [
        50,
        50.999
      ],
      "frame_range": [
        1501,
        1530
      ],
      "unified_description": "\nThis is an image with a green background showing a mountainous area from the sky. It appears to be taken from inside a plane or cockpit, as there is no camera movement visible. The camera captures a wide-angle view of the landscape, which includes mountains and possibly some wildlife or structures. There are no people or specific objects identified in this image description.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:50",
        "processing_time": 4.24,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1515,
          "frame_range": [
            1511,
            1515
          ],
          "description": "a view from the cockpit of a plane flying over a mountain range",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.25
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1501,
            1505
          ],
          "representative_frame": 1501,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            1506,
            1510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1511,
            1515
          ],
          "representative_frame": 1511,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            1516,
            1520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1521,
            1525
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            1526,
            1530
          ],
          "representative_frame": 1526,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 12
    },
    {
      "second": 51,
      "time_range": [
        51,
        51.999
      ],
      "frame_range": [
        1531,
        1560
      ],
      "unified_description": "15 seconds of footage from a first-person perspective inside a small airplane with a pilot flying the plane while wearing headphones. There is also a passenger sitting in the back, wearing a red jacket.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:52",
        "processing_time": 4.7,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1545,
          "frame_range": [
            1541,
            1545
          ],
          "description": "a man in a red jacket sitting in a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.87
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1531,
            1535
          ],
          "representative_frame": 1531,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9128912687301636,
              "bbox": [
                34.535057067871094,
                56.675140380859375,
                425.00604248046875,
                354.9708251953125
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1536,
            1540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1541,
            1545
          ],
          "representative_frame": 1541,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9326964020729065,
              "bbox": [
                29.793556213378906,
                56.890541076660156,
                417.3328552246094,
                355.4065856933594
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1546,
            1550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1551,
            1555
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9084623456001282,
              "bbox": [
                30.30622100830078,
                58.11406707763672,
                414.5068359375,
                355.4123840332031
              ]
            },
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.3616137206554413,
              "bbox": [
                1.711875319480896,
                0.724285900592804,
                636.4650268554688,
                354.99810791015625
              ]
            }
          ],
          "unique_tracks": [
            48,
            121
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1556,
            1560
          ],
          "representative_frame": 1556,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 12
    },
    {
      "second": 52,
      "time_range": [
        52,
        52.999
      ],
      "frame_range": [
        1561,
        1590
      ],
      "unified_description": "1 second long shot of a plane in front of some water. The camera is mounted on top of a person's head.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:53",
        "processing_time": 3.41,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1575,
          "frame_range": [
            1571,
            1575
          ],
          "description": "a view from the cockpit of a plane flying over a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.49
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1561,
            1565
          ],
          "representative_frame": 1561,
          "detections": [
            {
              "track_id": 3,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.7641370892524719,
              "bbox": [
                68.38529205322266,
                182.20022583007812,
                296.83538818359375,
                357.7548828125
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1566,
            1570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1571,
            1575
          ],
          "representative_frame": 1571,
          "detections": [
            {
              "track_id": 3,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5515680909156799,
              "bbox": [
                60.563690185546875,
                184.94573974609375,
                306.8101501464844,
                357.45263671875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1576,
            1580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1581,
            1585
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.4477342665195465,
              "bbox": [
                52.98480224609375,
                185.54623413085938,
                314.8492126464844,
                357.53814697265625
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1586,
            1590
          ],
          "representative_frame": 1586,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 13
    },
    {
      "second": 53,
      "time_range": [
        53,
        53.999
      ],
      "frame_range": [
        1591,
        1620
      ],
      "unified_description": "360-degree footage from a plane flying over a blue lake with green mountains in the background. The camera is stable, capturing the stunning landscape with no distortion.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:55",
        "processing_time": 3.37,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1605,
          "frame_range": [
            1601,
            1605
          ],
          "description": "a view of a lake from a plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.15
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1591,
            1595
          ],
          "representative_frame": 1591,
          "detections": [
            {
              "track_id": 3,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.5683962106704712,
              "bbox": [
                39.93559265136719,
                195.75331115722656,
                294.900634765625,
                356.5185546875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1596,
            1600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1601,
            1605
          ],
          "representative_frame": 1601,
          "detections": [
            {
              "track_id": 3,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.22840572893619537,
              "bbox": [
                30.68511199951172,
                195.9065399169922,
                292.258056640625,
                356.3437805175781
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1606,
            1610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1611,
            1615
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.14609722793102264,
              "bbox": [
                26.927858352661133,
                195.0997772216797,
                296.4219970703125,
                356.3738708496094
              ]
            },
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.418343722820282,
              "bbox": [
                55.46068572998047,
                62.78260803222656,
                584.7555541992188,
                353.894775390625
              ]
            }
          ],
          "unique_tracks": [
            3,
            121
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1616,
            1620
          ],
          "representative_frame": 1616,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 13
    },
    {
      "second": 54,
      "time_range": [
        54,
        54.999
      ],
      "frame_range": [
        1621,
        1650
      ],
      "unified_description": " A GoPro camera is capturing the view from inside an airplane flying over a beautiful lake with mountains in the background. The camera is stable, providing a clear view of the stunning scenery as the plane soars through the sky.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:56",
        "processing_time": 3.44,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1635,
          "frame_range": [
            1631,
            1635
          ],
          "description": "a plane flying over a lake with mountains in the background",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.21
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1621,
            1625
          ],
          "representative_frame": 1621,
          "detections": [
            {
              "track_id": 3,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.5319925546646118,
              "bbox": [
                23.870302200317383,
                195.02940368652344,
                299.036865234375,
                356.3641357421875
              ]
            }
          ],
          "unique_tracks": [
            3
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1626,
            1630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1631,
            1635
          ],
          "representative_frame": 1631,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            1636,
            1640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1641,
            1645
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.34259098768234253,
              "bbox": [
                72.42491912841797,
                90.52935028076172,
                568.767822265625,
                355.9801025390625
              ]
            }
          ],
          "unique_tracks": [
            121
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1646,
            1650
          ],
          "representative_frame": 1646,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 13
    },
    {
      "second": 55,
      "time_range": [
        55,
        55.999
      ],
      "frame_range": [
        1651,
        1680
      ],
      "unified_description": "1-second scene showing a aircraft with a camera mounted on its wings, capturing a beautiful view of a lake and mountains in the background.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:58",
        "processing_time": 3.39,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1665,
          "frame_range": [
            1661,
            1665
          ],
          "description": "a plane flying over a lake with mountains in the background",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.31
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1651,
            1655
          ],
          "representative_frame": 1651,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.32329121232032776,
              "bbox": [
                69.59049987792969,
                94.31462097167969,
                571.68115234375,
                355.769287109375
              ]
            }
          ],
          "unique_tracks": [
            121
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1656,
            1660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1661,
            1665
          ],
          "representative_frame": 1661,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.4359983503818512,
              "bbox": [
                12.205412864685059,
                30.75732421875,
                630.958984375,
                354.88165283203125
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8975052237510681,
              "bbox": [
                0.0,
                3.0978105068206787,
                412.4405212402344,
                355.9831848144531
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1666,
            1670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1671,
            1675
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5712747573852539,
              "bbox": [
                0.0,
                10.012201309204102,
                640.0,
                356.6912536621094
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9098714590072632,
              "bbox": [
                0.0,
                1.2954285144805908,
                407.68682861328125,
                356.0461730957031
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1676,
            1680
          ],
          "representative_frame": 1676,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 13
    },
    {
      "second": 56,
      "time_range": [
        56,
        56.999
      ],
      "frame_range": [
        1681,
        1710
      ],
      "unified_description": "10-second descriptions for each image are needed.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:26:59",
        "processing_time": 3.07,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1695,
          "frame_range": [
            1691,
            1695
          ],
          "description": "a man in a helicopter flying over a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.94
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1681,
            1685
          ],
          "representative_frame": 1681,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5304250717163086,
              "bbox": [
                0.0,
                0.9780318140983582,
                640.0,
                355.1016845703125
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8931311368942261,
              "bbox": [
                0.0,
                0.05703241378068924,
                402.8431396484375,
                356.2828369140625
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1686,
            1690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1691,
            1695
          ],
          "representative_frame": 1691,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6831372976303101,
              "bbox": [
                0.0,
                0.0,
                640.0,
                357.83197021484375
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8968839049339294,
              "bbox": [
                0.0,
                1.0944640636444092,
                388.2347412109375,
                356.10888671875
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1696,
            1700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1701,
            1705
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6843818426132202,
              "bbox": [
                0.0,
                0.0,
                640.0,
                358.4370422363281
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6122840642929077,
              "bbox": [
                0.0,
                4.378411769866943,
                350.7844543457031,
                356.5342102050781
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1706,
            1710
          ],
          "representative_frame": 1706,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 14
    },
    {
      "second": 57,
      "time_range": [
        57,
        57.999
      ],
      "frame_range": [
        1711,
        1740
      ],
      "unified_description": "3rd person perspective showing a pilot inside the cockpit of a plane flying over a mountain lake.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:00",
        "processing_time": 2.79,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1725,
          "frame_range": [
            1721,
            1725
          ],
          "description": "a man in a boat is driving through the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.22
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1711,
            1715
          ],
          "representative_frame": 1711,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.5599175691604614,
              "bbox": [
                0.0,
                0.0,
                640.0,
                357.8301696777344
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8221911191940308,
              "bbox": [
                0.0,
                4.14647102355957,
                292.3579406738281,
                356.1755676269531
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1716,
            1720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1721,
            1725
          ],
          "representative_frame": 1721,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.7387955188751221,
              "bbox": [
                0.0,
                0.0,
                640.0,
                357.4888610839844
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8013911247253418,
              "bbox": [
                0.0,
                2.4920060634613037,
                268.0464782714844,
                356.30401611328125
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1726,
            1730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1731,
            1735
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.37393587827682495,
              "bbox": [
                0.0,
                0.0,
                640.0,
                359.1510925292969
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8755959868431091,
              "bbox": [
                6.433385848999023,
                21.71407127380371,
                349.4649963378906,
                356.1229248046875
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1736,
            1740
          ],
          "representative_frame": 1736,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 14
    },
    {
      "second": 58,
      "time_range": [
        58,
        58.999
      ],
      "frame_range": [
        1741,
        1770
      ],
      "unified_description": "1-second scene featuring a man wearing a hat, potentially flying a plane or driving a boat. The camera perspective suggests that it could be a first-person POV shot. The image also includes a river, trees in the background, and possibly some gauges or controls inside the vehicle.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:02",
        "processing_time": 3.58,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1755,
          "frame_range": [
            1751,
            1755
          ],
          "description": "a man driving a boat on a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.94
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1741,
            1745
          ],
          "representative_frame": 1741,
          "detections": [
            {
              "track_id": 121,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.3480805456638336,
              "bbox": [
                0.0,
                0.0,
                640.0,
                357.5541687011719
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8369372487068176,
              "bbox": [
                39.82158660888672,
                29.022722244262695,
                387.4574890136719,
                355.8851318359375
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1746,
            1750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1751,
            1755
          ],
          "representative_frame": 1751,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.41212183237075806,
              "bbox": [
                0.0,
                0.0,
                640.0,
                357.69720458984375
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.813713014125824,
              "bbox": [
                54.88113784790039,
                31.816152572631836,
                409.0594177246094,
                356.5003662109375
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1756,
            1760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1761,
            1765
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.6882051229476929,
              "bbox": [
                0.0,
                0.0,
                640.0,
                357.72479248046875
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8257938623428345,
              "bbox": [
                61.6785888671875,
                34.05045700073242,
                421.20306396484375,
                357.2504577636719
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1766,
            1770
          ],
          "representative_frame": 1766,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 14
    },
    {
      "second": 59,
      "time_range": [
        59,
        59.999
      ],
      "frame_range": [
        1771,
        1800
      ],
      "unified_description": "1-second scene with a person inside a vehicle looking out. The video was captured using a wide-angle lens, which creates some distortion. There is a dashboard view, indicating that the person could be in a car or an airplane.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:04",
        "processing_time": 4.48,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1785,
          "frame_range": [
            1781,
            1785
          ],
          "description": "a man in a helicopter cockpit is seen",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.61
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1771,
            1775
          ],
          "representative_frame": 1771,
          "detections": [
            {
              "track_id": 121,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.32933294773101807,
              "bbox": [
                0.0,
                0.0,
                640.0,
                355.4688415527344
              ]
            },
            {
              "track_id": 48,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.44227513670921326,
              "bbox": [
                71.35173797607422,
                62.060970306396484,
                405.237548828125,
                355.5450744628906
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1776,
            1780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1781,
            1785
          ],
          "representative_frame": 1781,
          "detections": [
            {
              "track_id": 121,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.23559793829917908,
              "bbox": [
                0.0,
                0.0,
                640.0,
                355.029296875
              ]
            },
            {
              "track_id": 48,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.6845037937164307,
              "bbox": [
                80.79144287109375,
                82.53164672851562,
                395.60321044921875,
                355.8221435546875
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            1786,
            1790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1791,
            1795
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.5150527954101562,
              "bbox": [
                0.0,
                0.0,
                640.0,
                355.4632263183594
              ]
            },
            {
              "track_id": 48,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.6483159065246582,
              "bbox": [
                87.00277709960938,
                86.59201049804688,
                395.13018798828125,
                356.2709655761719
              ]
            }
          ],
          "unique_tracks": [
            121,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1796,
            1800
          ],
          "representative_frame": 1796,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 14
    },
    {
      "second": 60,
      "time_range": [
        60,
        60.999
      ],
      "frame_range": [
        1801,
        1830
      ],
      "unified_description": "3rd person perspective of a man standing behind a helicopter. The camera is mounted on the persons body, capturing the surrounding area.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:05",
        "processing_time": 3.84,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1815,
          "frame_range": [
            1811,
            1815
          ],
          "description": "a man in a gray jacket is standing next to a helicopter",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1801,
            1805
          ],
          "representative_frame": 1801,
          "detections": [
            {
              "track_id": 121,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9180534482002258,
              "bbox": [
                0.0,
                0.0,
                587.6270141601562,
                355.94378662109375
              ]
            }
          ],
          "unique_tracks": [
            121
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1806,
            1810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1811,
            1815
          ],
          "representative_frame": 1811,
          "detections": [
            {
              "track_id": 121,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9088388681411743,
              "bbox": [
                0.0,
                0.0,
                565.3617553710938,
                356.2378234863281
              ]
            }
          ],
          "unique_tracks": [
            121
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1816,
            1820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1821,
            1825
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9305567741394043,
              "bbox": [
                0.0,
                0.0,
                551.4478759765625,
                354.95428466796875
              ]
            }
          ],
          "unique_tracks": [
            121
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            1826,
            1830
          ],
          "representative_frame": 1826,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 15
    },
    {
      "second": 61,
      "time_range": [
        61,
        61.999
      ],
      "frame_range": [
        1831,
        1860
      ],
      "unified_description": "\nA man wearing glasses stands near the rear door of a small blue plane. The camera captures the scene from his point of view, showing the plane's number 7373. Another person can be seen in the background by the water, likely admiring the aircraft or preparing for departure.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:07",
        "processing_time": 4.0,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1845,
          "frame_range": [
            1841,
            1845
          ],
          "description": "a man standing next to a small plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1831,
            1835
          ],
          "representative_frame": 1831,
          "detections": [
            {
              "track_id": 121,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9257261157035828,
              "bbox": [
                0.0,
                0.0,
                557.80029296875,
                355.4994201660156
              ]
            }
          ],
          "unique_tracks": [
            121
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            1836,
            1840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1841,
            1845
          ],
          "representative_frame": 1841,
          "detections": [
            {
              "track_id": 121,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9214940071105957,
              "bbox": [
                48.059715270996094,
                0.0,
                611.2232055664062,
                356.077880859375
              ]
            }
          ],
          "unique_tracks": [
            121
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1846,
            1850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1851,
            1855
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 121,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9004103541374207,
              "bbox": [
                94.85189056396484,
                0.0,
                633.7464599609375,
                355.4883117675781
              ]
            },
            {
              "track_id": 128,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8642022609710693,
              "bbox": [
                519.1221313476562,
                192.46951293945312,
                632.4073486328125,
                356.2220153808594
              ]
            },
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.500272274017334,
              "bbox": [
                46.808719635009766,
                42.988746643066406,
                588.9891967773438,
                304.3181457519531
              ]
            }
          ],
          "unique_tracks": [
            121,
            128,
            130
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            1856,
            1860
          ],
          "representative_frame": 1856,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 15
    },
    {
      "second": 62,
      "time_range": [
        62,
        62.999
      ],
      "frame_range": [
        1861,
        1890
      ],
      "unified_description": "45 seconds of footage featuring a man with glasses and a hat standing in front of a small airplane. He appears to be smiling, possibly excited about flying the plane. The image captures the outdoor setting, providing an interesting glimpse into aviation.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:09",
        "processing_time": 3.59,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1875,
          "frame_range": [
            1871,
            1875
          ],
          "description": "a man in a hat is standing next to a small plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.47
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1861,
            1865
          ],
          "representative_frame": 1861,
          "detections": [
            {
              "track_id": 121,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8979006409645081,
              "bbox": [
                100.58441162109375,
                0.0,
                622.3289184570312,
                356.1247253417969
              ]
            },
            {
              "track_id": 128,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.877699613571167,
              "bbox": [
                515.0408935546875,
                173.70494079589844,
                637.681640625,
                351.4117431640625
              ]
            },
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.30328747630119324,
              "bbox": [
                67.2309341430664,
                50.779937744140625,
                564.1061401367188,
                288.8639831542969
              ]
            }
          ],
          "unique_tracks": [
            121,
            128,
            130
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            1866,
            1870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1871,
            1875
          ],
          "representative_frame": 1871,
          "detections": [
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6040440797805786,
              "bbox": [
                217.2530517578125,
                167.39427185058594,
                467.57171630859375,
                356.7561950683594
              ]
            }
          ],
          "unique_tracks": [
            48
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1876,
            1880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1881,
            1885
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 132,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8131746649742126,
              "bbox": [
                457.86553955078125,
                90.7493667602539,
                498.9342041015625,
                237.4746856689453
              ]
            },
            {
              "track_id": 133,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.747818648815155,
              "bbox": [
                386.780029296875,
                117.98299407958984,
                442.63751220703125,
                269.6085205078125
              ]
            },
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8636714816093445,
              "bbox": [
                225.323486328125,
                181.04257202148438,
                483.30584716796875,
                356.5353088378906
              ]
            },
            {
              "track_id": 121,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5083884596824646,
              "bbox": [
                131.54290771484375,
                4.703818321228027,
                510.57891845703125,
                236.8939971923828
              ]
            }
          ],
          "unique_tracks": [
            132,
            133,
            48,
            121
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            1886,
            1890
          ],
          "representative_frame": 1886,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 15
    },
    {
      "second": 63,
      "time_range": [
        63,
        63.999
      ],
      "frame_range": [
        1891,
        1920
      ],
      "unified_description": "4 people on a raft next to a large blue and white plane",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:10",
        "processing_time": 3.06,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1905,
          "frame_range": [
            1901,
            1905
          ],
          "description": "a man in a canoe is getting ready to go into the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.56
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1891,
            1895
          ],
          "representative_frame": 1891,
          "detections": [
            {
              "track_id": 132,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.811413586139679,
              "bbox": [
                459.2018737792969,
                89.3643569946289,
                500.730224609375,
                237.1105499267578
              ]
            },
            {
              "track_id": 133,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7424004077911377,
              "bbox": [
                363.52734375,
                118.89751434326172,
                423.9377746582031,
                282.8595275878906
              ]
            },
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8219082951545715,
              "bbox": [
                211.04132080078125,
                179.67376708984375,
                492.84539794921875,
                357.0745544433594
              ]
            },
            {
              "track_id": 121,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.19659925997257233,
              "bbox": [
                137.842041015625,
                4.248417377471924,
                502.40130615234375,
                208.05767822265625
              ]
            }
          ],
          "unique_tracks": [
            132,
            133,
            48,
            121
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            1896,
            1900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1901,
            1905
          ],
          "representative_frame": 1901,
          "detections": [
            {
              "track_id": 132,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7679026126861572,
              "bbox": [
                459.9647521972656,
                90.38105773925781,
                502.73583984375,
                241.93902587890625
              ]
            },
            {
              "track_id": 133,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.816788375377655,
              "bbox": [
                328.3223571777344,
                124.17068481445312,
                392.37603759765625,
                297.5743713378906
              ]
            },
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6739115118980408,
              "bbox": [
                206.26980590820312,
                180.81605529785156,
                502.8556823730469,
                356.8876953125
              ]
            },
            {
              "track_id": 121,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.21520115435123444,
              "bbox": [
                123.90472412109375,
                2.666564464569092,
                504.87677001953125,
                201.22927856445312
              ]
            },
            {
              "track_id": 137,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6594936847686768,
              "bbox": [
                389.4112243652344,
                68.14448547363281,
                451.25592041015625,
                188.56997680664062
              ]
            }
          ],
          "unique_tracks": [
            132,
            133,
            48,
            121,
            137
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            1906,
            1910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1911,
            1915
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 133,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7527011632919312,
              "bbox": [
                330.3174743652344,
                109.80906677246094,
                389.6829833984375,
                268.37261962890625
              ]
            },
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7971479892730713,
              "bbox": [
                195.5067596435547,
                197.09481811523438,
                449.0273742675781,
                345.2774963378906
              ]
            }
          ],
          "unique_tracks": [
            133,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1916,
            1920
          ],
          "representative_frame": 1916,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 15
    },
    {
      "second": 64,
      "time_range": [
        64,
        64.999
      ],
      "frame_range": [
        1921,
        1950
      ],
      "unified_description": "1-second scene featuring people preparing to water ski, with a pontoon-style water craft on the left side of the image and a boat in the background. There are two men on the shore of a lake, one man standing in the water and another man standing on the pontoon-style water craft. The third man is wearing a red life jacket, standing on top of the water ski device as they get ready for the activity.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:12",
        "processing_time": 3.82,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1935,
          "frame_range": [
            1931,
            1935
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.09
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1921,
            1925
          ],
          "representative_frame": 1921,
          "detections": [
            {
              "track_id": 133,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8038236498832703,
              "bbox": [
                313.21405029296875,
                96.7351303100586,
                372.5220947265625,
                255.86656188964844
              ]
            },
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7544324398040771,
              "bbox": [
                189.26089477539062,
                202.32626342773438,
                429.27874755859375,
                340.80010986328125
              ]
            },
            {
              "track_id": 141,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7536445260047913,
              "bbox": [
                355.9966125488281,
                96.11700439453125,
                418.5552978515625,
                225.63369750976562
              ]
            },
            {
              "track_id": 121,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.46349403262138367,
              "bbox": [
                134.53036499023438,
                3.323387622833252,
                502.1375427246094,
                177.45108032226562
              ]
            }
          ],
          "unique_tracks": [
            133,
            48,
            141,
            121
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            1926,
            1930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1931,
            1935
          ],
          "representative_frame": 1931,
          "detections": [
            {
              "track_id": 133,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.815609872341156,
              "bbox": [
                293.0438537597656,
                90.77571868896484,
                356.2856140136719,
                260.904541015625
              ]
            },
            {
              "track_id": 48,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.8366308212280273,
              "bbox": [
                185.80673217773438,
                203.73829650878906,
                423.8319091796875,
                339.56512451171875
              ]
            },
            {
              "track_id": 141,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7960394620895386,
              "bbox": [
                356.70709228515625,
                96.18099975585938,
                420.98602294921875,
                230.08644104003906
              ]
            }
          ],
          "unique_tracks": [
            133,
            48,
            141
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            1936,
            1940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1941,
            1945
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8712595701217651,
              "bbox": [
                8.30463981628418,
                113.55229949951172,
                328.4906921386719,
                357.11138916015625
              ]
            },
            {
              "track_id": 130,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6066520810127258,
              "bbox": [
                74.54702758789062,
                0.3135709762573242,
                640.0,
                351.6548767089844
              ]
            }
          ],
          "unique_tracks": [
            3,
            130
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1946,
            1950
          ],
          "representative_frame": 1946,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 16
    },
    {
      "second": 65,
      "time_range": [
        65,
        65.999
      ],
      "frame_range": [
        1951,
        1980
      ],
      "unified_description": "4 people are visible in the image, with one person on a boat holding an orange canister.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:14",
        "processing_time": 3.62,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1965,
          "frame_range": [
            1961,
            1965
          ],
          "description": "a man is getting off the boat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.82
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1951,
            1955
          ],
          "representative_frame": 1951,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8886952996253967,
              "bbox": [
                35.912784576416016,
                113.07443237304688,
                302.60302734375,
                356.7803039550781
              ]
            },
            {
              "track_id": 130,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.7281893491744995,
              "bbox": [
                87.27653503417969,
                0.0,
                640.0,
                355.5985107421875
              ]
            }
          ],
          "unique_tracks": [
            3,
            130
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            1956,
            1960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1961,
            1965
          ],
          "representative_frame": 1961,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8806496262550354,
              "bbox": [
                59.41250991821289,
                114.56770324707031,
                297.20184326171875,
                356.7399597167969
              ]
            },
            {
              "track_id": 130,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.6560624241828918,
              "bbox": [
                20.94083595275879,
                0.0,
                640.0,
                358.2740478515625
              ]
            },
            {
              "track_id": 133,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.56175297498703,
              "bbox": [
                243.19776916503906,
                137.3643341064453,
                289.7925109863281,
                250.46376037597656
              ]
            }
          ],
          "unique_tracks": [
            3,
            130,
            133
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            1966,
            1970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            1971,
            1975
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5714382529258728,
              "bbox": [
                86.26166534423828,
                114.5246810913086,
                317.56768798828125,
                356.1006164550781
              ]
            },
            {
              "track_id": 130,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5274325013160706,
              "bbox": [
                0.0,
                0.0,
                640.0,
                358.25360107421875
              ]
            }
          ],
          "unique_tracks": [
            3,
            130
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            1976,
            1980
          ],
          "representative_frame": 1976,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 16
    },
    {
      "second": 66,
      "time_range": [
        66,
        66.999
      ],
      "frame_range": [
        1981,
        2010
      ],
      "unified_description": "\nA man stands on the side of a small white and blue airplane holding an orange tank, while preparing to disembark.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:15",
        "processing_time": 3.99,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 1995,
          "frame_range": [
            1991,
            1995
          ],
          "description": "a man is getting off the plane",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.66
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            1981,
            1985
          ],
          "representative_frame": 1981,
          "detections": [
            {
              "track_id": 3,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.69224613904953,
              "bbox": [
                91.72920989990234,
                117.39354705810547,
                311.58563232421875,
                355.2597961425781
              ]
            },
            {
              "track_id": 130,
              "class_id": 7,
              "class_name": "truck",
              "confidence": 0.4111415445804596,
              "bbox": [
                0.0,
                0.0,
                640.0,
                359.9459533691406
              ]
            },
            {
              "track_id": 153,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.3741980195045471,
              "bbox": [
                219.64031982421875,
                146.72964477539062,
                312.7154235839844,
                245.8067626953125
              ]
            }
          ],
          "unique_tracks": [
            3,
            130,
            153
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            1986,
            1990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            1991,
            1995
          ],
          "representative_frame": 1991,
          "detections": [
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.4043748676776886,
              "bbox": [
                13.991518020629883,
                33.72380828857422,
                636.0939331054688,
                357.78045654296875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            1996,
            2000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2001,
            2005
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.41043201088905334,
              "bbox": [
                26.658803939819336,
                51.71859359741211,
                619.2644653320312,
                356.6171875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2006,
            2010
          ],
          "representative_frame": 2006,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 16
    },
    {
      "second": 67,
      "time_range": [
        67,
        67.999
      ],
      "frame_range": [
        2011,
        2040
      ],
      "unified_description": "1-second scene featuring a small airplane that is sitting on the water. A rope is hanging from a hook next to the airplane.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:16",
        "processing_time": 2.93,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2025,
          "frame_range": [
            2021,
            2025
          ],
          "description": "a small plane is sitting on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.11
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2011,
            2015
          ],
          "representative_frame": 2011,
          "detections": [
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.3982805013656616,
              "bbox": [
                30.236989974975586,
                59.642696380615234,
                613.3746948242188,
                356.1400451660156
              ]
            },
            {
              "track_id": 158,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.3148951232433319,
              "bbox": [
                9.881368637084961,
                67.2349624633789,
                633.492431640625,
                241.36724853515625
              ]
            }
          ],
          "unique_tracks": [
            130,
            158
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2016,
            2020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2021,
            2025
          ],
          "representative_frame": 2021,
          "detections": [
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.2857315242290497,
              "bbox": [
                36.139095306396484,
                64.72673034667969,
                611.2516479492188,
                353.6015930175781
              ]
            },
            {
              "track_id": 158,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.3578837215900421,
              "bbox": [
                15.591707229614258,
                70.24768829345703,
                629.6786499023438,
                241.602294921875
              ]
            }
          ],
          "unique_tracks": [
            130,
            158
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2026,
            2030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2031,
            2035
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 158,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.4789198040962219,
              "bbox": [
                6.712647438049316,
                68.03528594970703,
                636.6856079101562,
                243.8211669921875
              ]
            }
          ],
          "unique_tracks": [
            158
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2036,
            2040
          ],
          "representative_frame": 2036,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 16
    },
    {
      "second": 68,
      "time_range": [
        68,
        68.999
      ],
      "frame_range": [
        2041,
        2070
      ],
      "unified_description": "30-second time-lapse shot of a seaplane on a lake on an overcast day.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:18",
        "processing_time": 3.21,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2055,
          "frame_range": [
            2051,
            2055
          ],
          "description": "a small plane is sitting on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.93
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2041,
            2045
          ],
          "representative_frame": 2041,
          "detections": [
            {
              "track_id": 158,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.47987091541290283,
              "bbox": [
                9.822996139526367,
                70.21369171142578,
                633.0535278320312,
                243.94419860839844
              ]
            }
          ],
          "unique_tracks": [
            158
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2046,
            2050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2051,
            2055
          ],
          "representative_frame": 2051,
          "detections": [
            {
              "track_id": 158,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.3774492144584656,
              "bbox": [
                0.0,
                36.45241928100586,
                640.0,
                244.78875732421875
              ]
            }
          ],
          "unique_tracks": [
            158
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2056,
            2060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2061,
            2065
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 158,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.534654974937439,
              "bbox": [
                0.0,
                15.329360008239746,
                640.0,
                250.2880401611328
              ]
            }
          ],
          "unique_tracks": [
            158
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2066,
            2070
          ],
          "representative_frame": 2066,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 17
    },
    {
      "second": 69,
      "time_range": [
        69,
        69.999
      ],
      "frame_range": [
        2071,
        2100
      ],
      "unified_description": "1 second video showing a blue and white airplane that is sitting on the water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:19",
        "processing_time": 3.48,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2085,
          "frame_range": [
            2081,
            2085
          ],
          "description": "a small plane is sitting on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2071,
            2075
          ],
          "representative_frame": 2071,
          "detections": [
            {
              "track_id": 158,
              "class_id": 8,
              "class_name": "boat",
              "confidence": 0.5101149678230286,
              "bbox": [
                0.0,
                1.9225397109985352,
                640.0,
                237.02029418945312
              ]
            }
          ],
          "unique_tracks": [
            158
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2076,
            2080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2081,
            2085
          ],
          "representative_frame": 2081,
          "detections": [
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.8640574812889099,
              "bbox": [
                0.0,
                5.0422539710998535,
                640.0,
                343.2922058105469
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2086,
            2090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2091,
            2095
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.9059922695159912,
              "bbox": [
                1.8890973329544067,
                1.7238601446151733,
                639.4844360351562,
                322.9095153808594
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2096,
            2100
          ],
          "representative_frame": 2096,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 17
    },
    {
      "second": 70,
      "time_range": [
        70,
        70.999
      ],
      "frame_range": [
        2101,
        2130
      ],
      "unified_description": "10 second video of a man looking out over a body of water, possibly a lake or ocean.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:21",
        "processing_time": 3.03,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2115,
          "frame_range": [
            2111,
            2115
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.1
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2101,
            2105
          ],
          "representative_frame": 2101,
          "detections": [
            {
              "track_id": 130,
              "class_id": 4,
              "class_name": "airplane",
              "confidence": 0.7743924856185913,
              "bbox": [
                22.318403244018555,
                0.0,
                600.6951904296875,
                285.95196533203125
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2106,
            2110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2111,
            2115
          ],
          "representative_frame": 2111,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9436278343200684,
              "bbox": [
                176.67913818359375,
                48.64300537109375,
                640.0,
                333.1921691894531
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2116,
            2120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2121,
            2125
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9443424344062805,
              "bbox": [
                241.0924835205078,
                65.50399017333984,
                640.0,
                349.2739562988281
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2126,
            2130
          ],
          "representative_frame": 2126,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 17
    },
    {
      "second": 71,
      "time_range": [
        71,
        71.999
      ],
      "frame_range": [
        2131,
        2160
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:22",
        "processing_time": 2.77,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2145,
          "frame_range": [
            2141,
            2145
          ],
          "description": "a man standing on a rock near a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.16
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2131,
            2135
          ],
          "representative_frame": 2131,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9474409222602844,
              "bbox": [
                272.5150146484375,
                71.66314697265625,
                640.0,
                355.1110534667969
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2136,
            2140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2141,
            2145
          ],
          "representative_frame": 2141,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9501105546951294,
              "bbox": [
                291.42303466796875,
                73.57957458496094,
                640.0,
                357.0924987792969
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2146,
            2150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2151,
            2155
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9437077641487122,
              "bbox": [
                305.5888977050781,
                75.01495361328125,
                640.0,
                357.6251525878906
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2156,
            2160
          ],
          "representative_frame": 2156,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 17
    },
    {
      "second": 72,
      "time_range": [
        72,
        72.999
      ],
      "frame_range": [
        2161,
        2190
      ],
      "unified_description": "3 people standing by a large body of water, likely a lake. The image is somewhat blurry, suggesting that it may have been taken with a slow shutter speed or in low light conditions.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:23",
        "processing_time": 3.17,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2175,
          "frame_range": [
            2171,
            2175
          ],
          "description": "a man in red raincoats standing on a rock near a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.28
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2161,
            2165
          ],
          "representative_frame": 2161,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9290874600410461,
              "bbox": [
                279.41796875,
                56.174198150634766,
                640.0,
                357.76324462890625
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2166,
            2170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2171,
            2175
          ],
          "representative_frame": 2171,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9451223015785217,
              "bbox": [
                279.6341857910156,
                46.42384719848633,
                640.0,
                357.7940368652344
              ]
            },
            {
              "track_id": 159,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.836891233921051,
              "bbox": [
                555.847412109375,
                192.6768798828125,
                636.0310668945312,
                358.0928039550781
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9184622764587402,
              "bbox": [
                36.981300354003906,
                216.1944122314453,
                262.2841491699219,
                358.7255859375
              ]
            }
          ],
          "unique_tracks": [
            130,
            159,
            48
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            2176,
            2180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2181,
            2185
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9370725750923157,
              "bbox": [
                298.1621398925781,
                45.07318878173828,
                640.0,
                357.7508239746094
              ]
            },
            {
              "track_id": 159,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8208936452865601,
              "bbox": [
                569.8671264648438,
                210.61160278320312,
                640.0,
                358.2608642578125
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9155217409133911,
              "bbox": [
                79.11206817626953,
                226.13414001464844,
                274.95208740234375,
                359.29852294921875
              ]
            }
          ],
          "unique_tracks": [
            130,
            159,
            48
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            2186,
            2190
          ],
          "representative_frame": 2186,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 18
    },
    {
      "second": 73,
      "time_range": [
        73,
        73.999
      ],
      "frame_range": [
        2191,
        2220
      ],
      "unified_description": "1-second video showing a family at a lake on an overcast day with dark skies, grey water, and muted colors.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:25",
        "processing_time": 3.32,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2205,
          "frame_range": [
            2201,
            2205
          ],
          "description": "a man and two children are standing near the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2191,
            2195
          ],
          "representative_frame": 2191,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9459744095802307,
              "bbox": [
                306.1728820800781,
                44.19963455200195,
                640.0,
                357.6835632324219
              ]
            },
            {
              "track_id": 159,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8395221829414368,
              "bbox": [
                577.4476318359375,
                212.13487243652344,
                640.0,
                357.6352233886719
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9284921288490295,
              "bbox": [
                87.78831481933594,
                221.5241241455078,
                281.13665771484375,
                359.2192077636719
              ]
            }
          ],
          "unique_tracks": [
            130,
            159,
            48
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            2196,
            2200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2201,
            2205
          ],
          "representative_frame": 2201,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.943558931350708,
              "bbox": [
                317.0716247558594,
                48.37803268432617,
                640.0,
                357.3912658691406
              ]
            },
            {
              "track_id": 159,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8098440170288086,
              "bbox": [
                578.3553466796875,
                213.75753784179688,
                640.0,
                357.940673828125
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9255026578903198,
              "bbox": [
                104.35200500488281,
                220.42494201660156,
                290.6184387207031,
                359.12481689453125
              ]
            }
          ],
          "unique_tracks": [
            130,
            159,
            48
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            2206,
            2210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2211,
            2215
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9430294632911682,
              "bbox": [
                334.5859069824219,
                48.85354995727539,
                640.0,
                357.3084716796875
              ]
            },
            {
              "track_id": 159,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7982245683670044,
              "bbox": [
                581.1873168945312,
                216.1580047607422,
                640.0,
                358.0632019042969
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9146209359169006,
              "bbox": [
                120.1544189453125,
                216.47894287109375,
                301.8125305175781,
                359.2085266113281
              ]
            }
          ],
          "unique_tracks": [
            130,
            159,
            48
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            2216,
            2220
          ],
          "representative_frame": 2216,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 18
    },
    {
      "second": 74,
      "time_range": [
        74,
        74.999
      ],
      "frame_range": [
        2221,
        2250
      ],
      "unified_description": "1-second scene showing a man standing by the water's edge on a cloudy day with a fishing rod in his hand. The camera is placed on a tripod for stability, capturing the scene in wide-angle perspective.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:27",
        "processing_time": 3.97,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2235,
          "frame_range": [
            2231,
            2235
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.83
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2221,
            2225
          ],
          "representative_frame": 2221,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9312692284584045,
              "bbox": [
                331.5435791015625,
                62.35675811767578,
                629.5634155273438,
                356.94342041015625
              ]
            },
            {
              "track_id": 159,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8966338038444519,
              "bbox": [
                584.8174438476562,
                169.5578155517578,
                640.0,
                298.1982116699219
              ]
            }
          ],
          "unique_tracks": [
            130,
            159
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2226,
            2230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2231,
            2235
          ],
          "representative_frame": 2231,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9074275493621826,
              "bbox": [
                353.89752197265625,
                65.70699310302734,
                637.71630859375,
                356.365966796875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2236,
            2240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2241,
            2245
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9336799383163452,
              "bbox": [
                374.54693603515625,
                64.27496337890625,
                640.0,
                356.3008728027344
              ]
            },
            {
              "track_id": 141,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8526765704154968,
              "bbox": [
                373.5523376464844,
                144.80780029296875,
                421.602783203125,
                250.9613494873047
              ]
            }
          ],
          "unique_tracks": [
            130,
            141
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            2246,
            2250
          ],
          "representative_frame": 2246,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 18
    },
    {
      "second": 75,
      "time_range": [
        75,
        75.999
      ],
      "frame_range": [
        2251,
        2280
      ],
      "unified_description": "\nA man is standing by the water with his hands in his pockets.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:28",
        "processing_time": 3.06,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2265,
          "frame_range": [
            2261,
            2265
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.29
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2251,
            2255
          ],
          "representative_frame": 2251,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9270318150520325,
              "bbox": [
                381.8365783691406,
                64.03545379638672,
                640.0,
                356.02008056640625
              ]
            },
            {
              "track_id": 163,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8348928093910217,
              "bbox": [
                336.2560119628906,
                148.6891326904297,
                371.0802001953125,
                257.58782958984375
              ]
            }
          ],
          "unique_tracks": [
            130,
            163
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2256,
            2260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2261,
            2265
          ],
          "representative_frame": 2261,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.935015857219696,
              "bbox": [
                386.4687194824219,
                68.45509338378906,
                640.0,
                356.44281005859375
              ]
            },
            {
              "track_id": 164,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7625415325164795,
              "bbox": [
                307.95684814453125,
                150.18099975585938,
                343.0332336425781,
                262.0874328613281
              ]
            }
          ],
          "unique_tracks": [
            130,
            164
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2266,
            2270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2271,
            2275
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.936265766620636,
              "bbox": [
                387.6820373535156,
                69.64028930664062,
                634.1973266601562,
                356.6624450683594
              ]
            },
            {
              "track_id": 164,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8922810554504395,
              "bbox": [
                292.157958984375,
                148.1251678466797,
                328.7057189941406,
                264.2711181640625
              ]
            }
          ],
          "unique_tracks": [
            130,
            164
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            2276,
            2280
          ],
          "representative_frame": 2276,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 18
    },
    {
      "second": 76,
      "time_range": [
        76,
        76.999
      ],
      "frame_range": [
        2281,
        2310
      ],
      "unified_description": "2 men are standing on a gravel shore beside a calm lake with trees in the background",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:29",
        "processing_time": 3.05,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2295,
          "frame_range": [
            2291,
            2295
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.26
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2281,
            2285
          ],
          "representative_frame": 2281,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9279900789260864,
              "bbox": [
                395.6746826171875,
                74.5311279296875,
                631.9458618164062,
                356.33367919921875
              ]
            },
            {
              "track_id": 164,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8501365780830383,
              "bbox": [
                294.91571044921875,
                155.10040283203125,
                327.3211975097656,
                258.11767578125
              ]
            },
            {
              "track_id": 153,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.79984050989151,
              "bbox": [
                237.2975311279297,
                150.66969299316406,
                337.26556396484375,
                276.0630187988281
              ]
            }
          ],
          "unique_tracks": [
            130,
            164,
            153
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            2286,
            2290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2291,
            2295
          ],
          "representative_frame": 2291,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9332036972045898,
              "bbox": [
                403.8307800292969,
                79.4061508178711,
                631.4349365234375,
                356.4385681152344
              ]
            },
            {
              "track_id": 164,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8605124354362488,
              "bbox": [
                279.35882568359375,
                158.15675354003906,
                311.830810546875,
                261.0487060546875
              ]
            },
            {
              "track_id": 153,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8520857691764832,
              "bbox": [
                226.71009826660156,
                154.38241577148438,
                319.5551452636719,
                283.5971374511719
              ]
            }
          ],
          "unique_tracks": [
            130,
            164,
            153
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            2296,
            2300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2301,
            2305
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9239043593406677,
              "bbox": [
                399.5970458984375,
                76.26287841796875,
                624.7879028320312,
                356.634521484375
              ]
            },
            {
              "track_id": 164,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.877282440662384,
              "bbox": [
                266.01837158203125,
                156.7931671142578,
                299.10809326171875,
                261.3094482421875
              ]
            },
            {
              "track_id": 153,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9058433175086975,
              "bbox": [
                205.6160430908203,
                155.28985595703125,
                294.0165710449219,
                290.60394287109375
              ]
            }
          ],
          "unique_tracks": [
            130,
            164,
            153
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            2306,
            2310
          ],
          "representative_frame": 2306,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 19
    },
    {
      "second": 77,
      "time_range": [
        77,
        77.999
      ],
      "frame_range": [
        2311,
        2340
      ],
      "unified_description": "1-second video with a father and son on the beach.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:31",
        "processing_time": 2.9,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2325,
          "frame_range": [
            2321,
            2325
          ],
          "description": "a man and a little girl are standing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.07
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2311,
            2315
          ],
          "representative_frame": 2311,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9310140609741211,
              "bbox": [
                379.52435302734375,
                72.35098266601562,
                603.7888793945312,
                356.7894592285156
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8600950837135315,
              "bbox": [
                144.95802307128906,
                234.91738891601562,
                300.2633056640625,
                358.78759765625
              ]
            }
          ],
          "unique_tracks": [
            130,
            48
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2316,
            2320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2321,
            2325
          ],
          "representative_frame": 2321,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9202433228492737,
              "bbox": [
                383.6749267578125,
                73.42646026611328,
                603.5533447265625,
                356.5672607421875
              ]
            },
            {
              "track_id": 168,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9443598389625549,
              "bbox": [
                300.8970947265625,
                190.14781188964844,
                388.93719482421875,
                358.56158447265625
              ]
            },
            {
              "track_id": 48,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.24378542602062225,
              "bbox": [
                155.38900756835938,
                266.3939208984375,
                279.2841491699219,
                358.8216552734375
              ]
            }
          ],
          "unique_tracks": [
            130,
            168,
            48
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            2326,
            2330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2331,
            2335
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9171761870384216,
              "bbox": [
                386.24932861328125,
                78.96247100830078,
                598.8711547851562,
                356.5586242675781
              ]
            },
            {
              "track_id": 168,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9393736720085144,
              "bbox": [
                294.3547668457031,
                190.32313537597656,
                382.0198059082031,
                358.6701965332031
              ]
            }
          ],
          "unique_tracks": [
            130,
            168
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            2336,
            2340
          ],
          "representative_frame": 2336,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 19
    },
    {
      "second": 78,
      "time_range": [
        78,
        78.999
      ],
      "frame_range": [
        2341,
        2370
      ],
      "unified_description": "48-hour timelapse of a man and boy on the beach.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:32",
        "processing_time": 3.07,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2355,
          "frame_range": [
            2351,
            2355
          ],
          "description": "a man and a little girl are standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.16
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2341,
            2345
          ],
          "representative_frame": 2341,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9273861050605774,
              "bbox": [
                385.908935546875,
                85.47413635253906,
                591.3582763671875,
                356.4824523925781
              ]
            },
            {
              "track_id": 168,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9235483407974243,
              "bbox": [
                305.2403564453125,
                193.32510375976562,
                390.9612731933594,
                358.7190246582031
              ]
            }
          ],
          "unique_tracks": [
            130,
            168
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2346,
            2350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2351,
            2355
          ],
          "representative_frame": 2351,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9350325465202332,
              "bbox": [
                376.4366760253906,
                90.09698486328125,
                576.42138671875,
                356.71258544921875
              ]
            },
            {
              "track_id": 168,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9204655885696411,
              "bbox": [
                317.381591796875,
                193.28457641601562,
                402.53564453125,
                358.6380310058594
              ]
            }
          ],
          "unique_tracks": [
            130,
            168
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2356,
            2360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2361,
            2365
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9244393110275269,
              "bbox": [
                354.385009765625,
                93.27763366699219,
                550.5554809570312,
                356.9371032714844
              ]
            },
            {
              "track_id": 168,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8888822793960571,
              "bbox": [
                317.9443359375,
                197.91659545898438,
                399.8896484375,
                357.88775634765625
              ]
            }
          ],
          "unique_tracks": [
            130,
            168
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            2366,
            2370
          ],
          "representative_frame": 2366,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 19
    },
    {
      "second": 79,
      "time_range": [
        79,
        79.999
      ],
      "frame_range": [
        2371,
        2400
      ],
      "unified_description": "\nA man stands on the shoreline of a calm lake with his young daughter. They are positioned near the center of the image, which seems to be shot in a wide-angle perspective. The man appears to be wearing a hat, and both he and the girl are dressed for the outdoors. There is a backpack and two bicycles located on the right side of the frame, suggesting that they may have been used to travel to this picturesque location.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:34",
        "processing_time": 4.15,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2385,
          "frame_range": [
            2381,
            2385
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2371,
            2375
          ],
          "representative_frame": 2371,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.884158730506897,
              "bbox": [
                337.9773254394531,
                92.29322814941406,
                533.163330078125,
                357.2174072265625
              ]
            },
            {
              "track_id": 168,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8589947819709778,
              "bbox": [
                315.1000671386719,
                202.00025939941406,
                393.97125244140625,
                356.9880065917969
              ]
            }
          ],
          "unique_tracks": [
            130,
            168
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2376,
            2380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2381,
            2385
          ],
          "representative_frame": 2381,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.887614369392395,
              "bbox": [
                331.00762939453125,
                92.1407699584961,
                524.8900756835938,
                357.1265869140625
              ]
            },
            {
              "track_id": 168,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6064786911010742,
              "bbox": [
                322.2725830078125,
                204.34837341308594,
                395.76434326171875,
                349.9927062988281
              ]
            }
          ],
          "unique_tracks": [
            130,
            168
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2386,
            2390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2391,
            2395
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9048250913619995,
              "bbox": [
                327.0128173828125,
                92.12805938720703,
                519.554931640625,
                356.5379638671875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2396,
            2400
          ],
          "representative_frame": 2396,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 19
    },
    {
      "second": 80,
      "time_range": [
        80,
        80.999
      ],
      "frame_range": [
        2401,
        2430
      ],
      "unified_description": "365 days ago, someone captured this scene where a man is standing on a rocky shore next to a body of water. The camera was stable, with a wide-angle lens capturing the beautiful landscape and the man wearing glasses. This footage could be part of a travel vlog or a hiking adventure.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:36",
        "processing_time": 4.25,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2415,
          "frame_range": [
            2411,
            2415
          ],
          "description": "a man standing on a rocky shore next to a body of water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.3
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2401,
            2405
          ],
          "representative_frame": 2401,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.952565610408783,
              "bbox": [
                282.8898620605469,
                50.76057815551758,
                501.98492431640625,
                356.3726501464844
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2406,
            2410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2411,
            2415
          ],
          "representative_frame": 2411,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.949283242225647,
              "bbox": [
                266.42095947265625,
                34.868282318115234,
                493.615478515625,
                356.2581787109375
              ]
            },
            {
              "track_id": 170,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8035388588905334,
              "bbox": [
                527.0003051757812,
                189.65060424804688,
                549.0473022460938,
                255.51986694335938
              ]
            }
          ],
          "unique_tracks": [
            130,
            170
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2416,
            2420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2421,
            2425
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9481241703033447,
              "bbox": [
                264.1548156738281,
                29.153759002685547,
                493.78131103515625,
                356.20123291015625
              ]
            },
            {
              "track_id": 170,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7952952980995178,
              "bbox": [
                528.04833984375,
                189.59915161132812,
                549.9049682617188,
                254.9589385986328
              ]
            }
          ],
          "unique_tracks": [
            130,
            170
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            2426,
            2430
          ],
          "representative_frame": 2426,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 20
    },
    {
      "second": 81,
      "time_range": [
        81,
        81.999
      ],
      "frame_range": [
        2431,
        2460
      ],
      "unified_description": "\nA man with glasses is standing near water wearing a green jacket and hat. There is also another person in an orange jacket nearby.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:38",
        "processing_time": 4.17,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2445,
          "frame_range": [
            2441,
            2445
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.21
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2431,
            2435
          ],
          "representative_frame": 2431,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9524813294410706,
              "bbox": [
                258.1348571777344,
                33.9041862487793,
                486.3974609375,
                356.71380615234375
              ]
            },
            {
              "track_id": 170,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8393930792808533,
              "bbox": [
                530.9749145507812,
                189.16429138183594,
                552.6739501953125,
                254.09877014160156
              ]
            }
          ],
          "unique_tracks": [
            130,
            170
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2436,
            2440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2441,
            2445
          ],
          "representative_frame": 2441,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            2446,
            2450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2451,
            2455
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            2456,
            2460
          ],
          "representative_frame": 2456,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 20
    },
    {
      "second": 82,
      "time_range": [
        82,
        82.999
      ],
      "frame_range": [
        2461,
        2490
      ],
      "unified_description": "31 seconds of camera footage from a first-person perspective in Alaska.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:39",
        "processing_time": 3.23,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2475,
          "frame_range": [
            2471,
            2475
          ],
          "description": "a map of the alaska region",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.93
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2461,
            2465
          ],
          "representative_frame": 2461,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            2466,
            2470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2471,
            2475
          ],
          "representative_frame": 2471,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            2476,
            2480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2481,
            2485
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            2486,
            2490
          ],
          "representative_frame": 2486,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 20
    },
    {
      "second": 83,
      "time_range": [
        83,
        83.999
      ],
      "frame_range": [
        2491,
        2520
      ],
      "unified_description": "360-degree panoramic image of a man standing on gravel near a body of water. He appears to be wearing a backpack and talking into a camera. The image was captured using a first-person perspective, providing an immersive view of the surrounding area.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:41",
        "processing_time": 3.28,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2505,
          "frame_range": [
            2501,
            2505
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.13
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2491,
            2495
          ],
          "representative_frame": 2491,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            2496,
            2500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2501,
            2505
          ],
          "representative_frame": 2501,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9439659118652344,
              "bbox": [
                278.8406066894531,
                39.39213562011719,
                500.5555114746094,
                356.8114318847656
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2506,
            2510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2511,
            2515
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9428735971450806,
              "bbox": [
                284.5472412109375,
                40.71253204345703,
                503.2138366699219,
                356.72100830078125
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2516,
            2520
          ],
          "representative_frame": 2516,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 20
    },
    {
      "second": 84,
      "time_range": [
        84,
        84.999
      ],
      "frame_range": [
        2521,
        2550
      ],
      "unified_description": "360-degree image with an older man standing by the ocean. He has his mouth open, and there is a wide-angle lens being used.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:42",
        "processing_time": 3.23,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2535,
          "frame_range": [
            2531,
            2535
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.29
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2521,
            2525
          ],
          "representative_frame": 2521,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9429008364677429,
              "bbox": [
                286.972412109375,
                40.864559173583984,
                503.7838439941406,
                356.5174255371094
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2526,
            2530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2531,
            2535
          ],
          "representative_frame": 2531,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9438028931617737,
              "bbox": [
                287.9102783203125,
                41.38943862915039,
                502.70086669921875,
                356.3175964355469
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2536,
            2540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2541,
            2545
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9396802186965942,
              "bbox": [
                288.27423095703125,
                42.00704574584961,
                501.8891296386719,
                356.3016357421875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2546,
            2550
          ],
          "representative_frame": 2546,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 21
    },
    {
      "second": 85,
      "time_range": [
        85,
        85.999
      ],
      "frame_range": [
        2551,
        2580
      ],
      "unified_description": "1 second long video showing a man wearing a hat standing next to the water. He has a patch on his jacket that says \"KM\". In the background there are tents suggesting that he is camping by the lake.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:44",
        "processing_time": 4.19,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2565,
          "frame_range": [
            2561,
            2565
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.75
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2551,
            2555
          ],
          "representative_frame": 2551,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9414775371551514,
              "bbox": [
                288.79083251953125,
                41.540157318115234,
                501.9705505371094,
                356.4786071777344
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2556,
            2560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2561,
            2565
          ],
          "representative_frame": 2561,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9439215064048767,
              "bbox": [
                292.7452392578125,
                41.197872161865234,
                504.984619140625,
                356.5434875488281
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2566,
            2570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2571,
            2575
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9451601505279541,
              "bbox": [
                290.29443359375,
                39.91962814331055,
                502.31219482421875,
                356.9493408203125
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2576,
            2580
          ],
          "representative_frame": 2576,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 21
    },
    {
      "second": 86,
      "time_range": [
        86,
        86.999
      ],
      "frame_range": [
        2581,
        2610
      ],
      "unified_description": "\nA man standing by the water with an NH jacket on looking back at the camera. In the background there is a backpack and another person near the edge of the frame.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:45",
        "processing_time": 3.46,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2595,
          "frame_range": [
            2591,
            2595
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2581,
            2585
          ],
          "representative_frame": 2581,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9423187375068665,
              "bbox": [
                275.4644470214844,
                41.883052825927734,
                485.61199951171875,
                356.8184814453125
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2586,
            2590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2591,
            2595
          ],
          "representative_frame": 2591,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9423162937164307,
              "bbox": [
                265.31866455078125,
                44.98966598510742,
                473.5073547363281,
                356.6658935546875
              ]
            },
            {
              "track_id": 175,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8198567032814026,
              "bbox": [
                455.8743896484375,
                187.1865692138672,
                476.9428405761719,
                244.99740600585938
              ]
            }
          ],
          "unique_tracks": [
            130,
            175
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2596,
            2600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2601,
            2605
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9471852779388428,
              "bbox": [
                274.3519287109375,
                47.91636276245117,
                480.3682556152344,
                356.66015625
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2606,
            2610
          ],
          "representative_frame": 2606,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 21
    },
    {
      "second": 87,
      "time_range": [
        87,
        87.999
      ],
      "frame_range": [
        2611,
        2640
      ],
      "unified_description": "\n\nA man wearing a hat and a raincoat is standing by a body of water. He appears to be looking towards the camera as if having his picture taken. There are a few other people present in the background, along with some backpacks and a boat on the water. The image is slightly overexposed, causing some loss of detail in the brightest areas.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:47",
        "processing_time": 3.87,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2625,
          "frame_range": [
            2621,
            2625
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.16
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2611,
            2615
          ],
          "representative_frame": 2611,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9407297968864441,
              "bbox": [
                295.24127197265625,
                49.52449035644531,
                499.18402099609375,
                356.56591796875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2616,
            2620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2621,
            2625
          ],
          "representative_frame": 2621,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9463698267936707,
              "bbox": [
                309.4011535644531,
                51.652503967285156,
                510.5166015625,
                356.619873046875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2626,
            2630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2631,
            2635
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9416394233703613,
              "bbox": [
                308.9540710449219,
                51.96748352050781,
                508.9042053222656,
                356.8873596191406
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2636,
            2640
          ],
          "representative_frame": 2636,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 21
    },
    {
      "second": 88,
      "time_range": [
        88,
        88.999
      ],
      "frame_range": [
        2641,
        2670
      ],
      "unified_description": "4K video taken with an action camera mounted on a backpack while hiking near a body of water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:48",
        "processing_time": 3.51,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2655,
          "frame_range": [
            2651,
            2655
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.19
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2641,
            2645
          ],
          "representative_frame": 2641,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9462761282920837,
              "bbox": [
                301.2552185058594,
                48.95583724975586,
                501.5476379394531,
                356.9953308105469
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2646,
            2650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2651,
            2655
          ],
          "representative_frame": 2651,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9403504729270935,
              "bbox": [
                288.45306396484375,
                45.13502883911133,
                489.5146484375,
                356.69549560546875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2656,
            2660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2661,
            2665
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9458233714103699,
              "bbox": [
                277.703369140625,
                44.240455627441406,
                477.89276123046875,
                356.7667236328125
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2666,
            2670
          ],
          "representative_frame": 2666,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 22
    },
    {
      "second": 89,
      "time_range": [
        89,
        89.999
      ],
      "frame_range": [
        2671,
        2700
      ],
      "unified_description": "1-second scene showing a man standing on the shore next to a lake with a backpack on his back and another person across the water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:50",
        "processing_time": 3.57,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2685,
          "frame_range": [
            2681,
            2685
          ],
          "description": "a man standing on a beach next to a body of water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.09
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2671,
            2675
          ],
          "representative_frame": 2671,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.94392991065979,
              "bbox": [
                272.4151916503906,
                44.600589752197266,
                471.7386169433594,
                356.5924377441406
              ]
            },
            {
              "track_id": 170,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7960841059684753,
              "bbox": [
                550.73828125,
                179.70086669921875,
                572.9982299804688,
                243.81338500976562
              ]
            }
          ],
          "unique_tracks": [
            130,
            170
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2676,
            2680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2681,
            2685
          ],
          "representative_frame": 2681,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9433876872062683,
              "bbox": [
                271.78582763671875,
                44.47267150878906,
                470.5565185546875,
                356.7580871582031
              ]
            },
            {
              "track_id": 190,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7660399675369263,
              "bbox": [
                518.0407104492188,
                180.68003845214844,
                539.8373413085938,
                244.41595458984375
              ]
            },
            {
              "track_id": 170,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8073617219924927,
              "bbox": [
                552.9932250976562,
                178.4834747314453,
                576.4255981445312,
                243.3760986328125
              ]
            }
          ],
          "unique_tracks": [
            130,
            190,
            170
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            2686,
            2690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2691,
            2695
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9347882866859436,
              "bbox": [
                267.9111022949219,
                46.11720275878906,
                466.21337890625,
                356.66046142578125
              ]
            },
            {
              "track_id": 190,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8174219727516174,
              "bbox": [
                515.4849853515625,
                178.46412658691406,
                536.6875610351562,
                240.46669006347656
              ]
            },
            {
              "track_id": 170,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.720287024974823,
              "bbox": [
                548.0975952148438,
                176.29795837402344,
                571.5392456054688,
                241.1327362060547
              ]
            }
          ],
          "unique_tracks": [
            130,
            190,
            170
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            2696,
            2700
          ],
          "representative_frame": 2696,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 22
    },
    {
      "second": 90,
      "time_range": [
        90,
        90.999
      ],
      "frame_range": [
        2701,
        2730
      ],
      "unified_description": "0:59 to 0:64: A man wearing sunglasses.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:51",
        "processing_time": 2.85,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2715,
          "frame_range": [
            2711,
            2715
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.18
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2701,
            2705
          ],
          "representative_frame": 2701,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9471218585968018,
              "bbox": [
                274.85308837890625,
                47.985042572021484,
                472.2230529785156,
                356.2577209472656
              ]
            },
            {
              "track_id": 190,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8127703070640564,
              "bbox": [
                520.0621337890625,
                173.46316528320312,
                541.5530395507812,
                236.27244567871094
              ]
            }
          ],
          "unique_tracks": [
            130,
            190
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2706,
            2710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2711,
            2715
          ],
          "representative_frame": 2711,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9511908292770386,
              "bbox": [
                207.77720642089844,
                32.5689582824707,
                421.0672607421875,
                356.261474609375
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2716,
            2720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2721,
            2725
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9508533477783203,
              "bbox": [
                192.02493286132812,
                29.471879959106445,
                412.44647216796875,
                356.53466796875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2726,
            2730
          ],
          "representative_frame": 2726,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 22
    },
    {
      "second": 91,
      "time_range": [
        91,
        91.999
      ],
      "frame_range": [
        2731,
        2760
      ],
      "unified_description": "1-second shot of a man standing in front of a mountain with a lake nearby. The camera is positioned above the man's shoulder, capturing his face as he looks toward the water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:53",
        "processing_time": 3.31,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2745,
          "frame_range": [
            2741,
            2745
          ],
          "description": "a man standing on a rock near a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.3
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2731,
            2735
          ],
          "representative_frame": 2731,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9521914720535278,
              "bbox": [
                189.42367553710938,
                24.20206069946289,
                416.77813720703125,
                356.0707092285156
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2736,
            2740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2741,
            2745
          ],
          "representative_frame": 2741,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9512898325920105,
              "bbox": [
                187.549560546875,
                21.99509620666504,
                419.7589111328125,
                355.85272216796875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2746,
            2750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2751,
            2755
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9426975250244141,
              "bbox": [
                181.95745849609375,
                23.517322540283203,
                417.50738525390625,
                355.7815856933594
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2756,
            2760
          ],
          "representative_frame": 2756,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 22
    },
    {
      "second": 92,
      "time_range": [
        92,
        92.999
      ],
      "frame_range": [
        2761,
        2790
      ],
      "unified_description": "3rd person POV of a middle-aged man with a beard standing near water on a cloudy day. The camera is possibly mounted on his backpack, capturing his outdoor adventure.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:55",
        "processing_time": 3.95,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2775,
          "frame_range": [
            2771,
            2775
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.84
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2761,
            2765
          ],
          "representative_frame": 2761,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9441957473754883,
              "bbox": [
                179.11849975585938,
                23.41716766357422,
                418.700927734375,
                355.82916259765625
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2766,
            2770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2771,
            2775
          ],
          "representative_frame": 2771,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9472317099571228,
              "bbox": [
                183.81629943847656,
                25.908720016479492,
                425.25958251953125,
                355.8593444824219
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2776,
            2780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2781,
            2785
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9493350982666016,
              "bbox": [
                185.47962951660156,
                27.14237403869629,
                428.8451232910156,
                355.77569580078125
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2786,
            2790
          ],
          "representative_frame": 2786,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 23
    },
    {
      "second": 93,
      "time_range": [
        93,
        93.999
      ],
      "frame_range": [
        2791,
        2820
      ],
      "unified_description": "03 - A man wearing sunglasses and a grey hat stands near a river.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:56",
        "processing_time": 3.2,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2805,
          "frame_range": [
            2801,
            2805
          ],
          "description": "a man standing on a rocky shore next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.23
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2791,
            2795
          ],
          "representative_frame": 2791,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9405276775360107,
              "bbox": [
                178.08804321289062,
                32.666046142578125,
                421.7842712402344,
                356.06866455078125
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2796,
            2800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2801,
            2805
          ],
          "representative_frame": 2801,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9432894587516785,
              "bbox": [
                157.59310913085938,
                36.39222717285156,
                403.0924072265625,
                356.5212097167969
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2806,
            2810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2811,
            2815
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9514726400375366,
              "bbox": [
                157.5053253173828,
                38.16984176635742,
                404.68914794921875,
                356.5151062011719
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2816,
            2820
          ],
          "representative_frame": 2816,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 23
    },
    {
      "second": 94,
      "time_range": [
        94,
        94.999
      ],
      "frame_range": [
        2821,
        2850
      ],
      "unified_description": "2nd person POV shot of a man standing on rocky shore next to a lake with mouth open, looking forward with a backpack strapped on.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:58",
        "processing_time": 3.09,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2835,
          "frame_range": [
            2831,
            2835
          ],
          "description": "a man standing on a rocky shore next to a body of water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.4
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2821,
            2825
          ],
          "representative_frame": 2821,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9496263861656189,
              "bbox": [
                180.77255249023438,
                39.163841247558594,
                428.6736145019531,
                356.0163269042969
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2826,
            2830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2831,
            2835
          ],
          "representative_frame": 2831,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9512262940406799,
              "bbox": [
                182.59596252441406,
                38.852996826171875,
                432.4936828613281,
                355.63104248046875
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2836,
            2840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2841,
            2845
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9503269195556641,
              "bbox": [
                179.82278442382812,
                35.73623275756836,
                434.73516845703125,
                355.6295166015625
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2846,
            2850
          ],
          "representative_frame": 2846,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 23
    },
    {
      "second": 95,
      "time_range": [
        95,
        95.999
      ],
      "frame_range": [
        2851,
        2880
      ],
      "unified_description": "00:57-01:59 - A man with glasses and a hat on stands on the shoreline of a lake with his mouth open.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:27:59",
        "processing_time": 3.38,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2865,
          "frame_range": [
            2861,
            2865
          ],
          "description": "a man standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2851,
            2855
          ],
          "representative_frame": 2851,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9479320645332336,
              "bbox": [
                175.84197998046875,
                33.150150299072266,
                435.1330871582031,
                356.1820983886719
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2856,
            2860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2861,
            2865
          ],
          "representative_frame": 2861,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.951962947845459,
              "bbox": [
                176.72467041015625,
                29.8330020904541,
                440.20501708984375,
                356.76702880859375
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            2866,
            2870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2871,
            2875
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            2876,
            2880
          ],
          "representative_frame": 2876,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 23
    },
    {
      "second": 96,
      "time_range": [
        96,
        96.999
      ],
      "frame_range": [
        2881,
        2910
      ],
      "unified_description": "3 people wearing red jackets are walking on gravel along a shoreline by a lake",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:00",
        "processing_time": 3.14,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2895,
          "frame_range": [
            2891,
            2895
          ],
          "description": "two people are walking along the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.18
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2881,
            2885
          ],
          "representative_frame": 2881,
          "detections": [
            {
              "track_id": 196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9209455847740173,
              "bbox": [
                108.04907989501953,
                73.92840576171875,
                205.3084716796875,
                352.01422119140625
              ]
            },
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7724496126174927,
              "bbox": [
                378.20587158203125,
                154.72303771972656,
                563.4324951171875,
                357.6860046386719
              ]
            },
            {
              "track_id": 198,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.8916462659835815,
              "bbox": [
                483.388671875,
                149.537841796875,
                604.4182739257812,
                357.2457275390625
              ]
            }
          ],
          "unique_tracks": [
            196,
            197,
            198
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            2886,
            2890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2891,
            2895
          ],
          "representative_frame": 2891,
          "detections": [
            {
              "track_id": 196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7656845450401306,
              "bbox": [
                70.37262725830078,
                106.63217163085938,
                159.62794494628906,
                356.8730773925781
              ]
            },
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7491766810417175,
              "bbox": [
                372.2357177734375,
                153.08938598632812,
                556.9939575195312,
                357.17950439453125
              ]
            },
            {
              "track_id": 198,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.9037652611732483,
              "bbox": [
                483.3848876953125,
                144.67947387695312,
                606.4270629882812,
                356.1960144042969
              ]
            }
          ],
          "unique_tracks": [
            196,
            197,
            198
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            2896,
            2900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2901,
            2905
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8015248775482178,
              "bbox": [
                31.762224197387695,
                134.39158630371094,
                113.03011322021484,
                357.7889099121094
              ]
            },
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.533810555934906,
              "bbox": [
                363.04388427734375,
                149.13192749023438,
                549.1803588867188,
                356.76165771484375
              ]
            },
            {
              "track_id": 198,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.8464273810386658,
              "bbox": [
                476.48724365234375,
                140.7520294189453,
                600.5044555664062,
                354.607666015625
              ]
            }
          ],
          "unique_tracks": [
            196,
            197,
            198
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            2906,
            2910
          ],
          "representative_frame": 2906,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 24
    },
    {
      "second": 97,
      "time_range": [
        97,
        97.999
      ],
      "frame_range": [
        2911,
        2940
      ],
      "unified_description": "2 men are walking by the water. One is carrying a red bag while the other is wearing a backpack. They seem to be enjoying their time outdoors.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:02",
        "processing_time": 3.07,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2925,
          "frame_range": [
            2921,
            2925
          ],
          "description": "two people walking along a river with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2911,
            2915
          ],
          "representative_frame": 2911,
          "detections": [
            {
              "track_id": 196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8819084167480469,
              "bbox": [
                36.00891876220703,
                62.82490921020508,
                144.6608428955078,
                357.0195617675781
              ]
            },
            {
              "track_id": 198,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8763406872749329,
              "bbox": [
                462.0740051269531,
                68.62051391601562,
                616.95654296875,
                340.1676330566406
              ]
            }
          ],
          "unique_tracks": [
            196,
            198
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            2916,
            2920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2921,
            2925
          ],
          "representative_frame": 2921,
          "detections": [
            {
              "track_id": 196,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7083407044410706,
              "bbox": [
                64.54134368896484,
                50.75423812866211,
                165.64010620117188,
                317.8323669433594
              ]
            },
            {
              "track_id": 198,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7020279765129089,
              "bbox": [
                458.847900390625,
                62.2592658996582,
                616.926025390625,
                345.5323486328125
              ]
            },
            {
              "track_id": 203,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5608465671539307,
              "bbox": [
                558.2188720703125,
                109.50895690917969,
                639.7665405273438,
                242.65733337402344
              ]
            }
          ],
          "unique_tracks": [
            196,
            198,
            203
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            2926,
            2930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2931,
            2935
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 198,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8116335272789001,
              "bbox": [
                462.4561462402344,
                48.74937057495117,
                620.4205932617188,
                336.6717224121094
              ]
            },
            {
              "track_id": 203,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.645013153553009,
              "bbox": [
                564.1211547851562,
                93.43331146240234,
                640.0,
                224.122314453125
              ]
            }
          ],
          "unique_tracks": [
            198,
            203
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            2936,
            2940
          ],
          "representative_frame": 2936,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 24
    },
    {
      "second": 98,
      "time_range": [
        98,
        98.999
      ],
      "frame_range": [
        2941,
        2970
      ],
      "unified_description": "2 people walking by the water with backpacks, one is wearing an orange coat.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:03",
        "processing_time": 3.02,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2955,
          "frame_range": [
            2951,
            2955
          ],
          "description": "two people walking along a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.9
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2941,
            2945
          ],
          "representative_frame": 2941,
          "detections": [
            {
              "track_id": 198,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9124985933303833,
              "bbox": [
                469.374755859375,
                47.967803955078125,
                618.0953369140625,
                324.5593566894531
              ]
            },
            {
              "track_id": 203,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7378026843070984,
              "bbox": [
                572.1953125,
                96.91104888916016,
                640.0,
                220.69447326660156
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8044452667236328,
              "bbox": [
                148.0146484375,
                34.240333557128906,
                248.59844970703125,
                295.8963317871094
              ]
            }
          ],
          "unique_tracks": [
            198,
            203,
            207
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            2946,
            2950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2951,
            2955
          ],
          "representative_frame": 2951,
          "detections": [
            {
              "track_id": 198,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.766238808631897,
              "bbox": [
                460.7267761230469,
                33.409000396728516,
                605.0588989257812,
                303.6358337402344
              ]
            },
            {
              "track_id": 203,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.8037058711051941,
              "bbox": [
                545.7606201171875,
                58.09382247924805,
                640.0,
                221.67987060546875
              ]
            }
          ],
          "unique_tracks": [
            198,
            203
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2956,
            2960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2961,
            2965
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 198,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5655851364135742,
              "bbox": [
                445.91070556640625,
                19.98142433166504,
                591.188720703125,
                300.4842834472656
              ]
            },
            {
              "track_id": 203,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7254670858383179,
              "bbox": [
                532.0440673828125,
                47.57102584838867,
                640.0,
                226.4420928955078
              ]
            }
          ],
          "unique_tracks": [
            198,
            203
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            2966,
            2970
          ],
          "representative_frame": 2966,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 24
    },
    {
      "second": 99,
      "time_range": [
        99,
        99.999
      ],
      "frame_range": [
        2971,
        3000
      ],
      "unified_description": "\nA man is carrying a grey backpack while walking down a path in the forest.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:04",
        "processing_time": 3.16,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 2985,
          "frame_range": [
            2981,
            2985
          ],
          "description": "a man walking through the woods with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.87
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            2971,
            2975
          ],
          "representative_frame": 2971,
          "detections": [
            {
              "track_id": 198,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7080119252204895,
              "bbox": [
                412.53851318359375,
                12.59598159790039,
                554.0448608398438,
                294.4808349609375
              ]
            }
          ],
          "unique_tracks": [
            198
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            2976,
            2980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            2981,
            2985
          ],
          "representative_frame": 2981,
          "detections": [
            {
              "track_id": 198,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7729028463363647,
              "bbox": [
                410.0887145996094,
                23.47715187072754,
                509.2920837402344,
                217.7559814453125
              ]
            },
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8743106722831726,
              "bbox": [
                302.62451171875,
                20.360227584838867,
                504.6943054199219,
                257.68511962890625
              ]
            }
          ],
          "unique_tracks": [
            198,
            197
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            2986,
            2990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            2991,
            2995
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8462839722633362,
              "bbox": [
                280.62847900390625,
                11.92641830444336,
                458.2644958496094,
                232.75669860839844
              ]
            }
          ],
          "unique_tracks": [
            197
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            2996,
            3000
          ],
          "representative_frame": 2996,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 24
    },
    {
      "second": 100,
      "time_range": [
        100,
        100.999
      ],
      "frame_range": [
        3001,
        3030
      ],
      "unified_description": "3rd person perspective showing a man hiking in the woods with a red jacket on his back.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:06",
        "processing_time": 2.91,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3015,
          "frame_range": [
            3011,
            3015
          ],
          "description": "a person walking through the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.9
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3001,
            3005
          ],
          "representative_frame": 3001,
          "detections": [
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8692699670791626,
              "bbox": [
                261.62725830078125,
                16.428388595581055,
                418.171630859375,
                220.6094970703125
              ]
            }
          ],
          "unique_tracks": [
            197
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3006,
            3010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3011,
            3015
          ],
          "representative_frame": 3011,
          "detections": [
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8580992817878723,
              "bbox": [
                242.3047332763672,
                12.632452964782715,
                377.7116394042969,
                196.22874450683594
              ]
            }
          ],
          "unique_tracks": [
            197
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3016,
            3020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3021,
            3025
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8595330715179443,
              "bbox": [
                225.67013549804688,
                12.366527557373047,
                340.9614562988281,
                171.2939453125
              ]
            }
          ],
          "unique_tracks": [
            197
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3026,
            3030
          ],
          "representative_frame": 3026,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 25
    },
    {
      "second": 101,
      "time_range": [
        101,
        101.999
      ],
      "frame_range": [
        3031,
        3060
      ],
      "unified_description": "4K resolution, camera mounted on backpack, wide-angle lens with distortion, first-person perspective",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:07",
        "processing_time": 2.99,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3045,
          "frame_range": [
            3041,
            3045
          ],
          "description": "a man in a red jacket is walking through the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.11
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3031,
            3035
          ],
          "representative_frame": 3031,
          "detections": [
            {
              "track_id": 197,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7424910068511963,
              "bbox": [
                207.2628173828125,
                7.091735363006592,
                318.4478759765625,
                164.17784118652344
              ]
            }
          ],
          "unique_tracks": [
            197
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3036,
            3040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3041,
            3045
          ],
          "representative_frame": 3041,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8532754182815552,
              "bbox": [
                197.95428466796875,
                39.8304443359375,
                391.9630126953125,
                282.8007507324219
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3046,
            3050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3051,
            3055
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9347096681594849,
              "bbox": [
                422.4796447753906,
                15.80194091796875,
                558.5269165039062,
                357.3227844238281
              ]
            },
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.438507616519928,
              "bbox": [
                205.8130645751953,
                66.02536010742188,
                400.21282958984375,
                302.6325378417969
              ]
            }
          ],
          "unique_tracks": [
            218,
            130
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3056,
            3060
          ],
          "representative_frame": 3056,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 25
    },
    {
      "second": 102,
      "time_range": [
        102,
        102.999
      ],
      "frame_range": [
        3061,
        3090
      ],
      "unified_description": "2 people wearing red coats are walking through grassy area with trees",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:08",
        "processing_time": 3.2,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3075,
          "frame_range": [
            3071,
            3075
          ],
          "description": "two men in red jackets are walking through the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.89
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3061,
            3065
          ],
          "representative_frame": 3061,
          "detections": [
            {
              "track_id": 218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9264512062072754,
              "bbox": [
                472.9166259765625,
                4.111672878265381,
                613.7216796875,
                356.7039794921875
              ]
            },
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7799413800239563,
              "bbox": [
                199.53440856933594,
                65.71089935302734,
                394.91162109375,
                319.840576171875
              ]
            },
            {
              "track_id": 220,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7536598443984985,
              "bbox": [
                314.9925231933594,
                94.71705627441406,
                412.68695068359375,
                264.8417053222656
              ]
            }
          ],
          "unique_tracks": [
            218,
            130,
            220
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3066,
            3070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3071,
            3075
          ],
          "representative_frame": 3071,
          "detections": [
            {
              "track_id": 218,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9122398495674133,
              "bbox": [
                513.9298095703125,
                0.0,
                640.0,
                356.0217590332031
              ]
            },
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7362146377563477,
              "bbox": [
                214.8498077392578,
                56.92259979248047,
                411.9329528808594,
                327.9312744140625
              ]
            }
          ],
          "unique_tracks": [
            218,
            130
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3076,
            3080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3081,
            3085
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9162073135375977,
              "bbox": [
                233.8638916015625,
                50.43668746948242,
                422.1150817871094,
                322.8162841796875
              ]
            },
            {
              "track_id": 224,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.6922544836997986,
              "bbox": [
                454.80609130859375,
                235.35452270507812,
                552.88671875,
                347.912109375
              ]
            }
          ],
          "unique_tracks": [
            130,
            224
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3086,
            3090
          ],
          "representative_frame": 3086,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 25
    },
    {
      "second": 103,
      "time_range": [
        103,
        103.999
      ],
      "frame_range": [
        3091,
        3120
      ],
      "unified_description": "360 video of a person in a red coat and blue jeans walking in the rain with a backpack on.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:10",
        "processing_time": 3.06,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3105,
          "frame_range": [
            3101,
            3105
          ],
          "description": "a man in a red jacket is walking up a hill",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.05
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3091,
            3095
          ],
          "representative_frame": 3091,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9033286571502686,
              "bbox": [
                233.54530334472656,
                49.843231201171875,
                423.9801025390625,
                325.9751892089844
              ]
            },
            {
              "track_id": 224,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7553817629814148,
              "bbox": [
                478.30584716796875,
                254.71688842773438,
                566.6777954101562,
                355.9379577636719
              ]
            }
          ],
          "unique_tracks": [
            130,
            224
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3096,
            3100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3101,
            3105
          ],
          "representative_frame": 3101,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9001418948173523,
              "bbox": [
                264.3531188964844,
                43.59831237792969,
                454.56988525390625,
                329.23388671875
              ]
            },
            {
              "track_id": 224,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7827298641204834,
              "bbox": [
                527.3632202148438,
                280.11083984375,
                597.4022216796875,
                359.520751953125
              ]
            }
          ],
          "unique_tracks": [
            130,
            224
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3106,
            3110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3111,
            3115
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 130,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9154114127159119,
              "bbox": [
                327.0849914550781,
                33.98585891723633,
                523.90478515625,
                345.1706237792969
              ]
            }
          ],
          "unique_tracks": [
            130
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3116,
            3120
          ],
          "representative_frame": 3116,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 25
    },
    {
      "second": 104,
      "time_range": [
        104,
        104.999
      ],
      "frame_range": [
        3121,
        3150
      ],
      "unified_description": "3rd person perspective of a man walking in the woods carrying a large backpack. The image also contains details about camera perspective, field of view, and lens characteristics.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:12",
        "processing_time": 3.0,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3135,
          "frame_range": [
            3131,
            3135
          ],
          "description": "a man is walking through the woods with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.34
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3121,
            3125
          ],
          "representative_frame": 3121,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8740720152854919,
              "bbox": [
                271.6236572265625,
                8.202432632446289,
                407.4631042480469,
                248.04330444335938
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3126,
            3130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3131,
            3135
          ],
          "representative_frame": 3131,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.809426486492157,
              "bbox": [
                265.36273193359375,
                2.273960828781128,
                396.599609375,
                236.52215576171875
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3136,
            3140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3141,
            3145
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7813968658447266,
              "bbox": [
                261.291015625,
                2.279064178466797,
                400.2000732421875,
                257.181884765625
              ]
            },
            {
              "track_id": 230,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4866982400417328,
              "bbox": [
                242.19711303710938,
                174.66078186035156,
                288.7125244140625,
                216.2892608642578
              ]
            }
          ],
          "unique_tracks": [
            220,
            230
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3146,
            3150
          ],
          "representative_frame": 3146,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 26
    },
    {
      "second": 105,
      "time_range": [
        105,
        105.999
      ],
      "frame_range": [
        3151,
        3180
      ],
      "unified_description": "3rd person perspective showing a man standing in the woods with a backpack on his back. He is near many trees and appears to be looking at something off-camera.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:13",
        "processing_time": 3.54,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3165,
          "frame_range": [
            3161,
            3165
          ],
          "description": "a man is standing in the woods with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.08
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3151,
            3155
          ],
          "representative_frame": 3151,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8903627395629883,
              "bbox": [
                267.7049255371094,
                11.5460786819458,
                404.4369812011719,
                266.3008728027344
              ]
            },
            {
              "track_id": 230,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5962164402008057,
              "bbox": [
                241.37042236328125,
                173.85830688476562,
                290.33502197265625,
                217.74905395507812
              ]
            }
          ],
          "unique_tracks": [
            220,
            230
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3156,
            3160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3161,
            3165
          ],
          "representative_frame": 3161,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.76705002784729,
              "bbox": [
                269.5240173339844,
                14.559654235839844,
                402.2982177734375,
                266.2096862792969
              ]
            },
            {
              "track_id": 230,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5202887654304504,
              "bbox": [
                240.93511962890625,
                173.49562072753906,
                290.7741394042969,
                218.28469848632812
              ]
            }
          ],
          "unique_tracks": [
            220,
            230
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3166,
            3170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3171,
            3175
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7968211770057678,
              "bbox": [
                273.3418273925781,
                20.0999755859375,
                397.27099609375,
                256.1324462890625
              ]
            },
            {
              "track_id": 230,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.521270751953125,
              "bbox": [
                240.78216552734375,
                173.39352416992188,
                290.7953796386719,
                218.48439025878906
              ]
            }
          ],
          "unique_tracks": [
            220,
            230
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3176,
            3180
          ],
          "representative_frame": 3176,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 26
    },
    {
      "second": 106,
      "time_range": [
        106,
        106.999
      ],
      "frame_range": [
        3181,
        3210
      ],
      "unified_description": "1-second scene showing a man wearing a brown hat and tan pants standing next to a tree with a backpack in the wilderness.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:14",
        "processing_time": 3.52,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3195,
          "frame_range": [
            3191,
            3195
          ],
          "description": "a man standing next to a tree with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.83
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3181,
            3185
          ],
          "representative_frame": 3181,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.887338399887085,
              "bbox": [
                258.8253479003906,
                35.938541412353516,
                392.19940185546875,
                296.2153625488281
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3186,
            3190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3191,
            3195
          ],
          "representative_frame": 3191,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9113285541534424,
              "bbox": [
                247.56565856933594,
                41.95199203491211,
                381.9920349121094,
                311.0115966796875
              ]
            },
            {
              "track_id": 234,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7515401244163513,
              "bbox": [
                369.0485534667969,
                250.52622985839844,
                497.7257385253906,
                319.70562744140625
              ]
            },
            {
              "track_id": 236,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.31894218921661377,
              "bbox": [
                140.26678466796875,
                233.5201416015625,
                205.2462158203125,
                276.79736328125
              ]
            }
          ],
          "unique_tracks": [
            220,
            234,
            236
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            3196,
            3200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3201,
            3205
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.914757490158081,
              "bbox": [
                250.3546600341797,
                45.59724807739258,
                381.5445556640625,
                316.3835754394531
              ]
            },
            {
              "track_id": 234,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.7562969326972961,
              "bbox": [
                368.8638916015625,
                250.38702392578125,
                497.4632873535156,
                319.50537109375
              ]
            },
            {
              "track_id": 236,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.34873631596565247,
              "bbox": [
                140.07272338867188,
                233.39480590820312,
                204.8787841796875,
                276.5416259765625
              ]
            }
          ],
          "unique_tracks": [
            220,
            234,
            236
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            3206,
            3210
          ],
          "representative_frame": 3206,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 26
    },
    {
      "second": 107,
      "time_range": [
        107,
        107.999
      ],
      "frame_range": [
        3211,
        3240
      ],
      "unified_description": "2 men are standing near a tent in the woods",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:16",
        "processing_time": 2.73,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3225,
          "frame_range": [
            3221,
            3225
          ],
          "description": "two men are standing near a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.2
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3211,
            3215
          ],
          "representative_frame": 3211,
          "detections": [
            {
              "track_id": 236,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5331587195396423,
              "bbox": [
                148.10731506347656,
                234.16607666015625,
                211.8468017578125,
                276.9703369140625
              ]
            }
          ],
          "unique_tracks": [
            236
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3216,
            3220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3221,
            3225
          ],
          "representative_frame": 3221,
          "detections": [
            {
              "track_id": 239,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.76036137342453,
              "bbox": [
                127.21435546875,
                109.86152648925781,
                178.8011016845703,
                281.7719421386719
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.789924681186676,
              "bbox": [
                400.6712951660156,
                59.50923538208008,
                495.79840087890625,
                304.35498046875
              ]
            }
          ],
          "unique_tracks": [
            239,
            240
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3226,
            3230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3231,
            3235
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 239,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.816783607006073,
              "bbox": [
                127.58280944824219,
                110.38636779785156,
                178.82508850097656,
                280.8325500488281
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.29874345660209656,
              "bbox": [
                393.816162109375,
                55.41912078857422,
                490.3904724121094,
                303.13763427734375
              ]
            }
          ],
          "unique_tracks": [
            239,
            240
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3236,
            3240
          ],
          "representative_frame": 3236,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 26
    },
    {
      "second": 108,
      "time_range": [
        108,
        108.999
      ],
      "frame_range": [
        3241,
        3270
      ],
      "unified_description": "2 men are near an umbrella in a wooded area",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:17",
        "processing_time": 2.96,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3255,
          "frame_range": [
            3251,
            3255
          ],
          "description": "a man is standing next to a large bird",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.99
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3241,
            3245
          ],
          "representative_frame": 3241,
          "detections": [
            {
              "track_id": 239,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6205352544784546,
              "bbox": [
                125.94295501708984,
                110.93013763427734,
                177.38336181640625,
                281.802490234375
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.482158899307251,
              "bbox": [
                386.7191162109375,
                50.88663101196289,
                485.2877197265625,
                303.4134826660156
              ]
            }
          ],
          "unique_tracks": [
            239,
            240
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3246,
            3250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3251,
            3255
          ],
          "representative_frame": 3251,
          "detections": [
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.890302300453186,
              "bbox": [
                162.86410522460938,
                95.6572265625,
                250.05809020996094,
                330.0453186035156
              ]
            },
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8863058090209961,
              "bbox": [
                269.3840637207031,
                71.01887512207031,
                406.0184020996094,
                352.8106994628906
              ]
            }
          ],
          "unique_tracks": [
            207,
            220
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3256,
            3260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3261,
            3265
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.910316526889801,
              "bbox": [
                158.904052734375,
                91.8427734375,
                245.10777282714844,
                330.5334167480469
              ]
            },
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8897581696510315,
              "bbox": [
                267.7035217285156,
                38.190040588378906,
                420.159423828125,
                356.8695068359375
              ]
            }
          ],
          "unique_tracks": [
            207,
            220
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3266,
            3270
          ],
          "representative_frame": 3266,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 27
    },
    {
      "second": 109,
      "time_range": [
        109,
        109.999
      ],
      "frame_range": [
        3271,
        3300
      ],
      "unified_description": "3 people are in a wooded area, with one man wearing tan pants and carrying a sheet.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:18",
        "processing_time": 3.19,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3285,
          "frame_range": [
            3281,
            3285
          ],
          "description": "a man is walking through the woods with a dog",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3271,
            3275
          ],
          "representative_frame": 3271,
          "detections": [
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9160047173500061,
              "bbox": [
                158.18812561035156,
                86.45738220214844,
                245.4730224609375,
                337.6411437988281
              ]
            },
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.936369776725769,
              "bbox": [
                270.372802734375,
                14.369260787963867,
                433.5110168457031,
                358.2921447753906
              ]
            }
          ],
          "unique_tracks": [
            207,
            220
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3276,
            3280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3281,
            3285
          ],
          "representative_frame": 3281,
          "detections": [
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9210827946662903,
              "bbox": [
                404.82427978515625,
                3.4427802562713623,
                542.7554321289062,
                353.7319030761719
              ]
            }
          ],
          "unique_tracks": [
            240
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3286,
            3290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3291,
            3295
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 244,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9110872149467468,
              "bbox": [
                0.0,
                61.44858932495117,
                73.79920959472656,
                356.47113037109375
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.939130961894989,
              "bbox": [
                408.17950439453125,
                0.0,
                551.3556518554688,
                358.5274658203125
              ]
            }
          ],
          "unique_tracks": [
            244,
            240
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3296,
            3300
          ],
          "representative_frame": 3296,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 27
    },
    {
      "second": 110,
      "time_range": [
        110,
        110.999
      ],
      "frame_range": [
        3301,
        3330
      ],
      "unified_description": "1-second video showing a man in an orange jacket doing something with two other people in orange jackets who are working on a tree.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:20",
        "processing_time": 2.94,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3315,
          "frame_range": [
            3311,
            3315
          ],
          "description": "two men in orange jackets are working on a tree",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.15
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3301,
            3305
          ],
          "representative_frame": 3301,
          "detections": [
            {
              "track_id": 244,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.916176974773407,
              "bbox": [
                0.0,
                61.48332977294922,
                72.49020385742188,
                356.6615905761719
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9313207268714905,
              "bbox": [
                410.98028564453125,
                0.0,
                557.2242431640625,
                360.0
              ]
            },
            {
              "track_id": 220,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.6205413937568665,
              "bbox": [
                298.5830078125,
                38.70241928100586,
                418.93951416015625,
                274.97564697265625
              ]
            }
          ],
          "unique_tracks": [
            244,
            240,
            220
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3306,
            3310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3311,
            3315
          ],
          "representative_frame": 3311,
          "detections": [
            {
              "track_id": 244,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9284384846687317,
              "bbox": [
                1.1873527765274048,
                59.38633728027344,
                77.08741760253906,
                356.4584655761719
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.927944004535675,
              "bbox": [
                411.47564697265625,
                0.0,
                559.5760498046875,
                360.0
              ]
            },
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9306328296661377,
              "bbox": [
                265.9989318847656,
                26.640846252441406,
                424.3960876464844,
                331.1106262207031
              ]
            }
          ],
          "unique_tracks": [
            244,
            240,
            220
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            3316,
            3320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3321,
            3325
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8806374669075012,
              "bbox": [
                163.59495544433594,
                42.18137741088867,
                350.4924621582031,
                346.95562744140625
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3326,
            3330
          ],
          "representative_frame": 3326,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 27
    },
    {
      "second": 111,
      "time_range": [
        111,
        111.999
      ],
      "frame_range": [
        3331,
        3360
      ],
      "unified_description": "30 second video clip with an adult male subject. The man is wearing a black jacket and is standing outdoors under a tree. Multiple object detections indicate the presence of various elements within the scene, providing context and setting for the viewer. Technical details on camera perspective, positioning, field of view, lens characteristics, and video production style contribute to an overall understanding of how the scene was captured and presented in the clip.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:22",
        "processing_time": 3.88,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3345,
          "frame_range": [
            3341,
            3345
          ],
          "description": "a man in a black jacket is standing under a tree",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.14
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3331,
            3335
          ],
          "representative_frame": 3331,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8456403613090515,
              "bbox": [
                115.5755844116211,
                91.70647430419922,
                301.8954162597656,
                353.8127746582031
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3336,
            3340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3341,
            3345
          ],
          "representative_frame": 3341,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9257598519325256,
              "bbox": [
                89.54183959960938,
                119.88523864746094,
                279.66876220703125,
                356.82659912109375
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3346,
            3350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3351,
            3355
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8467649221420288,
              "bbox": [
                72.8763427734375,
                120.03034210205078,
                280.53790283203125,
                357.514892578125
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3356,
            3360
          ],
          "representative_frame": 3356,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 27
    },
    {
      "second": 112,
      "time_range": [
        112,
        112.999
      ],
      "frame_range": [
        3361,
        3390
      ],
      "unified_description": "\nA man wearing glasses is being hugged by someone under an umbrella.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:23",
        "processing_time": 4.29,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3375,
          "frame_range": [
            3371,
            3375
          ],
          "description": "a man is holding a large umbrella",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.63
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3361,
            3365
          ],
          "representative_frame": 3361,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.906500518321991,
              "bbox": [
                56.558921813964844,
                82.9299545288086,
                308.12432861328125,
                357.0196228027344
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3366,
            3370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3371,
            3375
          ],
          "representative_frame": 3371,
          "detections": [
            {
              "track_id": 220,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8591503500938416,
              "bbox": [
                79.0479736328125,
                119.13861846923828,
                310.80712890625,
                357.4967041015625
              ]
            }
          ],
          "unique_tracks": [
            220
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3376,
            3380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3381,
            3385
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7029392719268799,
              "bbox": [
                485.3880615234375,
                0.37520307302474976,
                589.491943359375,
                221.5888214111328
              ]
            }
          ],
          "unique_tracks": [
            240
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3386,
            3390
          ],
          "representative_frame": 3386,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 28
    },
    {
      "second": 113,
      "time_range": [
        113,
        113.999
      ],
      "frame_range": [
        3391,
        3420
      ],
      "unified_description": "3 people are under a white canopy, with the man on the right and two children on the left. There is a red blanket near them.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:25",
        "processing_time": 3.84,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3405,
          "frame_range": [
            3401,
            3405
          ],
          "description": "a man and two children sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3391,
            3395
          ],
          "representative_frame": 3391,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.830260694026947,
              "bbox": [
                276.31103515625,
                50.7619743347168,
                379.47320556640625,
                202.96444702148438
              ]
            }
          ],
          "unique_tracks": [
            252
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3396,
            3400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3401,
            3405
          ],
          "representative_frame": 3401,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7841440439224243,
              "bbox": [
                275.85107421875,
                54.661231994628906,
                373.6770324707031,
                199.12014770507812
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8555861115455627,
              "bbox": [
                155.44654846191406,
                34.861289978027344,
                254.5568084716797,
                261.8323974609375
              ]
            }
          ],
          "unique_tracks": [
            252,
            207
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3406,
            3410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3411,
            3415
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8748890161514282,
              "bbox": [
                298.4391784667969,
                35.03989791870117,
                396.677490234375,
                177.1627655029297
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.840717613697052,
              "bbox": [
                183.20938110351562,
                111.95309448242188,
                245.78709411621094,
                228.73788452148438
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7919060587882996,
              "bbox": [
                461.5072937011719,
                44.59536361694336,
                593.2957153320312,
                310.53118896484375
              ]
            }
          ],
          "unique_tracks": [
            252,
            207,
            240
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            3416,
            3420
          ],
          "representative_frame": 3416,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 28
    },
    {
      "second": 114,
      "time_range": [
        114,
        114.999
      ],
      "frame_range": [
        3421,
        3450
      ],
      "unified_description": "3 men are sitting inside a tent with their gear, while one person is taking a photo with the camera mounted on his helmet.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:26",
        "processing_time": 3.13,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3435,
          "frame_range": [
            3431,
            3435
          ],
          "description": "a group of people sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.12
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3421,
            3425
          ],
          "representative_frame": 3421,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5189257860183716,
              "bbox": [
                294.3004150390625,
                28.661006927490234,
                414.4319152832031,
                200.48541259765625
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8699878454208374,
              "bbox": [
                193.11158752441406,
                138.9480743408203,
                248.0699462890625,
                232.07192993164062
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8266035318374634,
              "bbox": [
                455.1492919921875,
                49.32957077026367,
                595.2860107421875,
                322.4792175292969
              ]
            }
          ],
          "unique_tracks": [
            252,
            207,
            240
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3426,
            3430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3431,
            3435
          ],
          "representative_frame": 3431,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7828999161720276,
              "bbox": [
                293.0413513183594,
                26.501022338867188,
                421.7384033203125,
                208.17013549804688
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8714296817779541,
              "bbox": [
                191.4461212158203,
                144.1764678955078,
                255.98065185546875,
                248.7794952392578
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.79911208152771,
              "bbox": [
                453.12554931640625,
                50.79317092895508,
                597.60400390625,
                326.8709411621094
              ]
            }
          ],
          "unique_tracks": [
            252,
            207,
            240
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            3436,
            3440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3441,
            3445
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.848476767539978,
              "bbox": [
                287.9058532714844,
                25.859819412231445,
                429.4829406738281,
                224.14369201660156
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7869232296943665,
              "bbox": [
                170.88348388671875,
                146.2611083984375,
                262.1499938964844,
                292.6221923828125
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.41465169191360474,
              "bbox": [
                450.2636413574219,
                51.075965881347656,
                598.3847045898438,
                328.24359130859375
              ]
            }
          ],
          "unique_tracks": [
            252,
            207,
            240
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            3446,
            3450
          ],
          "representative_frame": 3446,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 28
    },
    {
      "second": 115,
      "time_range": [
        115,
        115.999
      ],
      "frame_range": [
        3451,
        3480
      ],
      "unified_description": "1 second video of a family on a camping trip. They are sitting on blankets in a tent.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:28",
        "processing_time": 3.34,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3465,
          "frame_range": [
            3461,
            3465
          ],
          "description": "a group of people sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3451,
            3455
          ],
          "representative_frame": 3451,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8556743860244751,
              "bbox": [
                291.81256103515625,
                21.505897521972656,
                433.362548828125,
                218.5648651123047
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5287957787513733,
              "bbox": [
                148.31201171875,
                151.9098358154297,
                258.73431396484375,
                308.3234558105469
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8817865252494812,
              "bbox": [
                436.49285888671875,
                57.08999252319336,
                592.7506103515625,
                348.0771179199219
              ]
            }
          ],
          "unique_tracks": [
            252,
            207,
            240
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3456,
            3460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3461,
            3465
          ],
          "representative_frame": 3461,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8632764220237732,
              "bbox": [
                299.3743591308594,
                16.247827529907227,
                436.6549377441406,
                204.56678771972656
              ]
            },
            {
              "track_id": 207,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6496531963348389,
              "bbox": [
                119.05847930908203,
                154.99867248535156,
                249.31927490234375,
                317.48468017578125
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7963442206382751,
              "bbox": [
                444.5582275390625,
                57.26596450805664,
                597.3534545898438,
                340.1495056152344
              ]
            }
          ],
          "unique_tracks": [
            252,
            207,
            240
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            3466,
            3470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3471,
            3475
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7185339331626892,
              "bbox": [
                274.1478576660156,
                14.466197967529297,
                447.251220703125,
                252.42855834960938
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8648219704627991,
              "bbox": [
                444.15948486328125,
                56.745662689208984,
                595.1130981445312,
                330.3428955078125
              ]
            }
          ],
          "unique_tracks": [
            252,
            240
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3476,
            3480
          ],
          "representative_frame": 3476,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 28
    },
    {
      "second": 116,
      "time_range": [
        116,
        116.999
      ],
      "frame_range": [
        3481,
        3510
      ],
      "unified_description": "\nIn the image, there is a man wearing a black jacket with grey hood who is looking behind him while standing in the forest. The camera is mounted on a pole, providing a unique perspective of the scene. Trees can be seen in the background, along with other objects or people in the frame.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:30",
        "processing_time": 3.65,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3495,
          "frame_range": [
            3491,
            3495
          ],
          "description": "a man in a hat is standing in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.36
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3481,
            3485
          ],
          "representative_frame": 3481,
          "detections": [
            {
              "track_id": 252,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5972378253936768,
              "bbox": [
                291.4361267089844,
                12.148508071899414,
                446.6207275390625,
                223.98648071289062
              ]
            },
            {
              "track_id": 240,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7675110101699829,
              "bbox": [
                447.5360107421875,
                56.63409423828125,
                600.9124755859375,
                330.5978088378906
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6811829805374146,
              "bbox": [
                180.46424865722656,
                152.89370727539062,
                290.9908752441406,
                290.7926940917969
              ]
            }
          ],
          "unique_tracks": [
            252,
            240,
            263
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3486,
            3490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3491,
            3495
          ],
          "representative_frame": 3491,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            3496,
            3500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3501,
            3505
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6944353580474854,
              "bbox": [
                93.7602767944336,
                0.546844482421875,
                459.3074645996094,
                353.9249267578125
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3506,
            3510
          ],
          "representative_frame": 3506,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 29
    },
    {
      "second": 117,
      "time_range": [
        117,
        117.999
      ],
      "frame_range": [
        3511,
        3540
      ],
      "unified_description": "30 second video of a man outdoors",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:31",
        "processing_time": 3.04,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3525,
          "frame_range": [
            3521,
            3525
          ],
          "description": "a man is putting a tent in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.29
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3511,
            3515
          ],
          "representative_frame": 3511,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9398477077484131,
              "bbox": [
                89.00664520263672,
                2.4565505981445312,
                454.2682800292969,
                354.5942077636719
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3516,
            3520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3521,
            3525
          ],
          "representative_frame": 3521,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7396438121795654,
              "bbox": [
                102.2410659790039,
                2.005584239959717,
                473.390380859375,
                355.6563415527344
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3526,
            3530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3531,
            3535
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4641384482383728,
              "bbox": [
                97.58834075927734,
                0.5937514305114746,
                476.17437744140625,
                354.2817077636719
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3536,
            3540
          ],
          "representative_frame": 3536,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 29
    },
    {
      "second": 118,
      "time_range": [
        118,
        118.999
      ],
      "frame_range": [
        3541,
        3570
      ],
      "unified_description": "4 fisherman standing on gravel by stream with tents in background",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:32",
        "processing_time": 3.17,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3555,
          "frame_range": [
            3551,
            3555
          ],
          "description": "a man in a rain suit standing next to a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.13
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3541,
            3545
          ],
          "representative_frame": 3541,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9215824007987976,
              "bbox": [
                137.70516967773438,
                0.21979433298110962,
                496.7915954589844,
                345.339599609375
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8764322996139526,
              "bbox": [
                144.60264587402344,
                120.91742706298828,
                293.7840270996094,
                309.21368408203125
              ]
            }
          ],
          "unique_tracks": [
            267,
            263
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3546,
            3550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3551,
            3555
          ],
          "representative_frame": 3551,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9122290015220642,
              "bbox": [
                158.1002197265625,
                0.5992540717124939,
                502.1361389160156,
                342.46685791015625
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.885309100151062,
              "bbox": [
                149.90098571777344,
                105.5445327758789,
                308.184814453125,
                312.0494384765625
              ]
            }
          ],
          "unique_tracks": [
            267,
            263
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3556,
            3560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3561,
            3565
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9220811128616333,
              "bbox": [
                177.3651580810547,
                0.3007894456386566,
                509.03216552734375,
                341.4822082519531
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9080408811569214,
              "bbox": [
                145.7598419189453,
                89.12598419189453,
                311.9149475097656,
                312.93890380859375
              ]
            }
          ],
          "unique_tracks": [
            267,
            263
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            3566,
            3570
          ],
          "representative_frame": 3566,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 29
    },
    {
      "second": 119,
      "time_range": [
        119,
        119.999
      ],
      "frame_range": [
        3571,
        3600
      ],
      "unified_description": "10-second video showing people in red jumpsuits near water and rocky areas, with tents set up on the riverbank.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:34",
        "processing_time": 2.93,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3585,
          "frame_range": [
            3581,
            3585
          ],
          "description": "a man in a red rain suit standing next to a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.66
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3571,
            3575
          ],
          "representative_frame": 3571,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9211535453796387,
              "bbox": [
                181.9883270263672,
                0.05077271908521652,
                500.5995178222656,
                341.33294677734375
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.898541271686554,
              "bbox": [
                138.88955688476562,
                74.84490966796875,
                309.42926025390625,
                312.6844177246094
              ]
            }
          ],
          "unique_tracks": [
            267,
            263
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3576,
            3580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3581,
            3585
          ],
          "representative_frame": 3581,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5721912980079651,
              "bbox": [
                192.08750915527344,
                0.41206470131874084,
                512.4476318359375,
                351.4593811035156
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8320372700691223,
              "bbox": [
                143.411865234375,
                64.93997192382812,
                311.2098083496094,
                308.4684753417969
              ]
            }
          ],
          "unique_tracks": [
            267,
            263
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3586,
            3590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3591,
            3595
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8139034509658813,
              "bbox": [
                173.52316284179688,
                0.11112038791179657,
                486.6436767578125,
                355.2525634765625
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8253172039985657,
              "bbox": [
                148.00442504882812,
                61.89105987548828,
                310.044189453125,
                306.6105651855469
              ]
            },
            {
              "track_id": 271,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.831418514251709,
              "bbox": [
                396.40521240234375,
                79.58860778808594,
                434.31732177734375,
                290.6396484375
              ]
            }
          ],
          "unique_tracks": [
            267,
            263,
            271
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            3596,
            3600
          ],
          "representative_frame": 3596,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 29
    },
    {
      "second": 120,
      "time_range": [
        120,
        120.999
      ],
      "frame_range": [
        3601,
        3630
      ],
      "unified_description": "3 fishermen standing by a stream, wearing waders and holding fishing rods",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:36",
        "processing_time": 2.78,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3615,
          "frame_range": [
            3611,
            3615
          ],
          "description": "a man in a red jacket and black pants standing next to a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.1
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3601,
            3605
          ],
          "representative_frame": 3601,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9040698409080505,
              "bbox": [
                163.61732482910156,
                0.0009621985373087227,
                468.6544189453125,
                356.32110595703125
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7646893262863159,
              "bbox": [
                155.67486572265625,
                73.64421844482422,
                303.95977783203125,
                305.4424743652344
              ]
            },
            {
              "track_id": 271,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8908631801605225,
              "bbox": [
                400.2363586425781,
                73.29615020751953,
                439.783935546875,
                291.5119934082031
              ]
            }
          ],
          "unique_tracks": [
            267,
            263,
            271
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3606,
            3610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3611,
            3615
          ],
          "representative_frame": 3611,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7614779472351074,
              "bbox": [
                165.265380859375,
                0.4002474248409271,
                461.1772155761719,
                357.0859069824219
              ]
            },
            {
              "track_id": 271,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.904147744178772,
              "bbox": [
                418.06146240234375,
                69.47820281982422,
                460.0798034667969,
                295.15277099609375
              ]
            }
          ],
          "unique_tracks": [
            267,
            271
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            3616,
            3620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3621,
            3625
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            3626,
            3630
          ],
          "representative_frame": 3626,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 30
    },
    {
      "second": 121,
      "time_range": [
        121,
        121.999
      ],
      "frame_range": [
        3631,
        3660
      ],
      "unified_description": "1-second video showing a woman wearing a red jacket walking next to the ocean.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:37",
        "processing_time": 3.59,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3645,
          "frame_range": [
            3641,
            3645
          ],
          "description": "a person in red jacket walking along the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.23
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3631,
            3635
          ],
          "representative_frame": 3631,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            3636,
            3640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3641,
            3645
          ],
          "representative_frame": 3641,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            3646,
            3650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3651,
            3655
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 276,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8829826712608337,
              "bbox": [
                552.254638671875,
                197.98818969726562,
                597.5117797851562,
                316.0326843261719
              ]
            }
          ],
          "unique_tracks": [
            276
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3656,
            3660
          ],
          "representative_frame": 3656,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 30
    },
    {
      "second": 122,
      "time_range": [
        122,
        122.999
      ],
      "frame_range": [
        3661,
        3690
      ],
      "unified_description": "1 second video taken from a first-person perspective showing someone in red standing on a pebble beach next to the ocean.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:38",
        "processing_time": 3.35,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3675,
          "frame_range": [
            3671,
            3675
          ],
          "description": "a person in red clothes standing on a rocky shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.78
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3661,
            3665
          ],
          "representative_frame": 3661,
          "detections": [
            {
              "track_id": 276,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8545997738838196,
              "bbox": [
                565.0084228515625,
                196.00921630859375,
                609.2446899414062,
                311.5843505859375
              ]
            }
          ],
          "unique_tracks": [
            276
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3666,
            3670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3671,
            3675
          ],
          "representative_frame": 3671,
          "detections": [
            {
              "track_id": 276,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7579959630966187,
              "bbox": [
                575.6484375,
                191.90380859375,
                619.5733642578125,
                307.6937561035156
              ]
            }
          ],
          "unique_tracks": [
            276
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3676,
            3680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3681,
            3685
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 276,
              "class_id": 10,
              "class_name": "fire hydrant",
              "confidence": 0.7772905826568604,
              "bbox": [
                581.7394409179688,
                189.11105346679688,
                626.0833129882812,
                306.9093322753906
              ]
            }
          ],
          "unique_tracks": [
            276
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3686,
            3690
          ],
          "representative_frame": 3686,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 30
    },
    {
      "second": 123,
      "time_range": [
        123,
        123.999
      ],
      "frame_range": [
        3691,
        3720
      ],
      "unified_description": "1 second video showing someone standing on gravel near water with a mountain range in the background.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:40",
        "processing_time": 2.82,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3705,
          "frame_range": [
            3701,
            3705
          ],
          "description": "a person walking along a lake with mountains in the background",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.63
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3691,
            3695
          ],
          "representative_frame": 3691,
          "detections": [
            {
              "track_id": 276,
              "class_id": 10,
              "class_name": "fire hydrant",
              "confidence": 0.8149906396865845,
              "bbox": [
                585.6935424804688,
                190.08628845214844,
                629.0830078125,
                305.5992126464844
              ]
            }
          ],
          "unique_tracks": [
            276
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3696,
            3700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3701,
            3705
          ],
          "representative_frame": 3701,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            3706,
            3710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3711,
            3715
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 278,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7512038946151733,
              "bbox": [
                561.9268798828125,
                154.4962615966797,
                587.0379638671875,
                220.54161071777344
              ]
            }
          ],
          "unique_tracks": [
            278
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3716,
            3720
          ],
          "representative_frame": 3716,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 30
    },
    {
      "second": 124,
      "time_range": [
        124,
        124.999
      ],
      "frame_range": [
        3721,
        3750
      ],
      "unified_description": "4K ultra high definition camera mounted on a body harness capturing a woman's point of view while walking along a gravel road near a lake with mountains in the distance.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:42",
        "processing_time": 3.7,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3735,
          "frame_range": [
            3731,
            3735
          ],
          "description": "a person walking along a lake with mountains in the background",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.44
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3721,
            3725
          ],
          "representative_frame": 3721,
          "detections": [
            {
              "track_id": 278,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7703260183334351,
              "bbox": [
                559.8180541992188,
                152.8216094970703,
                585.2260131835938,
                219.72132873535156
              ]
            }
          ],
          "unique_tracks": [
            278
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3726,
            3730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3731,
            3735
          ],
          "representative_frame": 3731,
          "detections": [
            {
              "track_id": 278,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7729820609092712,
              "bbox": [
                558.7317504882812,
                152.01345825195312,
                584.4120483398438,
                219.75706481933594
              ]
            }
          ],
          "unique_tracks": [
            278
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3736,
            3740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3741,
            3745
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9210354685783386,
              "bbox": [
                117.45537567138672,
                0.7366932034492493,
                319.8447570800781,
                317.6894226074219
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3746,
            3750
          ],
          "representative_frame": 3746,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 31
    },
    {
      "second": 125,
      "time_range": [
        125,
        125.999
      ],
      "frame_range": [
        3751,
        3780
      ],
      "unified_description": "0",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:43",
        "processing_time": 3.54,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3765,
          "frame_range": [
            3761,
            3765
          ],
          "description": "a person in an orange jacket is standing near a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.89
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3751,
            3755
          ],
          "representative_frame": 3751,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9191197156906128,
              "bbox": [
                165.12554931640625,
                23.991003036499023,
                404.37847900390625,
                319.63983154296875
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3756,
            3760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3761,
            3765
          ],
          "representative_frame": 3761,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8590918779373169,
              "bbox": [
                210.3111572265625,
                59.5807991027832,
                417.80181884765625,
                313.3562316894531
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3766,
            3770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3771,
            3775
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9064251184463501,
              "bbox": [
                226.0743865966797,
                76.56267547607422,
                422.82586669921875,
                313.3888244628906
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3776,
            3780
          ],
          "representative_frame": 3776,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 31
    },
    {
      "second": 126,
      "time_range": [
        126,
        126.999
      ],
      "frame_range": [
        3781,
        3810
      ],
      "unified_description": "0:01 to 1:00",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:45",
        "processing_time": 3.01,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3795,
          "frame_range": [
            3791,
            3795
          ],
          "description": "a man in a red raincoat holding a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3781,
            3785
          ],
          "representative_frame": 3781,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8522056341171265,
              "bbox": [
                233.4984130859375,
                75.81134796142578,
                426.449462890625,
                304.1158752441406
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3786,
            3790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3791,
            3795
          ],
          "representative_frame": 3791,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9239524602890015,
              "bbox": [
                147.79502868652344,
                0.0,
                366.7275390625,
                349.7167663574219
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3796,
            3800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3801,
            3805
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9414013624191284,
              "bbox": [
                119.45958709716797,
                0.0,
                343.2064514160156,
                352.51885986328125
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3806,
            3810
          ],
          "representative_frame": 3806,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 31
    },
    {
      "second": 127,
      "time_range": [
        127,
        127.999
      ],
      "frame_range": [
        3811,
        3840
      ],
      "unified_description": "\n\nIn the image, there is a person wearing a red raincoat standing in front of a blue tent with a fishing rod in hand. Behind him, there is an area with gravel on the ground. The scene appears to be set outdoors during the daytime.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:48",
        "processing_time": 3.36,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3825,
          "frame_range": [
            3821,
            3825
          ],
          "description": "a man in a red suit is holding a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.2
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3811,
            3815
          ],
          "representative_frame": 3811,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9397888779640198,
              "bbox": [
                90.59207916259766,
                0.0,
                320.7160949707031,
                354.7749938964844
              ]
            },
            {
              "track_id": 281,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5897716283798218,
              "bbox": [
                14.13266658782959,
                3.370593309402466,
                78.35966491699219,
                106.71493530273438
              ]
            }
          ],
          "unique_tracks": [
            263,
            281
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3816,
            3820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3821,
            3825
          ],
          "representative_frame": 3821,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8679614663124084,
              "bbox": [
                104.25006866455078,
                3.204742431640625,
                327.5244140625,
                355.2072448730469
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3826,
            3830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3831,
            3835
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9243423342704773,
              "bbox": [
                206.77915954589844,
                132.92666625976562,
                397.7207336425781,
                347.4817199707031
              ]
            }
          ],
          "unique_tracks": [
            267
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3836,
            3840
          ],
          "representative_frame": 3836,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 31
    },
    {
      "second": 128,
      "time_range": [
        128,
        128.999
      ],
      "frame_range": [
        3841,
        3870
      ],
      "unified_description": "1-second video showing a man with a gun in the forest",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:49",
        "processing_time": 3.85,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3855,
          "frame_range": [
            3851,
            3855
          ],
          "description": "a man kneeling on a trail with a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.99
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3841,
            3845
          ],
          "representative_frame": 3841,
          "detections": [
            {
              "track_id": 284,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.47634559869766235,
              "bbox": [
                85.19857025146484,
                155.14491271972656,
                280.9656982421875,
                285.20361328125
              ]
            },
            {
              "track_id": 285,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4605056643486023,
              "bbox": [
                16.01636505126953,
                234.04014587402344,
                71.30549621582031,
                281.0043029785156
              ]
            },
            {
              "track_id": 286,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4092094898223877,
              "bbox": [
                148.78598022460938,
                311.79638671875,
                181.947021484375,
                352.7572937011719
              ]
            },
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9208215475082397,
              "bbox": [
                201.72267150878906,
                137.58709716796875,
                403.1380310058594,
                350.9912414550781
              ]
            }
          ],
          "unique_tracks": [
            284,
            285,
            286,
            267
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            3846,
            3850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3851,
            3855
          ],
          "representative_frame": 3851,
          "detections": [
            {
              "track_id": 284,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.5039286017417908,
              "bbox": [
                104.80691528320312,
                154.92626953125,
                264.5828857421875,
                260.37957763671875
              ]
            },
            {
              "track_id": 285,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.49681052565574646,
              "bbox": [
                17.208032608032227,
                234.78846740722656,
                71.55355072021484,
                280.9568176269531
              ]
            },
            {
              "track_id": 286,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.28776076436042786,
              "bbox": [
                148.8736572265625,
                311.7747802734375,
                181.93698120117188,
                352.619384765625
              ]
            },
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9268589019775391,
              "bbox": [
                201.6426544189453,
                139.72763061523438,
                412.2584228515625,
                352.3917236328125
              ]
            }
          ],
          "unique_tracks": [
            284,
            285,
            286,
            267
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            3856,
            3860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3861,
            3865
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 284,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.394092321395874,
              "bbox": [
                94.05780029296875,
                154.92141723632812,
                272.8049011230469,
                272.653076171875
              ]
            },
            {
              "track_id": 285,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.44527468085289,
              "bbox": [
                17.68712615966797,
                235.10586547851562,
                71.60930633544922,
                280.91986083984375
              ]
            },
            {
              "track_id": 286,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2971270680427551,
              "bbox": [
                148.4531707763672,
                311.7378234863281,
                181.76138305664062,
                352.8908386230469
              ]
            },
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8860067129135132,
              "bbox": [
                217.97120666503906,
                141.8557891845703,
                429.95697021484375,
                352.176513671875
              ]
            }
          ],
          "unique_tracks": [
            284,
            285,
            286,
            267
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            3866,
            3870
          ],
          "representative_frame": 3866,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 32
    },
    {
      "second": 129,
      "time_range": [
        129,
        129.999
      ],
      "frame_range": [
        3871,
        3900
      ],
      "unified_description": "2 men are outdoors, one wearing a red suit and hat, while another is sitting down in a black jacket with a raincoat, holding a blue object. They seem to be having a conversation.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:51",
        "processing_time": 4.43,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3885,
          "frame_range": [
            3881,
            3885
          ],
          "description": "a man in a raincoat is sitting on the ground",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.08
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3871,
            3875
          ],
          "representative_frame": 3871,
          "detections": [
            {
              "track_id": 284,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.4663860499858856,
              "bbox": [
                94.28135681152344,
                155.60462951660156,
                273.8116455078125,
                273.69879150390625
              ]
            },
            {
              "track_id": 285,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.21636982262134552,
              "bbox": [
                17.66950225830078,
                235.7194366455078,
                71.83189392089844,
                281.7498779296875
              ]
            },
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7466035485267639,
              "bbox": [
                238.08505249023438,
                140.64300537109375,
                448.49237060546875,
                350.67852783203125
              ]
            }
          ],
          "unique_tracks": [
            284,
            285,
            267
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3876,
            3880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3881,
            3885
          ],
          "representative_frame": 3881,
          "detections": [
            {
              "track_id": 284,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.15915492177009583,
              "bbox": [
                93.84870147705078,
                155.5462646484375,
                274.62103271484375,
                274.2528076171875
              ]
            },
            {
              "track_id": 285,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.21591965854167938,
              "bbox": [
                15.871758460998535,
                235.37159729003906,
                71.44573974609375,
                282.5693664550781
              ]
            },
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6196988224983215,
              "bbox": [
                245.709716796875,
                140.0030517578125,
                454.60626220703125,
                349.65704345703125
              ]
            },
            {
              "track_id": 288,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9294126629829407,
              "bbox": [
                448.4509582519531,
                20.016870498657227,
                568.9406127929688,
                357.0301513671875
              ]
            }
          ],
          "unique_tracks": [
            284,
            285,
            267,
            288
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            3886,
            3890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3891,
            3895
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 284,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.18991149961948395,
              "bbox": [
                92.34513092041016,
                155.72999572753906,
                275.9184875488281,
                276.2392883300781
              ]
            },
            {
              "track_id": 285,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.17743781208992004,
              "bbox": [
                16.433609008789062,
                235.71896362304688,
                71.28902435302734,
                282.2642822265625
              ]
            },
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7603909373283386,
              "bbox": [
                248.1461944580078,
                139.45010375976562,
                456.7845458984375,
                349.9248962402344
              ]
            },
            {
              "track_id": 288,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9274353981018066,
              "bbox": [
                449.0870666503906,
                19.293685913085938,
                569.7992553710938,
                356.966552734375
              ]
            }
          ],
          "unique_tracks": [
            284,
            285,
            267,
            288
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            3896,
            3900
          ],
          "representative_frame": 3896,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 32
    },
    {
      "second": 130,
      "time_range": [
        130,
        130.999
      ],
      "frame_range": [
        3901,
        3930
      ],
      "unified_description": "1-second video showing a man and a child fishing by a stream of water. The man is holding a fishing lure in his hand while the child looks on with interest. A container filled with different colored bait can be seen between them, along with several individual pieces of bait scattered around. There are multiple fish visible within the scene, indicating that they have already caught some fish.\n\nIn addition to the fishing activity, there are two backpacks in the scene, one close to the man and another close to the child, suggesting that they may have brought supplies and gear for their outdoor adventure.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:54",
        "processing_time": 4.35,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3915,
          "frame_range": [
            3911,
            3915
          ],
          "description": "a man and a child are fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.79
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3901,
            3905
          ],
          "representative_frame": 3901,
          "detections": [
            {
              "track_id": 284,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.36138564348220825,
              "bbox": [
                93.14584350585938,
                155.81678771972656,
                275.1715087890625,
                275.0836181640625
              ]
            },
            {
              "track_id": 285,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.20954281091690063,
              "bbox": [
                17.41349220275879,
                236.037841796875,
                71.4136962890625,
                281.8436279296875
              ]
            },
            {
              "track_id": 267,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7487442493438721,
              "bbox": [
                249.0355224609375,
                139.01051330566406,
                457.00384521484375,
                349.80230712890625
              ]
            },
            {
              "track_id": 288,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9276703000068665,
              "bbox": [
                449.58258056640625,
                18.748586654663086,
                570.4299926757812,
                356.92291259765625
              ]
            }
          ],
          "unique_tracks": [
            284,
            285,
            267,
            288
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            3906,
            3910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3911,
            3915
          ],
          "representative_frame": 3911,
          "detections": [
            {
              "track_id": 267,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.8555405139923096,
              "bbox": [
                271.65216064453125,
                156.54087829589844,
                482.4960632324219,
                354.4132995605469
              ]
            },
            {
              "track_id": 288,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9160124063491821,
              "bbox": [
                427.9867858886719,
                5.046103477478027,
                513.1635131835938,
                228.32669067382812
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.918298602104187,
              "bbox": [
                56.73206329345703,
                1.5559217929840088,
                273.4300231933594,
                303.5324401855469
              ]
            }
          ],
          "unique_tracks": [
            267,
            288,
            263
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            3916,
            3920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3921,
            3925
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 267,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.8324699401855469,
              "bbox": [
                276.4409484863281,
                162.8548583984375,
                495.48724365234375,
                355.8115234375
              ]
            },
            {
              "track_id": 288,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9224461317062378,
              "bbox": [
                419.4749755859375,
                0.5820472240447998,
                495.2762451171875,
                185.64678955078125
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9373006224632263,
              "bbox": [
                45.17530822753906,
                1.461925745010376,
                277.3657531738281,
                300.909423828125
              ]
            }
          ],
          "unique_tracks": [
            267,
            288,
            263
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            3926,
            3930
          ],
          "representative_frame": 3926,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 32
    },
    {
      "second": 131,
      "time_range": [
        131,
        131.999
      ],
      "frame_range": [
        3931,
        3960
      ],
      "unified_description": "1-second video showing a man and a child fishing by a stream of water. The man is kneeling down beside a container with bait in it, while the child is observing. There are several fish nearby, and an additional two people are present, one close to the observer and another nearer objects. A backpack can be seen placed on the ground next to the main subjects.\n\n cameras used for capturing the scene: 1-second videos covering various outdoor scenes, such as fishing, sports, and other activities",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:57",
        "processing_time": 5.75,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3945,
          "frame_range": [
            3941,
            3945
          ],
          "description": "a man and a child are fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.05
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3931,
            3935
          ],
          "representative_frame": 3931,
          "detections": [
            {
              "track_id": 267,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.8232827186584473,
              "bbox": [
                274.5673828125,
                165.1013946533203,
                503.2452087402344,
                356.1445617675781
              ]
            },
            {
              "track_id": 288,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9196203947067261,
              "bbox": [
                415.79620361328125,
                0.0,
                494.6133728027344,
                178.73768615722656
              ]
            },
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9396750330924988,
              "bbox": [
                39.43749237060547,
                1.3295612335205078,
                285.4447021484375,
                300.6626281738281
              ]
            }
          ],
          "unique_tracks": [
            267,
            288,
            263
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            3936,
            3940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3941,
            3945
          ],
          "representative_frame": 3941,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8674430251121521,
              "bbox": [
                80.44036865234375,
                0.9506572484970093,
                364.0397033691406,
                336.21148681640625
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3946,
            3950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3951,
            3955
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.939605176448822,
              "bbox": [
                69.96310424804688,
                0.5726470351219177,
                369.99853515625,
                349.1933288574219
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3956,
            3960
          ],
          "representative_frame": 3956,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 32
    },
    {
      "second": 132,
      "time_range": [
        132,
        132.999
      ],
      "frame_range": [
        3961,
        3990
      ],
      "unified_description": "\nA person wearing a red snowsuit is standing in the gravel.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:58",
        "processing_time": 5.84,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 3975,
          "frame_range": [
            3971,
            3975
          ],
          "description": "a man in a raincoat is holding a blue bottle",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.35
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3961,
            3965
          ],
          "representative_frame": 3961,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9337807297706604,
              "bbox": [
                64.80403137207031,
                0.33668404817581177,
                377.8264465332031,
                354.381591796875
              ]
            },
            {
              "track_id": 291,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8572908639907837,
              "bbox": [
                502.07745361328125,
                129.78927612304688,
                527.3197021484375,
                225.9468994140625
              ]
            }
          ],
          "unique_tracks": [
            263,
            291
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            3966,
            3970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            3971,
            3975
          ],
          "representative_frame": 3971,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9329207539558411,
              "bbox": [
                164.6983184814453,
                13.946122169494629,
                437.4096984863281,
                336.1076965332031
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            3976,
            3980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            3981,
            3985
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9324756860733032,
              "bbox": [
                204.9334259033203,
                19.564817428588867,
                455.85772705078125,
                328.8355712890625
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            3986,
            3990
          ],
          "representative_frame": 3986,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 33
    },
    {
      "second": 133,
      "time_range": [
        133,
        133.999
      ],
      "frame_range": [
        3991,
        4020
      ],
      "unified_description": "\nA man is fishing on a lake and there are some rocks nearby.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:28:59",
        "processing_time": 3.2,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4005,
          "frame_range": [
            4001,
            4005
          ],
          "description": "a man standing in the water with a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.91
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            3991,
            3995
          ],
          "representative_frame": 3991,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.908667266368866,
              "bbox": [
                217.3486785888672,
                27.62584114074707,
                444.37261962890625,
                325.6298522949219
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            3996,
            4000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4001,
            4005
          ],
          "representative_frame": 4001,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9179757833480835,
              "bbox": [
                218.056640625,
                37.952327728271484,
                421.3387756347656,
                323.0021057128906
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4006,
            4010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4011,
            4015
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9123133420944214,
              "bbox": [
                215.9710693359375,
                44.40370559692383,
                401.2050476074219,
                319.0133056640625
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4016,
            4020
          ],
          "representative_frame": 4016,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 33
    },
    {
      "second": 134,
      "time_range": [
        134,
        134.999
      ],
      "frame_range": [
        4021,
        4050
      ],
      "unified_description": "4K raw file with a lot of detail for editing purposes",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:01",
        "processing_time": 2.7,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4035,
          "frame_range": [
            4031,
            4035
          ],
          "description": "a man standing in the water near a mountain lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.44
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4021,
            4025
          ],
          "representative_frame": 4021,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9170299172401428,
              "bbox": [
                218.5652618408203,
                46.494293212890625,
                389.0827331542969,
                312.0735168457031
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4026,
            4030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4031,
            4035
          ],
          "representative_frame": 4031,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.920879602432251,
              "bbox": [
                223.52597045898438,
                29.3050537109375,
                399.34173583984375,
                316.33538818359375
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4036,
            4040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4041,
            4045
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.923750638961792,
              "bbox": [
                226.94039916992188,
                23.44733238220215,
                400.3505859375,
                319.667236328125
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4046,
            4050
          ],
          "representative_frame": 4046,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 33
    },
    {
      "second": 135,
      "time_range": [
        135,
        135.999
      ],
      "frame_range": [
        4051,
        4080
      ],
      "unified_description": "360-degree view of a man standing on a rock in the water, wearing a black jacket.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:02",
        "processing_time": 3.09,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4065,
          "frame_range": [
            4061,
            4065
          ],
          "description": "a man standing on a rock in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.31
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4051,
            4055
          ],
          "representative_frame": 4051,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9267103672027588,
              "bbox": [
                226.40237426757812,
                19.5357723236084,
                398.72650146484375,
                326.63580322265625
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4056,
            4060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4061,
            4065
          ],
          "representative_frame": 4061,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9183721542358398,
              "bbox": [
                227.26560974121094,
                16.893590927124023,
                394.1890869140625,
                326.5847473144531
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4066,
            4070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4071,
            4075
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9281783103942871,
              "bbox": [
                214.2215576171875,
                13.999114990234375,
                379.33880615234375,
                328.68994140625
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4076,
            4080
          ],
          "representative_frame": 4076,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 33
    },
    {
      "second": 136,
      "time_range": [
        136,
        136.999
      ],
      "frame_range": [
        4081,
        4110
      ],
      "unified_description": "\nA man standing on rocks next to a body of water holding a fishing rod.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:03",
        "processing_time": 3.8,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4095,
          "frame_range": [
            4091,
            4095
          ],
          "description": "a man fishing in a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.55
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4081,
            4085
          ],
          "representative_frame": 4081,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9100279808044434,
              "bbox": [
                193.02056884765625,
                8.195027351379395,
                359.560791015625,
                326.27264404296875
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4086,
            4090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4091,
            4095
          ],
          "representative_frame": 4091,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9241730570793152,
              "bbox": [
                167.77928161621094,
                2.8041419982910156,
                339.109619140625,
                329.1983947753906
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4096,
            4100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4101,
            4105
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9349157214164734,
              "bbox": [
                135.9355926513672,
                0.46839049458503723,
                320.3051452636719,
                342.6177978515625
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4106,
            4110
          ],
          "representative_frame": 4106,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 34
    },
    {
      "second": 137,
      "time_range": [
        137,
        137.999
      ],
      "frame_range": [
        4111,
        4140
      ],
      "unified_description": "00:01: A person is fishing with a red fish in the water",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:05",
        "processing_time": 2.9,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4125,
          "frame_range": [
            4121,
            4125
          ],
          "description": "a man is fishing in the water with a red fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.11
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4111,
            4115
          ],
          "representative_frame": 4111,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8914709687232971,
              "bbox": [
                99.37251281738281,
                0.0,
                295.49896240234375,
                349.327392578125
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4116,
            4120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4121,
            4125
          ],
          "representative_frame": 4121,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9278166890144348,
              "bbox": [
                87.39044189453125,
                0.0,
                297.0467529296875,
                354.9071960449219
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4126,
            4130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4131,
            4135
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9434413909912109,
              "bbox": [
                84.06859588623047,
                0.0,
                310.2976989746094,
                356.3312683105469
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4136,
            4140
          ],
          "representative_frame": 4136,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 34
    },
    {
      "second": 138,
      "time_range": [
        138,
        138.999
      ],
      "frame_range": [
        4141,
        4170
      ],
      "unified_description": "\nA man in a black jacket stands in a stream with a fishing rod. The image captures a 1-second scene that includes the following objects and actions: \n\n1. Person: A man wearing a black jacket is holding a fishing rod. He appears to be standing in a body of water, possibly fishing or simply enjoying the outdoors. \n2. Camera: The camera perspective suggests that the video was captured using a first-person point of view. This could mean that the camera is mounted on the person's helmet, chest, or another part of their body. \n3. Environment: The surrounding environment includes water and possibly mountains in the distance.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:08",
        "processing_time": 4.43,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4155,
          "frame_range": [
            4151,
            4155
          ],
          "description": "a man is standing in the water near a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.3
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4141,
            4145
          ],
          "representative_frame": 4141,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9470335245132446,
              "bbox": [
                146.17330932617188,
                0.0,
                382.7840270996094,
                356.6968994140625
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4146,
            4150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4151,
            4155
          ],
          "representative_frame": 4151,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9456887245178223,
              "bbox": [
                200.81065368652344,
                0.0,
                442.5738220214844,
                357.7358093261719
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4156,
            4160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4161,
            4165
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8400540351867676,
              "bbox": [
                263.119873046875,
                0.0,
                521.5897827148438,
                356.15667724609375
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4166,
            4170
          ],
          "representative_frame": 4166,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 34
    },
    {
      "second": 139,
      "time_range": [
        139,
        139.999
      ],
      "frame_range": [
        4171,
        4200
      ],
      "unified_description": "360 footage of man fly fishing on mountain lake with gray sky in background.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:09",
        "processing_time": 4.73,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4185,
          "frame_range": [
            4181,
            4185
          ],
          "description": "a person in red raincoat fishing on a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.94
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4171,
            4175
          ],
          "representative_frame": 4171,
          "detections": [
            {
              "track_id": 263,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.789762556552887,
              "bbox": [
                340.4327087402344,
                0.0,
                598.962646484375,
                354.0995788574219
              ]
            }
          ],
          "unique_tracks": [
            263
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4176,
            4180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4181,
            4185
          ],
          "representative_frame": 4181,
          "detections": [
            {
              "track_id": 298,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9412792325019836,
              "bbox": [
                40.61436462402344,
                56.351646423339844,
                139.0257110595703,
                356.2978820800781
              ]
            }
          ],
          "unique_tracks": [
            298
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4186,
            4190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4191,
            4195
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 298,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9292574524879456,
              "bbox": [
                27.29482650756836,
                114.67074584960938,
                107.82888793945312,
                357.0223693847656
              ]
            }
          ],
          "unique_tracks": [
            298
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4196,
            4200
          ],
          "representative_frame": 4196,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 34
    },
    {
      "second": 140,
      "time_range": [
        140,
        140.999
      ],
      "frame_range": [
        4201,
        4230
      ],
      "unified_description": "2 people standing by a river with their fishing rods.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:10",
        "processing_time": 4.42,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4215,
          "frame_range": [
            4211,
            4215
          ],
          "description": "a man fishing on a lake with a small boat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.87
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4201,
            4205
          ],
          "representative_frame": 4201,
          "detections": [
            {
              "track_id": 298,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9196736216545105,
              "bbox": [
                30.97791862487793,
                134.1464385986328,
                106.95972442626953,
                357.1019592285156
              ]
            }
          ],
          "unique_tracks": [
            298
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4206,
            4210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4211,
            4215
          ],
          "representative_frame": 4211,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            4216,
            4220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4221,
            4225
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8865914344787598,
              "bbox": [
                332.1776123046875,
                59.939796447753906,
                437.73486328125,
                283.7725524902344
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4226,
            4230
          ],
          "representative_frame": 4226,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 35
    },
    {
      "second": 141,
      "time_range": [
        141,
        141.999
      ],
      "frame_range": [
        4231,
        4260
      ],
      "unified_description": "1-second scene featuring a boy in an orange rain suit standing by a river and holding a fishing rod.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:12",
        "processing_time": 2.83,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4245,
          "frame_range": [
            4241,
            4245
          ],
          "description": "a young boy fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.06
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4231,
            4235
          ],
          "representative_frame": 4231,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8770541548728943,
              "bbox": [
                347.6111145019531,
                62.19424057006836,
                448.5191650390625,
                276.0837097167969
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4236,
            4240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4241,
            4245
          ],
          "representative_frame": 4241,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8901546001434326,
              "bbox": [
                368.7629699707031,
                69.94515228271484,
                465.3848571777344,
                274.1275939941406
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4246,
            4250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4251,
            4255
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9063456654548645,
              "bbox": [
                386.151611328125,
                70.5520248413086,
                481.65362548828125,
                271.8453369140625
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4256,
            4260
          ],
          "representative_frame": 4256,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 35
    },
    {
      "second": 142,
      "time_range": [
        142,
        142.999
      ],
      "frame_range": [
        4261,
        4290
      ],
      "unified_description": "1 second video showing young child wearing red jacket, waders and hat while fishing along riverbank in rocky area. Camera perspective is from behind the boy with stable camera positioning.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:14",
        "processing_time": 3.32,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4275,
          "frame_range": [
            4271,
            4275
          ],
          "description": "a little boy fishing on the river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.07
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4261,
            4265
          ],
          "representative_frame": 4261,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9420864582061768,
              "bbox": [
                395.2187194824219,
                67.64002227783203,
                490.9107666015625,
                265.77880859375
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4266,
            4270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4271,
            4275
          ],
          "representative_frame": 4271,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.922636866569519,
              "bbox": [
                409.1127624511719,
                62.831642150878906,
                508.4542236328125,
                265.3794250488281
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4276,
            4280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4281,
            4285
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9300698637962341,
              "bbox": [
                422.143798828125,
                57.88496780395508,
                523.9860229492188,
                263.1670837402344
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4286,
            4290
          ],
          "representative_frame": 4286,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 35
    },
    {
      "second": 143,
      "time_range": [
        143,
        143.999
      ],
      "frame_range": [
        4291,
        4320
      ],
      "unified_description": "360-degree video of a person fishing in a stream of water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:15",
        "processing_time": 3.74,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4305,
          "frame_range": [
            4301,
            4305
          ],
          "description": "a man in red jacket fishing on a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.75
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4291,
            4295
          ],
          "representative_frame": 4291,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9064003229141235,
              "bbox": [
                439.2178649902344,
                51.250064849853516,
                540.202392578125,
                255.2964324951172
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4296,
            4300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4301,
            4305
          ],
          "representative_frame": 4301,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9156732559204102,
              "bbox": [
                451.9591064453125,
                40.789302825927734,
                554.9269409179688,
                249.174072265625
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4306,
            4310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4311,
            4315
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8982585072517395,
              "bbox": [
                470.8917236328125,
                32.275699615478516,
                573.7933959960938,
                244.32228088378906
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4316,
            4320
          ],
          "representative_frame": 4316,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 35
    },
    {
      "second": 144,
      "time_range": [
        144,
        144.999
      ],
      "frame_range": [
        4321,
        4350
      ],
      "unified_description": "1-second scene of a man in a red outfit fishing on a rocky stream with a fly fishing rod.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:16",
        "processing_time": 3.11,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4335,
          "frame_range": [
            4331,
            4335
          ],
          "description": "a man in red jacket fishing on a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.15
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4321,
            4325
          ],
          "representative_frame": 4321,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9221512675285339,
              "bbox": [
                473.6224670410156,
                23.9945011138916,
                572.72314453125,
                230.83682250976562
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4326,
            4330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4331,
            4335
          ],
          "representative_frame": 4331,
          "detections": [
            {
              "track_id": 302,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8714593648910522,
              "bbox": [
                463.9439697265625,
                11.809684753417969,
                560.5751953125,
                216.76451110839844
              ]
            }
          ],
          "unique_tracks": [
            302
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4336,
            4340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4341,
            4345
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            4346,
            4350
          ],
          "representative_frame": 4346,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 36
    },
    {
      "second": 145,
      "time_range": [
        145,
        145.999
      ],
      "frame_range": [
        4351,
        4380
      ],
      "unified_description": "1 second video of a man fishing next to rocks.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:18",
        "processing_time": 2.68,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4365,
          "frame_range": [
            4361,
            4365
          ],
          "description": "a man is fishing in the water with a small fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.5
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4351,
            4355
          ],
          "representative_frame": 4351,
          "detections": [
            {
              "track_id": 303,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.888228714466095,
              "bbox": [
                429.3377990722656,
                0.0,
                501.9226379394531,
                187.99301147460938
              ]
            }
          ],
          "unique_tracks": [
            303
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4356,
            4360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4361,
            4365
          ],
          "representative_frame": 4361,
          "detections": [
            {
              "track_id": 303,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9133565425872803,
              "bbox": [
                427.6697692871094,
                0.10157407075166702,
                495.0918884277344,
                174.6377410888672
              ]
            }
          ],
          "unique_tracks": [
            303
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4366,
            4370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4371,
            4375
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 303,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8918793797492981,
              "bbox": [
                422.38232421875,
                0.459198921918869,
                484.2999572753906,
                159.8180389404297
              ]
            },
            {
              "track_id": 306,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7163785696029663,
              "bbox": [
                393.25335693359375,
                151.18846130371094,
                640.0,
                313.19024658203125
              ]
            }
          ],
          "unique_tracks": [
            303,
            306
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4376,
            4380
          ],
          "representative_frame": 4376,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 36
    },
    {
      "second": 146,
      "time_range": [
        146,
        146.999
      ],
      "frame_range": [
        4381,
        4410
      ],
      "unified_description": "\nAn outdoor scene captured with a wide-angle lens that showcases the area's surroundings. A small black dog is visible, walking on the ground. The camera positioning indicates it might be mounted on a backpack or body, allowing for an immersive perspective. The video style suggests this could be a vlog or documentation of daily life.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:20",
        "processing_time": 3.81,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4395,
          "frame_range": [
            4391,
            4395
          ],
          "description": "a small black dog is walking on the ground",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.14
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4381,
            4385
          ],
          "representative_frame": 4381,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            4386,
            4390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4391,
            4395
          ],
          "representative_frame": 4391,
          "detections": [
            {
              "track_id": 307,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.48331955075263977,
              "bbox": [
                304.3439025878906,
                324.91131591796875,
                368.4895935058594,
                359.0875549316406
              ]
            }
          ],
          "unique_tracks": [
            307
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4396,
            4400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4401,
            4405
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 307,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.20916417241096497,
              "bbox": [
                316.1864929199219,
                325.103271484375,
                380.3106689453125,
                359.1342468261719
              ]
            }
          ],
          "unique_tracks": [
            307
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4406,
            4410
          ],
          "representative_frame": 4406,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 36
    },
    {
      "second": 147,
      "time_range": [
        147,
        147.999
      ],
      "frame_range": [
        4411,
        4440
      ],
      "unified_description": "20 seconds of footage taken outdoors with a focus on a small dog. The camera is positioned in such a way that it is capturing the dog's movements as it walks around on the ground. This perspective allows viewers to closely observe the dog's features and behavior within its environment.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:22",
        "processing_time": 4.51,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4425,
          "frame_range": [
            4421,
            4425
          ],
          "description": "a small dog is walking on the ground",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.69
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4411,
            4415
          ],
          "representative_frame": 4411,
          "detections": [
            {
              "track_id": 307,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46176329255104065,
              "bbox": [
                316.5909423828125,
                318.5804138183594,
                393.49078369140625,
                359.3419494628906
              ]
            }
          ],
          "unique_tracks": [
            307
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4416,
            4420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4421,
            4425
          ],
          "representative_frame": 4421,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            4426,
            4430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4431,
            4435
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            4436,
            4440
          ],
          "representative_frame": 4436,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 36
    },
    {
      "second": 148,
      "time_range": [
        148,
        148.999
      ],
      "frame_range": [
        4441,
        4470
      ],
      "unified_description": "5-second scene captured by an action camera mounted on a helmet, showing a bird standing on the ground near a road.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:23",
        "processing_time": 3.86,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4455,
          "frame_range": [
            4451,
            4455
          ],
          "description": "a bird is standing on the ground near a road",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.06
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4441,
            4445
          ],
          "representative_frame": 4441,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            4446,
            4450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4451,
            4455
          ],
          "representative_frame": 4451,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            4456,
            4460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4461,
            4465
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            4466,
            4470
          ],
          "representative_frame": 4466,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 37
    },
    {
      "second": 149,
      "time_range": [
        149,
        149.999
      ],
      "frame_range": [
        4471,
        4500
      ],
      "unified_description": "1-second scene from a first-person perspective, showing a green bottle being held up.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:24",
        "processing_time": 3.23,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4485,
          "frame_range": [
            4481,
            4485
          ],
          "description": "a person is holding a bottle in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.01
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4471,
            4475
          ],
          "representative_frame": 4471,
          "detections": [
            {
              "track_id": 311,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4566049873828888,
              "bbox": [
                312.5059814453125,
                280.42181396484375,
                481.5094299316406,
                357.58551025390625
              ]
            }
          ],
          "unique_tracks": [
            311
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4476,
            4480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4481,
            4485
          ],
          "representative_frame": 4481,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            4486,
            4490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4491,
            4495
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 10,
              "class_name": "fire hydrant",
              "confidence": 0.8182810544967651,
              "bbox": [
                162.6947479248047,
                129.90281677246094,
                340.6569519042969,
                327.3556213378906
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4496,
            4500
          ],
          "representative_frame": 4496,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 37
    },
    {
      "second": 150,
      "time_range": [
        150,
        150.999
      ],
      "frame_range": [
        4501,
        4530
      ],
      "unified_description": "48 seconds of video with one person in red clothing bent over by rocks. The scene is set on the shore of a river with gravelly terrain. There are several different angles captured, including first-person perspective, wide-angle shots, and various other camera perspectives.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:26",
        "processing_time": 3.54,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4515,
          "frame_range": [
            4511,
            4515
          ],
          "description": "a little boy is standing on the shore of a river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.27
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4501,
            4505
          ],
          "representative_frame": 4501,
          "detections": [
            {
              "track_id": 312,
              "class_id": 10,
              "class_name": "fire hydrant",
              "confidence": 0.6393530964851379,
              "bbox": [
                175.61376953125,
                144.9830780029297,
                343.1524353027344,
                330.3402099609375
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4506,
            4510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4511,
            4515
          ],
          "representative_frame": 4511,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8926174640655518,
              "bbox": [
                148.91851806640625,
                92.37730407714844,
                335.39251708984375,
                299.8992919921875
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4516,
            4520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4521,
            4525
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9296920895576477,
              "bbox": [
                118.90109252929688,
                19.640031814575195,
                367.3115234375,
                299.5069274902344
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4526,
            4530
          ],
          "representative_frame": 4526,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 37
    },
    {
      "second": 151,
      "time_range": [
        151,
        151.999
      ],
      "frame_range": [
        4531,
        4560
      ],
      "unified_description": "2 men in red and white are at a rocky beach",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:28",
        "processing_time": 3.43,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4545,
          "frame_range": [
            4541,
            4545
          ],
          "description": "a man in a red jacket is fishing",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.16
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4531,
            4535
          ],
          "representative_frame": 4531,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9392074346542358,
              "bbox": [
                53.853755950927734,
                0.0,
                336.7944030761719,
                312.21881103515625
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4536,
            4540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4541,
            4545
          ],
          "representative_frame": 4541,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8808006644248962,
              "bbox": [
                26.68848991394043,
                0.0,
                318.3622131347656,
                311.60400390625
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4546,
            4550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4551,
            4555
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8737634420394897,
              "bbox": [
                8.837708473205566,
                0.0,
                300.14349365234375,
                307.7331848144531
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4556,
            4560
          ],
          "representative_frame": 4556,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 37
    },
    {
      "second": 152,
      "time_range": [
        152,
        152.999
      ],
      "frame_range": [
        4561,
        4590
      ],
      "unified_description": "1 person wearing orange is standing on rocks and holding a fishing pole",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:29",
        "processing_time": 3.18,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4575,
          "frame_range": [
            4571,
            4575
          ],
          "description": "a man in an orange jacket is holding a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.27
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4561,
            4565
          ],
          "representative_frame": 4561,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8596010208129883,
              "bbox": [
                9.271576881408691,
                0.0,
                318.08966064453125,
                326.9610900878906
              ]
            },
            {
              "track_id": 315,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.6094241142272949,
              "bbox": [
                542.5086669921875,
                218.04832458496094,
                640.0,
                354.0495910644531
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4566,
            4570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4571,
            4575
          ],
          "representative_frame": 4571,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8875506520271301,
              "bbox": [
                0.7186834812164307,
                0.0,
                324.70697021484375,
                343.907958984375
              ]
            },
            {
              "track_id": 315,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5661569833755493,
              "bbox": [
                533.8858642578125,
                200.3057098388672,
                640.0,
                356.5206298828125
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4576,
            4580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4581,
            4585
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4095940887928009,
              "bbox": [
                2.913428544998169,
                0.0,
                302.15789794921875,
                314.900390625
              ]
            },
            {
              "track_id": 315,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.24045465886592865,
              "bbox": [
                525.4176635742188,
                184.27902221679688,
                640.0,
                357.0458984375
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4586,
            4590
          ],
          "representative_frame": 4586,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 38
    },
    {
      "second": 153,
      "time_range": [
        153,
        153.999
      ],
      "frame_range": [
        4591,
        4620
      ],
      "unified_description": "34 second video showing two people on rocks with a fishing line",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:32",
        "processing_time": 2.77,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4605,
          "frame_range": [
            4601,
            4605
          ],
          "description": "a man in a red jacket is holding a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.34
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4591,
            4595
          ],
          "representative_frame": 4591,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4125855267047882,
              "bbox": [
                3.227276086807251,
                0.0,
                278.6756896972656,
                288.9560241699219
              ]
            },
            {
              "track_id": 315,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8111610412597656,
              "bbox": [
                514.6787109375,
                171.1211700439453,
                640.0,
                357.6986999511719
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4596,
            4600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4601,
            4605
          ],
          "representative_frame": 4601,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4477510154247284,
              "bbox": [
                0.0,
                0.0,
                271.5699462890625,
                288.28460693359375
              ]
            },
            {
              "track_id": 315,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8857772350311279,
              "bbox": [
                504.56268310546875,
                159.02261352539062,
                640.0,
                358.1815490722656
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4606,
            4610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4611,
            4615
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.845524787902832,
              "bbox": [
                0.0,
                2.69170880317688,
                276.5010070800781,
                320.63623046875
              ]
            },
            {
              "track_id": 315,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8893605470657349,
              "bbox": [
                497.12164306640625,
                150.48220825195312,
                640.0,
                357.8010559082031
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4616,
            4620
          ],
          "representative_frame": 4616,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 38
    },
    {
      "second": 154,
      "time_range": [
        154,
        154.999
      ],
      "frame_range": [
        4621,
        4650
      ],
      "unified_description": "3D object tracking and description (including camera positioning, focal length, object motion, etc.)",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:33",
        "processing_time": 3.26,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4635,
          "frame_range": [
            4631,
            4635
          ],
          "description": "a man in a red jacket is fishing",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 2.05
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4621,
            4625
          ],
          "representative_frame": 4621,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9203968048095703,
              "bbox": [
                0.0,
                23.293014526367188,
                280.9141540527344,
                343.24249267578125
              ]
            },
            {
              "track_id": 315,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.7662994265556335,
              "bbox": [
                493.13824462890625,
                146.63710021972656,
                640.0,
                358.2980041503906
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4626,
            4630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4631,
            4635
          ],
          "representative_frame": 4631,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9379542469978333,
              "bbox": [
                0.0,
                6.06247615814209,
                267.03900146484375,
                352.3517150878906
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4636,
            4640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4641,
            4645
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8760069012641907,
              "bbox": [
                0.0,
                0.0,
                246.08058166503906,
                355.167724609375
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4646,
            4650
          ],
          "representative_frame": 4646,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 38
    },
    {
      "second": 155,
      "time_range": [
        155,
        155.999
      ],
      "frame_range": [
        4651,
        4680
      ],
      "unified_description": "\nAn action camera is capturing a person's hand holding up a fish. The image features a first-person perspective, focusing on the fish being held up. There are two distinct tracks in the video, with a total of six groups of objects detected.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:35",
        "processing_time": 4.82,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4665,
          "frame_range": [
            4661,
            4665
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.24
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4651,
            4655
          ],
          "representative_frame": 4651,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            4656,
            4660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4661,
            4665
          ],
          "representative_frame": 4661,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5789675116539001,
              "bbox": [
                288.51666259765625,
                2.0318970680236816,
                640.0,
                297.2168273925781
              ]
            },
            {
              "track_id": 320,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8168693780899048,
              "bbox": [
                511.926513671875,
                6.2679290771484375,
                640.0,
                141.49156188964844
              ]
            }
          ],
          "unique_tracks": [
            319,
            320
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4666,
            4670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4671,
            4675
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.42330893874168396,
              "bbox": [
                319.08740234375,
                0.5110228657722473,
                640.0,
                271.5677795410156
              ]
            },
            {
              "track_id": 320,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7936788201332092,
              "bbox": [
                513.8333129882812,
                1.901511549949646,
                640.0,
                139.65174865722656
              ]
            }
          ],
          "unique_tracks": [
            319,
            320
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4676,
            4680
          ],
          "representative_frame": 4676,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 38
    },
    {
      "second": 156,
      "time_range": [
        156,
        156.999
      ],
      "frame_range": [
        4681,
        4710
      ],
      "unified_description": "1 second long fishing line that is attached to a large hook and being held by someone. The hook has a fish on it and there are rocks in the background.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:36",
        "processing_time": 3.48,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4695,
          "frame_range": [
            4691,
            4695
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.18
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4681,
            4685
          ],
          "representative_frame": 4681,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7909078001976013,
              "bbox": [
                318.03607177734375,
                0.5182351469993591,
                640.0,
                301.025634765625
              ]
            },
            {
              "track_id": 320,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7306848168373108,
              "bbox": [
                521.615478515625,
                8.604674339294434,
                640.0,
                149.17550659179688
              ]
            }
          ],
          "unique_tracks": [
            319,
            320
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4686,
            4690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4691,
            4695
          ],
          "representative_frame": 4691,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6605784893035889,
              "bbox": [
                327.0694580078125,
                14.075570106506348,
                640.0,
                309.19891357421875
              ]
            },
            {
              "track_id": 320,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7220056056976318,
              "bbox": [
                525.4408569335938,
                24.755014419555664,
                640.0,
                163.06346130371094
              ]
            }
          ],
          "unique_tracks": [
            319,
            320
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4696,
            4700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4701,
            4705
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 320,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8223918080329895,
              "bbox": [
                528.3626708984375,
                41.40770721435547,
                640.0,
                171.1859893798828
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8913098573684692,
              "bbox": [
                0.0,
                0.0,
                190.69566345214844,
                353.6866455078125
              ]
            }
          ],
          "unique_tracks": [
            320,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4706,
            4710
          ],
          "representative_frame": 4706,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 39
    },
    {
      "second": 157,
      "time_range": [
        157,
        157.999
      ],
      "frame_range": [
        4711,
        4740
      ],
      "unified_description": "2 frames of a man holding a fish outdoors",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:38",
        "processing_time": 3.09,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4725,
          "frame_range": [
            4721,
            4725
          ],
          "description": "a young boy holding a fish while standing on a rock",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.51
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4711,
            4715
          ],
          "representative_frame": 4711,
          "detections": [
            {
              "track_id": 320,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3923282027244568,
              "bbox": [
                540.8836059570312,
                49.5606689453125,
                640.0,
                170.89797973632812
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8478654623031616,
              "bbox": [
                0.0,
                0.638555109500885,
                189.28416442871094,
                353.5643615722656
              ]
            },
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5474868416786194,
              "bbox": [
                340.67950439453125,
                38.697696685791016,
                640.0,
                331.22998046875
              ]
            }
          ],
          "unique_tracks": [
            320,
            312,
            319
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            4716,
            4720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4721,
            4725
          ],
          "representative_frame": 4721,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8460029363632202,
              "bbox": [
                0.0,
                7.5406107902526855,
                184.90223693847656,
                353.4988708496094
              ]
            },
            {
              "track_id": 315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.554185152053833,
              "bbox": [
                441.028564453125,
                57.15785217285156,
                640.0,
                329.4996643066406
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4726,
            4730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4731,
            4735
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7803180813789368,
              "bbox": [
                0.0,
                36.866668701171875,
                180.2200469970703,
                353.7883605957031
              ]
            },
            {
              "track_id": 315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8045141100883484,
              "bbox": [
                449.4284362792969,
                60.03998565673828,
                640.0,
                327.4786376953125
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4736,
            4740
          ],
          "representative_frame": 4736,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 39
    },
    {
      "second": 158,
      "time_range": [
        158,
        158.999
      ],
      "frame_range": [
        4741,
        4770
      ],
      "unified_description": "1-second scene featuring a young boy holding a fish in his hand. Shot with an action camera, capturing the excitement and motion of the moment.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:39",
        "processing_time": 3.14,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4755,
          "frame_range": [
            4751,
            4755
          ],
          "description": "a young boy is holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.34
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4741,
            4745
          ],
          "representative_frame": 4741,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7623041272163391,
              "bbox": [
                0.0,
                52.41299057006836,
                205.73416137695312,
                354.4271545410156
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4746,
            4750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4751,
            4755
          ],
          "representative_frame": 4751,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8516412973403931,
              "bbox": [
                29.00789451599121,
                52.52294158935547,
                245.29440307617188,
                354.2013854980469
              ]
            },
            {
              "track_id": 315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.36167076230049133,
              "bbox": [
                467.0254211425781,
                83.80436706542969,
                640.0,
                341.599609375
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4756,
            4760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4761,
            4765
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9273594617843628,
              "bbox": [
                75.641357421875,
                46.90336608886719,
                306.292724609375,
                354.6307373046875
              ]
            },
            {
              "track_id": 315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.14855177700519562,
              "bbox": [
                481.7049560546875,
                94.2965087890625,
                640.0,
                329.0397644042969
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4766,
            4770
          ],
          "representative_frame": 4766,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 39
    },
    {
      "second": 159,
      "time_range": [
        159,
        159.999
      ],
      "frame_range": [
        4771,
        4800
      ],
      "unified_description": "1-second video depicting a boy in a red jacket holding up a fish near water. Another person is also present in the scene. The image features wide-angle distortion, giving the scene a broader perspective.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:41",
        "processing_time": 3.53,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4785,
          "frame_range": [
            4781,
            4785
          ],
          "description": "a young boy holding a fish while another looks on",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.32
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4771,
            4775
          ],
          "representative_frame": 4771,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9345875978469849,
              "bbox": [
                119.10761260986328,
                42.464454650878906,
                368.2901916503906,
                354.8338928222656
              ]
            },
            {
              "track_id": 315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5594966411590576,
              "bbox": [
                470.98187255859375,
                108.97759246826172,
                638.2896118164062,
                346.2293395996094
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4776,
            4780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4781,
            4785
          ],
          "representative_frame": 4781,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8848044276237488,
              "bbox": [
                148.10595703125,
                32.628150939941406,
                429.2641296386719,
                355.0283508300781
              ]
            },
            {
              "track_id": 315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.18933901190757751,
              "bbox": [
                478.75531005859375,
                117.14830780029297,
                640.0,
                352.09423828125
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4786,
            4790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4791,
            4795
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.930401086807251,
              "bbox": [
                125.04756927490234,
                24.316307067871094,
                435.3075866699219,
                354.9537658691406
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4796,
            4800
          ],
          "representative_frame": 4796,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 39
    },
    {
      "second": 160,
      "time_range": [
        160,
        160.999
      ],
      "frame_range": [
        4801,
        4830
      ],
      "unified_description": "2 people in red jackets are standing by a river holding fishing rods and reeling in fish",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:43",
        "processing_time": 3.82,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4815,
          "frame_range": [
            4811,
            4815
          ],
          "description": "a young boy is holding a fish in his hands",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4801,
            4805
          ],
          "representative_frame": 4801,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8786701560020447,
              "bbox": [
                87.52788543701172,
                41.314064025878906,
                387.44476318359375,
                353.9051513671875
              ]
            },
            {
              "track_id": 315,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8437597751617432,
              "bbox": [
                500.96099853515625,
                151.8039093017578,
                616.6842041015625,
                303.8447265625
              ]
            }
          ],
          "unique_tracks": [
            312,
            315
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4806,
            4810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4811,
            4815
          ],
          "representative_frame": 4811,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9509128332138062,
              "bbox": [
                32.877803802490234,
                13.946446418762207,
                358.93505859375,
                353.8651428222656
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4816,
            4820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4821,
            4825
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9328352808952332,
              "bbox": [
                42.78407287597656,
                88.74918365478516,
                310.2909240722656,
                354.2375793457031
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4826,
            4830
          ],
          "representative_frame": 4826,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 40
    },
    {
      "second": 161,
      "time_range": [
        161,
        161.999
      ],
      "frame_range": [
        4831,
        4860
      ],
      "unified_description": "1-second scene featuring a person standing on rocks that are brown and white, possibly in a wooded area. The camera is positioned above the person's shoulder, capturing their perspective as they look ahead.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:44",
        "processing_time": 3.58,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4845,
          "frame_range": [
            4841,
            4845
          ],
          "description": "a man is standing on a rock in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.37
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4831,
            4835
          ],
          "representative_frame": 4831,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            4836,
            4840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4841,
            4845
          ],
          "representative_frame": 4841,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            4846,
            4850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4851,
            4855
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 330,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8933636546134949,
              "bbox": [
                13.843061447143555,
                182.64483642578125,
                92.2089614868164,
                356.5507507324219
              ]
            }
          ],
          "unique_tracks": [
            330
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4856,
            4860
          ],
          "representative_frame": 4856,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 40
    },
    {
      "second": 162,
      "time_range": [
        162,
        162.999
      ],
      "frame_range": [
        4861,
        4890
      ],
      "unified_description": "3rd person perspective showing a child in a red coat reaching down to grab something out of frame. The image is grainy and appears to be captured with a wide-angle lens, giving a sense of context to the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:46",
        "processing_time": 3.16,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4875,
          "frame_range": [
            4871,
            4875
          ],
          "description": "a little boy in a red shirt is playing with a toy",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.75
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4861,
            4865
          ],
          "representative_frame": 4861,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8993358016014099,
              "bbox": [
                317.6246032714844,
                113.3757095336914,
                600.8434448242188,
                355.1620788574219
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4866,
            4870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4871,
            4875
          ],
          "representative_frame": 4871,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.926656186580658,
              "bbox": [
                390.1656494140625,
                173.73268127441406,
                612.6911010742188,
                357.1202697753906
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4876,
            4880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4881,
            4885
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7860571146011353,
              "bbox": [
                416.59765625,
                170.09521484375,
                640.0,
                357.60650634765625
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4886,
            4890
          ],
          "representative_frame": 4886,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 40
    },
    {
      "second": 163,
      "time_range": [
        163,
        163.999
      ],
      "frame_range": [
        4891,
        4920
      ],
      "unified_description": "3rd person perspective of a man in a red shirt who appears to be laying down by some rocks, possibly near water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:48",
        "processing_time": 3.56,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4905,
          "frame_range": [
            4901,
            4905
          ],
          "description": "a man in a red jacket is standing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.5
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4891,
            4895
          ],
          "representative_frame": 4891,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4740697741508484,
              "bbox": [
                418.6505126953125,
                161.9189453125,
                640.0,
                357.6028747558594
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4896,
            4900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4901,
            4905
          ],
          "representative_frame": 4901,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9276478290557861,
              "bbox": [
                348.17193603515625,
                156.23338317871094,
                578.1008911132812,
                356.4931640625
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4906,
            4910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4911,
            4915
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9232717752456665,
              "bbox": [
                247.22555541992188,
                123.41206359863281,
                506.7452697753906,
                355.3744201660156
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4916,
            4920
          ],
          "representative_frame": 4916,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 40
    },
    {
      "second": 164,
      "time_range": [
        164,
        164.999
      ],
      "frame_range": [
        4921,
        4950
      ],
      "unified_description": "4 frames per second 2k x 1k resolution sensor detected",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:49",
        "processing_time": 3.59,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4935,
          "frame_range": [
            4931,
            4935
          ],
          "description": "a little boy is playing with a toy on the beach",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.8
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4921,
            4925
          ],
          "representative_frame": 4921,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9115676879882812,
              "bbox": [
                176.22927856445312,
                117.66719055175781,
                431.97308349609375,
                351.73260498046875
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            4926,
            4930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4931,
            4935
          ],
          "representative_frame": 4931,
          "detections": [
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8882397413253784,
              "bbox": [
                75.6298828125,
                113.19013977050781,
                311.860595703125,
                352.6136474609375
              ]
            }
          ],
          "unique_tracks": [
            312
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            4936,
            4940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4941,
            4945
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9151659607887268,
              "bbox": [
                141.01414489746094,
                85.99337005615234,
                373.5735168457031,
                308.9243469238281
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            4946,
            4950
          ],
          "representative_frame": 4946,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 41
    },
    {
      "second": 165,
      "time_range": [
        165,
        165.999
      ],
      "frame_range": [
        4951,
        4980
      ],
      "unified_description": "3D model of a toddler in an orange snowsuit playing with rocks outdoors.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:51",
        "processing_time": 2.8,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4965,
          "frame_range": [
            4961,
            4965
          ],
          "description": "a baby in a red suit is playing with a toy",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.56
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4951,
            4955
          ],
          "representative_frame": 4951,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8829693794250488,
              "bbox": [
                435.6434326171875,
                180.76531982421875,
                528.2238159179688,
                310.7308349609375
              ]
            },
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.924800455570221,
              "bbox": [
                134.8405303955078,
                78.82254028320312,
                355.6300354003906,
                299.3954162597656
              ]
            }
          ],
          "unique_tracks": [
            335,
            319
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4956,
            4960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4961,
            4965
          ],
          "representative_frame": 4961,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8925555944442749,
              "bbox": [
                430.519287109375,
                181.3338623046875,
                523.4252319335938,
                311.756591796875
              ]
            },
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9183207154273987,
              "bbox": [
                131.64703369140625,
                80.56382751464844,
                341.24676513671875,
                297.6235656738281
              ]
            }
          ],
          "unique_tracks": [
            335,
            319
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4966,
            4970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            4971,
            4975
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.9105227589607239,
              "bbox": [
                436.6992492675781,
                185.24034118652344,
                527.5872192382812,
                312.9039611816406
              ]
            },
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8298460841178894,
              "bbox": [
                127.16133880615234,
                81.89787292480469,
                327.02349853515625,
                296.4176025390625
              ]
            }
          ],
          "unique_tracks": [
            335,
            319
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            4976,
            4980
          ],
          "representative_frame": 4976,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 41
    },
    {
      "second": 166,
      "time_range": [
        166,
        166.999
      ],
      "frame_range": [
        4981,
        5010
      ],
      "unified_description": "30 seconds left of video.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:52",
        "processing_time": 2.78,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 4995,
          "frame_range": [
            4991,
            4995
          ],
          "description": "a young boy in a red suit is playing with a toy",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.48
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            4981,
            4985
          ],
          "representative_frame": 4981,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.9075855612754822,
              "bbox": [
                448.1309509277344,
                186.8720245361328,
                538.5866088867188,
                314.1083679199219
              ]
            },
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9188287854194641,
              "bbox": [
                132.6003875732422,
                81.3159408569336,
                328.706298828125,
                299.1451721191406
              ]
            }
          ],
          "unique_tracks": [
            335,
            319
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            4986,
            4990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            4991,
            4995
          ],
          "representative_frame": 4991,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.9106636047363281,
              "bbox": [
                455.83270263671875,
                192.37265014648438,
                550.42138671875,
                325.9068298339844
              ]
            },
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7848377227783203,
              "bbox": [
                139.80616760253906,
                83.08729553222656,
                341.3787841796875,
                310.60162353515625
              ]
            }
          ],
          "unique_tracks": [
            335,
            319
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            4996,
            5000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5001,
            5005
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8312718868255615,
              "bbox": [
                469.3564147949219,
                203.64768981933594,
                569.7420654296875,
                345.985595703125
              ]
            },
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9223653078079224,
              "bbox": [
                132.14584350585938,
                93.05060577392578,
                339.2665100097656,
                333.21124267578125
              ]
            }
          ],
          "unique_tracks": [
            335,
            319
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5006,
            5010
          ],
          "representative_frame": 5006,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 41
    },
    {
      "second": 167,
      "time_range": [
        167,
        167.999
      ],
      "frame_range": [
        5011,
        5040
      ],
      "unified_description": "3rd person perspective of a child playing outside by the stream of water. The boy has a sand molding bucket and is playing with it while enjoying the water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:53",
        "processing_time": 3.42,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5025,
          "frame_range": [
            5021,
            5025
          ],
          "description": "a little boy is playing with a toy in the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.08
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5011,
            5015
          ],
          "representative_frame": 5011,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8835859894752502,
              "bbox": [
                482.97772216796875,
                214.30621337890625,
                583.4566650390625,
                357.07745361328125
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9204436540603638,
              "bbox": [
                122.48300170898438,
                117.99468994140625,
                346.93133544921875,
                358.1656188964844
              ]
            }
          ],
          "unique_tracks": [
            335,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5016,
            5020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5021,
            5025
          ],
          "representative_frame": 5021,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8357574939727783,
              "bbox": [
                485.26739501953125,
                218.7717742919922,
                584.9319458007812,
                360.0
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9141672253608704,
              "bbox": [
                133.8037109375,
                128.09814453125,
                344.93255615234375,
                357.23199462890625
              ]
            }
          ],
          "unique_tracks": [
            335,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5026,
            5030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5031,
            5035
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8614785075187683,
              "bbox": [
                476.5721740722656,
                213.8830108642578,
                576.9844970703125,
                358.6987609863281
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8965955376625061,
              "bbox": [
                149.1288299560547,
                151.8852081298828,
                339.7721862792969,
                357.2054138183594
              ]
            }
          ],
          "unique_tracks": [
            335,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5036,
            5040
          ],
          "representative_frame": 5036,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 41
    },
    {
      "second": 168,
      "time_range": [
        168,
        168.999
      ],
      "frame_range": [
        5041,
        5070
      ],
      "unified_description": "1 second of a young boy in a red jacket looking down at rocks and gravel on the ground with a fishing pole.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:55",
        "processing_time": 3.15,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5055,
          "frame_range": [
            5051,
            5055
          ],
          "description": "a young boy in a red jacket is fishing",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.91
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5041,
            5045
          ],
          "representative_frame": 5041,
          "detections": [
            {
              "track_id": 335,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.7737190127372742,
              "bbox": [
                471.0116882324219,
                203.15936279296875,
                568.8346557617188,
                346.686279296875
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9256290793418884,
              "bbox": [
                157.49844360351562,
                113.62548065185547,
                384.79815673828125,
                356.7939758300781
              ]
            }
          ],
          "unique_tracks": [
            335,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5046,
            5050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5051,
            5055
          ],
          "representative_frame": 5051,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            5056,
            5060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5061,
            5065
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8867955803871155,
              "bbox": [
                70.53390502929688,
                28.54171371459961,
                253.83871459960938,
                254.57766723632812
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9018373489379883,
              "bbox": [
                137.0054931640625,
                44.36376953125,
                355.6602478027344,
                298.191650390625
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5066,
            5070
          ],
          "representative_frame": 5066,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 42
    },
    {
      "second": 169,
      "time_range": [
        169,
        169.999
      ],
      "frame_range": [
        5071,
        5100
      ],
      "unified_description": "2 people with orange clothing standing by some water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:56",
        "processing_time": 3.07,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5085,
          "frame_range": [
            5081,
            5085
          ],
          "description": "a man and a child fishing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.11
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5071,
            5075
          ],
          "representative_frame": 5071,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9034910202026367,
              "bbox": [
                37.63624954223633,
                10.100027084350586,
                235.33694458007812,
                268.8561706542969
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.874995768070221,
              "bbox": [
                120.30886840820312,
                31.610645294189453,
                336.44122314453125,
                299.093505859375
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5076,
            5080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5081,
            5085
          ],
          "representative_frame": 5081,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.92645663022995,
              "bbox": [
                0.8910603523254395,
                6.002739906311035,
                212.18359375,
                296.8083190917969
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9058399796485901,
              "bbox": [
                108.40957641601562,
                37.8989372253418,
                320.3951110839844,
                314.0813903808594
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5086,
            5090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5091,
            5095
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9364771246910095,
              "bbox": [
                0.0,
                0.0,
                194.2222137451172,
                329.4370422363281
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.905439019203186,
              "bbox": [
                93.62471771240234,
                31.374067306518555,
                314.31524658203125,
                332.1023254394531
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5096,
            5100
          ],
          "representative_frame": 5096,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 42
    },
    {
      "second": 170,
      "time_range": [
        170,
        170.999
      ],
      "frame_range": [
        5101,
        5130
      ],
      "unified_description": "2 boys on the beach near some water. One boy is wearing a red jumpsuit while the other is wearing black clothes. They are playing by the water's edge and also talking to each other. A cell phone can be seen in the scene, possibly being used or recorded by one of the boys.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:29:58",
        "processing_time": 3.84,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5115,
          "frame_range": [
            5111,
            5115
          ],
          "description": "two boys playing in the water at the beach",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.0
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5101,
            5105
          ],
          "representative_frame": 5101,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9440268278121948,
              "bbox": [
                0.0,
                0.0,
                189.78665161132812,
                345.4314270019531
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9244157671928406,
              "bbox": [
                105.81529998779297,
                34.22062683105469,
                324.1150817871094,
                344.1172790527344
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5106,
            5110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5111,
            5115
          ],
          "representative_frame": 5111,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9212497472763062,
              "bbox": [
                0.0,
                0.0,
                192.1504364013672,
                351.6128234863281
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9229233264923096,
              "bbox": [
                126.78443145751953,
                30.45287322998047,
                338.995849609375,
                342.72369384765625
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5116,
            5120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5121,
            5125
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9477468729019165,
              "bbox": [
                0.0,
                0.0,
                200.51600646972656,
                355.92822265625
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9219252467155457,
              "bbox": [
                142.22569274902344,
                42.38793182373047,
                339.36419677734375,
                338.1576843261719
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5126,
            5130
          ],
          "representative_frame": 5126,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 42
    },
    {
      "second": 171,
      "time_range": [
        171,
        171.999
      ],
      "frame_range": [
        5131,
        5160
      ],
      "unified_description": "2 young boys in red raincoats are by a lake, one of them holding a fish while the other watches",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:00",
        "processing_time": 2.97,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5145,
          "frame_range": [
            5141,
            5145
          ],
          "description": "a young boy is holding a fish while another boy watches",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.89
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5131,
            5135
          ],
          "representative_frame": 5131,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.920724630355835,
              "bbox": [
                0.0,
                0.0,
                227.64755249023438,
                357.37353515625
              ]
            },
            {
              "track_id": 312,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9341825246810913,
              "bbox": [
                169.26405334472656,
                53.08281326293945,
                354.68121337890625,
                334.2976379394531
              ]
            }
          ],
          "unique_tracks": [
            319,
            312
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5136,
            5140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5141,
            5145
          ],
          "representative_frame": 5141,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9176084995269775,
              "bbox": [
                9.920516014099121,
                92.06190490722656,
                184.0093536376953,
                358.94683837890625
              ]
            }
          ],
          "unique_tracks": [
            319
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5146,
            5150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5151,
            5155
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9368338584899902,
              "bbox": [
                12.13298225402832,
                133.8043212890625,
                163.216796875,
                359.46136474609375
              ]
            },
            {
              "track_id": 341,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8348084092140198,
              "bbox": [
                543.4950561523438,
                90.36190032958984,
                585.7164306640625,
                183.05445861816406
              ]
            }
          ],
          "unique_tracks": [
            319,
            341
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5156,
            5160
          ],
          "representative_frame": 5156,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 42
    },
    {
      "second": 172,
      "time_range": [
        172,
        172.999
      ],
      "frame_range": [
        5161,
        5190
      ],
      "unified_description": "3 boys standing by a body of water, one of whom has a fishing rod",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:01",
        "processing_time": 3.2,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5175,
          "frame_range": [
            5171,
            5175
          ],
          "description": "a little boy is fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.42
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5161,
            5165
          ],
          "representative_frame": 5161,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.930839478969574,
              "bbox": [
                16.863893508911133,
                147.5526885986328,
                161.09364318847656,
                359.2975158691406
              ]
            },
            {
              "track_id": 341,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8253772854804993,
              "bbox": [
                536.374267578125,
                84.69139862060547,
                582.0540161132812,
                185.51275634765625
              ]
            }
          ],
          "unique_tracks": [
            319,
            341
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5166,
            5170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5171,
            5175
          ],
          "representative_frame": 5171,
          "detections": [
            {
              "track_id": 319,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9344913959503174,
              "bbox": [
                13.615920066833496,
                151.97816467285156,
                157.9364013671875,
                359.3590393066406
              ]
            },
            {
              "track_id": 341,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8597415089607239,
              "bbox": [
                531.92138671875,
                81.54613494873047,
                577.643798828125,
                183.43533325195312
              ]
            }
          ],
          "unique_tracks": [
            319,
            341
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5176,
            5180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5181,
            5185
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            5186,
            5190
          ],
          "representative_frame": 5186,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 43
    },
    {
      "second": 173,
      "time_range": [
        173,
        173.999
      ],
      "frame_range": [
        5191,
        5220
      ],
      "unified_description": "1-second video showing a person standing knee deep in a river with a fish nearby. The camera's perspective is from the person's point of view, making it appear as if the viewer is experiencing the scene from within the moment.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:03",
        "processing_time": 3.4,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5205,
          "frame_range": [
            5201,
            5205
          ],
          "description": "a man standing in the water with a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.88
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5191,
            5195
          ],
          "representative_frame": 5191,
          "detections": [
            {
              "track_id": 343,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9281894564628601,
              "bbox": [
                496.32928466796875,
                0.6596618890762329,
                640.0,
                354.88671875
              ]
            },
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7608978152275085,
              "bbox": [
                164.730224609375,
                195.27825927734375,
                184.01597595214844,
                222.46783447265625
              ]
            }
          ],
          "unique_tracks": [
            343,
            344
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5196,
            5200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5201,
            5205
          ],
          "representative_frame": 5201,
          "detections": [
            {
              "track_id": 343,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9363650679588318,
              "bbox": [
                500.52813720703125,
                0.6749630570411682,
                640.0,
                356.1379089355469
              ]
            },
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7226076722145081,
              "bbox": [
                165.1674346923828,
                195.21780395507812,
                184.34022521972656,
                222.2054443359375
              ]
            }
          ],
          "unique_tracks": [
            343,
            344
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5206,
            5210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5211,
            5215
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 343,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9227842688560486,
              "bbox": [
                506.2726745605469,
                0.38121578097343445,
                640.0,
                355.4765930175781
              ]
            },
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7514481544494629,
              "bbox": [
                165.15890502929688,
                194.67710876464844,
                184.6216583251953,
                221.94387817382812
              ]
            }
          ],
          "unique_tracks": [
            343,
            344
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5216,
            5220
          ],
          "representative_frame": 5216,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 43
    },
    {
      "second": 174,
      "time_range": [
        174,
        174.999
      ],
      "frame_range": [
        5221,
        5250
      ],
      "unified_description": "360-degree footage shows a man fishing in a lake.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:04",
        "processing_time": 3.01,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5235,
          "frame_range": [
            5231,
            5235
          ],
          "description": "a man fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.02
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5221,
            5225
          ],
          "representative_frame": 5221,
          "detections": [
            {
              "track_id": 343,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9196679592132568,
              "bbox": [
                509.5222473144531,
                0.2592177093029022,
                640.0,
                355.22161865234375
              ]
            },
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7261301279067993,
              "bbox": [
                165.49465942382812,
                194.7743682861328,
                185.22332763671875,
                222.23297119140625
              ]
            }
          ],
          "unique_tracks": [
            343,
            344
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5226,
            5230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5231,
            5235
          ],
          "representative_frame": 5231,
          "detections": [
            {
              "track_id": 343,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9088490009307861,
              "bbox": [
                513.425537109375,
                0.3059825301170349,
                640.0,
                354.8275146484375
              ]
            },
            {
              "track_id": 344,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.4050411880016327,
              "bbox": [
                166.69308471679688,
                199.7772216796875,
                182.70533752441406,
                221.75624084472656
              ]
            }
          ],
          "unique_tracks": [
            343,
            344
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5236,
            5240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5241,
            5245
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.538180947303772,
              "bbox": [
                168.37451171875,
                196.58840942382812,
                182.64332580566406,
                216.2259063720703
              ]
            }
          ],
          "unique_tracks": [
            344
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5246,
            5250
          ],
          "representative_frame": 5246,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 43
    },
    {
      "second": 175,
      "time_range": [
        175,
        175.999
      ],
      "frame_range": [
        5251,
        5280
      ],
      "unified_description": "1 second of video featuring a person fishing with a rod. The footage appears to be slightly blurry, indicating motion or unsteady camera work. The scene is set in an outdoor location, possibly near a lake or river.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:05",
        "processing_time": 3.47,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5265,
          "frame_range": [
            5261,
            5265
          ],
          "description": "a man is fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5251,
            5255
          ],
          "representative_frame": 5251,
          "detections": [
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5532517433166504,
              "bbox": [
                169.61801147460938,
                195.63783264160156,
                181.84500122070312,
                212.42286682128906
              ]
            },
            {
              "track_id": 346,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6814907193183899,
              "bbox": [
                597.8801879882812,
                0.437173455953598,
                640.0,
                140.58460998535156
              ]
            }
          ],
          "unique_tracks": [
            344,
            346
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5256,
            5260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5261,
            5265
          ],
          "representative_frame": 5261,
          "detections": [
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.35994991660118103,
              "bbox": [
                169.06239318847656,
                195.4078369140625,
                183.1121368408203,
                214.90103149414062
              ]
            },
            {
              "track_id": 346,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.848861813545227,
              "bbox": [
                596.2578125,
                0.11173190921545029,
                638.7237548828125,
                140.55616760253906
              ]
            }
          ],
          "unique_tracks": [
            344,
            346
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5266,
            5270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5271,
            5275
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 344,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.41639116406440735,
              "bbox": [
                169.25767517089844,
                195.29367065429688,
                183.31192016601562,
                214.9426727294922
              ]
            },
            {
              "track_id": 346,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6521244645118713,
              "bbox": [
                594.4468994140625,
                0.16909413039684296,
                640.0,
                163.070556640625
              ]
            },
            {
              "track_id": 348,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4385325312614441,
              "bbox": [
                169.7101287841797,
                195.32354736328125,
                182.97154235839844,
                223.41995239257812
              ]
            }
          ],
          "unique_tracks": [
            344,
            346,
            348
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            5276,
            5280
          ],
          "representative_frame": 5276,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 43
    },
    {
      "second": 176,
      "time_range": [
        176,
        176.999
      ],
      "frame_range": [
        5281,
        5310
      ],
      "unified_description": "1 second long, an action camera video depicting a man fishing in the water with a rod. The video has some technical artifacts present, such as motion blur, lens flare, and compression artifacts. It's captured from the first-person perspective, offering an immersive experience of the outdoors.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:07",
        "processing_time": 3.6,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5295,
          "frame_range": [
            5291,
            5295
          ],
          "description": "a man fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5281,
            5285
          ],
          "representative_frame": 5281,
          "detections": [
            {
              "track_id": 346,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8223833441734314,
              "bbox": [
                588.9314575195312,
                0.412706583738327,
                640.0,
                173.40260314941406
              ]
            },
            {
              "track_id": 348,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.636078953742981,
              "bbox": [
                171.30850219726562,
                195.30467224121094,
                185.679931640625,
                225.527099609375
              ]
            }
          ],
          "unique_tracks": [
            346,
            348
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5286,
            5290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5291,
            5295
          ],
          "representative_frame": 5291,
          "detections": [
            {
              "track_id": 346,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4552532434463501,
              "bbox": [
                583.894775390625,
                0.5657723546028137,
                638.8536987304688,
                182.60482788085938
              ]
            },
            {
              "track_id": 348,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.54554283618927,
              "bbox": [
                170.3324737548828,
                195.47235107421875,
                184.46127319335938,
                225.09425354003906
              ]
            },
            {
              "track_id": 343,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7516137361526489,
              "bbox": [
                542.037353515625,
                0.47423601150512695,
                640.0,
                354.79779052734375
              ]
            }
          ],
          "unique_tracks": [
            346,
            348,
            343
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            5296,
            5300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5301,
            5305
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 346,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3986172080039978,
              "bbox": [
                576.8670043945312,
                0.464653342962265,
                634.4386596679688,
                188.31484985351562
              ]
            },
            {
              "track_id": 348,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5893583297729492,
              "bbox": [
                170.23333740234375,
                195.5476837158203,
                184.2494659423828,
                224.7449951171875
              ]
            },
            {
              "track_id": 343,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4292701184749603,
              "bbox": [
                542.4889526367188,
                0.8680613040924072,
                640.0,
                352.2469482421875
              ]
            }
          ],
          "unique_tracks": [
            346,
            348,
            343
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            5306,
            5310
          ],
          "representative_frame": 5306,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 44
    },
    {
      "second": 177,
      "time_range": [
        177,
        177.999
      ],
      "frame_range": [
        5311,
        5340
      ],
      "unified_description": "3rd person perspective of a boy fishing with his flies. The image has been slightly blurred to emphasize the motion of the fisherman and the water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:09",
        "processing_time": 3.69,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5325,
          "frame_range": [
            5321,
            5325
          ],
          "description": "a man fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.94
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5311,
            5315
          ],
          "representative_frame": 5311,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            5316,
            5320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5321,
            5325
          ],
          "representative_frame": 5321,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9392979741096497,
              "bbox": [
                30.075132369995117,
                67.46487426757812,
                172.24449157714844,
                356.869384765625
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5326,
            5330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5331,
            5335
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9104964733123779,
              "bbox": [
                25.07503890991211,
                60.655879974365234,
                168.97207641601562,
                354.0326232910156
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5336,
            5340
          ],
          "representative_frame": 5336,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 44
    },
    {
      "second": 178,
      "time_range": [
        178,
        178.999
      ],
      "frame_range": [
        5341,
        5370
      ],
      "unified_description": "1-second video capturing a person fishing in a river with a fisheye perspective.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:10",
        "processing_time": 3.36,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5355,
          "frame_range": [
            5351,
            5355
          ],
          "description": "a boy fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.94
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5341,
            5345
          ],
          "representative_frame": 5341,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9218047857284546,
              "bbox": [
                24.52728843688965,
                52.87847137451172,
                173.64242553710938,
                354.98583984375
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5346,
            5350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5351,
            5355
          ],
          "representative_frame": 5351,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9231960773468018,
              "bbox": [
                24.454898834228516,
                48.07109069824219,
                176.27438354492188,
                355.7867126464844
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5356,
            5360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5361,
            5365
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.909283459186554,
              "bbox": [
                22.33523178100586,
                42.03041076660156,
                172.96018981933594,
                348.0800476074219
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5366,
            5370
          ],
          "representative_frame": 5366,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 44
    },
    {
      "second": 179,
      "time_range": [
        179,
        179.999
      ],
      "frame_range": [
        5371,
        5400
      ],
      "unified_description": "2 men are standing outside near water with fishing rods in their hands.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:11",
        "processing_time": 2.8,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5385,
          "frame_range": [
            5381,
            5385
          ],
          "description": "a young boy fishing on a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.81
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5371,
            5375
          ],
          "representative_frame": 5371,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9438202381134033,
              "bbox": [
                14.039931297302246,
                47.24640655517578,
                165.80067443847656,
                353.6448059082031
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5376,
            5380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5381,
            5385
          ],
          "representative_frame": 5381,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8675960898399353,
              "bbox": [
                4.618818283081055,
                41.28384780883789,
                159.28997802734375,
                353.222412109375
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5386,
            5390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5391,
            5395
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 351,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8995794653892517,
              "bbox": [
                0.0,
                37.90673065185547,
                153.25979614257812,
                353.71905517578125
              ]
            }
          ],
          "unique_tracks": [
            351
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5396,
            5400
          ],
          "representative_frame": 5396,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 44
    },
    {
      "second": 180,
      "time_range": [
        180,
        180.999
      ],
      "frame_range": [
        5401,
        5430
      ],
      "unified_description": "2 people are standing by a river with a fish between them",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:12",
        "processing_time": 2.78,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5415,
          "frame_range": [
            5411,
            5415
          ],
          "description": "a person is holding a small fish in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.04
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5401,
            5405
          ],
          "representative_frame": 5401,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            5406,
            5410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5411,
            5415
          ],
          "representative_frame": 5411,
          "detections": [
            {
              "track_id": 346,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8330817818641663,
              "bbox": [
                500.2812194824219,
                49.548614501953125,
                567.5701904296875,
                190.58334350585938
              ]
            }
          ],
          "unique_tracks": [
            346
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5416,
            5420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5421,
            5425
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            5426,
            5430
          ],
          "representative_frame": 5426,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 45
    },
    {
      "second": 181,
      "time_range": [
        181,
        181.999
      ],
      "frame_range": [
        5431,
        5460
      ],
      "unified_description": "\nA person walking on wet ground. The camera is mounted on a backpack.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:14",
        "processing_time": 3.08,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5445,
          "frame_range": [
            5441,
            5445
          ],
          "description": "a man is holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.7
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5431,
            5435
          ],
          "representative_frame": 5431,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            5436,
            5440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5441,
            5445
          ],
          "representative_frame": 5441,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            5446,
            5450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5451,
            5455
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            5456,
            5460
          ],
          "representative_frame": 5456,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 45
    },
    {
      "second": 182,
      "time_range": [
        182,
        182.999
      ],
      "frame_range": [
        5461,
        5490
      ],
      "unified_description": "3rd person perspective of a wet ground surface.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:15",
        "processing_time": 2.69,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5475,
          "frame_range": [
            5471,
            5475
          ],
          "description": "a dog is walking on the road with a leash",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.97
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5461,
            5465
          ],
          "representative_frame": 5461,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            5466,
            5470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5471,
            5475
          ],
          "representative_frame": 5471,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            5476,
            5480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5481,
            5485
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            5486,
            5490
          ],
          "representative_frame": 5486,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 45
    },
    {
      "second": 183,
      "time_range": [
        183,
        183.999
      ],
      "frame_range": [
        5491,
        5520
      ],
      "unified_description": "10-second video with a hand picking up a book from the floor, set in an outdoor location. The camera is mounted on the person's head, capturing their first-person perspective as they bend down to retrieve the dropped object.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:17",
        "processing_time": 3.2,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5505,
          "frame_range": [
            5501,
            5505
          ],
          "description": "a man is holding a bag of food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5491,
            5495
          ],
          "representative_frame": 5491,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8022205829620361,
              "bbox": [
                339.13482666015625,
                11.484094619750977,
                640.0,
                254.48416137695312
              ]
            }
          ],
          "unique_tracks": [
            366
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5496,
            5500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5501,
            5505
          ],
          "representative_frame": 5501,
          "detections": [
            {
              "track_id": 366,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8743597269058228,
              "bbox": [
                274.1254577636719,
                20.510143280029297,
                606.756103515625,
                266.9635925292969
              ]
            },
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5576781630516052,
              "bbox": [
                319.21954345703125,
                65.1202163696289,
                602.8892822265625,
                352.9620056152344
              ]
            }
          ],
          "unique_tracks": [
            366,
            369
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5506,
            5510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5511,
            5515
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            5516,
            5520
          ],
          "representative_frame": 5516,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 45
    },
    {
      "second": 184,
      "time_range": [
        184,
        184.999
      ],
      "frame_range": [
        5521,
        5550
      ],
      "unified_description": "3rd person perspective showing a stream with green trees on the side.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:18",
        "processing_time": 3.59,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5535,
          "frame_range": [
            5531,
            5535
          ],
          "description": "a man is fishing in the river",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.53
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5521,
            5525
          ],
          "representative_frame": 5521,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            5526,
            5530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5531,
            5535
          ],
          "representative_frame": 5531,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            5536,
            5540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5541,
            5545
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            5546,
            5550
          ],
          "representative_frame": 5546,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 46
    },
    {
      "second": 185,
      "time_range": [
        185,
        185.999
      ],
      "frame_range": [
        5551,
        5580
      ],
      "unified_description": "1 second long video that shows two people fishing next to a body of water with rocks in it. The camera is capturing the action from an overhead perspective.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:19",
        "processing_time": 3.74,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5565,
          "frame_range": [
            5561,
            5565
          ],
          "description": "a man and woman fishing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.57
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5551,
            5555
          ],
          "representative_frame": 5551,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            5556,
            5560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5561,
            5565
          ],
          "representative_frame": 5561,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            5566,
            5570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5571,
            5575
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9130672216415405,
              "bbox": [
                565.04150390625,
                2.2550415992736816,
                639.4678955078125,
                254.75222778320312
              ]
            },
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9392371773719788,
              "bbox": [
                0.0,
                2.2017934322357178,
                420.7179870605469,
                346.9678039550781
              ]
            }
          ],
          "unique_tracks": [
            374,
            366
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5576,
            5580
          ],
          "representative_frame": 5576,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 46
    },
    {
      "second": 186,
      "time_range": [
        186,
        186.999
      ],
      "frame_range": [
        5581,
        5610
      ],
      "unified_description": "1-second scene featuring two men fishing with one man holding a fish near the water's edge while another man stands further back on the shore",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:21",
        "processing_time": 2.92,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5595,
          "frame_range": [
            5591,
            5595
          ],
          "description": "a man holding a fish while another man holds it",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.05
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5581,
            5585
          ],
          "representative_frame": 5581,
          "detections": [
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9187454581260681,
              "bbox": [
                567.3665161132812,
                1.6942416429519653,
                640.0,
                255.85533142089844
              ]
            },
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9426503777503967,
              "bbox": [
                0.0,
                0.8503158092498779,
                413.33770751953125,
                353.7829895019531
              ]
            }
          ],
          "unique_tracks": [
            374,
            366
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5586,
            5590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5591,
            5595
          ],
          "representative_frame": 5591,
          "detections": [
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9068547487258911,
              "bbox": [
                566.15869140625,
                0.8847631812095642,
                640.0,
                257.4070129394531
              ]
            },
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.926922082901001,
              "bbox": [
                0.0,
                0.0,
                396.158203125,
                357.36029052734375
              ]
            }
          ],
          "unique_tracks": [
            374,
            366
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5596,
            5600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5601,
            5605
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.91934734582901,
              "bbox": [
                565.6592407226562,
                1.4044791460037231,
                640.0,
                257.3759460449219
              ]
            },
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9333745837211609,
              "bbox": [
                0.0,
                0.0,
                375.2656555175781,
                358.7870178222656
              ]
            }
          ],
          "unique_tracks": [
            374,
            366
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5606,
            5610
          ],
          "representative_frame": 5606,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 46
    },
    {
      "second": 187,
      "time_range": [
        187,
        187.999
      ],
      "frame_range": [
        5611,
        5640
      ],
      "unified_description": "4 people are standing around in the rain next to a lake and talking. The camera is positioned on an overhead tripod and is capturing the scene with a wide-angle lens, creating a panoramic effect. The image also features fish and a boat on the water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:22",
        "processing_time": 3.53,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5625,
          "frame_range": [
            5621,
            5625
          ],
          "description": "a man is fishing on the water with a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.04
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5611,
            5615
          ],
          "representative_frame": 5611,
          "detections": [
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5692390203475952,
              "bbox": [
                580.3338012695312,
                27.845354080200195,
                637.49658203125,
                221.0421905517578
              ]
            },
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7584248185157776,
              "bbox": [
                5.335646629333496,
                0.09527631103992462,
                399.00531005859375,
                359.78369140625
              ]
            }
          ],
          "unique_tracks": [
            374,
            366
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5616,
            5620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5621,
            5625
          ],
          "representative_frame": 5621,
          "detections": [
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8640958666801453,
              "bbox": [
                587.3464965820312,
                24.206777572631836,
                640.0,
                217.4116973876953
              ]
            },
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6543794274330139,
              "bbox": [
                20.38423728942871,
                0.010637642815709114,
                406.6833801269531,
                359.6978759765625
              ]
            }
          ],
          "unique_tracks": [
            374,
            366
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5626,
            5630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5631,
            5635
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.707241952419281,
              "bbox": [
                592.934326171875,
                39.2801628112793,
                640.0,
                217.58853149414062
              ]
            },
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8909397125244141,
              "bbox": [
                27.32643699645996,
                0.0,
                406.10015869140625,
                359.1607666015625
              ]
            }
          ],
          "unique_tracks": [
            374,
            366
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5636,
            5640
          ],
          "representative_frame": 5636,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 46
    },
    {
      "second": 188,
      "time_range": [
        188,
        188.999
      ],
      "frame_range": [
        5641,
        5670
      ],
      "unified_description": "365 days of fishing on a lake, capturing a single moment where a man casts his line into the water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:24",
        "processing_time": 3.84,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5655,
          "frame_range": [
            5651,
            5655
          ],
          "description": "a man is fishing on the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.65
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5641,
            5645
          ],
          "representative_frame": 5641,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8450759053230286,
              "bbox": [
                32.82575225830078,
                0.27928200364112854,
                404.040283203125,
                358.6175537109375
              ]
            }
          ],
          "unique_tracks": [
            366
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5646,
            5650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5651,
            5655
          ],
          "representative_frame": 5651,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7002034783363342,
              "bbox": [
                42.03224563598633,
                0.0,
                406.0140380859375,
                358.9801330566406
              ]
            },
            {
              "track_id": 378,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5456008911132812,
              "bbox": [
                623.9221801757812,
                105.83584594726562,
                638.8037109375,
                241.61849975585938
              ]
            }
          ],
          "unique_tracks": [
            366,
            378
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5656,
            5660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5661,
            5665
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7936193943023682,
              "bbox": [
                38.7495231628418,
                0.0,
                396.4687805175781,
                357.6952819824219
              ]
            },
            {
              "track_id": 378,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.495149165391922,
              "bbox": [
                623.9840087890625,
                109.47456359863281,
                638.4824829101562,
                241.23162841796875
              ]
            }
          ],
          "unique_tracks": [
            366,
            378
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5666,
            5670
          ],
          "representative_frame": 5666,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 47
    },
    {
      "second": 189,
      "time_range": [
        189,
        189.999
      ],
      "frame_range": [
        5671,
        5700
      ],
      "unified_description": "1-second video showing a person fishing at the edge of a river with a GoPro camera capturing the moment.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:25",
        "processing_time": 3.38,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5685,
          "frame_range": [
            5681,
            5685
          ],
          "description": "a man is fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.93
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5671,
            5675
          ],
          "representative_frame": 5671,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9044017791748047,
              "bbox": [
                50.774803161621094,
                0.6081656217575073,
                406.3130187988281,
                356.74981689453125
              ]
            },
            {
              "track_id": 378,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5653356313705444,
              "bbox": [
                623.8920288085938,
                109.65845489501953,
                638.4088745117188,
                240.83055114746094
              ]
            }
          ],
          "unique_tracks": [
            366,
            378
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5676,
            5680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5681,
            5685
          ],
          "representative_frame": 5681,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9188506007194519,
              "bbox": [
                54.984928131103516,
                0.5719946622848511,
                403.6469421386719,
                353.1747741699219
              ]
            },
            {
              "track_id": 378,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4108165204524994,
              "bbox": [
                623.903076171875,
                110.81440734863281,
                638.552734375,
                242.3511962890625
              ]
            }
          ],
          "unique_tracks": [
            366,
            378
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5686,
            5690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5691,
            5695
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.915213406085968,
              "bbox": [
                64.3698959350586,
                11.905373573303223,
                400.45672607421875,
                353.0533142089844
              ]
            },
            {
              "track_id": 378,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5908233523368835,
              "bbox": [
                622.7661743164062,
                106.99309539794922,
                638.19384765625,
                244.04144287109375
              ]
            }
          ],
          "unique_tracks": [
            366,
            378
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5696,
            5700
          ],
          "representative_frame": 5696,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 47
    },
    {
      "second": 190,
      "time_range": [
        190,
        190.999
      ],
      "frame_range": [
        5701,
        5730
      ],
      "unified_description": "1 person standing near the water's edge holding a fishing pole and interacting with the ground.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:26",
        "processing_time": 3.06,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5715,
          "frame_range": [
            5711,
            5715
          ],
          "description": "a man is fishing on the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.06
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5701,
            5705
          ],
          "representative_frame": 5701,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.26184728741645813,
              "bbox": [
                78.60221862792969,
                30.72465705871582,
                397.3179626464844,
                355.4866027832031
              ]
            },
            {
              "track_id": 378,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5084297060966492,
              "bbox": [
                621.8639526367188,
                97.73182678222656,
                638.5552978515625,
                244.98941040039062
              ]
            }
          ],
          "unique_tracks": [
            366,
            378
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5706,
            5710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5711,
            5715
          ],
          "representative_frame": 5711,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3070394694805145,
              "bbox": [
                81.0107421875,
                52.80995559692383,
                378.72857666015625,
                356.3763122558594
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8669914603233337,
              "bbox": [
                591.429443359375,
                45.22052001953125,
                640.0,
                240.67236328125
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5716,
            5720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5721,
            5725
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.18782831728458405,
              "bbox": [
                85.9681167602539,
                63.81769561767578,
                373.6969909667969,
                355.5003967285156
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9295886754989624,
              "bbox": [
                574.8440551757812,
                19.541797637939453,
                638.638427734375,
                241.50643920898438
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5726,
            5730
          ],
          "representative_frame": 5726,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 47
    },
    {
      "second": 191,
      "time_range": [
        191,
        191.999
      ],
      "frame_range": [
        5731,
        5760
      ],
      "unified_description": "2 people on a gravel beach with one wearing a red jacket and the other a black jacket. The person in the red jacket is bending over to pick up an object while the other person stands nearby. A bottle can also be seen in the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:28",
        "processing_time": 3.21,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5745,
          "frame_range": [
            5741,
            5745
          ],
          "description": "a man in a red jacket and a black jacket is standing on a rocky beach",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.46
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5731,
            5735
          ],
          "representative_frame": 5731,
          "detections": [
            {
              "track_id": 366,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.3676256239414215,
              "bbox": [
                83.3306884765625,
                60.69782638549805,
                372.3822326660156,
                353.24786376953125
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9130101203918457,
              "bbox": [
                576.1196899414062,
                7.066376209259033,
                640.0,
                249.71669006347656
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5736,
            5740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5741,
            5745
          ],
          "representative_frame": 5741,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7040678262710571,
              "bbox": [
                72.81397247314453,
                27.331424713134766,
                394.1393737792969,
                355.00347900390625
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8943873047828674,
              "bbox": [
                580.1460571289062,
                1.9925482273101807,
                640.0,
                255.9514617919922
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5746,
            5750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5751,
            5755
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.940861701965332,
              "bbox": [
                47.34363555908203,
                9.721059799194336,
                377.4328918457031,
                355.8296203613281
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9097604155540466,
              "bbox": [
                571.9265747070312,
                0.1662483513355255,
                640.0,
                258.3453369140625
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5756,
            5760
          ],
          "representative_frame": 5756,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 47
    },
    {
      "second": 192,
      "time_range": [
        192,
        192.999
      ],
      "frame_range": [
        5761,
        5790
      ],
      "unified_description": "1-second video with two people standing by the water on a pebbly beach. One person is wearing a red raincoat while the other is dressed in weather-appropriate attire. The camera capturing the scene appears to be mounted on a backpack, providing a stable perspective as the subjects go about their activities on the shoreline.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:30",
        "processing_time": 3.89,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5775,
          "frame_range": [
            5771,
            5775
          ],
          "description": "a man in a red raincoat and a woman in a red raincoat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.19
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5761,
            5765
          ],
          "representative_frame": 5761,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7100653052330017,
              "bbox": [
                37.96992111206055,
                3.0023036003112793,
                365.4969177246094,
                353.951416015625
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9314975738525391,
              "bbox": [
                566.7294921875,
                0.0,
                638.2199096679688,
                259.601806640625
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5766,
            5770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5771,
            5775
          ],
          "representative_frame": 5771,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6468013525009155,
              "bbox": [
                24.5560359954834,
                0.6056018471717834,
                348.2811584472656,
                354.0653991699219
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9444978833198547,
              "bbox": [
                562.6717529296875,
                0.0,
                635.8582153320312,
                260.313720703125
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5776,
            5780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5781,
            5785
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 366,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9205869436264038,
              "bbox": [
                31.525903701782227,
                0.0,
                348.21270751953125,
                354.2514953613281
              ]
            },
            {
              "track_id": 374,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9413642883300781,
              "bbox": [
                559.2753295898438,
                0.0,
                634.0709228515625,
                260.30255126953125
              ]
            }
          ],
          "unique_tracks": [
            366,
            374
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5786,
            5790
          ],
          "representative_frame": 5786,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 48
    },
    {
      "second": 193,
      "time_range": [
        193,
        193.999
      ],
      "frame_range": [
        5791,
        5820
      ],
      "unified_description": "1-second scene featuring a young man fishing along the shore of a large lake with a mountain in the background. The image was captured using an action camera, resulting in some fisheye distortion and slight motion blur.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:32",
        "processing_time": 4.47,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5805,
          "frame_range": [
            5801,
            5805
          ],
          "description": "a man fishing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.62
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5791,
            5795
          ],
          "representative_frame": 5791,
          "detections": [
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8899666666984558,
              "bbox": [
                265.1890869140625,
                77.94346618652344,
                496.07421875,
                352.5050048828125
              ]
            }
          ],
          "unique_tracks": [
            369
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5796,
            5800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5801,
            5805
          ],
          "representative_frame": 5801,
          "detections": [
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9125574827194214,
              "bbox": [
                260.03338623046875,
                80.64122009277344,
                471.8013916015625,
                355.50372314453125
              ]
            }
          ],
          "unique_tracks": [
            369
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5806,
            5810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5811,
            5815
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9297991394996643,
              "bbox": [
                227.1564483642578,
                80.49889373779297,
                417.5022888183594,
                346.79742431640625
              ]
            }
          ],
          "unique_tracks": [
            369
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5816,
            5820
          ],
          "representative_frame": 5816,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 48
    },
    {
      "second": 194,
      "time_range": [
        194,
        194.999
      ],
      "frame_range": [
        5821,
        5850
      ],
      "unified_description": "3rd person perspective of a man fishing by a stream of water. The camera is positioned on the left side of the scene, focused on the fisherman and his surroundings.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:33",
        "processing_time": 3.67,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5835,
          "frame_range": [
            5831,
            5835
          ],
          "description": "a man fishing on the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5821,
            5825
          ],
          "representative_frame": 5821,
          "detections": [
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9308459758758545,
              "bbox": [
                199.09474182128906,
                82.68194580078125,
                381.2690124511719,
                352.537109375
              ]
            }
          ],
          "unique_tracks": [
            369
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5826,
            5830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5831,
            5835
          ],
          "representative_frame": 5831,
          "detections": [
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9329923391342163,
              "bbox": [
                167.6722869873047,
                82.09256744384766,
                342.6516418457031,
                355.046142578125
              ]
            }
          ],
          "unique_tracks": [
            369
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5836,
            5840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5841,
            5845
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9146161675453186,
              "bbox": [
                122.33295440673828,
                87.99073028564453,
                284.4218444824219,
                352.3859558105469
              ]
            }
          ],
          "unique_tracks": [
            369
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5846,
            5850
          ],
          "representative_frame": 5846,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 48
    },
    {
      "second": 195,
      "time_range": [
        195,
        195.999
      ],
      "frame_range": [
        5851,
        5880
      ],
      "unified_description": "1-second video showing a person standing in the water with their fishing pole.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:34",
        "processing_time": 3.02,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5865,
          "frame_range": [
            5861,
            5865
          ],
          "description": "a man fishing on a lake with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.97
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5851,
            5855
          ],
          "representative_frame": 5851,
          "detections": [
            {
              "track_id": 369,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9158307909965515,
              "bbox": [
                55.36655044555664,
                110.60633087158203,
                198.6296844482422,
                350.1976623535156
              ]
            }
          ],
          "unique_tracks": [
            369
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5856,
            5860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5861,
            5865
          ],
          "representative_frame": 5861,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            5866,
            5870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5871,
            5875
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 387,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9282131195068359,
              "bbox": [
                381.4728088378906,
                0.0,
                504.1718444824219,
                353.4304504394531
              ]
            }
          ],
          "unique_tracks": [
            387
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5876,
            5880
          ],
          "representative_frame": 5876,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 48
    },
    {
      "second": 196,
      "time_range": [
        196,
        196.999
      ],
      "frame_range": [
        5881,
        5910
      ],
      "unified_description": "2d scene with a man wearing a jacket and holding a cell phone standing on a river bank. The image is captured from the first-person perspective and has a wide field of view.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:36",
        "processing_time": 3.06,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5895,
          "frame_range": [
            5891,
            5895
          ],
          "description": "a man standing on a river bank in the rain",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.04
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5881,
            5885
          ],
          "representative_frame": 5881,
          "detections": [
            {
              "track_id": 387,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9290095567703247,
              "bbox": [
                374.18487548828125,
                0.10818483680486679,
                493.8714599609375,
                345.066162109375
              ]
            }
          ],
          "unique_tracks": [
            387
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5886,
            5890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5891,
            5895
          ],
          "representative_frame": 5891,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            5896,
            5900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5901,
            5905
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9098967909812927,
              "bbox": [
                296.18572998046875,
                93.54264831542969,
                363.2579345703125,
                271.4231262207031
              ]
            },
            {
              "track_id": 389,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4641462564468384,
              "bbox": [
                112.2907485961914,
                172.37506103515625,
                127.3765640258789,
                189.42697143554688
              ]
            }
          ],
          "unique_tracks": [
            388,
            389
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5906,
            5910
          ],
          "representative_frame": 5906,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 49
    },
    {
      "second": 197,
      "time_range": [
        197,
        197.999
      ],
      "frame_range": [
        5911,
        5940
      ],
      "unified_description": "365 days of photography tips, tricks, and techniques book: (Not Available)",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:37",
        "processing_time": 2.99,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5925,
          "frame_range": [
            5921,
            5925
          ],
          "description": "a man standing in the water with a fishing rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.92
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5911,
            5915
          ],
          "representative_frame": 5911,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9060783386230469,
              "bbox": [
                295.7515563964844,
                93.96939849853516,
                362.9134521484375,
                272.1372375488281
              ]
            },
            {
              "track_id": 389,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4682897925376892,
              "bbox": [
                110.77607727050781,
                171.6742706298828,
                128.19070434570312,
                191.42660522460938
              ]
            }
          ],
          "unique_tracks": [
            388,
            389
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            5916,
            5920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5921,
            5925
          ],
          "representative_frame": 5921,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9062952399253845,
              "bbox": [
                296.6114807128906,
                94.06329345703125,
                362.2443542480469,
                268.1982421875
              ]
            },
            {
              "track_id": 389,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.48456108570098877,
              "bbox": [
                109.60469055175781,
                171.49375915527344,
                129.0743865966797,
                193.7005157470703
              ]
            }
          ],
          "unique_tracks": [
            388,
            389
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            5926,
            5930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5931,
            5935
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9151055812835693,
              "bbox": [
                295.3161315917969,
                94.0809326171875,
                362.298095703125,
                271.89508056640625
              ]
            },
            {
              "track_id": 389,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4582716226577759,
              "bbox": [
                109.47029876708984,
                171.5293731689453,
                129.83140563964844,
                194.79393005371094
              ]
            }
          ],
          "unique_tracks": [
            388,
            389
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            5936,
            5940
          ],
          "representative_frame": 5936,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 49
    },
    {
      "second": 198,
      "time_range": [
        198,
        198.999
      ],
      "frame_range": [
        5941,
        5970
      ],
      "unified_description": "1 second of a man fishing from a boat on the water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:38",
        "processing_time": 3.15,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5955,
          "frame_range": [
            5951,
            5955
          ],
          "description": "a man fishing in the middle of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.67
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5941,
            5945
          ],
          "representative_frame": 5941,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9252985715866089,
              "bbox": [
                294.46722412109375,
                58.68276596069336,
                378.7442626953125,
                281.550048828125
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5946,
            5950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5951,
            5955
          ],
          "representative_frame": 5951,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9214993715286255,
              "bbox": [
                284.2480163574219,
                42.503074645996094,
                377.8280334472656,
                288.5742492675781
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5956,
            5960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5961,
            5965
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9238731861114502,
              "bbox": [
                259.6632995605469,
                29.572616577148438,
                362.65362548828125,
                299.1722412109375
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5966,
            5970
          ],
          "representative_frame": 5966,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 49
    },
    {
      "second": 199,
      "time_range": [
        199,
        199.999
      ],
      "frame_range": [
        5971,
        6000
      ],
      "unified_description": " A man standing in the rain holding a fishing rod.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:39",
        "processing_time": 2.72,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 5985,
          "frame_range": [
            5981,
            5985
          ],
          "description": "a man fishing in the water with a rod",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.82
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            5971,
            5975
          ],
          "representative_frame": 5971,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9345775246620178,
              "bbox": [
                245.65390014648438,
                18.914880752563477,
                358.1177062988281,
                309.7571716308594
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            5976,
            5980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            5981,
            5985
          ],
          "representative_frame": 5981,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9488586783409119,
              "bbox": [
                248.0501708984375,
                9.367741584777832,
                373.0955810546875,
                325.4680480957031
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            5986,
            5990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            5991,
            5995
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9332122206687927,
              "bbox": [
                259.8188171386719,
                0.09568920731544495,
                385.4507751464844,
                299.5788269042969
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            5996,
            6000
          ],
          "representative_frame": 5996,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 49
    },
    {
      "second": 200,
      "time_range": [
        200,
        200.999
      ],
      "frame_range": [
        6001,
        6030
      ],
      "unified_description": " A boy stands on the shore of a river wearing a red jacket and fishing gear. The image captures the essence of an outdoor adventure as the young angler enjoys his time by the water.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:41",
        "processing_time": 3.06,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6015,
          "frame_range": [
            6011,
            6015
          ],
          "description": "a man in a red jacket is standing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.11
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6001,
            6005
          ],
          "representative_frame": 6001,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9441232681274414,
              "bbox": [
                253.46600341796875,
                0.0,
                388.6316833496094,
                304.4294738769531
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6006,
            6010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6011,
            6015
          ],
          "representative_frame": 6011,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9437474608421326,
              "bbox": [
                246.7202911376953,
                0.0,
                397.7551574707031,
                325.9845886230469
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6016,
            6020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6021,
            6025
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8782771825790405,
              "bbox": [
                241.58070373535156,
                0.0,
                406.6512756347656,
                343.8962097167969
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6026,
            6030
          ],
          "representative_frame": 6026,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 50
    },
    {
      "second": 201,
      "time_range": [
        201,
        201.999
      ],
      "frame_range": [
        6031,
        6060
      ],
      "unified_description": "10-second scene of a little boy wearing a jacket and standing on the shore of a lake.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:42",
        "processing_time": 3.48,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6045,
          "frame_range": [
            6041,
            6045
          ],
          "description": "a little boy standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.77
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6031,
            6035
          ],
          "representative_frame": 6031,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8989170789718628,
              "bbox": [
                252.36761474609375,
                0.0,
                420.5457763671875,
                353.2558898925781
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6036,
            6040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6041,
            6045
          ],
          "representative_frame": 6041,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.761814534664154,
              "bbox": [
                250.547119140625,
                0.0,
                418.1094970703125,
                356.3153991699219
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6046,
            6050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6051,
            6055
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7973104119300842,
              "bbox": [
                247.8766326904297,
                7.033366680145264,
                411.1996154785156,
                358.48175048828125
              ]
            },
            {
              "track_id": 391,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.5573267936706543,
              "bbox": [
                212.22254943847656,
                55.33290481567383,
                329.07440185546875,
                241.322021484375
              ]
            }
          ],
          "unique_tracks": [
            388,
            391
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            6056,
            6060
          ],
          "representative_frame": 6056,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 50
    },
    {
      "second": 202,
      "time_range": [
        202,
        202.999
      ],
      "frame_range": [
        6061,
        6090
      ],
      "unified_description": "1-second video of a man standing by the water wearing a raincoat while holding a fishing rod.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:44",
        "processing_time": 3.47,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6075,
          "frame_range": [
            6071,
            6075
          ],
          "description": "a man in a raincoat is fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.69
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6061,
            6065
          ],
          "representative_frame": 6061,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8767443299293518,
              "bbox": [
                233.9271697998047,
                8.778407096862793,
                394.451904296875,
                358.5541687011719
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6066,
            6070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6071,
            6075
          ],
          "representative_frame": 6071,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9420968890190125,
              "bbox": [
                186.2733154296875,
                2.106658458709717,
                361.94134521484375,
                358.5594787597656
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6076,
            6080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6081,
            6085
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9415079355239868,
              "bbox": [
                163.86956787109375,
                0.0,
                352.63330078125,
                358.542236328125
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6086,
            6090
          ],
          "representative_frame": 6086,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 50
    },
    {
      "second": 203,
      "time_range": [
        203,
        203.999
      ],
      "frame_range": [
        6091,
        6120
      ],
      "unified_description": "360-degree footage of a person in a hooded raincoat, standing next to a body of water with a view of the mountains in the distance.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:45",
        "processing_time": 2.99,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6105,
          "frame_range": [
            6101,
            6105
          ],
          "description": "a man in a raincoat fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.02
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6091,
            6095
          ],
          "representative_frame": 6091,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9430614709854126,
              "bbox": [
                135.95204162597656,
                0.0,
                339.63623046875,
                357.96533203125
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6096,
            6100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6101,
            6105
          ],
          "representative_frame": 6101,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9112944006919861,
              "bbox": [
                120.48165893554688,
                0.0,
                339.6258544921875,
                358.286376953125
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6106,
            6110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6111,
            6115
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 387,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8293517827987671,
              "bbox": [
                352.3885192871094,
                2.039912700653076,
                487.70556640625,
                355.32061767578125
              ]
            }
          ],
          "unique_tracks": [
            387
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6116,
            6120
          ],
          "representative_frame": 6116,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 50
    },
    {
      "second": 204,
      "time_range": [
        204,
        204.999
      ],
      "frame_range": [
        6121,
        6150
      ],
      "unified_description": "30 seconds of footage showing a person in an orange rain coat holding a fishing rod beside some water. The shot appears to be taken from the first-person perspective, with the camera positioned close to the person's head. There are no other objects or people visible in the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:47",
        "processing_time": 3.49,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6135,
          "frame_range": [
            6131,
            6135
          ],
          "description": "a man in a red raincoat fishing on the shore",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.13
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6121,
            6125
          ],
          "representative_frame": 6121,
          "detections": [
            {
              "track_id": 387,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9245981574058533,
              "bbox": [
                355.93743896484375,
                1.1812012195587158,
                502.6437683105469,
                355.88360595703125
              ]
            }
          ],
          "unique_tracks": [
            387
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6126,
            6130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6131,
            6135
          ],
          "representative_frame": 6131,
          "detections": [
            {
              "track_id": 387,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.931547224521637,
              "bbox": [
                354.6319885253906,
                1.0544368028640747,
                507.18731689453125,
                354.9691162109375
              ]
            }
          ],
          "unique_tracks": [
            387
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6136,
            6140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6141,
            6145
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 387,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9312980771064758,
              "bbox": [
                351.8567810058594,
                0.6346862316131592,
                509.6916809082031,
                355.9565734863281
              ]
            }
          ],
          "unique_tracks": [
            387
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6146,
            6150
          ],
          "representative_frame": 6146,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 51
    },
    {
      "second": 205,
      "time_range": [
        205,
        205.999
      ],
      "frame_range": [
        6151,
        6180
      ],
      "unified_description": " A man wearing a raincoat standing by the water and holding a pole. The image is taken from the man's perspective, providing an immersive view of the surrounding area.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:48",
        "processing_time": 4.07,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6165,
          "frame_range": [
            6161,
            6165
          ],
          "description": "a man in a raincoat is fishing on the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.74
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6151,
            6155
          ],
          "representative_frame": 6151,
          "detections": [
            {
              "track_id": 387,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9153900742530823,
              "bbox": [
                349.7563781738281,
                0.30650413036346436,
                510.5262451171875,
                355.8551330566406
              ]
            }
          ],
          "unique_tracks": [
            387
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6156,
            6160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6161,
            6165
          ],
          "representative_frame": 6161,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9306058883666992,
              "bbox": [
                130.06112670898438,
                0.0,
                368.8717956542969,
                354.7546691894531
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6166,
            6170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6171,
            6175
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.933128833770752,
              "bbox": [
                115.3006362915039,
                0.5051048994064331,
                374.9957275390625,
                354.66448974609375
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6176,
            6180
          ],
          "representative_frame": 6176,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 51
    },
    {
      "second": 206,
      "time_range": [
        206,
        206.999
      ],
      "frame_range": [
        6181,
        6210
      ],
      "unified_description": "4K raw footage of a hiking trail next to a lake, a man in a black rain jacket is visible.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:50",
        "processing_time": 3.5,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6195,
          "frame_range": [
            6191,
            6195
          ],
          "description": "a man in a black jacket is standing near the water",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.89
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6181,
            6185
          ],
          "representative_frame": 6181,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9064615964889526,
              "bbox": [
                159.94688415527344,
                0.7804595232009888,
                425.7971496582031,
                353.9146423339844
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6186,
            6190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6191,
            6195
          ],
          "representative_frame": 6191,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9015679359436035,
              "bbox": [
                188.20855712890625,
                0.6729761362075806,
                461.447265625,
                354.4644775390625
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6196,
            6200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6201,
            6205
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9016116857528687,
              "bbox": [
                213.82107543945312,
                0.48543763160705566,
                496.3941345214844,
                353.29656982421875
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6206,
            6210
          ],
          "representative_frame": 6206,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 51
    },
    {
      "second": 207,
      "time_range": [
        207,
        207.999
      ],
      "frame_range": [
        6211,
        6240
      ],
      "unified_description": "30-second video with a man in a black hooded raincoat walking through a wooded area with trees.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:51",
        "processing_time": 2.94,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6225,
          "frame_range": [
            6221,
            6225
          ],
          "description": "a man in a black jacket is standing in the woods",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.1
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6211,
            6215
          ],
          "representative_frame": 6211,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9352431297302246,
              "bbox": [
                275.1500549316406,
                0.5937756896018982,
                568.2796020507812,
                354.1919250488281
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6216,
            6220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6221,
            6225
          ],
          "representative_frame": 6221,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 3,
          "frame_range": [
            6226,
            6230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6231,
            6235
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8865185379981995,
              "bbox": [
                262.5628356933594,
                0.8138175010681152,
                558.5413818359375,
                355.8460388183594
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6236,
            6240
          ],
          "representative_frame": 6236,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 51
    },
    {
      "second": 208,
      "time_range": [
        208,
        208.999
      ],
      "frame_range": [
        6241,
        6270
      ],
      "unified_description": "1 second video of a man standing on the shore of a lake fishing. He is wearing a black jacket and holding a fish. The image has a wide-angle perspective which captures the surrounding area and shows the man's fishing pole in action.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:53",
        "processing_time": 3.45,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6255,
          "frame_range": [
            6251,
            6255
          ],
          "description": "a man is standing on the shore of a lake",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.02
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6241,
            6245
          ],
          "representative_frame": 6241,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9124066233634949,
              "bbox": [
                264.5577392578125,
                0.5308300256729126,
                559.4473266601562,
                354.8349304199219
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6246,
            6250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6251,
            6255
          ],
          "representative_frame": 6251,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.897496223449707,
              "bbox": [
                255.70571899414062,
                0.4767564833164215,
                552.37451171875,
                354.174560546875
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6256,
            6260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6261,
            6265
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8721825480461121,
              "bbox": [
                247.0966339111328,
                0.5763499140739441,
                546.3692626953125,
                353.8887023925781
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6266,
            6270
          ],
          "representative_frame": 6266,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 52
    },
    {
      "second": 209,
      "time_range": [
        209,
        209.999
      ],
      "frame_range": [
        6271,
        6300
      ],
      "unified_description": "\nA person in a black jacket is standing by a river and holding a fish in their hand. They are wearing a backpack and seem to be either fishing or releasing the fish back into the water. The camera perspective suggests that it might be a first-person view, possibly captured with an action camera mounted on the individual's body. The image includes various objects such as trees and rocks, indicating that the person is in a natural outdoor setting, likely close to the water's edge.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:55",
        "processing_time": 4.9,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6285,
          "frame_range": [
            6281,
            6285
          ],
          "description": "a man is holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.71
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6271,
            6275
          ],
          "representative_frame": 6271,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9128134846687317,
              "bbox": [
                288.01373291015625,
                0.7237901091575623,
                593.818359375,
                354.83502197265625
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6276,
            6280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6281,
            6285
          ],
          "representative_frame": 6281,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9270437955856323,
              "bbox": [
                300.5902404785156,
                0.9250839948654175,
                611.6962280273438,
                354.7836608886719
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6286,
            6290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6291,
            6295
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9444047212600708,
              "bbox": [
                301.3896484375,
                1.059016466140747,
                617.7859497070312,
                354.5417175292969
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6296,
            6300
          ],
          "representative_frame": 6296,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 52
    },
    {
      "second": 210,
      "time_range": [
        210,
        210.999
      ],
      "frame_range": [
        6301,
        6330
      ],
      "unified_description": "\n\nA man with a fishing rod in his hands, standing next to a river filled with fish. The man seems to be focused on catching fish and might be using the fishing rod to either cast or retrieve bait. There are multiple fish visible in the water, scattered across various positions within the scene. The camera perspective provides an immersive experience for viewers, as they can witness the fishing activity up close.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:57",
        "processing_time": 5.24,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6315,
          "frame_range": [
            6311,
            6315
          ],
          "description": "a man in a wet suit holding a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6301,
            6305
          ],
          "representative_frame": 6301,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9502205848693848,
              "bbox": [
                302.4290466308594,
                1.035583734512329,
                622.8338623046875,
                354.15887451171875
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6306,
            6310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6311,
            6315
          ],
          "representative_frame": 6311,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.917542576789856,
              "bbox": [
                299.1771545410156,
                1.0667355060577393,
                624.1326293945312,
                354.5824890136719
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6316,
            6320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6321,
            6325
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9114586710929871,
              "bbox": [
                294.3997802734375,
                0.9156298041343689,
                623.906494140625,
                354.7994079589844
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6326,
            6330
          ],
          "representative_frame": 6326,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 52
    },
    {
      "second": 211,
      "time_range": [
        211,
        211.999
      ],
      "frame_range": [
        6331,
        6360
      ],
      "unified_description": "3rd person perspective of a man fishing in a river with a green surrounding environment.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:30:59",
        "processing_time": 4.26,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6345,
          "frame_range": [
            6341,
            6345
          ],
          "description": "a man in a wet suit is holding a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.29
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6331,
            6335
          ],
          "representative_frame": 6331,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9529431462287903,
              "bbox": [
                294.1497497558594,
                1.0381828546524048,
                626.608154296875,
                354.68560791015625
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6336,
            6340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6341,
            6345
          ],
          "representative_frame": 6341,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9548088908195496,
              "bbox": [
                291.19647216796875,
                0.9526873826980591,
                626.9508666992188,
                354.54705810546875
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6346,
            6350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6351,
            6355
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9530326724052429,
              "bbox": [
                288.46453857421875,
                0.8913083672523499,
                627.5166625976562,
                354.8181457519531
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6356,
            6360
          ],
          "representative_frame": 6356,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 52
    },
    {
      "second": 212,
      "time_range": [
        212,
        212.999
      ],
      "frame_range": [
        6361,
        6390
      ],
      "unified_description": "3D video with a fisheye lens showing a hand holding something.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:00",
        "processing_time": 3.33,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6375,
          "frame_range": [
            6371,
            6375
          ],
          "description": "a person holding a small piece of wood",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6361,
            6365
          ],
          "representative_frame": 6361,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            6366,
            6370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6371,
            6375
          ],
          "representative_frame": 6371,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4224861264228821,
              "bbox": [
                0.0,
                73.1741943359375,
                419.39056396484375,
                349.9325256347656
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6376,
            6380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6381,
            6385
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7953743934631348,
              "bbox": [
                0.0,
                72.8823471069336,
                413.6941223144531,
                351.18560791015625
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6386,
            6390
          ],
          "representative_frame": 6386,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 53
    },
    {
      "second": 213,
      "time_range": [
        213,
        213.999
      ],
      "frame_range": [
        6391,
        6420
      ],
      "unified_description": "1-second scene where someone is holding a dead fish.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:01",
        "processing_time": 2.71,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6405,
          "frame_range": [
            6401,
            6405
          ],
          "description": "a person holding a small fish in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.14
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6391,
            6395
          ],
          "representative_frame": 6391,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8510057330131531,
              "bbox": [
                2.516371250152588,
                93.71826171875,
                393.74017333984375,
                351.71453857421875
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6396,
            6400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6401,
            6405
          ],
          "representative_frame": 6401,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8924845457077026,
              "bbox": [
                7.370102405548096,
                104.6580581665039,
                381.5767822265625,
                351.0360412597656
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6406,
            6410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6411,
            6415
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8902199268341064,
              "bbox": [
                6.802402019500732,
                108.7662124633789,
                372.7985534667969,
                349.4130859375
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6416,
            6420
          ],
          "representative_frame": 6416,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 53
    },
    {
      "second": 214,
      "time_range": [
        214,
        214.999
      ],
      "frame_range": [
        6421,
        6450
      ],
      "unified_description": "\nAn action camera is being used to film a hand holding a small fish.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:03",
        "processing_time": 2.98,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6435,
          "frame_range": [
            6431,
            6435
          ],
          "description": "a person holding a small fish in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6421,
            6425
          ],
          "representative_frame": 6421,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8833304047584534,
              "bbox": [
                2.1277084350585938,
                102.5057373046875,
                368.3147277832031,
                343.3427734375
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6426,
            6430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6431,
            6435
          ],
          "representative_frame": 6431,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8008123636245728,
              "bbox": [
                9.06409740447998,
                93.6899642944336,
                351.18951416015625,
                317.7395324707031
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6436,
            6440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6441,
            6445
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8868045806884766,
              "bbox": [
                0.0,
                88.53607940673828,
                361.02752685546875,
                334.3400573730469
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6446,
            6450
          ],
          "representative_frame": 6446,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 53
    },
    {
      "second": 215,
      "time_range": [
        215,
        215.999
      ],
      "frame_range": [
        6451,
        6480
      ],
      "unified_description": "0:01 second long shot showing a hand holding some sort of dirty animal. The camera is positioned in such a way that it captures the entire scene which includes the ground with twigs, leaves, and debris scattered all over. This first-person perspective shot might have been taken using a body-mounted or backpack-mounted camera.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:04",
        "processing_time": 4.16,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6465,
          "frame_range": [
            6461,
            6465
          ],
          "description": "a person holding a small animal in their hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.64
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6451,
            6455
          ],
          "representative_frame": 6451,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7717301249504089,
              "bbox": [
                0.0,
                91.63065338134766,
                369.29742431640625,
                337.4974060058594
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6456,
            6460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6461,
            6465
          ],
          "representative_frame": 6461,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8154164552688599,
              "bbox": [
                0.0,
                60.00202941894531,
                382.0087890625,
                316.80596923828125
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6466,
            6470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6471,
            6475
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.34084075689315796,
              "bbox": [
                269.18951416015625,
                1.0947002172470093,
                597.3445434570312,
                323.91949462890625
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6476,
            6480
          ],
          "representative_frame": 6476,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 53
    },
    {
      "second": 216,
      "time_range": [
        216,
        216.999
      ],
      "frame_range": [
        6481,
        6510
      ],
      "unified_description": "1-second scene where a person is standing in water with an object in their hand.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:06",
        "processing_time": 3.43,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6495,
          "frame_range": [
            6491,
            6495
          ],
          "description": "a man is standing on the beach with a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.92
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6481,
            6485
          ],
          "representative_frame": 6481,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6910065412521362,
              "bbox": [
                274.4746398925781,
                0.437101274728775,
                612.9236450195312,
                326.2739562988281
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6486,
            6490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6491,
            6495
          ],
          "representative_frame": 6491,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9175097346305847,
              "bbox": [
                286.0325012207031,
                0.12682871520519257,
                623.7780151367188,
                322.2907409667969
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6496,
            6500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6501,
            6505
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.921183168888092,
              "bbox": [
                284.1389465332031,
                0.8129590749740601,
                623.9762573242188,
                320.61334228515625
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6506,
            6510
          ],
          "representative_frame": 6506,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 54
    },
    {
      "second": 217,
      "time_range": [
        217,
        217.999
      ],
      "frame_range": [
        6511,
        6540
      ],
      "unified_description": "4k or higher resolution is recommended for clearer visuals.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:07",
        "processing_time": 2.98,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6525,
          "frame_range": [
            6521,
            6525
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.14
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6511,
            6515
          ],
          "representative_frame": 6511,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9105321764945984,
              "bbox": [
                301.525390625,
                0.9012078046798706,
                640.0,
                330.7409973144531
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8962520360946655,
              "bbox": [
                0.0,
                4.550429821014404,
                474.67633056640625,
                350.79876708984375
              ]
            }
          ],
          "unique_tracks": [
            388,
            402
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            6516,
            6520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6521,
            6525
          ],
          "representative_frame": 6521,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7033097743988037,
              "bbox": [
                280.58154296875,
                1.300646424293518,
                631.238037109375,
                331.4519958496094
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6526,
            6530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6531,
            6535
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.84503173828125,
              "bbox": [
                249.50733947753906,
                1.381282925605774,
                611.8765869140625,
                332.7330322265625
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6536,
            6540
          ],
          "representative_frame": 6536,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 54
    },
    {
      "second": 218,
      "time_range": [
        218,
        218.999
      ],
      "frame_range": [
        6541,
        6570
      ],
      "unified_description": "2 people fishing with rods and line, and they caught a fish.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:08",
        "processing_time": 2.75,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6555,
          "frame_range": [
            6551,
            6555
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6541,
            6545
          ],
          "representative_frame": 6541,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5321466326713562,
              "bbox": [
                282.3339538574219,
                1.7357102632522583,
                640.0,
                333.3045959472656
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6661708354949951,
              "bbox": [
                111.01530456542969,
                0.0,
                591.2019653320312,
                335.1111145019531
              ]
            }
          ],
          "unique_tracks": [
            388,
            402
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            6546,
            6550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6551,
            6555
          ],
          "representative_frame": 6551,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.297696590423584,
              "bbox": [
                298.1143798828125,
                3.2354953289031982,
                640.0,
                340.4127502441406
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.25798308849334717,
              "bbox": [
                123.96733856201172,
                0.0,
                616.3834228515625,
                341.0155944824219
              ]
            }
          ],
          "unique_tracks": [
            388,
            402
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            6556,
            6560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6561,
            6565
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5430958271026611,
              "bbox": [
                323.64739990234375,
                2.1703197956085205,
                640.0,
                336.3757629394531
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.20820681750774384,
              "bbox": [
                136.17665100097656,
                0.0,
                622.5206298828125,
                333.8515625
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6751425266265869,
              "bbox": [
                134.83432006835938,
                0.6987549066543579,
                369.99078369140625,
                197.47401428222656
              ]
            }
          ],
          "unique_tracks": [
            388,
            402,
            411
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            6566,
            6570
          ],
          "representative_frame": 6566,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 54
    },
    {
      "second": 219,
      "time_range": [
        219,
        219.999
      ],
      "frame_range": [
        6571,
        6600
      ],
      "unified_description": "1-second scene that includes a man holding a fish near water, captured with an action camera setup.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:10",
        "processing_time": 3.02,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6585,
          "frame_range": [
            6581,
            6585
          ],
          "description": "a man holding a fish in his hand",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.87
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6571,
            6575
          ],
          "representative_frame": 6571,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5869698524475098,
              "bbox": [
                334.6568908691406,
                1.9310275316238403,
                640.0,
                334.2169189453125
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.13474994897842407,
              "bbox": [
                130.4361114501953,
                0.0,
                617.165283203125,
                328.1998291015625
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6673977971076965,
              "bbox": [
                125.68344116210938,
                0.3454933166503906,
                354.87896728515625,
                191.5194854736328
              ]
            }
          ],
          "unique_tracks": [
            388,
            402,
            411
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            6576,
            6580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6581,
            6585
          ],
          "representative_frame": 6581,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7235931754112244,
              "bbox": [
                332.7736511230469,
                1.5637383460998535,
                640.0,
                333.091064453125
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.49829578399658203,
              "bbox": [
                123.48512268066406,
                0.9384151697158813,
                346.2714538574219,
                186.02157592773438
              ]
            },
            {
              "track_id": 413,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.5687150359153748,
              "bbox": [
                110.53095245361328,
                110.31366729736328,
                417.93597412109375,
                247.9656982421875
              ]
            }
          ],
          "unique_tracks": [
            388,
            411,
            413
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            6586,
            6590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6591,
            6595
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7118789553642273,
              "bbox": [
                335.7593078613281,
                1.010388731956482,
                640.0,
                335.96209716796875
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5328014492988586,
              "bbox": [
                117.51090240478516,
                0.8589312434196472,
                346.701171875,
                190.59182739257812
              ]
            },
            {
              "track_id": 413,
              "class_id": 37,
              "class_name": "surfboard",
              "confidence": 0.49324002861976624,
              "bbox": [
                97.16114044189453,
                108.90518951416016,
                421.3746032714844,
                254.16748046875
              ]
            }
          ],
          "unique_tracks": [
            388,
            411,
            413
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            6596,
            6600
          ],
          "representative_frame": 6596,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 54
    },
    {
      "second": 220,
      "time_range": [
        220,
        220.999
      ],
      "frame_range": [
        6601,
        6630
      ],
      "unified_description": "00:19 second scene showing a man wearing a black hoodie looking up. The image has a fisheye effect, and there is a tree in the background.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:11",
        "processing_time": 3.61,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6615,
          "frame_range": [
            6611,
            6615
          ],
          "description": "a woman is standing under a tree",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.55
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6601,
            6605
          ],
          "representative_frame": 6601,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8945109248161316,
              "bbox": [
                122.74779510498047,
                59.19395065307617,
                552.8743896484375,
                348.9988098144531
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6606,
            6610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6611,
            6615
          ],
          "representative_frame": 6611,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4965454936027527,
              "bbox": [
                191.6177215576172,
                131.4430389404297,
                541.4425048828125,
                354.8806457519531
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6616,
            6620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6621,
            6625
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8102216720581055,
              "bbox": [
                188.04017639160156,
                104.78933715820312,
                586.2056274414062,
                355.56280517578125
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            6626,
            6630
          ],
          "representative_frame": 6626,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 55
    },
    {
      "second": 221,
      "time_range": [
        221,
        221.999
      ],
      "frame_range": [
        6631,
        6660
      ],
      "unified_description": "1-second video of a man and a boy with a gun in the foreground. The man is pointing at something with the camera while the boy looks on.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:12",
        "processing_time": 3.18,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6645,
          "frame_range": [
            6641,
            6645
          ],
          "description": "a man and a boy sitting under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.81
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6631,
            6635
          ],
          "representative_frame": 6631,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8672677874565125,
              "bbox": [
                131.9727325439453,
                66.69285583496094,
                587.8345947265625,
                355.67803955078125
              ]
            }
          ],
          "unique_tracks": [
            402
          ],
          "total_detections": 1
        },
        {
          "group_index": 1,
          "frame_range": [
            6636,
            6640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6641,
            6645
          ],
          "representative_frame": 6641,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8388353586196899,
              "bbox": [
                335.3285217285156,
                58.227256774902344,
                628.4285888671875,
                351.5884094238281
              ]
            }
          ],
          "unique_tracks": [
            388
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            6646,
            6650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6651,
            6655
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.818041980266571,
              "bbox": [
                19.398387908935547,
                121.20805358886719,
                185.7737274169922,
                356.20208740234375
              ]
            },
            {
              "track_id": 418,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4133085608482361,
              "bbox": [
                212.57901000976562,
                250.42916870117188,
                283.61883544921875,
                334.86029052734375
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.569333553314209,
              "bbox": [
                344.8689270019531,
                56.806297302246094,
                631.2545166015625,
                354.38330078125
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.34227702021598816,
              "bbox": [
                192.151611328125,
                56.418453216552734,
                640.0,
                354.806884765625
              ]
            }
          ],
          "unique_tracks": [
            417,
            418,
            388,
            402
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            6656,
            6660
          ],
          "representative_frame": 6656,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 55
    },
    {
      "second": 222,
      "time_range": [
        222,
        222.999
      ],
      "frame_range": [
        6661,
        6690
      ],
      "unified_description": "30-second edit showing a man and a child sitting in a camping area under a tent. The scene includes a backpack, trees, and possibly some outdoor elements such as a body of water or a campsite. The camera is positioned either on the person's chest or mounted on a backpack, capturing the scene from that perspective.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:14",
        "processing_time": 3.71,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6675,
          "frame_range": [
            6671,
            6675
          ],
          "description": "a man and a boy sitting under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.01
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6661,
            6665
          ],
          "representative_frame": 6661,
          "detections": [
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8470178246498108,
              "bbox": [
                25.97020721435547,
                126.493408203125,
                189.6117706298828,
                356.78424072265625
              ]
            },
            {
              "track_id": 418,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4682199954986572,
              "bbox": [
                206.61386108398438,
                250.27761840820312,
                290.89202880859375,
                350.43109130859375
              ]
            },
            {
              "track_id": 419,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.37720656394958496,
              "bbox": [
                259.916015625,
                139.30503845214844,
                420.57867431640625,
                342.2505798339844
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6563935875892639,
              "bbox": [
                198.15443420410156,
                56.67018508911133,
                639.5816650390625,
                354.8049011230469
              ]
            }
          ],
          "unique_tracks": [
            417,
            418,
            419,
            402
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            6666,
            6670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6671,
            6675
          ],
          "representative_frame": 6671,
          "detections": [
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8492952585220337,
              "bbox": [
                18.382287979125977,
                121.42496490478516,
                185.5686492919922,
                356.40313720703125
              ]
            },
            {
              "track_id": 418,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.570812463760376,
              "bbox": [
                206.75164794921875,
                250.00308227539062,
                292.7203674316406,
                351.9324035644531
              ]
            },
            {
              "track_id": 419,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3571430742740631,
              "bbox": [
                253.45785522460938,
                143.86965942382812,
                410.2074890136719,
                342.1936340332031
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5841333270072937,
              "bbox": [
                215.1419219970703,
                58.368247985839844,
                639.383544921875,
                354.8839111328125
              ]
            }
          ],
          "unique_tracks": [
            417,
            418,
            419,
            402
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            6676,
            6680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6681,
            6685
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6099410057067871,
              "bbox": [
                200.92701721191406,
                20.435991287231445,
                640.0,
                353.39495849609375
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6545197367668152,
              "bbox": [
                66.53907012939453,
                0.4798116981983185,
                311.7594299316406,
                207.47537231445312
              ]
            }
          ],
          "unique_tracks": [
            402,
            411
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            6686,
            6690
          ],
          "representative_frame": 6686,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 55
    },
    {
      "second": 223,
      "time_range": [
        223,
        223.999
      ],
      "frame_range": [
        6691,
        6720
      ],
      "unified_description": "\nBased on these descriptions, what objects, people, actions, and location compose this single frame?",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:16",
        "processing_time": 3.82,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6705,
          "frame_range": [
            6701,
            6705
          ],
          "description": "a man is holding a can of paint",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.76
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6691,
            6695
          ],
          "representative_frame": 6691,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.48362594842910767,
              "bbox": [
                139.30543518066406,
                6.200143337249756,
                634.4906616210938,
                354.00250244140625
              ]
            },
            {
              "track_id": 420,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5299025177955627,
              "bbox": [
                205.07920837402344,
                206.9620361328125,
                285.9054870605469,
                263.31427001953125
              ]
            },
            {
              "track_id": 421,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4276667535305023,
              "bbox": [
                0.07315954566001892,
                94.92594909667969,
                71.10456848144531,
                163.15472412109375
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3672417998313904,
              "bbox": [
                63.08264923095703,
                0.15203341841697693,
                304.1863708496094,
                208.2030792236328
              ]
            }
          ],
          "unique_tracks": [
            402,
            420,
            421,
            411
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            6696,
            6700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6701,
            6705
          ],
          "representative_frame": 6701,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6176756024360657,
              "bbox": [
                175.30654907226562,
                1.3424288034439087,
                640.0,
                351.3154602050781
              ]
            },
            {
              "track_id": 420,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4818666875362396,
              "bbox": [
                207.55044555664062,
                207.36141967773438,
                287.6315002441406,
                263.052734375
              ]
            },
            {
              "track_id": 421,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4127226769924164,
              "bbox": [
                0.10494028031826019,
                94.98773193359375,
                71.04601287841797,
                163.12884521484375
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7448037266731262,
              "bbox": [
                64.75691223144531,
                0.3515937328338623,
                302.40240478515625,
                208.9309844970703
              ]
            },
            {
              "track_id": 424,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.4165266156196594,
              "bbox": [
                205.08404541015625,
                207.2623748779297,
                289.0960388183594,
                263.3549499511719
              ]
            }
          ],
          "unique_tracks": [
            402,
            420,
            421,
            411,
            424
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            6706,
            6710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6711,
            6715
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5475406050682068,
              "bbox": [
                135.68069458007812,
                0.0,
                634.2582397460938,
                351.91650390625
              ]
            },
            {
              "track_id": 420,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.42956215143203735,
              "bbox": [
                207.36611938476562,
                207.48646545410156,
                287.8657531738281,
                263.3150634765625
              ]
            },
            {
              "track_id": 421,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4548235535621643,
              "bbox": [
                0.09770779311656952,
                95.01585388183594,
                71.01802062988281,
                163.136962890625
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.12130901962518692,
              "bbox": [
                67.49172973632812,
                0.7013951539993286,
                302.6189270019531,
                210.0314178466797
              ]
            },
            {
              "track_id": 424,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.4694996178150177,
              "bbox": [
                204.91822814941406,
                206.77149963378906,
                290.0022888183594,
                263.5428466796875
              ]
            },
            {
              "track_id": 427,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3270215392112732,
              "bbox": [
                446.8570251464844,
                10.573657035827637,
                636.1282958984375,
                274.8611755371094
              ]
            }
          ],
          "unique_tracks": [
            402,
            420,
            421,
            411,
            424,
            427
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            6716,
            6720
          ],
          "representative_frame": 6716,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 55
    },
    {
      "second": 224,
      "time_range": [
        224,
        224.999
      ],
      "frame_range": [
        6721,
        6750
      ],
      "unified_description": "1 person is visible in the image. They are in an outdoor setting and wearing a black jacket. This person is holding something red while being next to a backpack. The image seems to have a first-person perspective, making it appear as if the viewer is experiencing the scene from the person's point of view.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:17",
        "processing_time": 3.95,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6735,
          "frame_range": [
            6731,
            6735
          ],
          "description": "a man in a black jacket is holding a red object",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.97
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6721,
            6725
          ],
          "representative_frame": 6721,
          "detections": [
            {
              "track_id": 402,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.1661340743303299,
              "bbox": [
                216.3283233642578,
                0.0,
                640.0,
                351.89306640625
              ]
            },
            {
              "track_id": 420,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.38896769285202026,
              "bbox": [
                206.2515411376953,
                207.83616638183594,
                286.1282043457031,
                263.11639404296875
              ]
            },
            {
              "track_id": 421,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3949429988861084,
              "bbox": [
                0.09066138416528702,
                95.01124572753906,
                70.96114349365234,
                163.08267211914062
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.18848007917404175,
              "bbox": [
                92.72015380859375,
                0.7560828328132629,
                334.7408447265625,
                211.46641540527344
              ]
            },
            {
              "track_id": 424,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.18920472264289856,
              "bbox": [
                204.38198852539062,
                207.8880615234375,
                287.4184875488281,
                263.2628173828125
              ]
            },
            {
              "track_id": 429,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6978908777236938,
              "bbox": [
                132.4040069580078,
                233.7292022705078,
                199.3929901123047,
                292.9944763183594
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3295516073703766,
              "bbox": [
                323.12091064453125,
                6.2806477546691895,
                640.0,
                354.4464111328125
              ]
            }
          ],
          "unique_tracks": [
            402,
            420,
            421,
            411,
            424,
            429,
            388
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            6726,
            6730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6731,
            6735
          ],
          "representative_frame": 6731,
          "detections": [
            {
              "track_id": 402,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.37573936581611633,
              "bbox": [
                144.98045349121094,
                0.0,
                632.8807983398438,
                350.4726867675781
              ]
            },
            {
              "track_id": 420,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.24555394053459167,
              "bbox": [
                205.80226135253906,
                207.80271911621094,
                286.8110656738281,
                263.7187194824219
              ]
            },
            {
              "track_id": 421,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.32127177715301514,
              "bbox": [
                0.10504377633333206,
                94.79680633544922,
                71.01097869873047,
                162.9144744873047
              ]
            },
            {
              "track_id": 411,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2033984512090683,
              "bbox": [
                84.58351135253906,
                0.7713331580162048,
                323.62884521484375,
                209.6387481689453
              ]
            },
            {
              "track_id": 424,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3017408549785614,
              "bbox": [
                204.25384521484375,
                208.05752563476562,
                287.43408203125,
                263.4814453125
              ]
            },
            {
              "track_id": 429,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2732551395893097,
              "bbox": [
                132.47857666015625,
                233.8402862548828,
                199.2924041748047,
                292.9268493652344
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.11050843447446823,
              "bbox": [
                295.7803649902344,
                2.442678451538086,
                633.8748168945312,
                353.28448486328125
              ]
            }
          ],
          "unique_tracks": [
            402,
            420,
            421,
            411,
            424,
            429,
            388
          ],
          "total_detections": 7
        },
        {
          "group_index": 3,
          "frame_range": [
            6736,
            6740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6741,
            6745
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9012858271598816,
              "bbox": [
                297.30816650390625,
                4.330109119415283,
                636.0914306640625,
                355.1950988769531
              ]
            },
            {
              "track_id": 413,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8429858088493347,
              "bbox": [
                4.1521148681640625,
                122.38245391845703,
                357.7920837402344,
                295.0251770019531
              ]
            }
          ],
          "unique_tracks": [
            388,
            413
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            6746,
            6750
          ],
          "representative_frame": 6746,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 56
    },
    {
      "second": 225,
      "time_range": [
        225,
        225.999
      ],
      "frame_range": [
        6751,
        6780
      ],
      "unified_description": "2 men are shown in an outdoor setting with tents.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:18",
        "processing_time": 2.95,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6765,
          "frame_range": [
            6761,
            6765
          ],
          "description": "a man in a hat and jacket sitting under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.14
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6751,
            6755
          ],
          "representative_frame": 6751,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8577509522438049,
              "bbox": [
                310.03662109375,
                11.086136817932129,
                640.0,
                355.8888244628906
              ]
            },
            {
              "track_id": 435,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.6177734136581421,
              "bbox": [
                262.214111328125,
                305.9508056640625,
                309.64111328125,
                359.3163146972656
              ]
            },
            {
              "track_id": 413,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5776820182800293,
              "bbox": [
                12.844953536987305,
                123.80950927734375,
                342.3175354003906,
                297.058349609375
              ]
            }
          ],
          "unique_tracks": [
            388,
            435,
            413
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            6756,
            6760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6761,
            6765
          ],
          "representative_frame": 6761,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9159314632415771,
              "bbox": [
                308.7816467285156,
                7.746252536773682,
                640.0,
                356.54345703125
              ]
            },
            {
              "track_id": 435,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.10794641077518463,
              "bbox": [
                264.8383483886719,
                311.6382751464844,
                307.4444885253906,
                359.43115234375
              ]
            },
            {
              "track_id": 413,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.47599363327026367,
              "bbox": [
                19.941160202026367,
                124.22482299804688,
                332.3731689453125,
                300.03533935546875
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.34334689378738403,
              "bbox": [
                10.023387908935547,
                189.95254516601562,
                115.66928100585938,
                293.4367370605469
              ]
            },
            {
              "track_id": 441,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.34692224860191345,
              "bbox": [
                150.0071258544922,
                125.09706115722656,
                261.3541259765625,
                289.0628967285156
              ]
            }
          ],
          "unique_tracks": [
            388,
            435,
            413,
            440,
            441
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            6766,
            6770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6771,
            6775
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9168768525123596,
              "bbox": [
                318.5142822265625,
                6.6789350509643555,
                640.0,
                355.4156494140625
              ]
            },
            {
              "track_id": 435,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.19841037690639496,
              "bbox": [
                262.9247131347656,
                307.1968078613281,
                309.50457763671875,
                359.4585876464844
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.30850425362586975,
              "bbox": [
                9.883787155151367,
                189.9051513671875,
                115.59383392333984,
                293.4459228515625
              ]
            },
            {
              "track_id": 441,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6361762285232544,
              "bbox": [
                125.53994750976562,
                124.95928955078125,
                243.0895233154297,
                296.8571472167969
              ]
            },
            {
              "track_id": 442,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.43733862042427063,
              "bbox": [
                431.6375732421875,
                140.4542999267578,
                518.6357421875,
                257.6273498535156
              ]
            }
          ],
          "unique_tracks": [
            388,
            435,
            440,
            441,
            442
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            6776,
            6780
          ],
          "representative_frame": 6776,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 56
    },
    {
      "second": 226,
      "time_range": [
        226,
        226.999
      ],
      "frame_range": [
        6781,
        6810
      ],
      "unified_description": "\n\nThe image shows a man sitting next to a young boy under a large tent. Both individuals are smiling as they share a moment together. A pot is placed in front of them, possibly indicating that they are having a meal or preparing food together. The scene captures a warm and happy atmosphere between the two persons. Additionally, there are multiple backpacks around them, suggesting that they may be on a camping trip or outdoor adventure.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:21",
        "processing_time": 4.05,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6795,
          "frame_range": [
            6791,
            6795
          ],
          "description": "a man in a tent with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.97
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6781,
            6785
          ],
          "representative_frame": 6781,
          "detections": [
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.30330339074134827,
              "bbox": [
                12.139144897460938,
                189.87075805664062,
                117.35159301757812,
                292.7155456542969
              ]
            },
            {
              "track_id": 441,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8804963231086731,
              "bbox": [
                122.75525665283203,
                129.67681884765625,
                240.9300537109375,
                301.1404113769531
              ]
            },
            {
              "track_id": 442,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5289421081542969,
              "bbox": [
                429.84368896484375,
                140.4586944580078,
                522.5213623046875,
                265.87744140625
              ]
            },
            {
              "track_id": 427,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7731870412826538,
              "bbox": [
                435.16619873046875,
                2.7597365379333496,
                640.0,
                354.2037658691406
              ]
            }
          ],
          "unique_tracks": [
            440,
            441,
            442,
            427
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            6786,
            6790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6791,
            6795
          ],
          "representative_frame": 6791,
          "detections": [
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2534921169281006,
              "bbox": [
                13.395275115966797,
                190.0538787841797,
                119.29120635986328,
                293.2493591308594
              ]
            },
            {
              "track_id": 441,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8751628994941711,
              "bbox": [
                118.57791900634766,
                131.09828186035156,
                236.6781768798828,
                301.3661193847656
              ]
            },
            {
              "track_id": 442,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.512095034122467,
              "bbox": [
                429.0535583496094,
                140.7366943359375,
                523.3563232421875,
                269.2372131347656
              ]
            },
            {
              "track_id": 427,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5359945297241211,
              "bbox": [
                437.3916015625,
                1.9696238040924072,
                640.0,
                358.00714111328125
              ]
            },
            {
              "track_id": 435,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.33872854709625244,
              "bbox": [
                268.52069091796875,
                321.1178283691406,
                303.6540222167969,
                359.726318359375
              ]
            }
          ],
          "unique_tracks": [
            440,
            441,
            442,
            427,
            435
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            6796,
            6800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6801,
            6805
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2349052131175995,
              "bbox": [
                13.306594848632812,
                190.0580291748047,
                120.21986389160156,
                293.9296569824219
              ]
            },
            {
              "track_id": 441,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.85634845495224,
              "bbox": [
                117.8202896118164,
                131.29345703125,
                236.7355194091797,
                301.3850402832031
              ]
            },
            {
              "track_id": 442,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.45572394132614136,
              "bbox": [
                428.90545654296875,
                140.8196258544922,
                523.0447998046875,
                270.23748779296875
              ]
            },
            {
              "track_id": 427,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.1941307634115219,
              "bbox": [
                440.98614501953125,
                1.8216675519943237,
                640.0,
                359.7631530761719
              ]
            },
            {
              "track_id": 435,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.46225041151046753,
              "bbox": [
                269.08392333984375,
                323.1315002441406,
                303.1315612792969,
                359.7547302246094
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.771366536617279,
              "bbox": [
                313.06201171875,
                5.131360054016113,
                640.0,
                356.3928527832031
              ]
            }
          ],
          "unique_tracks": [
            440,
            441,
            442,
            427,
            435,
            388
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            6806,
            6810
          ],
          "representative_frame": 6806,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 56
    },
    {
      "second": 227,
      "time_range": [
        227,
        227.999
      ],
      "frame_range": [
        6811,
        6840
      ],
      "unified_description": "1 second video that shows someone wearing a red jacket holding a bottle while two other bottles are visible in the foreground. The camera perspective is from behind the person in the red coat.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:22",
        "processing_time": 3.79,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6825,
          "frame_range": [
            6821,
            6825
          ],
          "description": "a man in a red jacket is holding a bottle",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.9
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6811,
            6815
          ],
          "representative_frame": 6811,
          "detections": [
            {
              "track_id": 427,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8186240196228027,
              "bbox": [
                450.5802307128906,
                104.61427307128906,
                629.4789428710938,
                359.2945861816406
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5798450708389282,
              "bbox": [
                0.0,
                1.3928234577178955,
                191.16854858398438,
                339.7421569824219
              ]
            }
          ],
          "unique_tracks": [
            427,
            417
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            6816,
            6820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6821,
            6825
          ],
          "representative_frame": 6821,
          "detections": [
            {
              "track_id": 452,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5660808086395264,
              "bbox": [
                343.1739807128906,
                236.33367919921875,
                412.1368713378906,
                358.1391296386719
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7306510806083679,
              "bbox": [
                0.0,
                0.0,
                185.8615264892578,
                334.87359619140625
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8506879806518555,
              "bbox": [
                351.1827087402344,
                12.950785636901855,
                640.0,
                348.98382568359375
              ]
            }
          ],
          "unique_tracks": [
            452,
            417,
            388
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            6826,
            6830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6831,
            6835
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 452,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2703774869441986,
              "bbox": [
                342.2277526855469,
                236.23040771484375,
                411.464599609375,
                358.39569091796875
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7590495347976685,
              "bbox": [
                0.0,
                0.0,
                183.8363494873047,
                335.4529724121094
              ]
            },
            {
              "track_id": 455,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.513515830039978,
              "bbox": [
                377.69091796875,
                291.5622863769531,
                571.276123046875,
                359.22821044921875
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8211390376091003,
              "bbox": [
                364.6678466796875,
                14.542474746704102,
                640.0,
                341.4444580078125
              ]
            }
          ],
          "unique_tracks": [
            452,
            417,
            455,
            388
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            6836,
            6840
          ],
          "representative_frame": 6836,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 56
    },
    {
      "second": 228,
      "time_range": [
        228,
        228.999
      ],
      "frame_range": [
        6841,
        6870
      ],
      "unified_description": "3 people are standing under a white canopy. A man in a red jacket is holding an aluminum bottle while someone else is grabbing a red water bottle. A third person seems to be watching them, and there is also a backpack in the scene. The image appears to have been captured with a GoPro camera mounted on a backpack.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:24",
        "processing_time": 4.32,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6855,
          "frame_range": [
            6851,
            6855
          ],
          "description": "a man in a red jacket is holding a bottle",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.0
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6841,
            6845
          ],
          "representative_frame": 6841,
          "detections": [
            {
              "track_id": 452,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4500824511051178,
              "bbox": [
                342.1975402832031,
                236.15695190429688,
                411.53131103515625,
                358.2924499511719
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7172395586967468,
              "bbox": [
                0.0,
                0.0,
                180.88348388671875,
                336.58795166015625
              ]
            },
            {
              "track_id": 455,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4295124411582947,
              "bbox": [
                380.7667236328125,
                285.8868713378906,
                588.4595336914062,
                358.67486572265625
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5911937952041626,
              "bbox": [
                372.4068298339844,
                17.472946166992188,
                640.0,
                334.2238464355469
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.35608530044555664,
              "bbox": [
                217.92202758789062,
                15.482218742370605,
                640.0,
                348.4043273925781
              ]
            },
            {
              "track_id": 413,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.8563790321350098,
              "bbox": [
                0.0,
                51.42349624633789,
                412.007080078125,
                354.1822814941406
              ]
            }
          ],
          "unique_tracks": [
            452,
            417,
            455,
            388,
            402,
            413
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            6846,
            6850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6851,
            6855
          ],
          "representative_frame": 6851,
          "detections": [
            {
              "track_id": 452,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4676458537578583,
              "bbox": [
                341.96929931640625,
                236.3419952392578,
                411.3583984375,
                358.2865905761719
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7140898704528809,
              "bbox": [
                0.0,
                0.0,
                177.24156188964844,
                335.5547790527344
              ]
            },
            {
              "track_id": 455,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3972112834453583,
              "bbox": [
                374.51239013671875,
                278.1181335449219,
                602.1869506835938,
                358.3796691894531
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.781935453414917,
              "bbox": [
                374.0222473144531,
                20.417503356933594,
                640.0,
                338.7944030761719
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.11238360404968262,
              "bbox": [
                229.73464965820312,
                17.12054443359375,
                640.0,
                350.8766784667969
              ]
            }
          ],
          "unique_tracks": [
            452,
            417,
            455,
            388,
            402
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            6856,
            6860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6861,
            6865
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 452,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4711056053638458,
              "bbox": [
                342.3114013671875,
                236.41610717773438,
                411.8475036621094,
                358.2175598144531
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7048091888427734,
              "bbox": [
                0.0,
                0.0,
                173.9270782470703,
                333.30029296875
              ]
            },
            {
              "track_id": 455,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.40511494874954224,
              "bbox": [
                370.9161071777344,
                273.86920166015625,
                608.4481201171875,
                358.2864990234375
              ]
            },
            {
              "track_id": 388,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8376133441925049,
              "bbox": [
                375.8164978027344,
                22.05154037475586,
                640.0,
                339.4366760253906
              ]
            },
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.11600625514984131,
              "bbox": [
                242.41319274902344,
                18.78618049621582,
                640.0,
                351.5207214355469
              ]
            }
          ],
          "unique_tracks": [
            452,
            417,
            455,
            388,
            402
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            6866,
            6870
          ],
          "representative_frame": 6866,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 57
    },
    {
      "second": 229,
      "time_range": [
        229,
        229.999
      ],
      "frame_range": [
        6871,
        6900
      ],
      "unified_description": "3d object detected near the main person, but it's just an object in the scene",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:25",
        "processing_time": 3.19,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6885,
          "frame_range": [
            6881,
            6885
          ],
          "description": "a man in a tent with a bag of food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.08
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6871,
            6875
          ],
          "representative_frame": 6871,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9136029481887817,
              "bbox": [
                197.30592346191406,
                8.665512084960938,
                632.939697265625,
                353.3582458496094
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4954475164413452,
              "bbox": [
                19.041061401367188,
                226.61399841308594,
                98.0091552734375,
                301.1745300292969
              ]
            }
          ],
          "unique_tracks": [
            402,
            440
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            6876,
            6880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6881,
            6885
          ],
          "representative_frame": 6881,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8636137247085571,
              "bbox": [
                229.78640747070312,
                3.782989740371704,
                640.0,
                354.4073486328125
              ]
            },
            {
              "track_id": 457,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8233681917190552,
              "bbox": [
                259.1431579589844,
                135.63604736328125,
                332.0317687988281,
                223.3592987060547
              ]
            },
            {
              "track_id": 458,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.31491807103157043,
              "bbox": [
                0.013931456953287125,
                269.2977600097656,
                124.65837097167969,
                358.4083557128906
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3826335668563843,
              "bbox": [
                20.00392723083496,
                229.34011840820312,
                95.09803771972656,
                297.41656494140625
              ]
            }
          ],
          "unique_tracks": [
            402,
            457,
            458,
            440
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            6886,
            6890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6891,
            6895
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8514543175697327,
              "bbox": [
                260.9446105957031,
                1.0905195474624634,
                640.0,
                353.9670104980469
              ]
            },
            {
              "track_id": 457,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8608945608139038,
              "bbox": [
                255.04800415039062,
                135.07432556152344,
                333.75946044921875,
                229.4967803955078
              ]
            },
            {
              "track_id": 458,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3968731164932251,
              "bbox": [
                0.0,
                268.6999206542969,
                125.17280578613281,
                358.43017578125
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.35216936469078064,
              "bbox": [
                19.095741271972656,
                229.1086883544922,
                95.68680572509766,
                296.32196044921875
              ]
            }
          ],
          "unique_tracks": [
            402,
            457,
            458,
            440
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            6896,
            6900
          ],
          "representative_frame": 6896,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 57
    },
    {
      "second": 230,
      "time_range": [
        230,
        230.999
      ],
      "frame_range": [
        6901,
        6930
      ],
      "unified_description": "0:58 to 0:67, A man wearing black color dress is seen in the image.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:26",
        "processing_time": 3.26,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6915,
          "frame_range": [
            6911,
            6915
          ],
          "description": "a man in a tent with a baby",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.88
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6901,
            6905
          ],
          "representative_frame": 6901,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9012885689735413,
              "bbox": [
                276.8713073730469,
                0.7036147713661194,
                640.0,
                353.29150390625
              ]
            },
            {
              "track_id": 457,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8740233778953552,
              "bbox": [
                253.4138641357422,
                133.29844665527344,
                337.2029113769531,
                233.4121551513672
              ]
            },
            {
              "track_id": 458,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3024110198020935,
              "bbox": [
                0.9548792243003845,
                268.26055908203125,
                126.7041244506836,
                358.1280212402344
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.4833076298236847,
              "bbox": [
                16.731630325317383,
                228.37950134277344,
                96.93751525878906,
                296.864990234375
              ]
            }
          ],
          "unique_tracks": [
            402,
            457,
            458,
            440
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            6906,
            6910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6911,
            6915
          ],
          "representative_frame": 6911,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.853409469127655,
              "bbox": [
                241.0958251953125,
                12.9699125289917,
                629.3676147460938,
                354.5517578125
              ]
            },
            {
              "track_id": 457,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8063774108886719,
              "bbox": [
                258.8204345703125,
                138.55892944335938,
                351.0919494628906,
                250.13168334960938
              ]
            },
            {
              "track_id": 458,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7110651135444641,
              "bbox": [
                0.0,
                266.1201477050781,
                128.44833374023438,
                358.6310119628906
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.27609944343566895,
              "bbox": [
                16.329708099365234,
                227.43373107910156,
                95.52125549316406,
                294.1175537109375
              ]
            }
          ],
          "unique_tracks": [
            402,
            457,
            458,
            440
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            6916,
            6920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6921,
            6925
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8780789971351624,
              "bbox": [
                229.0819854736328,
                17.898977279663086,
                607.0465087890625,
                355.2533874511719
              ]
            },
            {
              "track_id": 457,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8625630140304565,
              "bbox": [
                263.14312744140625,
                140.60910034179688,
                353.888671875,
                251.76290893554688
              ]
            },
            {
              "track_id": 458,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.713030219078064,
              "bbox": [
                0.0,
                265.53033447265625,
                128.71949768066406,
                358.7715759277344
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.22193080186843872,
              "bbox": [
                15.695330619812012,
                227.08995056152344,
                95.6608657836914,
                293.69775390625
              ]
            },
            {
              "track_id": 465,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7865556478500366,
              "bbox": [
                154.4227294921875,
                108.57969665527344,
                242.60707092285156,
                262.98114013671875
              ]
            },
            {
              "track_id": 467,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3220061957836151,
              "bbox": [
                0.43350425362586975,
                266.8280029296875,
                214.6398162841797,
                358.126953125
              ]
            }
          ],
          "unique_tracks": [
            402,
            457,
            458,
            440,
            465,
            467
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            6926,
            6930
          ],
          "representative_frame": 6926,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 57
    },
    {
      "second": 231,
      "time_range": [
        231,
        231.999
      ],
      "frame_range": [
        6931,
        6960
      ],
      "unified_description": "5 people are sitting under a large tent, one person is holding a bottle in hand, and the camera is placed at an angle to capture the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:28",
        "processing_time": 3.09,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6945,
          "frame_range": [
            6941,
            6945
          ],
          "description": "a man in a tent with a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.92
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6931,
            6935
          ],
          "representative_frame": 6931,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8529350161552429,
              "bbox": [
                248.95718383789062,
                17.453413009643555,
                614.927978515625,
                354.7611389160156
              ]
            },
            {
              "track_id": 457,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.850034773349762,
              "bbox": [
                264.7929992675781,
                141.206298828125,
                354.7918701171875,
                253.1171417236328
              ]
            },
            {
              "track_id": 458,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7157711982727051,
              "bbox": [
                0.0,
                265.2323303222656,
                128.69065856933594,
                358.8520812988281
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.26940199732780457,
              "bbox": [
                15.0525484085083,
                227.16482543945312,
                96.12730407714844,
                294.0672912597656
              ]
            },
            {
              "track_id": 465,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7570905685424805,
              "bbox": [
                156.95358276367188,
                108.03646087646484,
                240.5365447998047,
                254.38392639160156
              ]
            },
            {
              "track_id": 467,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.41752439737319946,
              "bbox": [
                1.4688165187835693,
                266.904541015625,
                215.6767120361328,
                358.1792907714844
              ]
            },
            {
              "track_id": 468,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6485873460769653,
              "bbox": [
                213.42007446289062,
                242.82354736328125,
                353.0655517578125,
                358.5649719238281
              ]
            }
          ],
          "unique_tracks": [
            402,
            457,
            458,
            440,
            465,
            467,
            468
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            6936,
            6940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6941,
            6945
          ],
          "representative_frame": 6941,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8403683304786682,
              "bbox": [
                252.49090576171875,
                13.989725112915039,
                612.4807739257812,
                354.2956237792969
              ]
            },
            {
              "track_id": 457,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8334612846374512,
              "bbox": [
                267.4932556152344,
                141.5215301513672,
                352.9209289550781,
                249.1789093017578
              ]
            },
            {
              "track_id": 458,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7247782945632935,
              "bbox": [
                0.0,
                265.2107238769531,
                128.5560760498047,
                358.90185546875
              ]
            },
            {
              "track_id": 440,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2264600396156311,
              "bbox": [
                14.958361625671387,
                227.3367156982422,
                96.34932708740234,
                293.90380859375
              ]
            },
            {
              "track_id": 465,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8282833695411682,
              "bbox": [
                157.37997436523438,
                111.7190170288086,
                239.92385864257812,
                256.2870788574219
              ]
            },
            {
              "track_id": 467,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.37954118847846985,
              "bbox": [
                0.76870197057724,
                266.4239807128906,
                216.17552185058594,
                358.2045593261719
              ]
            },
            {
              "track_id": 468,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.30808910727500916,
              "bbox": [
                207.20681762695312,
                220.5678253173828,
                372.4353942871094,
                357.8721008300781
              ]
            }
          ],
          "unique_tracks": [
            402,
            457,
            458,
            440,
            465,
            467,
            468
          ],
          "total_detections": 7
        },
        {
          "group_index": 3,
          "frame_range": [
            6946,
            6950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6951,
            6955
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9578766822814941,
              "bbox": [
                232.30352783203125,
                5.266718864440918,
                609.3621215820312,
                354.8163757324219
              ]
            },
            {
              "track_id": 465,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.14959293603897095,
              "bbox": [
                176.93516540527344,
                127.62432098388672,
                246.2564697265625,
                245.57855224609375
              ]
            }
          ],
          "unique_tracks": [
            402,
            465
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            6956,
            6960
          ],
          "representative_frame": 6956,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 57
    },
    {
      "second": 232,
      "time_range": [
        232,
        232.999
      ],
      "frame_range": [
        6961,
        6990
      ],
      "unified_description": "0:56 to 0:79 - A man is boiling water in a green kettle.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:29",
        "processing_time": 3.15,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 6975,
          "frame_range": [
            6971,
            6975
          ],
          "description": "a man in a tent with a knife and other people",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.09
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6961,
            6965
          ],
          "representative_frame": 6961,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9584329724311829,
              "bbox": [
                227.431884765625,
                1.8691693544387817,
                613.625244140625,
                355.0589904785156
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4150582551956177,
              "bbox": [
                0.7588577270507812,
                73.5188217163086,
                83.83265686035156,
                349.98638916015625
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4742245376110077,
              "bbox": [
                43.089847564697266,
                184.02378845214844,
                159.4669952392578,
                358.7969970703125
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            6966,
            6970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            6971,
            6975
          ],
          "representative_frame": 6971,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.959052324295044,
              "bbox": [
                231.0695343017578,
                0.9145864844322205,
                621.37939453125,
                355.17205810546875
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4806930422782898,
              "bbox": [
                0.7388734817504883,
                73.47834777832031,
                83.99208068847656,
                350.4854431152344
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3529253602027893,
              "bbox": [
                43.708492279052734,
                185.43540954589844,
                155.82957458496094,
                360.0
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            6976,
            6980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            6981,
            6985
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9460601806640625,
              "bbox": [
                242.7008819580078,
                0.5260948538780212,
                632.5220336914062,
                354.255859375
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6096359491348267,
              "bbox": [
                0.0,
                73.80928802490234,
                66.02099609375,
                295.7817687988281
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.36638426780700684,
              "bbox": [
                44.26191329956055,
                183.04733276367188,
                154.40675354003906,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4378148019313812,
              "bbox": [
                135.55763244628906,
                129.765380859375,
                273.1834411621094,
                262.32745361328125
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            6986,
            6990
          ],
          "representative_frame": 6986,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 58
    },
    {
      "second": 233,
      "time_range": [
        233,
        233.999
      ],
      "frame_range": [
        6991,
        7020
      ],
      "unified_description": "3 people are sitting around a campsite. One man is drinking from a blue coffee mug, while another man lights a lantern. There are various objects around them including two backpacks, a tent, and a fishing rod. The scene appears to be captured in a first-person perspective, with some motion blur due to the shaky camera.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:32",
        "processing_time": 4.4,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7005,
          "frame_range": [
            7001,
            7005
          ],
          "description": "a man in a tent with a cup",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.84
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            6991,
            6995
          ],
          "representative_frame": 6991,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8876944780349731,
              "bbox": [
                269.7380065917969,
                0.09606051445007324,
                640.0,
                353.5037536621094
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.45333877205848694,
              "bbox": [
                0.0,
                79.11959075927734,
                66.25006103515625,
                335.17877197265625
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.13853131234645844,
              "bbox": [
                45.359397888183594,
                181.9726104736328,
                153.40577697753906,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5242965817451477,
              "bbox": [
                129.27767944335938,
                126.01863861083984,
                276.6637878417969,
                268.25360107421875
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3472670614719391,
              "bbox": [
                178.26425170898438,
                298.0702209472656,
                223.9020233154297,
                359.6528015136719
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476,
            482
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            6996,
            7000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7001,
            7005
          ],
          "representative_frame": 7001,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8790320158004761,
              "bbox": [
                280.9878234863281,
                0.24527613818645477,
                640.0,
                353.68310546875
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6378664374351501,
              "bbox": [
                0.0,
                80.0490951538086,
                58.128177642822266,
                297.36871337890625
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.1114872470498085,
              "bbox": [
                47.04829406738281,
                182.63172912597656,
                152.0357208251953,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.47399404644966125,
              "bbox": [
                127.12586212158203,
                124.77639770507812,
                277.5972900390625,
                270.4083557128906
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.37357157468795776,
              "bbox": [
                178.06141662597656,
                297.5702209472656,
                224.09532165527344,
                359.67889404296875
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476,
            482
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            7006,
            7010
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7011,
            7015
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8673351407051086,
              "bbox": [
                287.2247619628906,
                0.0476604662835598,
                640.0,
                353.2257385253906
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5139912962913513,
              "bbox": [
                0.0,
                79.53573608398438,
                56.341922760009766,
                284.4383850097656
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.10824684053659439,
              "bbox": [
                48.523460388183594,
                182.62486267089844,
                151.3082733154297,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5263538360595703,
              "bbox": [
                127.67791748046875,
                124.71145629882812,
                276.5950927734375,
                269.2793884277344
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.49052876234054565,
              "bbox": [
                176.56532287597656,
                292.8330078125,
                226.04693603515625,
                359.7550354003906
              ]
            },
            {
              "track_id": 485,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.33568719029426575,
              "bbox": [
                319.2976379394531,
                106.75503540039062,
                373.1990966796875,
                158.59474182128906
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476,
            482,
            485
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            7016,
            7020
          ],
          "representative_frame": 7016,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 58
    },
    {
      "second": 234,
      "time_range": [
        234,
        234.999
      ],
      "frame_range": [
        7021,
        7050
      ],
      "unified_description": "3 people in a camping setting. A man sips coffee while his young companions sit nearby. The image contains multiple objects including two cups, one of which is closer to the older gentleman. There are three backpacks placed around the campsite along with a bottle and some other items such as an umbrella.\n\nThe camera perspective seems to be from the man's point of view as he sips coffee, providing a first-person experience. The scene appears to be captured in wide-angle format, showcasing the entire campsite area.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:34",
        "processing_time": 5.39,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7035,
          "frame_range": [
            7031,
            7035
          ],
          "description": "a man in a tent with two children",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.84
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7021,
            7025
          ],
          "representative_frame": 7021,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8625051975250244,
              "bbox": [
                289.9076232910156,
                0.022684982046484947,
                640.0,
                353.4309387207031
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6020572185516357,
              "bbox": [
                0.0,
                79.0031967163086,
                55.741172790527344,
                280.22503662109375
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.19060511887073517,
              "bbox": [
                49.69758224487305,
                182.66543579101562,
                150.63998413085938,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4642104506492615,
              "bbox": [
                128.37722778320312,
                125.01689147949219,
                275.7571105957031,
                268.6005554199219
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4145583510398865,
              "bbox": [
                176.7177734375,
                293.2164001464844,
                225.82518005371094,
                359.7292175292969
              ]
            },
            {
              "track_id": 485,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.6739083528518677,
              "bbox": [
                318.5480041503906,
                103.4946517944336,
                372.33477783203125,
                155.27767944335938
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476,
            482,
            485
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7026,
            7030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7031,
            7035
          ],
          "representative_frame": 7031,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8813963532447815,
              "bbox": [
                290.9293518066406,
                0.07278735935688019,
                640.0,
                354.3145446777344
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5786324739456177,
              "bbox": [
                0.0,
                79.04752349853516,
                55.61615753173828,
                279.6311950683594
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.12587343156337738,
              "bbox": [
                50.731868743896484,
                182.8064727783203,
                150.05029296875,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.469056636095047,
              "bbox": [
                128.7705841064453,
                124.84249114990234,
                275.4042663574219,
                268.30126953125
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.40025681257247925,
              "bbox": [
                177.4287872314453,
                295.1539306640625,
                225.0986328125,
                359.72955322265625
              ]
            },
            {
              "track_id": 485,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.6891332268714905,
              "bbox": [
                317.7949523925781,
                102.11734771728516,
                371.2287292480469,
                153.60975646972656
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476,
            482,
            485
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            7036,
            7040
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7041,
            7045
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9054608941078186,
              "bbox": [
                293.9869079589844,
                0.4286781847476959,
                640.0,
                354.47149658203125
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6625608801841736,
              "bbox": [
                0.0,
                79.98149108886719,
                54.561397552490234,
                278.5587158203125
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.6197117567062378,
              "bbox": [
                51.45446014404297,
                183.16372680664062,
                149.30540466308594,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7661114931106567,
              "bbox": [
                143.18807983398438,
                124.55045318603516,
                277.5133056640625,
                254.29615783691406
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.27198830246925354,
              "bbox": [
                178.68093872070312,
                298.55865478515625,
                223.91432189941406,
                359.616943359375
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476,
            482
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7046,
            7050
          ],
          "representative_frame": 7046,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 58
    },
    {
      "second": 235,
      "time_range": [
        235,
        235.999
      ],
      "frame_range": [
        7051,
        7080
      ],
      "unified_description": "3 people, one of them holding something out to another person. The scene takes place inside a tent with two backpacks visible in the background. A handshake is occurring between the individuals as they exchange an object.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:36",
        "processing_time": 4.73,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7065,
          "frame_range": [
            7061,
            7065
          ],
          "description": "a man in a tent with a man in a hat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.79
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7051,
            7055
          ],
          "representative_frame": 7051,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9164955615997314,
              "bbox": [
                294.4214782714844,
                0.7028676271438599,
                640.0,
                353.8016052246094
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6860536336898804,
              "bbox": [
                0.0,
                80.67367553710938,
                53.81477737426758,
                278.1680908203125
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.40501776337623596,
              "bbox": [
                52.02840805053711,
                183.5350799560547,
                148.66639709472656,
                360.0
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6329675912857056,
              "bbox": [
                145.93869018554688,
                123.76118469238281,
                279.7756042480469,
                251.57916259765625
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.33416640758514404,
              "bbox": [
                177.1312713623047,
                294.1618957519531,
                225.4115447998047,
                359.5683288574219
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            441,
            476,
            482
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7056,
            7060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7061,
            7065
          ],
          "representative_frame": 7061,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9249724745750427,
              "bbox": [
                292.10015869140625,
                0.7298018336296082,
                640.0,
                353.4800720214844
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6985617280006409,
              "bbox": [
                0.0,
                80.73072814941406,
                53.445003509521484,
                275.78228759765625
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5159158706665039,
              "bbox": [
                145.25186157226562,
                122.78148651123047,
                280.13818359375,
                250.5629119873047
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3107468783855438,
              "bbox": [
                177.13192749023438,
                293.28839111328125,
                225.94268798828125,
                359.545166015625
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            7066,
            7070
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7071,
            7075
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9160416126251221,
              "bbox": [
                287.906982421875,
                0.8650400042533875,
                640.0,
                353.4119873046875
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5453139543533325,
              "bbox": [
                0.0,
                80.95523071289062,
                53.85555648803711,
                278.4161682128906
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8214492201805115,
              "bbox": [
                140.622802734375,
                122.43836975097656,
                275.9875183105469,
                250.24867248535156
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2923630177974701,
              "bbox": [
                178.9070281982422,
                298.6294860839844,
                224.06871032714844,
                359.5020446777344
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3331242799758911,
              "bbox": [
                52.282142639160156,
                181.0599365234375,
                148.81788635253906,
                359.9612731933594
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482,
            441
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7076,
            7080
          ],
          "representative_frame": 7076,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 58
    },
    {
      "second": 236,
      "time_range": [
        236,
        236.999
      ],
      "frame_range": [
        7081,
        7110
      ],
      "unified_description": "3 guys outdoors having a conversation in front of a campsite. The man in the foreground is wearing a black leather jacket.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:37",
        "processing_time": 4.3,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7095,
          "frame_range": [
            7091,
            7095
          ],
          "description": "a man in a tent with a cell",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.17
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7081,
            7085
          ],
          "representative_frame": 7081,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9225226044654846,
              "bbox": [
                287.66729736328125,
                0.9742242693901062,
                640.0,
                353.52508544921875
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4356691539287567,
              "bbox": [
                0.0,
                81.07884979248047,
                54.57181930541992,
                280.3038024902344
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5406004786491394,
              "bbox": [
                139.42564392089844,
                121.59951782226562,
                273.9418640136719,
                247.98680114746094
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3393201231956482,
              "bbox": [
                177.7324676513672,
                295.5814514160156,
                225.01919555664062,
                359.4980163574219
              ]
            },
            {
              "track_id": 491,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.5644126534461975,
              "bbox": [
                263.1962890625,
                189.59896850585938,
                283.3963623046875,
                215.28981018066406
              ]
            },
            {
              "track_id": 441,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.15748615562915802,
              "bbox": [
                53.24711227416992,
                181.3973846435547,
                148.28709411621094,
                359.1809997558594
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482,
            491,
            441
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7086,
            7090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7091,
            7095
          ],
          "representative_frame": 7091,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9471574425697327,
              "bbox": [
                289.911865234375,
                0.9601112008094788,
                640.0,
                354.4098205566406
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.23321621119976044,
              "bbox": [
                0.0,
                78.36995697021484,
                54.287078857421875,
                279.8919982910156
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.50784832239151,
              "bbox": [
                138.48558044433594,
                121.33110809326172,
                273.6882629394531,
                247.43515014648438
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.32298770546913147,
              "bbox": [
                178.09410095214844,
                297.0168762207031,
                224.4686737060547,
                359.5770568847656
              ]
            },
            {
              "track_id": 491,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.4681428074836731,
              "bbox": [
                265.2649841308594,
                193.01234436035156,
                284.6055908203125,
                217.71633911132812
              ]
            },
            {
              "track_id": 493,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.3117983937263489,
              "bbox": [
                0.3692871928215027,
                276.7031555175781,
                48.93646240234375,
                358.4153747558594
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482,
            491,
            493
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            7096,
            7100
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7101,
            7105
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9141881465911865,
              "bbox": [
                267.66937255859375,
                0.8223068118095398,
                628.4371948242188,
                354.508056640625
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4006868302822113,
              "bbox": [
                0.0,
                76.42372131347656,
                54.31513977050781,
                280.4767150878906
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5237272381782532,
              "bbox": [
                135.7574005126953,
                120.34978485107422,
                274.99420166015625,
                249.83033752441406
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2761947512626648,
              "bbox": [
                177.50379943847656,
                295.1762390136719,
                225.28390502929688,
                359.7592468261719
              ]
            },
            {
              "track_id": 493,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.2755538523197174,
              "bbox": [
                0.3052240312099457,
                276.6531982421875,
                48.84467315673828,
                358.3212890625
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.365171879529953,
              "bbox": [
                0.0,
                78.07160186767578,
                57.79546356201172,
                349.2713928222656
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482,
            493,
            495
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            7106,
            7110
          ],
          "representative_frame": 7106,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 59
    },
    {
      "second": 237,
      "time_range": [
        237,
        237.999
      ],
      "frame_range": [
        7111,
        7140
      ],
      "unified_description": "\nA man, possibly an older man, is sitting down in front of a tent. He is wearing a black coat with red letters on it. The tent appears to be a mess tent, as there are a few other people present in the area, some of whom may also be engaging with the main subject. There's an open backpack nearby which could contain food or other supplies for the camping trip.\n\nIn summary, this image depicts a group of people on a camping trip, with the primary focus being an older man in a black coat with red letters on it. The scene likely takes place within a tent or a mess tent, as evidenced by the presence of various individuals and the open backpack.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:40",
        "processing_time": 4.88,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7125,
          "frame_range": [
            7121,
            7125
          ],
          "description": "a man in a tent with a bunch of food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.26
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7111,
            7115
          ],
          "representative_frame": 7111,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9309440851211548,
              "bbox": [
                274.79254150390625,
                0.6510568857192993,
                636.3473510742188,
                355.7155456542969
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5416102409362793,
              "bbox": [
                0.0,
                76.25423431396484,
                54.2464599609375,
                280.7546081542969
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6485273838043213,
              "bbox": [
                130.65188598632812,
                120.71366882324219,
                273.39483642578125,
                253.9691162109375
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2911493182182312,
              "bbox": [
                178.38311767578125,
                297.51458740234375,
                224.52890014648438,
                359.6712341308594
              ]
            },
            {
              "track_id": 493,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.2971864342689514,
              "bbox": [
                0.37282055616378784,
                276.7535400390625,
                48.91032409667969,
                358.4108581542969
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.19300994277000427,
              "bbox": [
                0.7860912084579468,
                78.23521423339844,
                58.47787857055664,
                347.4379577636719
              ]
            },
            {
              "track_id": 499,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5974728465080261,
              "bbox": [
                275.08282470703125,
                314.7859802246094,
                330.1525573730469,
                350.7295227050781
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482,
            493,
            495,
            499
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            7116,
            7120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7121,
            7125
          ],
          "representative_frame": 7121,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9185000061988831,
              "bbox": [
                277.41302490234375,
                0.4822138845920563,
                638.4686279296875,
                356.2249450683594
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5356913805007935,
              "bbox": [
                0.0,
                76.2988052368164,
                54.16169738769531,
                281.30517578125
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5988385081291199,
              "bbox": [
                128.0443878173828,
                121.33773040771484,
                273.1365051269531,
                257.5572204589844
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4057933986186981,
              "bbox": [
                179.34852600097656,
                300.6723327636719,
                223.51210021972656,
                359.6469421386719
              ]
            },
            {
              "track_id": 493,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.27790147066116333,
              "bbox": [
                0.46147915720939636,
                276.9183654785156,
                48.96238708496094,
                358.4927673339844
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2616114616394043,
              "bbox": [
                0.13623107969760895,
                78.18976593017578,
                57.55588150024414,
                346.2047119140625
              ]
            },
            {
              "track_id": 499,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5470415949821472,
              "bbox": [
                273.5174560546875,
                314.8482360839844,
                331.3990173339844,
                352.98992919921875
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482,
            493,
            495,
            499
          ],
          "total_detections": 7
        },
        {
          "group_index": 3,
          "frame_range": [
            7126,
            7130
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7131,
            7135
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8939712643623352,
              "bbox": [
                261.6943054199219,
                0.4754543900489807,
                626.1386108398438,
                355.5608825683594
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46065056324005127,
              "bbox": [
                0.0,
                76.80677795410156,
                53.99114990234375,
                281.7170104980469
              ]
            },
            {
              "track_id": 476,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.54485684633255,
              "bbox": [
                128.3579559326172,
                122.50968170166016,
                274.8243103027344,
                261.0240783691406
              ]
            },
            {
              "track_id": 482,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5332210659980774,
              "bbox": [
                179.2870635986328,
                300.9225769042969,
                223.5318603515625,
                359.7237243652344
              ]
            },
            {
              "track_id": 493,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.2470107078552246,
              "bbox": [
                0.47097113728523254,
                276.947509765625,
                48.91500473022461,
                358.4048156738281
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.34485819935798645,
              "bbox": [
                0.44304096698760986,
                78.17247009277344,
                58.07290267944336,
                347.0194091796875
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            476,
            482,
            493,
            495
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            7136,
            7140
          ],
          "representative_frame": 7136,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 59
    },
    {
      "second": 238,
      "time_range": [
        238,
        238.999
      ],
      "frame_range": [
        7141,
        7170
      ],
      "unified_description": "3 people inside a tent with a green baby sitting on the lap of a man. A handbag is placed nearby and there are a couple of cups and bottles in the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:42",
        "processing_time": 5.06,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7155,
          "frame_range": [
            7151,
            7155
          ],
          "description": "a man holding a bottle of beer",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.87
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7141,
            7145
          ],
          "representative_frame": 7141,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7617302536964417,
              "bbox": [
                310.3711853027344,
                0.8447405099868774,
                640.0,
                336.20513916015625
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.30973994731903076,
              "bbox": [
                1.6865428686141968,
                80.6738510131836,
                50.63480758666992,
                258.0514831542969
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8447892069816589,
              "bbox": [
                38.5333251953125,
                33.15327072143555,
                169.14723205566406,
                277.8338623046875
              ]
            }
          ],
          "unique_tracks": [
            402,
            471,
            417
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            7146,
            7150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7151,
            7155
          ],
          "representative_frame": 7151,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9293692708015442,
              "bbox": [
                305.5116882324219,
                1.0991376638412476,
                640.0,
                346.434814453125
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.43119868636131287,
              "bbox": [
                212.99359130859375,
                82.66386413574219,
                343.5417175292969,
                211.8782196044922
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8812316656112671,
              "bbox": [
                12.118356704711914,
                28.737632751464844,
                147.5070343017578,
                278.97308349609375
              ]
            },
            {
              "track_id": 457,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5122563242912292,
              "bbox": [
                281.56414794921875,
                173.6093292236328,
                407.4764709472656,
                347.1879577636719
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            457
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            7156,
            7160
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7161,
            7165
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9544684886932373,
              "bbox": [
                304.7966613769531,
                1.382267713546753,
                640.0,
                351.8780822753906
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3258250951766968,
              "bbox": [
                213.83778381347656,
                82.6830825805664,
                343.7372131347656,
                211.1994171142578
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9086689352989197,
              "bbox": [
                4.955087184906006,
                27.527606964111328,
                142.21029663085938,
                279.4150695800781
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4740968942642212,
              "bbox": [
                88.1131591796875,
                279.5060119628906,
                123.47235107421875,
                319.8712158203125
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.42194464802742004,
              "bbox": [
                226.589599609375,
                182.69497680664062,
                303.9703369140625,
                237.2140655517578
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            507
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7166,
            7170
          ],
          "representative_frame": 7166,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 59
    },
    {
      "second": 239,
      "time_range": [
        239,
        239.999
      ],
      "frame_range": [
        7171,
        7200
      ],
      "unified_description": "1-second video depicting a family playing with green stuffed animals. A man in a tent is looking down at his beer when he notices the children playing. The scene includes multiple people, a bottle of beer, and several toys.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:43",
        "processing_time": 5.12,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7185,
          "frame_range": [
            7181,
            7185
          ],
          "description": "a man in a tent with a bottle of beer",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.2
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7171,
            7175
          ],
          "representative_frame": 7171,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9383586049079895,
              "bbox": [
                307.3551330566406,
                1.372209906578064,
                640.0,
                353.30975341796875
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7990290522575378,
              "bbox": [
                213.79327392578125,
                83.16168975830078,
                344.1145935058594,
                212.03805541992188
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8996047377586365,
              "bbox": [
                17.260162353515625,
                34.69989013671875,
                149.97364807128906,
                279.1985168457031
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4309808909893036,
              "bbox": [
                87.93636322021484,
                279.5274658203125,
                123.17550659179688,
                319.7394104003906
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2582351863384247,
              "bbox": [
                225.6383514404297,
                182.67848205566406,
                303.4696044921875,
                237.4931640625
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            507
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7176,
            7180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7181,
            7185
          ],
          "representative_frame": 7181,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9534249901771545,
              "bbox": [
                305.1172790527344,
                1.1592400074005127,
                640.0,
                353.87994384765625
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8690560460090637,
              "bbox": [
                214.20286560058594,
                83.1540298461914,
                344.0811462402344,
                211.4830322265625
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8510628938674927,
              "bbox": [
                33.8415641784668,
                44.43952560424805,
                158.6475067138672,
                279.4278564453125
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4583035111427307,
              "bbox": [
                87.86434173583984,
                279.4587097167969,
                123.09477996826172,
                319.6478271484375
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.37199798226356506,
              "bbox": [
                226.19253540039062,
                182.526123046875,
                304.2615051269531,
                237.53224182128906
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46839606761932373,
              "bbox": [
                3.984327793121338,
                81.86956024169922,
                50.715667724609375,
                247.10020446777344
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            507,
            471
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            7186,
            7190
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7191,
            7195
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9419125318527222,
              "bbox": [
                313.1111755371094,
                1.1767475605010986,
                640.0,
                354.2900695800781
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7005867958068848,
              "bbox": [
                195.10047912597656,
                82.6950912475586,
                362.4758605957031,
                250.33633422851562
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.635633111000061,
              "bbox": [
                58.9831428527832,
                52.75755310058594,
                171.9183349609375,
                264.9661865234375
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7013967633247375,
              "bbox": [
                88.25641632080078,
                279.67059326171875,
                123.05687713623047,
                319.3218688964844
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.20583857595920563,
              "bbox": [
                3.7786219120025635,
                83.02811431884766,
                52.26103210449219,
                251.2787628173828
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            471
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7196,
            7200
          ],
          "representative_frame": 7196,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 59
    },
    {
      "second": 240,
      "time_range": [
        240,
        240.999
      ],
      "frame_range": [
        7201,
        7230
      ],
      "unified_description": "3 people are seated around a cooking pot inside a tent. A man is sitting near a little boy and another person. They seem to be engaging in a conversation or preparing food together. There is a sports ball present that might indicate leisure time or an upcoming activity. The camera is positioned overhead, capturing the entire scene with some technical artifacts such as motion blur and lens flare.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:46",
        "processing_time": 4.13,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7215,
          "frame_range": [
            7211,
            7215
          ],
          "description": "a man in a tent with a cell",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.0
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7201,
            7205
          ],
          "representative_frame": 7201,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9427052736282349,
              "bbox": [
                318.42840576171875,
                1.2618974447250366,
                640.0,
                354.1117858886719
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6490203738212585,
              "bbox": [
                189.65298461914062,
                82.43245697021484,
                366.902587890625,
                262.61962890625
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8152101039886475,
              "bbox": [
                72.18123626708984,
                60.8257942199707,
                177.3951416015625,
                258.4482116699219
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6412745118141174,
              "bbox": [
                88.3988265991211,
                279.797607421875,
                123.05780792236328,
                319.2180480957031
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.33581534028053284,
              "bbox": [
                3.3507003784179688,
                83.12890625,
                52.923274993896484,
                252.61106872558594
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            471
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7206,
            7210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7211,
            7215
          ],
          "representative_frame": 7211,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9218435883522034,
              "bbox": [
                318.8907165527344,
                1.5743807554244995,
                640.0,
                354.7977294921875
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.47220656275749207,
              "bbox": [
                186.53953552246094,
                82.20855712890625,
                368.78302001953125,
                270.70745849609375
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8144562840461731,
              "bbox": [
                70.81021881103516,
                60.7482795715332,
                175.93836975097656,
                258.08843994140625
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6303836703300476,
              "bbox": [
                88.4529800415039,
                279.84375,
                123.11804962158203,
                319.1971740722656
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4242258369922638,
              "bbox": [
                2.873769760131836,
                83.23477935791016,
                52.97474670410156,
                252.49432373046875
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.26043227314949036,
              "bbox": [
                225.263916015625,
                181.26519775390625,
                305.2509460449219,
                237.77394104003906
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            471,
            507
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            7216,
            7220
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7221,
            7225
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9135652184486389,
              "bbox": [
                320.0137023925781,
                0.829786479473114,
                640.0,
                353.6490173339844
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5600600838661194,
              "bbox": [
                186.71192932128906,
                81.7132568359375,
                367.1763916015625,
                271.72760009765625
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8166478872299194,
              "bbox": [
                73.60013580322266,
                56.53996658325195,
                180.12730407714844,
                261.76226806640625
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6233459711074829,
              "bbox": [
                88.35942840576172,
                279.84356689453125,
                123.22398376464844,
                319.3593444824219
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.23346103727817535,
              "bbox": [
                2.552262306213379,
                83.19864654541016,
                53.24168395996094,
                252.6892852783203
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3977508246898651,
              "bbox": [
                225.37319946289062,
                180.2075653076172,
                305.0098876953125,
                236.63636779785156
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.3252844214439392,
              "bbox": [
                0.0,
                238.47467041015625,
                89.51871490478516,
                321.9989318847656
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            471,
            507,
            440
          ],
          "total_detections": 7
        },
        {
          "group_index": 5,
          "frame_range": [
            7226,
            7230
          ],
          "representative_frame": 7226,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 60
    },
    {
      "second": 241,
      "time_range": [
        241,
        241.999
      ],
      "frame_range": [
        7231,
        7260
      ],
      "unified_description": "3 people in a tent, a father and his two sons. The boy in the foreground is holding a red canister.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:47",
        "processing_time": 3.91,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7245,
          "frame_range": [
            7241,
            7245
          ],
          "description": "a man and a boy are sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.08
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7231,
            7235
          ],
          "representative_frame": 7231,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9290370345115662,
              "bbox": [
                321.267578125,
                1.0927320718765259,
                640.0,
                353.07305908203125
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5366250276565552,
              "bbox": [
                194.69435119628906,
                80.82356262207031,
                359.6209716796875,
                256.2987365722656
              ]
            },
            {
              "track_id": 417,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7203680276870728,
              "bbox": [
                66.11061096191406,
                54.27647399902344,
                175.9736328125,
                266.442626953125
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5750441551208496,
              "bbox": [
                88.29204559326172,
                279.8730163574219,
                123.3503646850586,
                319.560546875
              ]
            },
            {
              "track_id": 471,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.18257464468479156,
              "bbox": [
                2.3586695194244385,
                83.05488586425781,
                53.18722915649414,
                251.22450256347656
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2516566812992096,
              "bbox": [
                223.24928283691406,
                178.3580322265625,
                306.1164855957031,
                237.44216918945312
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.3467983305454254,
              "bbox": [
                0.0,
                238.5653076171875,
                87.83758544921875,
                322.23638916015625
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            417,
            506,
            471,
            507,
            440
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            7236,
            7240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7241,
            7245
          ],
          "representative_frame": 7241,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.934419572353363,
              "bbox": [
                322.0921630859375,
                1.008590817451477,
                640.0,
                355.3524475097656
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.15788383781909943,
              "bbox": [
                190.4619598388672,
                82.9706802368164,
                363.7265625,
                271.0837707519531
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3075050413608551,
              "bbox": [
                225.55221557617188,
                180.10153198242188,
                304.98834228515625,
                236.79400634765625
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8402278423309326,
              "bbox": [
                31.35500144958496,
                2.8268277645111084,
                116.05023193359375,
                354.8923034667969
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            507,
            495
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            7246,
            7250
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7251,
            7255
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9434314966201782,
              "bbox": [
                305.48992919921875,
                0.9636185765266418,
                637.59765625,
                356.5345764160156
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.40447133779525757,
              "bbox": [
                202.2225341796875,
                83.76475524902344,
                389.5064392089844,
                287.1304016113281
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5280889868736267,
              "bbox": [
                226.56948852539062,
                180.86004638671875,
                304.3719177246094,
                236.4309844970703
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8266900777816772,
              "bbox": [
                29.200050354003906,
                0.0,
                122.74484252929688,
                355.5811462402344
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.3952716290950775,
              "bbox": [
                0.0,
                241.26976013183594,
                93.0210189819336,
                343.8675842285156
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            507,
            495,
            440
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7256,
            7260
          ],
          "representative_frame": 7256,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 60
    },
    {
      "second": 242,
      "time_range": [
        242,
        242.999
      ],
      "frame_range": [
        7261,
        7290
      ],
      "unified_description": "3 people, an adult male and two boys, are inside a tent. The man is showing something to one of the children.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:48",
        "processing_time": 3.52,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7275,
          "frame_range": [
            7271,
            7275
          ],
          "description": "a man and a boy are sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.19
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7261,
            7265
          ],
          "representative_frame": 7261,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9254406690597534,
              "bbox": [
                277.99188232421875,
                0.4860745072364807,
                615.3926391601562,
                353.3788146972656
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5286161303520203,
              "bbox": [
                198.33555603027344,
                84.42286682128906,
                373.0435791015625,
                277.63653564453125
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.54997318983078,
              "bbox": [
                226.5016632080078,
                181.25193786621094,
                304.51910400390625,
                237.0108642578125
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8464850187301636,
              "bbox": [
                25.933996200561523,
                0.0,
                126.15555572509766,
                355.2262268066406
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.1307644546031952,
              "bbox": [
                0.0,
                242.16806030273438,
                93.90727233886719,
                353.74285888671875
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            507,
            495,
            440
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7266,
            7270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7271,
            7275
          ],
          "representative_frame": 7271,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9283338189125061,
              "bbox": [
                259.46197509765625,
                0.2673349976539612,
                606.2996826171875,
                354.871826171875
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.38458704948425293,
              "bbox": [
                197.45123291015625,
                84.71125793457031,
                364.44677734375,
                272.6145324707031
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.42086830735206604,
              "bbox": [
                227.1042938232422,
                181.63272094726562,
                304.1062927246094,
                236.62689208984375
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9029285311698914,
              "bbox": [
                19.841270446777344,
                0.0,
                124.31767272949219,
                356.207275390625
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.5276060700416565,
              "bbox": [
                0.0,
                242.78390502929688,
                94.20641326904297,
                357.39398193359375
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            507,
            495,
            440
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            7276,
            7280
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7281,
            7285
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9481056332588196,
              "bbox": [
                259.6529846191406,
                0.2468900978565216,
                610.6856079101562,
                353.7020568847656
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6682677268981934,
              "bbox": [
                198.601806640625,
                84.70626831054688,
                359.60504150390625,
                268.7812194824219
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9115738272666931,
              "bbox": [
                21.247669219970703,
                5.307453632354736,
                129.6984100341797,
                356.9976501464844
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.1572439968585968,
              "bbox": [
                0.0,
                246.03990173339844,
                93.1590347290039,
                358.3507080078125
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            495,
            440
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            7286,
            7290
          ],
          "representative_frame": 7286,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 60
    },
    {
      "second": 243,
      "time_range": [
        243,
        243.999
      ],
      "frame_range": [
        7291,
        7320
      ],
      "unified_description": "3 people inside a tent and they are looking at something.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:49",
        "processing_time": 2.82,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7305,
          "frame_range": [
            7301,
            7305
          ],
          "description": "a man and two boys sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.08
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7291,
            7295
          ],
          "representative_frame": 7291,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9193848371505737,
              "bbox": [
                310.732421875,
                0.7182453274726868,
                640.0,
                350.2632141113281
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8317773938179016,
              "bbox": [
                218.5258026123047,
                84.10189819335938,
                400.84912109375,
                288.5741271972656
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9130707383155823,
              "bbox": [
                26.30730438232422,
                3.7381558418273926,
                128.305908203125,
                309.3319091796875
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.13352926075458527,
              "bbox": [
                0.0,
                247.55250549316406,
                92.02222442626953,
                346.7287902832031
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7066324949264526,
              "bbox": [
                88.82273864746094,
                279.968017578125,
                123.04431915283203,
                318.4915466308594
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            495,
            440,
            506
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7296,
            7300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7301,
            7305
          ],
          "representative_frame": 7301,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8786625266075134,
              "bbox": [
                338.0544128417969,
                0.8383297920227051,
                640.0,
                351.1611022949219
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8444907069206238,
              "bbox": [
                226.14930725097656,
                83.864501953125,
                419.2273864746094,
                296.05010986328125
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.889946460723877,
              "bbox": [
                46.30126190185547,
                14.798380851745605,
                141.327880859375,
                290.04571533203125
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.2506255805492401,
              "bbox": [
                0.0,
                247.6885986328125,
                97.04103088378906,
                354.86962890625
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7589966058731079,
              "bbox": [
                88.88011169433594,
                279.8883972167969,
                122.8860855102539,
                317.9775085449219
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2921571731567383,
              "bbox": [
                0.9260995388031006,
                82.74994659423828,
                52.801414489746094,
                253.4814910888672
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            495,
            440,
            506,
            471
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            7306,
            7310
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7311,
            7315
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8582961559295654,
              "bbox": [
                349.8944091796875,
                0.526900053024292,
                640.0,
                351.7326354980469
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8568300604820251,
              "bbox": [
                230.2433624267578,
                84.13726806640625,
                429.15545654296875,
                298.56854248046875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9007025957107544,
              "bbox": [
                56.37685775756836,
                24.848003387451172,
                149.44960021972656,
                282.631591796875
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.19629274308681488,
              "bbox": [
                0.0,
                247.8638153076172,
                98.6880111694336,
                357.6977844238281
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.7130752801895142,
              "bbox": [
                88.82501220703125,
                279.76593017578125,
                122.97042083740234,
                317.83477783203125
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.26291364431381226,
              "bbox": [
                1.0090529918670654,
                82.72946166992188,
                53.03227615356445,
                252.79312133789062
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            495,
            440,
            506,
            471
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            7316,
            7320
          ],
          "representative_frame": 7316,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 60
    },
    {
      "second": 244,
      "time_range": [
        244,
        244.999
      ],
      "frame_range": [
        7321,
        7350
      ],
      "unified_description": "1-second video with the following details: A man is in a tent and is handing a boy some type of canister or tool. They are surrounded by several backpacks and other items that indicate they might be preparing for an outdoor adventure or are involved in a survival situation. The camera capturing this scene may have been mounted on a helmet, body-mounted, or placed on the ground.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:52",
        "processing_time": 3.65,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7335,
          "frame_range": [
            7331,
            7335
          ],
          "description": "a man in a tent with a backpack and a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.17
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7321,
            7325
          ],
          "representative_frame": 7321,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8609594702720642,
              "bbox": [
                331.9089660644531,
                0.16192199289798737,
                640.0,
                353.67791748046875
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8567918539047241,
              "bbox": [
                230.98463439941406,
                84.00471496582031,
                434.0008544921875,
                299.1820068359375
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.906947135925293,
              "bbox": [
                60.60603332519531,
                30.845338821411133,
                154.60302734375,
                280.3515625
              ]
            },
            {
              "track_id": 440,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.15459325909614563,
              "bbox": [
                0.0,
                247.92910766601562,
                99.0739974975586,
                358.46881103515625
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.72216796875,
              "bbox": [
                88.12076568603516,
                279.1524658203125,
                123.52146911621094,
                318.7394104003906
              ]
            },
            {
              "track_id": 471,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.35776984691619873,
              "bbox": [
                0.9034574031829834,
                82.68433380126953,
                53.207069396972656,
                252.80799865722656
              ]
            }
          ],
          "unique_tracks": [
            402,
            502,
            495,
            440,
            506,
            471
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7326,
            7330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7331,
            7335
          ],
          "representative_frame": 7331,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7319095730781555,
              "bbox": [
                308.320556640625,
                0.4036094844341278,
                636.7963256835938,
                353.9518737792969
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8968572616577148,
              "bbox": [
                60.62342834472656,
                31.166624069213867,
                156.25999450683594,
                279.7083740234375
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.46422335505485535,
              "bbox": [
                88.36669158935547,
                279.1760559082031,
                123.09774017333984,
                317.9517822265625
              ]
            },
            {
              "track_id": 471,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.11442117393016815,
              "bbox": [
                2.2588131427764893,
                83.1283950805664,
                55.51546096801758,
                253.67095947265625
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            471
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            7336,
            7340
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7341,
            7345
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7349086999893188,
              "bbox": [
                300.15484619140625,
                0.3479152023792267,
                631.2009887695312,
                354.0530090332031
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8963592052459717,
              "bbox": [
                59.758209228515625,
                31.132173538208008,
                157.23854064941406,
                279.8603210449219
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.48222285509109497,
              "bbox": [
                88.43708038330078,
                279.18017578125,
                122.96829223632812,
                317.67510986328125
              ]
            },
            {
              "track_id": 471,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.14205315709114075,
              "bbox": [
                2.075369119644165,
                83.4226303100586,
                55.88011932373047,
                254.1944122314453
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            471
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            7346,
            7350
          ],
          "representative_frame": 7346,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 61
    },
    {
      "second": 245,
      "time_range": [
        245,
        245.999
      ],
      "frame_range": [
        7351,
        7380
      ],
      "unified_description": "0:54 to 0:62, Man wearing a hat in the tent",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:53",
        "processing_time": 3.79,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7365,
          "frame_range": [
            7361,
            7365
          ],
          "description": "a man in a tent with a backpack and a woman",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.88
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7351,
            7355
          ],
          "representative_frame": 7351,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.706386387348175,
              "bbox": [
                297.733642578125,
                0.3588479459285736,
                630.6798095703125,
                354.109375
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8947905898094177,
              "bbox": [
                57.71800231933594,
                30.78813934326172,
                157.25717163085938,
                279.7484130859375
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.44227346777915955,
              "bbox": [
                88.47466278076172,
                279.1546325683594,
                122.912109375,
                317.4754333496094
              ]
            },
            {
              "track_id": 471,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.13682730495929718,
              "bbox": [
                0.4316537380218506,
                83.5962142944336,
                54.00292205810547,
                254.21864318847656
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            471
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            7356,
            7360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7361,
            7365
          ],
          "representative_frame": 7361,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.856946587562561,
              "bbox": [
                381.06683349609375,
                0.5175322890281677,
                640.0,
                340.24102783203125
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8902748823165894,
              "bbox": [
                59.645511627197266,
                56.45637512207031,
                154.73825073242188,
                286.7790832519531
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2199341356754303,
              "bbox": [
                88.83513641357422,
                278.50994873046875,
                123.29304504394531,
                316.9892272949219
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5043247938156128,
              "bbox": [
                270.2518310546875,
                339.8638000488281,
                310.8144836425781,
                359.5981750488281
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.49948179721832275,
              "bbox": [
                248.7771759033203,
                83.75129699707031,
                461.42449951171875,
                298.4681396484375
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            499,
            502
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            7366,
            7370
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7371,
            7375
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6340979337692261,
              "bbox": [
                418.3433837890625,
                0.7849204540252686,
                640.0,
                335.4190368652344
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8639644384384155,
              "bbox": [
                59.23054504394531,
                57.8796272277832,
                156.32737731933594,
                288.3500061035156
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5077927708625793,
              "bbox": [
                89.09957885742188,
                279.0702209472656,
                122.85208129882812,
                316.6365661621094
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4092625081539154,
              "bbox": [
                245.39083862304688,
                234.36251831054688,
                289.0946960449219,
                320.24176025390625
              ]
            },
            {
              "track_id": 529,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3465447723865509,
              "bbox": [
                214.51626586914062,
                81.91712951660156,
                341.1351623535156,
                260.203857421875
              ]
            },
            {
              "track_id": 530,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.380859911441803,
              "bbox": [
                176.012451171875,
                336.6335754394531,
                223.24722290039062,
                359.71978759765625
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3540850877761841,
              "bbox": [
                220.22280883789062,
                292.6589050292969,
                298.830322265625,
                336.625244140625
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5250748991966248,
              "bbox": [
                266.74053955078125,
                340.1445617675781,
                314.1151123046875,
                359.6671142578125
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3772861063480377,
              "bbox": [
                247.43508911132812,
                83.57500457763672,
                467.9491271972656,
                297.54840087890625
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3572643995285034,
              "bbox": [
                232.6959228515625,
                181.08419799804688,
                308.1200866699219,
                234.9254608154297
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            529,
            530,
            532,
            499,
            502,
            507
          ],
          "total_detections": 10
        },
        {
          "group_index": 5,
          "frame_range": [
            7376,
            7380
          ],
          "representative_frame": 7376,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 61
    },
    {
      "second": 246,
      "time_range": [
        246,
        246.999
      ],
      "frame_range": [
        7381,
        7410
      ],
      "unified_description": "3 people in a tent eating snacks while holding items such as bottles and bags.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:54",
        "processing_time": 3.81,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7395,
          "frame_range": [
            7391,
            7395
          ],
          "description": "a man and two boys sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.66
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7381,
            7385
          ],
          "representative_frame": 7381,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8566742539405823,
              "bbox": [
                431.1439208984375,
                0.6363078951835632,
                640.0,
                343.1882629394531
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8996645212173462,
              "bbox": [
                56.42137145996094,
                51.49993133544922,
                158.0376434326172,
                289.94061279296875
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.539696455001831,
              "bbox": [
                89.30322265625,
                279.2105712890625,
                122.89724731445312,
                316.550048828125
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4298855662345886,
              "bbox": [
                245.5125732421875,
                234.54412841796875,
                289.0923767089844,
                320.1787414550781
              ]
            },
            {
              "track_id": 529,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.23203948140144348,
              "bbox": [
                208.96238708496094,
                82.01985168457031,
                347.9358825683594,
                277.9246520996094
              ]
            },
            {
              "track_id": 530,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3911176919937134,
              "bbox": [
                175.90113830566406,
                336.4924621582031,
                223.35223388671875,
                359.68377685546875
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3749064803123474,
              "bbox": [
                219.96922302246094,
                292.72552490234375,
                298.4577331542969,
                336.6261901855469
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5205863118171692,
              "bbox": [
                264.0340270996094,
                340.21026611328125,
                316.5553894042969,
                359.697998046875
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6234648823738098,
              "bbox": [
                243.62294006347656,
                83.55206298828125,
                471.0846252441406,
                297.0150451660156
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.18790559470653534,
              "bbox": [
                233.59030151367188,
                180.68182373046875,
                308.69354248046875,
                234.15992736816406
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            529,
            530,
            532,
            499,
            502,
            507
          ],
          "total_detections": 10
        },
        {
          "group_index": 1,
          "frame_range": [
            7386,
            7390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7391,
            7395
          ],
          "representative_frame": 7391,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8910920023918152,
              "bbox": [
                435.8809814453125,
                0.616276741027832,
                640.0,
                346.5589904785156
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.89995276927948,
              "bbox": [
                54.517311096191406,
                49.695716857910156,
                158.40750122070312,
                290.9925842285156
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5219413638114929,
              "bbox": [
                89.32554626464844,
                279.29840087890625,
                122.90028381347656,
                316.5680236816406
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5156735181808472,
              "bbox": [
                245.40960693359375,
                234.19833374023438,
                289.14599609375,
                320.1617126464844
              ]
            },
            {
              "track_id": 529,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5288711786270142,
              "bbox": [
                225.90220642089844,
                82.05241394042969,
                328.6763916015625,
                224.78248596191406
              ]
            },
            {
              "track_id": 530,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.37487828731536865,
              "bbox": [
                176.03997802734375,
                336.5218200683594,
                223.54957580566406,
                359.740234375
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.39281895756721497,
              "bbox": [
                220.0202178955078,
                292.868896484375,
                298.134033203125,
                336.5557556152344
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5380290150642395,
              "bbox": [
                262.0084228515625,
                340.2052001953125,
                318.6131896972656,
                359.7113952636719
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.16094209253787994,
              "bbox": [
                237.085693359375,
                83.57380676269531,
                469.7339172363281,
                297.0433044433594
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3133641481399536,
              "bbox": [
                233.05113220214844,
                181.0418701171875,
                308.28863525390625,
                234.59783935546875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            529,
            530,
            532,
            499,
            502,
            507
          ],
          "total_detections": 10
        },
        {
          "group_index": 3,
          "frame_range": [
            7396,
            7400
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7401,
            7405
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9239234924316406,
              "bbox": [
                447.9897766113281,
                0.47418296337127686,
                640.0,
                329.671875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.886395275592804,
              "bbox": [
                53.357383728027344,
                49.413780212402344,
                158.49786376953125,
                291.2700500488281
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4787009060382843,
              "bbox": [
                89.27383422851562,
                279.22332763671875,
                122.95387268066406,
                316.5834045410156
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4507104158401489,
              "bbox": [
                245.47482299804688,
                234.55592346191406,
                289.0360412597656,
                320.1780090332031
              ]
            },
            {
              "track_id": 529,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.39828577637672424,
              "bbox": [
                231.81521606445312,
                81.80290985107422,
                321.3904113769531,
                203.9014434814453
              ]
            },
            {
              "track_id": 530,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.37318846583366394,
              "bbox": [
                175.92262268066406,
                336.45660400390625,
                223.53656005859375,
                359.7338562011719
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3654443025588989,
              "bbox": [
                220.17355346679688,
                293.1042785644531,
                298.0208435058594,
                336.6296691894531
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5229966044425964,
              "bbox": [
                260.5281982421875,
                340.162353515625,
                320.39508056640625,
                359.6889343261719
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.29385003447532654,
              "bbox": [
                233.25799560546875,
                83.4326171875,
                471.50653076171875,
                297.34295654296875
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.197768896818161,
              "bbox": [
                232.2860870361328,
                180.87196350097656,
                307.819091796875,
                234.7379150390625
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            529,
            530,
            532,
            499,
            502,
            507
          ],
          "total_detections": 10
        },
        {
          "group_index": 5,
          "frame_range": [
            7406,
            7410
          ],
          "representative_frame": 7406,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 61
    },
    {
      "second": 247,
      "time_range": [
        247,
        247.999
      ],
      "frame_range": [
        7411,
        7440
      ],
      "unified_description": "3 boys siting inside a tent while holding their bowls.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:56",
        "processing_time": 2.73,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7425,
          "frame_range": [
            7421,
            7425
          ],
          "description": "a group of people sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.04
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7411,
            7415
          ],
          "representative_frame": 7411,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7192034721374512,
              "bbox": [
                454.55694580078125,
                0.14682266116142273,
                640.0,
                323.9666748046875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8973478674888611,
              "bbox": [
                51.38408660888672,
                44.7963752746582,
                158.8118438720703,
                291.7001953125
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3861158490180969,
              "bbox": [
                89.28279876708984,
                279.2680358886719,
                122.93016052246094,
                316.55572509765625
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3381742238998413,
              "bbox": [
                245.42486572265625,
                234.49481201171875,
                289.0135803222656,
                320.1983642578125
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.32014670968055725,
              "bbox": [
                175.8420867919922,
                336.61572265625,
                223.0601806640625,
                359.68487548828125
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3784950077533722,
              "bbox": [
                220.14390563964844,
                293.0392150878906,
                298.06884765625,
                336.5936279296875
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5344905853271484,
              "bbox": [
                259.1763000488281,
                340.08123779296875,
                321.837646484375,
                359.677490234375
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.15052849054336548,
              "bbox": [
                233.0155029296875,
                83.38617706298828,
                475.4044189453125,
                296.715087890625
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3006557524204254,
              "bbox": [
                233.37513732910156,
                181.20872497558594,
                307.75860595703125,
                234.09243774414062
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3748861253261566,
              "bbox": [
                208.44100952148438,
                81.40258026123047,
                344.91461181640625,
                261.9798889160156
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            530,
            532,
            499,
            502,
            507,
            537
          ],
          "total_detections": 10
        },
        {
          "group_index": 1,
          "frame_range": [
            7416,
            7420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7421,
            7425
          ],
          "representative_frame": 7421,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.91773921251297,
              "bbox": [
                380.5546569824219,
                0.57460618019104,
                630.2977294921875,
                339.4525451660156
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8859418034553528,
              "bbox": [
                45.01064682006836,
                40.047733306884766,
                154.86354064941406,
                291.56390380859375
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4377598762512207,
              "bbox": [
                89.05353546142578,
                278.97955322265625,
                123.12116241455078,
                316.7981262207031
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3859987258911133,
              "bbox": [
                245.557861328125,
                234.64256286621094,
                289.050048828125,
                320.1625671386719
              ]
            },
            {
              "track_id": 530,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.31092318892478943,
              "bbox": [
                176.18881225585938,
                336.70440673828125,
                223.0763397216797,
                359.58966064453125
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.40183544158935547,
              "bbox": [
                219.9119873046875,
                292.9102783203125,
                298.085693359375,
                336.5921630859375
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5817398428916931,
              "bbox": [
                257.8451232910156,
                339.9554138183594,
                322.9630432128906,
                359.65789794921875
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.24872516095638275,
              "bbox": [
                233.67156982421875,
                181.14002990722656,
                308.2079162597656,
                233.90626525878906
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.276500940322876,
              "bbox": [
                200.8603973388672,
                82.04103088378906,
                338.29620361328125,
                264.5858154296875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            530,
            532,
            499,
            507,
            537
          ],
          "total_detections": 9
        },
        {
          "group_index": 3,
          "frame_range": [
            7426,
            7430
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7431,
            7435
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7643857002258301,
              "bbox": [
                324.1133728027344,
                0.5090335011482239,
                593.3572998046875,
                346.7439880371094
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8963658213615417,
              "bbox": [
                43.02727508544922,
                39.21781539916992,
                153.43994140625,
                291.28167724609375
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.42232152819633484,
              "bbox": [
                89.01738739013672,
                278.929443359375,
                123.17332458496094,
                316.8980407714844
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.40897229313850403,
              "bbox": [
                245.74330139160156,
                235.31655883789062,
                288.8596496582031,
                320.0849609375
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.28715914487838745,
              "bbox": [
                176.0329132080078,
                336.8467102050781,
                222.7957000732422,
                359.62884521484375
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5164082646369934,
              "bbox": [
                219.73806762695312,
                292.8006286621094,
                298.2079772949219,
                336.6381530761719
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5530390739440918,
              "bbox": [
                256.8955383300781,
                339.99078369140625,
                323.4248962402344,
                359.56146240234375
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            530,
            532,
            499
          ],
          "total_detections": 7
        },
        {
          "group_index": 5,
          "frame_range": [
            7436,
            7440
          ],
          "representative_frame": 7436,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 61
    },
    {
      "second": 248,
      "time_range": [
        248,
        248.999
      ],
      "frame_range": [
        7441,
        7470
      ],
      "unified_description": "\nA scene of a man and a young boy with a frying pan in their hands, standing next to each other. The man is showing the child how to use the pan. They are located inside a tent, surrounded by other people, some of which are seated on chairs. Various items such as bowls can be seen placed around them.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:31:58",
        "processing_time": 3.59,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7455,
          "frame_range": [
            7451,
            7455
          ],
          "description": "a man and a boy are in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.04
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7441,
            7445
          ],
          "representative_frame": 7441,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7091614603996277,
              "bbox": [
                296.9579772949219,
                0.8945208787918091,
                582.228271484375,
                350.8666076660156
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8975578546524048,
              "bbox": [
                42.602867126464844,
                38.81105422973633,
                153.30072021484375,
                291.0474548339844
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.317211389541626,
              "bbox": [
                89.15061950683594,
                279.2083435058594,
                123.04072570800781,
                316.8491516113281
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.22869840264320374,
              "bbox": [
                245.91122436523438,
                236.20895385742188,
                288.6017150878906,
                320.055419921875
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.29966849088668823,
              "bbox": [
                175.80514526367188,
                336.70343017578125,
                222.9066619873047,
                359.62823486328125
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5193011164665222,
              "bbox": [
                219.84188842773438,
                292.89898681640625,
                297.9971008300781,
                336.5426940917969
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.522904098033905,
              "bbox": [
                255.67112731933594,
                339.6150817871094,
                324.7836608886719,
                359.5518493652344
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            530,
            532,
            499
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            7446,
            7450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7451,
            7455
          ],
          "representative_frame": 7451,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.29438334703445435,
              "bbox": [
                294.1935119628906,
                0.31968367099761963,
                588.5012817382812,
                349.63299560546875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9012776017189026,
              "bbox": [
                43.000816345214844,
                37.39511489868164,
                153.67759704589844,
                289.6709899902344
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2610333561897278,
              "bbox": [
                89.16827392578125,
                279.28460693359375,
                123.012451171875,
                316.85772705078125
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.18603180348873138,
              "bbox": [
                245.91749572753906,
                236.4400634765625,
                288.5334777832031,
                320.09039306640625
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.40517377853393555,
              "bbox": [
                175.7425994873047,
                336.6346740722656,
                223.1046600341797,
                359.6441650390625
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5286619663238525,
              "bbox": [
                220.1917266845703,
                292.95361328125,
                298.14105224609375,
                336.4433898925781
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5240322351455688,
              "bbox": [
                254.79603576660156,
                339.4417724609375,
                325.6116027832031,
                359.5428466796875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            528,
            530,
            532,
            499
          ],
          "total_detections": 7
        },
        {
          "group_index": 3,
          "frame_range": [
            7456,
            7460
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7461,
            7465
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9324536919593811,
              "bbox": [
                296.306640625,
                0.09884592145681381,
                598.994384765625,
                351.2931823730469
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9004548788070679,
              "bbox": [
                40.92997360229492,
                41.974708557128906,
                150.63453674316406,
                290.4320983886719
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.39956316351890564,
              "bbox": [
                89.17095947265625,
                279.45672607421875,
                122.93843841552734,
                316.8438415527344
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2774089276790619,
              "bbox": [
                175.67860412597656,
                336.61627197265625,
                222.96441650390625,
                359.52642822265625
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5035368800163269,
              "bbox": [
                220.08184814453125,
                292.6575622558594,
                298.4903259277344,
                336.4018249511719
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5825037956237793,
              "bbox": [
                254.32456970214844,
                339.5238037109375,
                326.0445556640625,
                359.5547180175781
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3867867588996887,
              "bbox": [
                206.61048889160156,
                82.61026763916016,
                345.4497985839844,
                267.724853515625
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            530,
            532,
            499,
            537
          ],
          "total_detections": 7
        },
        {
          "group_index": 5,
          "frame_range": [
            7466,
            7470
          ],
          "representative_frame": 7466,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 62
    },
    {
      "second": 249,
      "time_range": [
        249,
        249.999
      ],
      "frame_range": [
        7471,
        7500
      ],
      "unified_description": "3 people are in a tent. A man is showing two young boys how to tie knots. They have several items around them including pots, bowls, cups, and an assortment of miscellaneous objects. The camera capturing this moment is either a body-mounted or backpack-mounted camera, providing an immersive view of the activity.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:00",
        "processing_time": 4.82,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7485,
          "frame_range": [
            7481,
            7485
          ],
          "description": "a man and two children sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.66
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7471,
            7475
          ],
          "representative_frame": 7471,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8428304195404053,
              "bbox": [
                325.5948791503906,
                0.35753774642944336,
                627.3587646484375,
                352.0533752441406
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8896459937095642,
              "bbox": [
                42.135658264160156,
                45.718631744384766,
                151.5089569091797,
                290.3043518066406
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4610774517059326,
              "bbox": [
                89.05048370361328,
                279.5572204589844,
                122.85274505615234,
                316.8795166015625
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.26706117391586304,
              "bbox": [
                175.27828979492188,
                336.7922668457031,
                222.72015380859375,
                359.6630859375
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4548344314098358,
              "bbox": [
                219.7155303955078,
                292.4430847167969,
                298.5483703613281,
                336.46002197265625
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5715601444244385,
              "bbox": [
                253.99014282226562,
                339.6903991699219,
                326.3545227050781,
                359.6011962890625
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5032652020454407,
              "bbox": [
                208.64651489257812,
                82.74222564697266,
                345.2084045410156,
                265.1434326171875
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.45444729924201965,
              "bbox": [
                233.03646850585938,
                181.22113037109375,
                307.8511047363281,
                234.3529510498047
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4390975832939148,
              "bbox": [
                245.76730346679688,
                235.34620666503906,
                288.9819030761719,
                320.1312255859375
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            530,
            532,
            499,
            537,
            507,
            528
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            7476,
            7480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7481,
            7485
          ],
          "representative_frame": 7481,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8623733520507812,
              "bbox": [
                334.48846435546875,
                0.6221952438354492,
                636.5707397460938,
                353.43572998046875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.891788899898529,
              "bbox": [
                46.165077209472656,
                60.29927062988281,
                151.81051635742188,
                291.626708984375
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6067025661468506,
              "bbox": [
                88.75196838378906,
                279.8044128417969,
                122.51285552978516,
                317.01422119140625
              ]
            },
            {
              "track_id": 530,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.32766491174697876,
              "bbox": [
                174.87527465820312,
                337.0235900878906,
                222.1551513671875,
                359.7832336425781
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.41282275319099426,
              "bbox": [
                220.00228881835938,
                292.9137878417969,
                298.468017578125,
                336.69293212890625
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6499586701393127,
              "bbox": [
                253.56942749023438,
                339.73858642578125,
                326.72894287109375,
                359.6353759765625
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46014755964279175,
              "bbox": [
                209.2735137939453,
                82.52501678466797,
                344.06591796875,
                263.09088134765625
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.43226420879364014,
              "bbox": [
                233.399169921875,
                181.4464874267578,
                307.9456787109375,
                234.4215850830078
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4100729823112488,
              "bbox": [
                245.5308380126953,
                234.79861450195312,
                289.034912109375,
                320.2548522949219
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5480766296386719,
              "bbox": [
                206.14662170410156,
                83.16421508789062,
                445.4901428222656,
                296.5021057128906
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            530,
            532,
            499,
            537,
            507,
            528,
            502
          ],
          "total_detections": 10
        },
        {
          "group_index": 3,
          "frame_range": [
            7486,
            7490
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7491,
            7495
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8271175622940063,
              "bbox": [
                335.0554504394531,
                0.25180482864379883,
                637.8473510742188,
                353.8123474121094
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8721750974655151,
              "bbox": [
                47.260887145996094,
                68.7909927368164,
                151.89036560058594,
                292.5832214355469
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.45985087752342224,
              "bbox": [
                87.93048858642578,
                278.4596252441406,
                123.19546508789062,
                317.4947204589844
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.36121734976768494,
              "bbox": [
                174.66668701171875,
                337.010498046875,
                221.96975708007812,
                359.7377624511719
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.42717525362968445,
              "bbox": [
                220.0568084716797,
                293.10223388671875,
                298.294189453125,
                336.7180480957031
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6796278357505798,
              "bbox": [
                253.07241821289062,
                339.72906494140625,
                326.92852783203125,
                359.6238708496094
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.16921475529670715,
              "bbox": [
                209.3312225341797,
                82.14141845703125,
                342.6912536621094,
                261.4120788574219
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4504370391368866,
              "bbox": [
                233.38597106933594,
                181.27626037597656,
                308.1451110839844,
                234.38946533203125
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4534894526004791,
              "bbox": [
                245.50607299804688,
                234.6524658203125,
                289.07659912109375,
                320.2989196777344
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3737312853336334,
              "bbox": [
                206.14064025878906,
                84.0201644897461,
                442.2666931152344,
                296.19305419921875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            530,
            532,
            499,
            537,
            507,
            528,
            502
          ],
          "total_detections": 10
        },
        {
          "group_index": 5,
          "frame_range": [
            7496,
            7500
          ],
          "representative_frame": 7496,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 62
    },
    {
      "second": 250,
      "time_range": [
        250,
        250.999
      ],
      "frame_range": [
        7501,
        7530
      ],
      "unified_description": "1-second video showing a man interacting with children and handling objects in an outdoor setting.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:01",
        "processing_time": 4.39,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7515,
          "frame_range": [
            7511,
            7515
          ],
          "description": "a man is putting a bucket in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.76
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7501,
            7505
          ],
          "representative_frame": 7501,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5554124712944031,
              "bbox": [
                286.896484375,
                0.6675883531570435,
                602.6030883789062,
                355.2637023925781
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8529826998710632,
              "bbox": [
                45.263328552246094,
                71.37537384033203,
                154.13137817382812,
                300.655517578125
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.1053764745593071,
              "bbox": [
                91.576171875,
                282.9543151855469,
                122.9514389038086,
                317.1978759765625
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3945203125476837,
              "bbox": [
                174.7501983642578,
                337.0666198730469,
                221.88568115234375,
                359.69183349609375
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5313340425491333,
              "bbox": [
                219.86712646484375,
                293.2644348144531,
                297.8927917480469,
                336.7269592285156
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6551806926727295,
              "bbox": [
                252.68724060058594,
                339.7489318847656,
                326.9201965332031,
                359.577880859375
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.18880733847618103,
              "bbox": [
                194.12197875976562,
                82.13394165039062,
                335.89208984375,
                278.40484619140625
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.24854987859725952,
              "bbox": [
                232.3677520751953,
                181.73141479492188,
                306.89080810546875,
                234.64645385742188
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4028366208076477,
              "bbox": [
                245.61590576171875,
                234.88720703125,
                289.016357421875,
                320.25140380859375
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            530,
            532,
            499,
            537,
            507,
            528
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            7506,
            7510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7511,
            7515
          ],
          "representative_frame": 7511,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8410707712173462,
              "bbox": [
                287.6759033203125,
                1.0496501922607422,
                608.3494262695312,
                354.7972106933594
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.851408839225769,
              "bbox": [
                45.503231048583984,
                75.64421081542969,
                154.04248046875,
                299.96502685546875
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.10995490849018097,
              "bbox": [
                94.39768981933594,
                286.5942687988281,
                122.8493881225586,
                317.208740234375
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.41037848591804504,
              "bbox": [
                174.893798828125,
                336.97894287109375,
                222.15826416015625,
                359.6513671875
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.49206656217575073,
              "bbox": [
                219.70050048828125,
                293.20587158203125,
                297.89031982421875,
                336.7583312988281
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6379777789115906,
              "bbox": [
                252.4528350830078,
                339.8043518066406,
                327.0829772949219,
                359.5794677734375
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.11595466732978821,
              "bbox": [
                196.7446746826172,
                82.24998474121094,
                332.5185852050781,
                273.235595703125
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.10418377071619034,
              "bbox": [
                231.8850555419922,
                182.14515686035156,
                304.97100830078125,
                234.34518432617188
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.49234306812286377,
              "bbox": [
                245.5955047607422,
                234.84576416015625,
                288.9594421386719,
                320.2037048339844
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            530,
            532,
            499,
            537,
            507,
            528
          ],
          "total_detections": 9
        },
        {
          "group_index": 3,
          "frame_range": [
            7516,
            7520
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7521,
            7525
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.742397665977478,
              "bbox": [
                270.488525390625,
                0.3769533634185791,
                600.7731323242188,
                355.1896057128906
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8669044375419617,
              "bbox": [
                46.04319381713867,
                80.37248229980469,
                153.49832153320312,
                297.86785888671875
              ]
            },
            {
              "track_id": 506,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.17549128830432892,
              "bbox": [
                95.20832061767578,
                288.34857177734375,
                122.556884765625,
                317.2244873046875
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.40518781542778015,
              "bbox": [
                174.9102020263672,
                336.8310546875,
                222.45571899414062,
                359.6422119140625
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5449492335319519,
              "bbox": [
                219.77334594726562,
                293.1002502441406,
                298.13037109375,
                336.74969482421875
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6548979878425598,
              "bbox": [
                252.04808044433594,
                339.72918701171875,
                327.5101318359375,
                359.6041564941406
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.12045890837907791,
              "bbox": [
                191.41195678710938,
                81.81875610351562,
                326.7498474121094,
                278.16058349609375
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3485892415046692,
              "bbox": [
                245.7718048095703,
                235.27798461914062,
                288.8538818359375,
                320.06524658203125
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46439221501350403,
              "bbox": [
                206.55174255371094,
                82.74532318115234,
                308.4295959472656,
                200.2280731201172
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            506,
            530,
            532,
            499,
            537,
            528,
            549
          ],
          "total_detections": 9
        },
        {
          "group_index": 5,
          "frame_range": [
            7526,
            7530
          ],
          "representative_frame": 7526,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 62
    },
    {
      "second": 251,
      "time_range": [
        251,
        251.999
      ],
      "frame_range": [
        7531,
        7560
      ],
      "unified_description": "1-second video showing a man handing a blue object to one of three kids in a tent.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:02",
        "processing_time": 3.19,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7545,
          "frame_range": [
            7541,
            7545
          ],
          "description": "a man is putting a bucket in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.09
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7531,
            7535
          ],
          "representative_frame": 7531,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7407189011573792,
              "bbox": [
                277.7456970214844,
                0.6624779105186462,
                611.7347412109375,
                354.8701477050781
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8555931448936462,
              "bbox": [
                43.62089920043945,
                74.61241149902344,
                156.57650756835938,
                301.10821533203125
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.32898402214050293,
              "bbox": [
                175.04254150390625,
                336.8287048339844,
                222.57025146484375,
                359.6128234863281
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5105057954788208,
              "bbox": [
                219.40805053710938,
                292.6767272949219,
                298.4927673339844,
                336.79339599609375
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.641162633895874,
              "bbox": [
                251.56675720214844,
                339.7236633300781,
                327.5769958496094,
                359.64849853515625
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2342071533203125,
              "bbox": [
                194.10516357421875,
                81.65760040283203,
                325.1507568359375,
                275.9242858886719
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.40960612893104553,
              "bbox": [
                245.63319396972656,
                235.1884002685547,
                288.7447509765625,
                320.09161376953125
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5403099656105042,
              "bbox": [
                207.85044860839844,
                82.23989868164062,
                311.6966552734375,
                202.09295654296875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            530,
            532,
            499,
            537,
            528,
            549
          ],
          "total_detections": 8
        },
        {
          "group_index": 1,
          "frame_range": [
            7536,
            7540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7541,
            7545
          ],
          "representative_frame": 7541,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8848007917404175,
              "bbox": [
                262.4577941894531,
                0.6152881979942322,
                604.8724365234375,
                355.1905212402344
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8904051184654236,
              "bbox": [
                45.35576248168945,
                73.75244140625,
                156.88954162597656,
                294.7408752441406
              ]
            },
            {
              "track_id": 530,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3172752261161804,
              "bbox": [
                174.94973754882812,
                337.0137023925781,
                222.23553466796875,
                359.6370849609375
              ]
            },
            {
              "track_id": 532,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5298157930374146,
              "bbox": [
                219.34567260742188,
                292.60626220703125,
                298.6577453613281,
                336.89990234375
              ]
            },
            {
              "track_id": 499,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6656977534294128,
              "bbox": [
                251.31629943847656,
                339.7099914550781,
                327.6957702636719,
                359.6479797363281
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.16516149044036865,
              "bbox": [
                188.35177612304688,
                81.35489654541016,
                319.674072265625,
                283.0660705566406
              ]
            },
            {
              "track_id": 528,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4337952136993408,
              "bbox": [
                245.74855041503906,
                235.36151123046875,
                288.8125305175781,
                320.1558532714844
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.29913419485092163,
              "bbox": [
                202.21823120117188,
                82.42049407958984,
                304.43841552734375,
                201.0555419921875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            530,
            532,
            499,
            537,
            528,
            549
          ],
          "total_detections": 8
        },
        {
          "group_index": 3,
          "frame_range": [
            7546,
            7550
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7551,
            7555
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9536371231079102,
              "bbox": [
                245.20423889160156,
                0.21140311658382416,
                596.6765747070312,
                353.93115234375
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9134361147880554,
              "bbox": [
                4.943719863891602,
                51.560447692871094,
                134.25965881347656,
                313.9759216308594
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2239680141210556,
              "bbox": [
                164.74220275878906,
                72.895263671875,
                319.1589050292969,
                314.3980407714844
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.32662779092788696,
              "bbox": [
                185.16368103027344,
                71.73273468017578,
                295.8480529785156,
                199.23831176757812
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            537,
            549
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            7556,
            7560
          ],
          "representative_frame": 7556,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 62
    },
    {
      "second": 252,
      "time_range": [
        252,
        252.999
      ],
      "frame_range": [
        7561,
        7590
      ],
      "unified_description": "3 people are gathered under a tent. A man is holding a spaghetti sandwich in his hand. The camera captures this interesting moment with the group sitting around the man who seems to be explaining something to them.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:04",
        "processing_time": 3.18,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7575,
          "frame_range": [
            7571,
            7575
          ],
          "description": "a man in a tent with a child",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.99
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7561,
            7565
          ],
          "representative_frame": 7561,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9205979108810425,
              "bbox": [
                238.1060028076172,
                0.9274649620056152,
                597.0634155273438,
                353.56884765625
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9061326384544373,
              "bbox": [
                0.0,
                43.985809326171875,
                125.25765991210938,
                320.3857421875
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.17314651608467102,
              "bbox": [
                151.6046600341797,
                60.54939651489258,
                318.949462890625,
                327.01708984375
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.21190273761749268,
              "bbox": [
                176.13949584960938,
                58.25062942504883,
                297.660400390625,
                197.86444091796875
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4719252288341522,
              "bbox": [
                72.1484146118164,
                321.0682678222656,
                111.67305755615234,
                359.65478515625
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.33771923184394836,
              "bbox": [
                97.77629852294922,
                57.31414031982422,
                306.7970886230469,
                332.87042236328125
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            537,
            549,
            554,
            556
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7566,
            7570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7571,
            7575
          ],
          "representative_frame": 7571,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9309747219085693,
              "bbox": [
                231.40574645996094,
                0.8049759268760681,
                598.9798583984375,
                354.04351806640625
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8953536748886108,
              "bbox": [
                0.0,
                40.15318298339844,
                120.89360809326172,
                322.5387268066406
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4996802508831024,
              "bbox": [
                72.2471694946289,
                321.0747985839844,
                111.70293426513672,
                359.59307861328125
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            554
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            7576,
            7580
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7581,
            7585
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9285020232200623,
              "bbox": [
                228.23585510253906,
                0.3508148789405823,
                603.376953125,
                354.3309326171875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9025625586509705,
              "bbox": [
                0.0,
                38.433815002441406,
                118.49305725097656,
                323.1876220703125
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.43592193722724915,
              "bbox": [
                72.31127166748047,
                321.10687255859375,
                111.7388687133789,
                359.60418701171875
              ]
            },
            {
              "track_id": 558,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3391458988189697,
              "bbox": [
                192.64866638183594,
                300.9081726074219,
                271.6261291503906,
                353.5664367675781
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4916033148765564,
              "bbox": [
                167.4320831298828,
                66.85687255859375,
                302.61236572265625,
                280.3817138671875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            554,
            558,
            537
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7586,
            7590
          ],
          "representative_frame": 7586,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 63
    },
    {
      "second": 253,
      "time_range": [
        253,
        253.999
      ],
      "frame_range": [
        7591,
        7620
      ],
      "unified_description": "1-second video showing a group of people in a tent, with a man cooking food using a pan. There are also bowls, cups, and spoons visible in the scene, indicating that they may be preparing to eat or have just finished eating their meal.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:06",
        "processing_time": 3.88,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7605,
          "frame_range": [
            7601,
            7605
          ],
          "description": "a man is cooking food in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.94
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7591,
            7595
          ],
          "representative_frame": 7591,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9502729773521423,
              "bbox": [
                244.85801696777344,
                0.528377115726471,
                622.1488037109375,
                355.4309997558594
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9049022197723389,
              "bbox": [
                0.0,
                34.12733840942383,
                118.20951843261719,
                323.7422180175781
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.5957215428352356,
              "bbox": [
                72.39653778076172,
                321.1680603027344,
                111.74076843261719,
                359.5765380859375
              ]
            },
            {
              "track_id": 558,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3648374378681183,
              "bbox": [
                192.55386352539062,
                301.00115966796875,
                271.5475769042969,
                353.6704406738281
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5822335481643677,
              "bbox": [
                153.92051696777344,
                67.75614929199219,
                277.5240173339844,
                269.53253173828125
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.46096014976501465,
              "bbox": [
                213.12454223632812,
                149.82415771484375,
                328.1890563964844,
                236.2985076904297
              ]
            },
            {
              "track_id": 528,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7717136740684509,
              "bbox": [
                256.1542053222656,
                236.1510467529297,
                289.3752136230469,
                285.5033264160156
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            554,
            558,
            537,
            507,
            528
          ],
          "total_detections": 7
        },
        {
          "group_index": 1,
          "frame_range": [
            7596,
            7600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7601,
            7605
          ],
          "representative_frame": 7601,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9414275288581848,
              "bbox": [
                254.4295654296875,
                0.5883328318595886,
                632.262939453125,
                355.819580078125
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9153849482536316,
              "bbox": [
                0.0,
                31.7489013671875,
                117.8805923461914,
                324.1448974609375
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6229018568992615,
              "bbox": [
                72.41107940673828,
                321.1953125,
                111.7222900390625,
                359.5550231933594
              ]
            },
            {
              "track_id": 558,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4051643908023834,
              "bbox": [
                192.89047241210938,
                301.09698486328125,
                271.7037353515625,
                353.6291198730469
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7450037598609924,
              "bbox": [
                151.5294952392578,
                68.13690948486328,
                268.10723876953125,
                264.1643371582031
              ]
            },
            {
              "track_id": 560,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.8273548483848572,
              "bbox": [
                312.3805236816406,
                103.99440002441406,
                353.4501037597656,
                176.02227783203125
              ]
            },
            {
              "track_id": 507,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.1303820013999939,
              "bbox": [
                219.96542358398438,
                145.3494873046875,
                338.9901123046875,
                235.1441192626953
              ]
            },
            {
              "track_id": 528,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6860154271125793,
              "bbox": [
                257.351806640625,
                234.44326782226562,
                294.35321044921875,
                279.7515869140625
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            554,
            558,
            537,
            560,
            507,
            528
          ],
          "total_detections": 8
        },
        {
          "group_index": 3,
          "frame_range": [
            7606,
            7610
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7611,
            7615
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9539279937744141,
              "bbox": [
                253.66859436035156,
                0.5207457542419434,
                632.8244018554688,
                355.75201416015625
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9224666357040405,
              "bbox": [
                0.0,
                29.45660400390625,
                117.17037200927734,
                324.28851318359375
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6854422092437744,
              "bbox": [
                72.37290954589844,
                321.18536376953125,
                111.72164154052734,
                359.5697021484375
              ]
            },
            {
              "track_id": 558,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2961985766887665,
              "bbox": [
                192.93594360351562,
                301.0367126464844,
                271.6940002441406,
                353.5141906738281
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7590565085411072,
              "bbox": [
                155.1143035888672,
                68.45442199707031,
                269.3683166503906,
                264.1578369140625
              ]
            },
            {
              "track_id": 560,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.3671760857105255,
              "bbox": [
                313.4065246582031,
                107.51990509033203,
                353.01947021484375,
                177.00518798828125
              ]
            },
            {
              "track_id": 507,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.1316932886838913,
              "bbox": [
                201.8814697265625,
                142.5867919921875,
                344.5787658691406,
                258.3111572265625
              ]
            },
            {
              "track_id": 528,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.23032599687576294,
              "bbox": [
                248.94302368164062,
                235.6732940673828,
                285.9496765136719,
                276.988037109375
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            554,
            558,
            537,
            560,
            507,
            528
          ],
          "total_detections": 8
        },
        {
          "group_index": 5,
          "frame_range": [
            7616,
            7620
          ],
          "representative_frame": 7616,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 63
    },
    {
      "second": 254,
      "time_range": [
        254,
        254.999
      ],
      "frame_range": [
        7621,
        7650
      ],
      "unified_description": "3 people are gathered around a campfire for cooking.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:07",
        "processing_time": 4.11,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7635,
          "frame_range": [
            7631,
            7635
          ],
          "description": "a man is cooking food in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.61
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7621,
            7625
          ],
          "representative_frame": 7621,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9476842284202576,
              "bbox": [
                253.94561767578125,
                0.43059736490249634,
                634.104248046875,
                355.7200012207031
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9101656079292297,
              "bbox": [
                0.0,
                27.90563201904297,
                116.59452819824219,
                324.47235107421875
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.674058198928833,
              "bbox": [
                72.32379150390625,
                321.1689758300781,
                111.70284271240234,
                359.5759582519531
              ]
            },
            {
              "track_id": 558,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.25263965129852295,
              "bbox": [
                192.8848114013672,
                301.0283508300781,
                271.7041931152344,
                353.5293273925781
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7598714232444763,
              "bbox": [
                157.5796661376953,
                68.93334197998047,
                268.9894714355469,
                263.00494384765625
              ]
            },
            {
              "track_id": 560,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.6327352523803711,
              "bbox": [
                312.318359375,
                106.10486602783203,
                352.1416015625,
                175.99502563476562
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            554,
            558,
            537,
            560
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7626,
            7630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7631,
            7635
          ],
          "representative_frame": 7631,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9385333061218262,
              "bbox": [
                254.45294189453125,
                0.36114391684532166,
                635.2061767578125,
                355.4956359863281
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9163208603858948,
              "bbox": [
                0.0,
                27.150287628173828,
                115.69025421142578,
                324.2547912597656
              ]
            },
            {
              "track_id": 554,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.6588802337646484,
              "bbox": [
                72.4929428100586,
                321.2551574707031,
                111.7790756225586,
                359.566162109375
              ]
            },
            {
              "track_id": 558,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2799589931964874,
              "bbox": [
                192.86483764648438,
                301.123291015625,
                271.6437683105469,
                353.5771484375
              ]
            },
            {
              "track_id": 537,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7406448125839233,
              "bbox": [
                156.26307678222656,
                68.24636840820312,
                265.244140625,
                262.54754638671875
              ]
            },
            {
              "track_id": 560,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.4579509496688843,
              "bbox": [
                308.4655456542969,
                99.89262390136719,
                349.5890808105469,
                171.99867248535156
              ]
            },
            {
              "track_id": 528,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6843342781066895,
              "bbox": [
                253.41091918945312,
                234.14707946777344,
                296.8857116699219,
                276.9252624511719
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            554,
            558,
            537,
            560,
            528
          ],
          "total_detections": 7
        },
        {
          "group_index": 3,
          "frame_range": [
            7636,
            7640
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7641,
            7645
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.44623568654060364,
              "bbox": [
                255.2880859375,
                42.50497817993164,
                581.1650390625,
                349.45037841796875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6971521377563477,
              "bbox": [
                5.610039234161377,
                100.4989013671875,
                100.8593978881836,
                312.71405029296875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            7646,
            7650
          ],
          "representative_frame": 7646,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 63
    },
    {
      "second": 255,
      "time_range": [
        255,
        255.999
      ],
      "frame_range": [
        7651,
        7680
      ],
      "unified_description": "30 second video showing a man eating outdoors while inside a tent.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:08",
        "processing_time": 3.06,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7665,
          "frame_range": [
            7661,
            7665
          ],
          "description": "a man in a tent with a baby",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.31
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7651,
            7655
          ],
          "representative_frame": 7651,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.376690536737442,
              "bbox": [
                253.15223693847656,
                63.48888397216797,
                551.1636962890625,
                345.79296875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4856211543083191,
              "bbox": [
                13.94025707244873,
                133.91217041015625,
                94.41275787353516,
                304.2418518066406
              ]
            },
            {
              "track_id": 566,
              "class_id": 63,
              "class_name": "laptop",
              "confidence": 0.5105618238449097,
              "bbox": [
                259.8336181640625,
                228.2732696533203,
                349.04052734375,
                296.0308532714844
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.46579596400260925,
              "bbox": [
                53.822296142578125,
                69.04608154296875,
                534.1393432617188,
                354.889404296875
              ]
            },
            {
              "track_id": 569,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3287600576877594,
              "bbox": [
                524.1956787109375,
                302.71636962890625,
                553.1370849609375,
                359.6155090332031
              ]
            },
            {
              "track_id": 554,
              "class_id": 40,
              "class_name": "wine glass",
              "confidence": 0.4798943102359772,
              "bbox": [
                70.16487121582031,
                318.5701904296875,
                110.78779602050781,
                359.26226806640625
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            566,
            567,
            569,
            554
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7656,
            7660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7661,
            7665
          ],
          "representative_frame": 7661,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6169909238815308,
              "bbox": [
                252.12107849121094,
                73.9441909790039,
                540.9550170898438,
                348.88201904296875
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5737124681472778,
              "bbox": [
                16.701353073120117,
                146.98922729492188,
                92.88910675048828,
                300.1582946777344
              ]
            },
            {
              "track_id": 566,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.12398587912321091,
              "bbox": [
                251.24261474609375,
                229.71389770507812,
                342.0080261230469,
                298.646728515625
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3006954491138458,
              "bbox": [
                46.280174255371094,
                74.04032897949219,
                519.1742553710938,
                355.0531005859375
              ]
            },
            {
              "track_id": 569,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3177367150783539,
              "bbox": [
                524.5862426757812,
                302.3779602050781,
                552.4319458007812,
                357.0550537109375
              ]
            },
            {
              "track_id": 554,
              "class_id": 40,
              "class_name": "wine glass",
              "confidence": 0.36897528171539307,
              "bbox": [
                70.62451934814453,
                318.063720703125,
                110.4925765991211,
                359.1262512207031
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            566,
            567,
            569,
            554
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            7666,
            7670
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7671,
            7675
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7141402363777161,
              "bbox": [
                243.99749755859375,
                85.49649047851562,
                527.13818359375,
                352.6100158691406
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.581976056098938,
              "bbox": [
                17.473176956176758,
                152.8427276611328,
                94.34679412841797,
                300.01849365234375
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3003460168838501,
              "bbox": [
                55.63614273071289,
                84.4566421508789,
                512.65576171875,
                355.2481994628906
              ]
            },
            {
              "track_id": 569,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.38949936628341675,
              "bbox": [
                524.0364379882812,
                302.2304382324219,
                551.6015625,
                356.1740417480469
              ]
            },
            {
              "track_id": 554,
              "class_id": 40,
              "class_name": "wine glass",
              "confidence": 0.3472013473510742,
              "bbox": [
                71.06295776367188,
                317.8844909667969,
                110.03285217285156,
                359.10418701171875
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            567,
            569,
            554
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7676,
            7680
          ],
          "representative_frame": 7676,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 63
    },
    {
      "second": 256,
      "time_range": [
        256,
        256.999
      ],
      "frame_range": [
        7681,
        7710
      ],
      "unified_description": "4 men are in tents, two of them are having their meals while others are resting or sleeping. The tents have a white canvas structure, and the scene appears to be outdoors with natural lighting conditions.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:10",
        "processing_time": 3.38,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7695,
          "frame_range": [
            7691,
            7695
          ],
          "description": "a man in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.04
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7681,
            7685
          ],
          "representative_frame": 7681,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.819219172000885,
              "bbox": [
                243.57891845703125,
                94.3348617553711,
                519.920166015625,
                352.80413818359375
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7246634364128113,
              "bbox": [
                19.350383758544922,
                157.18019104003906,
                99.5657958984375,
                302.89276123046875
              ]
            },
            {
              "track_id": 569,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2613163888454437,
              "bbox": [
                524.4139404296875,
                302.353759765625,
                552.0338745117188,
                356.2904968261719
              ]
            },
            {
              "track_id": 554,
              "class_id": 40,
              "class_name": "wine glass",
              "confidence": 0.31810957193374634,
              "bbox": [
                70.84439086914062,
                317.78668212890625,
                109.10960388183594,
                359.1521911621094
              ]
            },
            {
              "track_id": 566,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.4284970462322235,
              "bbox": [
                228.88919067382812,
                232.21298217773438,
                328.466064453125,
                308.1055603027344
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            569,
            554,
            566
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7686,
            7690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7691,
            7695
          ],
          "representative_frame": 7691,
          "detections": [
            {
              "track_id": 402,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8666374087333679,
              "bbox": [
                244.27227783203125,
                96.13782501220703,
                521.03271484375,
                354.0563659667969
              ]
            },
            {
              "track_id": 495,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3903978765010834,
              "bbox": [
                18.042949676513672,
                164.83352661132812,
                99.30081176757812,
                305.9966125488281
              ]
            },
            {
              "track_id": 569,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3396154046058655,
              "bbox": [
                524.1065063476562,
                302.0283203125,
                552.1986694335938,
                356.7974853515625
              ]
            },
            {
              "track_id": 566,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.382841557264328,
              "bbox": [
                225.3849334716797,
                230.83389282226562,
                325.2588806152344,
                307.1147766113281
              ]
            }
          ],
          "unique_tracks": [
            402,
            495,
            569,
            566
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            7696,
            7700
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7701,
            7705
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6262475252151489,
              "bbox": [
                280.1875915527344,
                111.35636901855469,
                436.1061096191406,
                267.67474365234375
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6522505879402161,
              "bbox": [
                42.46006393432617,
                57.14279556274414,
                273.7978210449219,
                356.1489562988281
              ]
            }
          ],
          "unique_tracks": [
            502,
            556
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            7706,
            7710
          ],
          "representative_frame": 7706,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 64
    },
    {
      "second": 257,
      "time_range": [
        257,
        257.999
      ],
      "frame_range": [
        7711,
        7740
      ],
      "unified_description": "3 men are eating out of bowls in a tent, one man is filming",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:11",
        "processing_time": 3.41,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7725,
          "frame_range": [
            7721,
            7725
          ],
          "description": "a man sitting in a tent with a camera",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.2
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7711,
            7715
          ],
          "representative_frame": 7711,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8698768019676208,
              "bbox": [
                434.29681396484375,
                106.78318786621094,
                638.2105102539062,
                350.3267517089844
              ]
            },
            {
              "track_id": 578,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.45445960760116577,
              "bbox": [
                302.48907470703125,
                262.823486328125,
                353.4419250488281,
                310.35357666015625
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6977660059928894,
              "bbox": [
                286.43798828125,
                111.6436767578125,
                430.1633605957031,
                266.5108337402344
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2925803065299988,
              "bbox": [
                38.97080612182617,
                56.955230712890625,
                274.2197265625,
                356.1958923339844
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5613552927970886,
              "bbox": [
                42.29206848144531,
                59.113250732421875,
                546.7744140625,
                356.4622497558594
              ]
            }
          ],
          "unique_tracks": [
            577,
            578,
            502,
            556,
            567
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7716,
            7720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7721,
            7725
          ],
          "representative_frame": 7721,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8735467195510864,
              "bbox": [
                434.143798828125,
                106.9299545288086,
                638.5621948242188,
                351.07122802734375
              ]
            },
            {
              "track_id": 578,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.49782276153564453,
              "bbox": [
                302.7502746582031,
                263.2759094238281,
                353.181640625,
                310.3290100097656
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6629215478897095,
              "bbox": [
                290.4226379394531,
                112.86375427246094,
                426.61627197265625,
                267.4031982421875
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.366801381111145,
              "bbox": [
                49.7759895324707,
                56.51093673706055,
                295.3638916015625,
                357.2577819824219
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5646761655807495,
              "bbox": [
                38.709869384765625,
                55.45533752441406,
                552.2687377929688,
                356.5682067871094
              ]
            }
          ],
          "unique_tracks": [
            577,
            578,
            502,
            556,
            567
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            7726,
            7730
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7731,
            7735
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.891140341758728,
              "bbox": [
                433.8585510253906,
                106.97230529785156,
                639.3043823242188,
                352.3725891113281
              ]
            },
            {
              "track_id": 578,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.45277315378189087,
              "bbox": [
                302.91021728515625,
                263.5628662109375,
                353.06951904296875,
                310.37469482421875
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.657962441444397,
              "bbox": [
                281.0495910644531,
                111.81452941894531,
                421.4076843261719,
                274.88568115234375
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3972069025039673,
              "bbox": [
                67.01094055175781,
                57.553123474121094,
                325.82562255859375,
                357.35638427734375
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.595070481300354,
              "bbox": [
                36.098445892333984,
                54.098793029785156,
                554.33837890625,
                356.5059509277344
              ]
            },
            {
              "track_id": 507,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4833923876285553,
              "bbox": [
                167.15321350097656,
                129.28785705566406,
                340.9277038574219,
                290.83819580078125
              ]
            }
          ],
          "unique_tracks": [
            577,
            578,
            502,
            556,
            567,
            507
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            7736,
            7740
          ],
          "representative_frame": 7736,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 64
    },
    {
      "second": 258,
      "time_range": [
        258,
        258.999
      ],
      "frame_range": [
        7741,
        7770
      ],
      "unified_description": "3 people are inside a tent and playing with their fishing lures.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:13",
        "processing_time": 3.23,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7755,
          "frame_range": [
            7751,
            7755
          ],
          "description": "a man sitting in a tent with a woman",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.12
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7741,
            7745
          ],
          "representative_frame": 7741,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8934260010719299,
              "bbox": [
                433.83978271484375,
                107.23434448242188,
                639.3844604492188,
                352.7665710449219
              ]
            },
            {
              "track_id": 578,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4150995910167694,
              "bbox": [
                302.649658203125,
                263.15765380859375,
                353.12969970703125,
                310.2882385253906
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5771262645721436,
              "bbox": [
                287.4677429199219,
                108.99349975585938,
                422.1562805175781,
                270.4227600097656
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5736387372016907,
              "bbox": [
                42.750877380371094,
                55.79813766479492,
                303.6181335449219,
                357.0894470214844
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4973750412464142,
              "bbox": [
                15.026573181152344,
                53.36849594116211,
                531.7425537109375,
                356.7583312988281
              ]
            }
          ],
          "unique_tracks": [
            577,
            578,
            502,
            556,
            567
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            7746,
            7750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7751,
            7755
          ],
          "representative_frame": 7751,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6340901255607605,
              "bbox": [
                425.083740234375,
                109.4396743774414,
                617.8822021484375,
                339.5040283203125
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5546645522117615,
              "bbox": [
                314.1473693847656,
                114.79830932617188,
                422.3676452636719,
                250.53248596191406
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4648040533065796,
              "bbox": [
                67.15714263916016,
                61.58842849731445,
                327.97003173828125,
                356.4964599609375
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.36324334144592285,
              "bbox": [
                49.45112609863281,
                58.859458923339844,
                557.4072875976562,
                356.0325927734375
              ]
            }
          ],
          "unique_tracks": [
            577,
            502,
            556,
            567
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            7756,
            7760
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7761,
            7765
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.743389904499054,
              "bbox": [
                431.1119079589844,
                109.72595977783203,
                620.8782348632812,
                335.52789306640625
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7254534363746643,
              "bbox": [
                327.90264892578125,
                116.57332611083984,
                423.29107666015625,
                241.739990234375
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7823887467384338,
              "bbox": [
                83.98014831542969,
                68.04219055175781,
                344.6986083984375,
                356.247314453125
              ]
            },
            {
              "track_id": 591,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.4141917824745178,
              "bbox": [
                368.5849304199219,
                251.70010375976562,
                397.30615234375,
                295.9822692871094
              ]
            },
            {
              "track_id": 592,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.32579490542411804,
              "bbox": [
                532.8878173828125,
                224.62261962890625,
                550.374267578125,
                245.16925048828125
              ]
            }
          ],
          "unique_tracks": [
            577,
            502,
            556,
            591,
            592
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            7766,
            7770
          ],
          "representative_frame": 7766,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 64
    },
    {
      "second": 259,
      "time_range": [
        259,
        259.999
      ],
      "frame_range": [
        7771,
        7800
      ],
      "unified_description": "3 people are shown in this image, possibly a family on a camping trip. They are engaged in various activities, such as using a smartphone and flying a kite. The image captures their interactions and surroundings, which include a tent and outdoor elements.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:15",
        "processing_time": 3.27,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7785,
          "frame_range": [
            7781,
            7785
          ],
          "description": "a man is sitting in a tent with a woman",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.37
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7771,
            7775
          ],
          "representative_frame": 7771,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7883833050727844,
              "bbox": [
                432.0392150878906,
                108.02316284179688,
                622.83740234375,
                334.5957946777344
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5685481429100037,
              "bbox": [
                339.2668151855469,
                117.5333480834961,
                413.6600646972656,
                214.74502563476562
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5075016021728516,
              "bbox": [
                104.14092254638672,
                76.7581558227539,
                367.38470458984375,
                356.0312805175781
              ]
            },
            {
              "track_id": 591,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.145355686545372,
              "bbox": [
                371.164306640625,
                254.3321075439453,
                398.533935546875,
                296.5712890625
              ]
            },
            {
              "track_id": 592,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.31982696056365967,
              "bbox": [
                532.7703857421875,
                224.58616638183594,
                550.5635375976562,
                245.5016326904297
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5777743458747864,
              "bbox": [
                92.48564147949219,
                74.85154724121094,
                579.5316772460938,
                355.47802734375
              ]
            }
          ],
          "unique_tracks": [
            577,
            502,
            556,
            591,
            592,
            567
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7776,
            7780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7781,
            7785
          ],
          "representative_frame": 7781,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8130096793174744,
              "bbox": [
                432.8922119140625,
                108.2724609375,
                623.6364135742188,
                334.29217529296875
              ]
            },
            {
              "track_id": 502,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5366196632385254,
              "bbox": [
                337.7547912597656,
                117.84489440917969,
                421.3226318359375,
                231.16976928710938
              ]
            },
            {
              "track_id": 556,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7738736867904663,
              "bbox": [
                95.05431365966797,
                83.49048614501953,
                356.9321594238281,
                356.1695861816406
              ]
            },
            {
              "track_id": 591,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.46821972727775574,
              "bbox": [
                370.63763427734375,
                255.79600524902344,
                396.7701110839844,
                295.90704345703125
              ]
            },
            {
              "track_id": 592,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.31652191281318665,
              "bbox": [
                532.7114868164062,
                224.5685272216797,
                550.6472778320312,
                245.6643524169922
              ]
            }
          ],
          "unique_tracks": [
            577,
            502,
            556,
            591,
            592
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            7786,
            7790
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7791,
            7795
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.875271201133728,
              "bbox": [
                1.7034807205200195,
                0.0,
                211.29617309570312,
                259.93096923828125
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6440327167510986,
              "bbox": [
                170.6505889892578,
                271.70404052734375,
                240.7667694091797,
                325.19195556640625
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8824350833892822,
              "bbox": [
                177.37144470214844,
                15.651848793029785,
                640.0,
                348.3174133300781
              ]
            }
          ],
          "unique_tracks": [
            549,
            566,
            567
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            7796,
            7800
          ],
          "representative_frame": 7796,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 64
    },
    {
      "second": 260,
      "time_range": [
        260,
        260.999
      ],
      "frame_range": [
        7801,
        7830
      ],
      "unified_description": "3 men, a boy, and an older man at a campsite with tents, food cooking over a fire, and various objects like cups, bowls, and spoons in front of them.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:16",
        "processing_time": 3.6,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7815,
          "frame_range": [
            7811,
            7815
          ],
          "description": "a group of people sitting around a campfire",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.43
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7801,
            7805
          ],
          "representative_frame": 7801,
          "detections": [
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8184486031532288,
              "bbox": [
                246.05836486816406,
                260.1163635253906,
                337.6142883300781,
                354.5032043457031
              ]
            },
            {
              "track_id": 599,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4855619966983795,
              "bbox": [
                293.4425964355469,
                188.0897216796875,
                338.27178955078125,
                270.4271545410156
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5674962401390076,
              "bbox": [
                242.33885192871094,
                0.582501232624054,
                354.04638671875,
                167.03042602539062
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5359711050987244,
              "bbox": [
                357.7357177734375,
                231.35409545898438,
                413.8015441894531,
                270.09051513671875
              ]
            },
            {
              "track_id": 602,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.4701174199581146,
              "bbox": [
                279.0531311035156,
                256.5345153808594,
                292.8875732421875,
                323.7298583984375
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3293510675430298,
              "bbox": [
                146.747314453125,
                244.15438842773438,
                187.95530700683594,
                285.2140808105469
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8742265105247498,
              "bbox": [
                3.7127840518951416,
                0.0,
                203.37071228027344,
                260.99810791015625
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6652869582176208,
              "bbox": [
                169.50161743164062,
                273.16082763671875,
                238.81869506835938,
                326.01556396484375
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8944928646087646,
              "bbox": [
                207.34658813476562,
                3.6901793479919434,
                640.0,
                348.7406311035156
              ]
            }
          ],
          "unique_tracks": [
            598,
            599,
            600,
            601,
            602,
            604,
            549,
            566,
            567
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            7806,
            7810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7811,
            7815
          ],
          "representative_frame": 7811,
          "detections": [
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8211644887924194,
              "bbox": [
                245.93695068359375,
                260.0547180175781,
                337.9334411621094,
                354.92156982421875
              ]
            },
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.19137121737003326,
              "bbox": [
                296.9610900878906,
                202.5146026611328,
                334.4245910644531,
                270.9916076660156
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5650442242622375,
              "bbox": [
                238.9411163330078,
                0.7321977615356445,
                365.7888488769531,
                189.9690704345703
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7373805642127991,
              "bbox": [
                357.7828674316406,
                231.46388244628906,
                413.4844665527344,
                269.9374084472656
              ]
            },
            {
              "track_id": 602,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.5609801411628723,
              "bbox": [
                279.4705810546875,
                257.0418701171875,
                293.1692810058594,
                323.54632568359375
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3623912036418915,
              "bbox": [
                146.68568420410156,
                244.4261016845703,
                187.20045471191406,
                284.79754638671875
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8896141052246094,
              "bbox": [
                3.281736135482788,
                0.0,
                196.54063415527344,
                260.3577880859375
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7014169692993164,
              "bbox": [
                168.55540466308594,
                273.48321533203125,
                238.0959014892578,
                326.5959777832031
              ]
            },
            {
              "track_id": 567,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8679739236831665,
              "bbox": [
                225.6018829345703,
                0.0,
                640.0,
                346.35125732421875
              ]
            }
          ],
          "unique_tracks": [
            598,
            599,
            600,
            601,
            602,
            604,
            549,
            566,
            567
          ],
          "total_detections": 9
        },
        {
          "group_index": 3,
          "frame_range": [
            7816,
            7820
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7821,
            7825
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8759799003601074,
              "bbox": [
                245.9820098876953,
                260.11492919921875,
                338.0930480957031,
                355.1387023925781
              ]
            },
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.31104373931884766,
              "bbox": [
                298.6872253417969,
                208.5252685546875,
                332.5486145019531,
                269.9013671875
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5259049534797668,
              "bbox": [
                236.51904296875,
                0.7980812788009644,
                367.7872314453125,
                197.12210083007812
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.660748302936554,
              "bbox": [
                356.3290710449219,
                231.3438262939453,
                412.313720703125,
                270.0654602050781
              ]
            },
            {
              "track_id": 602,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.5559680461883545,
              "bbox": [
                279.6984558105469,
                257.0911865234375,
                293.3919982910156,
                323.5429382324219
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4631485044956207,
              "bbox": [
                146.5123291015625,
                244.5350341796875,
                186.8457489013672,
                284.7112121582031
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8990877866744995,
              "bbox": [
                1.9477680921554565,
                0.0,
                191.21270751953125,
                260.00811767578125
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6514652967453003,
              "bbox": [
                168.64434814453125,
                273.4975280761719,
                237.90757751464844,
                326.43560791015625
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8995376825332642,
              "bbox": [
                373.8443908691406,
                10.9376859664917,
                640.0,
                347.2146911621094
              ]
            }
          ],
          "unique_tracks": [
            598,
            599,
            600,
            601,
            602,
            604,
            549,
            566,
            577
          ],
          "total_detections": 9
        },
        {
          "group_index": 5,
          "frame_range": [
            7826,
            7830
          ],
          "representative_frame": 7826,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 65
    },
    {
      "second": 261,
      "time_range": [
        261,
        261.999
      ],
      "frame_range": [
        7831,
        7860
      ],
      "unified_description": "3 people are seen in this image which shows them sitting on the ground inside a tent. A man is holding a can while a boy is blowing out a candle. They have various items with them, such as cups, bowls and a backpack. The camera capturing this scene is mounted on a tripod, providing stable footage of the family enjoying their time together in the tent.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:18",
        "processing_time": 4.8,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7845,
          "frame_range": [
            7841,
            7845
          ],
          "description": "a man and two boys sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.87
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7831,
            7835
          ],
          "representative_frame": 7831,
          "detections": [
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8188042640686035,
              "bbox": [
                245.84829711914062,
                260.1484375,
                338.019775390625,
                355.2801513671875
              ]
            },
            {
              "track_id": 599,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.1942485272884369,
              "bbox": [
                297.8838806152344,
                206.5232391357422,
                333.3027038574219,
                270.2416076660156
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7712603211402893,
              "bbox": [
                270.1752624511719,
                2.5507752895355225,
                417.4220886230469,
                217.68942260742188
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.31764841079711914,
              "bbox": [
                358.3394470214844,
                230.98684692382812,
                415.2397766113281,
                270.2345886230469
              ]
            },
            {
              "track_id": 602,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.545951783657074,
              "bbox": [
                279.76959228515625,
                257.30877685546875,
                293.4152526855469,
                323.4789123535156
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.39648133516311646,
              "bbox": [
                146.9555206298828,
                244.78326416015625,
                186.87060546875,
                284.5259094238281
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8847560286521912,
              "bbox": [
                3.038357734680176,
                0.0,
                189.70510864257812,
                260.7254638671875
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5946100950241089,
              "bbox": [
                168.6851043701172,
                273.28662109375,
                238.2143096923828,
                326.49481201171875
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9006168246269226,
              "bbox": [
                373.7734069824219,
                0.0,
                640.0,
                349.67041015625
              ]
            }
          ],
          "unique_tracks": [
            598,
            599,
            600,
            601,
            602,
            604,
            549,
            566,
            577
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            7836,
            7840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7841,
            7845
          ],
          "representative_frame": 7841,
          "detections": [
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8152426481246948,
              "bbox": [
                245.73675537109375,
                259.99102783203125,
                338.0329284667969,
                355.3218994140625
              ]
            },
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.21355268359184265,
              "bbox": [
                298.1757507324219,
                208.48434448242188,
                332.8879089355469,
                270.23046875
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8168147802352905,
              "bbox": [
                281.41253662109375,
                3.829667568206787,
                439.63787841796875,
                228.777099609375
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5236912965774536,
              "bbox": [
                356.78216552734375,
                231.33746337890625,
                412.70440673828125,
                269.9788818359375
              ]
            },
            {
              "track_id": 602,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.56082683801651,
              "bbox": [
                279.8162536621094,
                257.3871765136719,
                293.44921875,
                323.4407043457031
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.29911699891090393,
              "bbox": [
                147.00311279296875,
                244.6531219482422,
                186.94720458984375,
                284.37420654296875
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8706158995628357,
              "bbox": [
                4.133296966552734,
                0.0,
                186.72772216796875,
                260.0934143066406
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.587751567363739,
              "bbox": [
                168.8310546875,
                273.0838928222656,
                238.61643981933594,
                326.54180908203125
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9097880721092224,
              "bbox": [
                373.2124328613281,
                0.0,
                640.0,
                353.4469909667969
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3825327455997467,
              "bbox": [
                2.9965269565582275,
                38.91764450073242,
                63.767799377441406,
                288.26959228515625
              ]
            }
          ],
          "unique_tracks": [
            598,
            599,
            600,
            601,
            602,
            604,
            549,
            566,
            577,
            611
          ],
          "total_detections": 10
        },
        {
          "group_index": 3,
          "frame_range": [
            7846,
            7850
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7851,
            7855
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.37333282828330994,
              "bbox": [
                298.02520751953125,
                208.3551788330078,
                333.3457946777344,
                270.4613037109375
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.15159066021442413,
              "bbox": [
                246.47689819335938,
                1.5144364833831787,
                413.5141296386719,
                229.38026428222656
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4675767719745636,
              "bbox": [
                356.3475341796875,
                231.60391235351562,
                411.322998046875,
                269.6554870605469
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5539857745170593,
              "bbox": [
                147.01812744140625,
                244.57095336914062,
                186.9679412841797,
                284.2517395019531
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.808035135269165,
              "bbox": [
                43.54302978515625,
                0.0,
                238.0503387451172,
                262.4453125
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6407478451728821,
              "bbox": [
                168.9718017578125,
                272.9296875,
                239.08676147460938,
                326.7448425292969
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8704676628112793,
              "bbox": [
                358.7338562011719,
                0.0,
                640.0,
                354.7736511230469
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.14936195313930511,
              "bbox": [
                1.9783945083618164,
                38.55961608886719,
                62.955528259277344,
                288.4941711425781
              ]
            },
            {
              "track_id": 507,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.7944835424423218,
              "bbox": [
                114.46428680419922,
                30.198144912719727,
                327.8582763671875,
                266.30316162109375
              ]
            }
          ],
          "unique_tracks": [
            599,
            600,
            601,
            604,
            549,
            566,
            577,
            611,
            507
          ],
          "total_detections": 9
        },
        {
          "group_index": 5,
          "frame_range": [
            7856,
            7860
          ],
          "representative_frame": 7856,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 65
    },
    {
      "second": 262,
      "time_range": [
        262,
        262.999
      ],
      "frame_range": [
        7861,
        7890
      ],
      "unified_description": "3 people in the scene. One is pouring water into a blue container while the other two are watching.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:20",
        "processing_time": 3.39,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7875,
          "frame_range": [
            7871,
            7875
          ],
          "description": "a man and a child are sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.31
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7861,
            7865
          ],
          "representative_frame": 7861,
          "detections": [
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3133520483970642,
              "bbox": [
                297.821044921875,
                208.00746154785156,
                333.7710266113281,
                270.48486328125
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5041131377220154,
              "bbox": [
                356.634521484375,
                231.85531616210938,
                410.8843688964844,
                269.4330139160156
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5667537450790405,
              "bbox": [
                147.1002197265625,
                244.55374145507812,
                186.90350341796875,
                284.0376281738281
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.690704882144928,
              "bbox": [
                57.291717529296875,
                0.0,
                261.3267822265625,
                263.6546325683594
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.572167694568634,
              "bbox": [
                169.24105834960938,
                272.807373046875,
                239.25335693359375,
                326.62445068359375
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8806492686271667,
              "bbox": [
                352.3626403808594,
                0.0,
                640.0,
                354.9083251953125
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.16669215261936188,
              "bbox": [
                4.98515510559082,
                36.86772918701172,
                66.34983825683594,
                286.93939208984375
              ]
            },
            {
              "track_id": 618,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.47038283944129944,
              "bbox": [
                265.9341735839844,
                231.86642456054688,
                347.3503112792969,
                289.7350158691406
              ]
            },
            {
              "track_id": 507,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.7494091987609863,
              "bbox": [
                121.96963500976562,
                19.95294761657715,
                317.6092224121094,
                266.5902404785156
              ]
            }
          ],
          "unique_tracks": [
            599,
            601,
            604,
            549,
            566,
            577,
            611,
            618,
            507
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            7866,
            7870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7871,
            7875
          ],
          "representative_frame": 7871,
          "detections": [
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2778940200805664,
              "bbox": [
                297.5782775878906,
                207.68106079101562,
                334.13677978515625,
                270.47332763671875
              ]
            },
            {
              "track_id": 601,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5558037161827087,
              "bbox": [
                356.509033203125,
                231.80918884277344,
                410.8767395019531,
                269.53863525390625
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5765309929847717,
              "bbox": [
                147.15585327148438,
                244.56248474121094,
                186.89105224609375,
                283.92657470703125
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8347865343093872,
              "bbox": [
                27.524885177612305,
                0.009339859709143639,
                225.41094970703125,
                264.1105651855469
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6384732127189636,
              "bbox": [
                169.40121459960938,
                272.7052917480469,
                239.46238708496094,
                326.64007568359375
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9269866347312927,
              "bbox": [
                348.53656005859375,
                0.0,
                639.480712890625,
                354.9598388671875
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.18320421874523163,
              "bbox": [
                6.181600093841553,
                34.003692626953125,
                68.616943359375,
                286.4483642578125
              ]
            },
            {
              "track_id": 618,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.582889199256897,
              "bbox": [
                265.93145751953125,
                231.9242706298828,
                347.1929016113281,
                289.6826171875
              ]
            },
            {
              "track_id": 507,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.7267904281616211,
              "bbox": [
                134.22869873046875,
                33.4616813659668,
                302.9788513183594,
                266.7933654785156
              ]
            },
            {
              "track_id": 621,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.31823888421058655,
              "bbox": [
                314.326904296875,
                315.5809631347656,
                341.2976989746094,
                359.4454345703125
              ]
            }
          ],
          "unique_tracks": [
            599,
            601,
            604,
            549,
            566,
            577,
            611,
            618,
            507,
            621
          ],
          "total_detections": 10
        },
        {
          "group_index": 3,
          "frame_range": [
            7876,
            7880
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7881,
            7885
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.1899392157793045,
              "bbox": [
                297.4054260253906,
                207.59825134277344,
                334.5098571777344,
                270.560791015625
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.49192142486572266,
              "bbox": [
                147.448974609375,
                244.6746368408203,
                186.88755798339844,
                283.7061462402344
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8645784854888916,
              "bbox": [
                17.301185607910156,
                0.0,
                210.26177978515625,
                264.7126159667969
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4841373860836029,
              "bbox": [
                169.82833862304688,
                272.68865966796875,
                239.40057373046875,
                326.24237060546875
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.823799192905426,
              "bbox": [
                349.08990478515625,
                0.0,
                638.8978271484375,
                353.9356384277344
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2542608082294464,
              "bbox": [
                4.298168182373047,
                35.98799514770508,
                66.91964721679688,
                288.0118408203125
              ]
            },
            {
              "track_id": 618,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5374207496643066,
              "bbox": [
                265.92388916015625,
                232.17153930664062,
                346.8584899902344,
                289.7264099121094
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3870600163936615,
              "bbox": [
                273.7140197753906,
                2.2398924827575684,
                454.317138671875,
                235.91432189941406
              ]
            }
          ],
          "unique_tracks": [
            599,
            604,
            549,
            566,
            577,
            611,
            618,
            600
          ],
          "total_detections": 8
        },
        {
          "group_index": 5,
          "frame_range": [
            7886,
            7890
          ],
          "representative_frame": 7886,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 65
    },
    {
      "second": 263,
      "time_range": [
        263,
        263.999
      ],
      "frame_range": [
        7891,
        7920
      ],
      "unified_description": "3 people in tents camping outdoors with bowls and bags visible around them.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:21",
        "processing_time": 3.22,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7905,
          "frame_range": [
            7901,
            7905
          ],
          "description": "a man and a child are sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.07
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7891,
            7895
          ],
          "representative_frame": 7891,
          "detections": [
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.17661833763122559,
              "bbox": [
                297.16241455078125,
                207.4002227783203,
                334.8381042480469,
                270.5979309082031
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4660899043083191,
              "bbox": [
                147.5347442626953,
                244.6913604736328,
                186.94039916992188,
                283.6617431640625
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8567741513252258,
              "bbox": [
                14.72562313079834,
                0.0,
                203.3983612060547,
                265.1016540527344
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5058155059814453,
              "bbox": [
                170.01815795898438,
                272.6361999511719,
                239.4937744140625,
                326.1225891113281
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8442144989967346,
              "bbox": [
                349.3287658691406,
                0.0,
                638.7401123046875,
                353.8481750488281
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.21109606325626373,
              "bbox": [
                5.340224742889404,
                37.1773567199707,
                65.85893249511719,
                278.165283203125
              ]
            },
            {
              "track_id": 618,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5387206673622131,
              "bbox": [
                266.1761474609375,
                232.18814086914062,
                346.9583740234375,
                289.6554870605469
              ]
            },
            {
              "track_id": 622,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.36090993881225586,
              "bbox": [
                219.55072021484375,
                0.628192126750946,
                350.7532043457031,
                109.92105102539062
              ]
            },
            {
              "track_id": 623,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.35667386651039124,
              "bbox": [
                221.62368774414062,
                0.2673492431640625,
                348.0079040527344,
                187.03363037109375
              ]
            }
          ],
          "unique_tracks": [
            599,
            604,
            549,
            566,
            577,
            611,
            618,
            622,
            623
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            7896,
            7900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7901,
            7905
          ],
          "representative_frame": 7901,
          "detections": [
            {
              "track_id": 599,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.1596611589193344,
              "bbox": [
                296.91839599609375,
                207.26199340820312,
                335.0923767089844,
                270.591064453125
              ]
            },
            {
              "track_id": 604,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4547119140625,
              "bbox": [
                147.6407470703125,
                244.70352172851562,
                186.8531494140625,
                283.42474365234375
              ]
            },
            {
              "track_id": 549,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8556984066963196,
              "bbox": [
                14.879300117492676,
                0.09554842859506607,
                198.99087524414062,
                264.51507568359375
              ]
            },
            {
              "track_id": 566,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.49570736289024353,
              "bbox": [
                170.1539306640625,
                272.5854187011719,
                239.59266662597656,
                326.05010986328125
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8178321123123169,
              "bbox": [
                365.3197937011719,
                0.0,
                640.0,
                354.41949462890625
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.17351676523685455,
              "bbox": [
                4.517327785491943,
                37.21647262573242,
                67.68770599365234,
                286.84210205078125
              ]
            },
            {
              "track_id": 618,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5250137448310852,
              "bbox": [
                266.2718811035156,
                232.1985626220703,
                346.9693298339844,
                289.6286926269531
              ]
            },
            {
              "track_id": 622,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2613714337348938,
              "bbox": [
                215.9748992919922,
                0.48690053820610046,
                345.50653076171875,
                108.0077896118164
              ]
            },
            {
              "track_id": 623,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.37724006175994873,
              "bbox": [
                216.85488891601562,
                0.44977736473083496,
                343.0958557128906,
                186.2418975830078
              ]
            },
            {
              "track_id": 507,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.46438491344451904,
              "bbox": [
                134.1395263671875,
                9.463577270507812,
                303.0074157714844,
                266.253173828125
              ]
            }
          ],
          "unique_tracks": [
            599,
            604,
            549,
            566,
            577,
            611,
            618,
            622,
            623,
            507
          ],
          "total_detections": 10
        },
        {
          "group_index": 3,
          "frame_range": [
            7906,
            7910
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7911,
            7915
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7152742743492126,
              "bbox": [
                375.77972412109375,
                0.0,
                640.0,
                346.95611572265625
              ]
            }
          ],
          "unique_tracks": [
            577
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            7916,
            7920
          ],
          "representative_frame": 7916,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 65
    },
    {
      "second": 264,
      "time_range": [
        264,
        264.999
      ],
      "frame_range": [
        7921,
        7950
      ],
      "unified_description": "\nIn the image, a person can be seen sitting on the ground in front of various objects. There is a blue bowl next to a red object, possibly a water bottle or a small red backpack. Other items, including a handbag, are also visible in the scene. The camera is set up in such a way that it captures the man's activities, as he interacts with these objects around him.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:23",
        "processing_time": 3.65,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7935,
          "frame_range": [
            7931,
            7935
          ],
          "description": "a man is sitting in the grass with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7921,
            7925
          ],
          "representative_frame": 7921,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6278578639030457,
              "bbox": [
                389.90911865234375,
                0.0,
                640.0,
                344.72418212890625
              ]
            },
            {
              "track_id": 628,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7874366044998169,
              "bbox": [
                350.0651550292969,
                201.87252807617188,
                461.38580322265625,
                292.5496520996094
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3878105878829956,
              "bbox": [
                250.66363525390625,
                146.5224151611328,
                339.2921447753906,
                200.58636474609375
              ]
            },
            {
              "track_id": 631,
              "class_id": 43,
              "class_name": "knife",
              "confidence": 0.416880339384079,
              "bbox": [
                302.1962585449219,
                325.9880065917969,
                474.5410461425781,
                355.2725830078125
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5017807483673096,
              "bbox": [
                140.98983764648438,
                176.22935485839844,
                220.76414489746094,
                230.42623901367188
              ]
            },
            {
              "track_id": 502,
              "class_id": 44,
              "class_name": "spoon",
              "confidence": 0.5230221152305603,
              "bbox": [
                369.1566467285156,
                82.59373474121094,
                479.30902099609375,
                242.2916259765625
              ]
            }
          ],
          "unique_tracks": [
            577,
            628,
            629,
            631,
            633,
            502
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            7926,
            7930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7931,
            7935
          ],
          "representative_frame": 7931,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8844832181930542,
              "bbox": [
                389.3044128417969,
                0.0,
                640.0,
                342.41387939453125
              ]
            },
            {
              "track_id": 628,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.504423975944519,
              "bbox": [
                338.354248046875,
                200.0646209716797,
                462.23944091796875,
                301.6775817871094
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5655696392059326,
              "bbox": [
                250.92291259765625,
                146.5704803466797,
                339.1591491699219,
                200.38978576660156
              ]
            },
            {
              "track_id": 631,
              "class_id": 43,
              "class_name": "knife",
              "confidence": 0.1663529872894287,
              "bbox": [
                306.0856018066406,
                325.9882507324219,
                471.21099853515625,
                354.01068115234375
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.40996456146240234,
              "bbox": [
                140.90792846679688,
                176.16964721679688,
                220.69210815429688,
                230.38671875
              ]
            }
          ],
          "unique_tracks": [
            577,
            628,
            629,
            631,
            633
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            7936,
            7940
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7941,
            7945
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9262943863868713,
              "bbox": [
                355.01025390625,
                0.0,
                626.067626953125,
                342.593505859375
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.503821074962616,
              "bbox": [
                252.3436279296875,
                146.69227600097656,
                338.89276123046875,
                199.4132080078125
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.29458144307136536,
              "bbox": [
                141.36083984375,
                176.2274169921875,
                220.40977478027344,
                229.94300842285156
              ]
            },
            {
              "track_id": 635,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.31781941652297974,
              "bbox": [
                4.760979652404785,
                273.6971130371094,
                254.80088806152344,
                357.7924499511719
              ]
            }
          ],
          "unique_tracks": [
            577,
            629,
            633,
            635
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            7946,
            7950
          ],
          "representative_frame": 7946,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 66
    },
    {
      "second": 265,
      "time_range": [
        265,
        265.999
      ],
      "frame_range": [
        7951,
        7980
      ],
      "unified_description": "1 second video showing a person cleaning a fish outdoors. There are blue bowls present and a backpack nearby indicating it might be a camping trip or fishing expedition.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:24",
        "processing_time": 3.8,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7965,
          "frame_range": [
            7961,
            7965
          ],
          "description": "a man is sitting on the ground with a fish",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.1
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7951,
            7955
          ],
          "representative_frame": 7951,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9407230615615845,
              "bbox": [
                339.84259033203125,
                0.0,
                616.8089599609375,
                343.0104675292969
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3893735408782959,
              "bbox": [
                252.47792053222656,
                146.63851928710938,
                339.4270935058594,
                199.5338592529297
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.34709349274635315,
              "bbox": [
                141.50579833984375,
                176.32559204101562,
                220.44561767578125,
                229.96331787109375
              ]
            },
            {
              "track_id": 635,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.29215294122695923,
              "bbox": [
                3.5419440269470215,
                272.53131103515625,
                257.6829528808594,
                357.96978759765625
              ]
            }
          ],
          "unique_tracks": [
            577,
            629,
            633,
            635
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            7956,
            7960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7961,
            7965
          ],
          "representative_frame": 7961,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9299252033233643,
              "bbox": [
                333.52862548828125,
                0.0,
                615.5663452148438,
                343.1455993652344
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.42980891466140747,
              "bbox": [
                252.2836151123047,
                146.657958984375,
                339.5376892089844,
                199.67083740234375
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.31878477334976196,
              "bbox": [
                141.55914306640625,
                176.3154296875,
                220.4447021484375,
                229.90980529785156
              ]
            },
            {
              "track_id": 635,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2775896191596985,
              "bbox": [
                0.9032386541366577,
                272.01727294921875,
                256.35235595703125,
                357.8988952636719
              ]
            }
          ],
          "unique_tracks": [
            577,
            629,
            633,
            635
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            7966,
            7970
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            7971,
            7975
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.930353045463562,
              "bbox": [
                329.70367431640625,
                0.0,
                616.168701171875,
                343.0703125
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.43384069204330444,
              "bbox": [
                252.2691192626953,
                146.65565490722656,
                339.7165222167969,
                199.69961547851562
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4147486388683319,
              "bbox": [
                141.61927795410156,
                176.3184814453125,
                220.3747100830078,
                229.81524658203125
              ]
            },
            {
              "track_id": 635,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.29568591713905334,
              "bbox": [
                2.017534017562866,
                271.9769592285156,
                257.56182861328125,
                357.8284606933594
              ]
            }
          ],
          "unique_tracks": [
            577,
            629,
            633,
            635
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            7976,
            7980
          ],
          "representative_frame": 7976,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 66
    },
    {
      "second": 266,
      "time_range": [
        266,
        266.999
      ],
      "frame_range": [
        7981,
        8010
      ],
      "unified_description": "1-second video with a person cleaning a fish outside in 2015.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:26",
        "processing_time": 4.29,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 7995,
          "frame_range": [
            7991,
            7995
          ],
          "description": "a man is putting a fish in a bucket",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.62
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            7981,
            7985
          ],
          "representative_frame": 7981,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9211560487747192,
              "bbox": [
                313.3548889160156,
                0.0,
                605.8030395507812,
                340.3551940917969
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.55855792760849,
              "bbox": [
                251.1384735107422,
                146.43740844726562,
                339.9976806640625,
                200.3741912841797
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.40730002522468567,
              "bbox": [
                142.419677734375,
                176.11427307128906,
                219.37503051757812,
                228.28289794921875
              ]
            },
            {
              "track_id": 635,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2148115634918213,
              "bbox": [
                0.4147382378578186,
                270.8072509765625,
                258.4449157714844,
                357.5169982910156
              ]
            }
          ],
          "unique_tracks": [
            577,
            629,
            633,
            635
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            7986,
            7990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            7991,
            7995
          ],
          "representative_frame": 7991,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9184203147888184,
              "bbox": [
                304.60589599609375,
                0.0,
                603.6199951171875,
                339.05670166015625
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.545185923576355,
              "bbox": [
                250.86122131347656,
                146.36239624023438,
                340.10089111328125,
                200.5536346435547
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4536355137825012,
              "bbox": [
                142.43040466308594,
                175.92665100097656,
                219.5101776123047,
                228.06300354003906
              ]
            },
            {
              "track_id": 635,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.299805611371994,
              "bbox": [
                0.0,
                270.432861328125,
                259.17095947265625,
                357.6207275390625
              ]
            },
            {
              "track_id": 638,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3235057294368744,
              "bbox": [
                229.56396484375,
                110.99848175048828,
                260.0094909667969,
                143.29974365234375
              ]
            },
            {
              "track_id": 639,
              "class_id": 51,
              "class_name": "carrot",
              "confidence": 0.30440282821655273,
              "bbox": [
                490.86505126953125,
                311.58892822265625,
                614.6846923828125,
                359.8641662597656
              ]
            }
          ],
          "unique_tracks": [
            577,
            629,
            633,
            635,
            638,
            639
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            7996,
            8000
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8001,
            8005
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9253782033920288,
              "bbox": [
                299.43914794921875,
                0.0,
                605.0035400390625,
                338.7336730957031
              ]
            },
            {
              "track_id": 629,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.561390221118927,
              "bbox": [
                250.775634765625,
                146.3450164794922,
                339.98095703125,
                200.54014587402344
              ]
            },
            {
              "track_id": 633,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4706999957561493,
              "bbox": [
                142.43336486816406,
                175.87559509277344,
                219.56666564941406,
                227.9219970703125
              ]
            },
            {
              "track_id": 635,
              "class_id": 26,
              "class_name": "handbag",
              "confidence": 0.28516021370887756,
              "bbox": [
                2.5756516456604004,
                272.318115234375,
                256.4001770019531,
                357.5332946777344
              ]
            },
            {
              "track_id": 638,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3402214050292969,
              "bbox": [
                229.56932067871094,
                110.99024200439453,
                260.0537414550781,
                143.3318328857422
              ]
            },
            {
              "track_id": 639,
              "class_id": 51,
              "class_name": "carrot",
              "confidence": 0.27256709337234497,
              "bbox": [
                490.9561462402344,
                311.5071716308594,
                615.2764892578125,
                359.9691467285156
              ]
            },
            {
              "track_id": 642,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.3074233829975128,
              "bbox": [
                90.3803482055664,
                221.4825897216797,
                137.67416381835938,
                258.85345458984375
              ]
            }
          ],
          "unique_tracks": [
            577,
            629,
            633,
            635,
            638,
            639,
            642
          ],
          "total_detections": 7
        },
        {
          "group_index": 5,
          "frame_range": [
            8006,
            8010
          ],
          "representative_frame": 8006,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 66
    },
    {
      "second": 267,
      "time_range": [
        267,
        267.999
      ],
      "frame_range": [
        8011,
        8040
      ],
      "unified_description": "\nA man wearing glasses is pointing at something with his finger while holding a bottle in his hand. He is standing next to a backpack and a cup.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:27",
        "processing_time": 3.06,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8025,
          "frame_range": [
            8021,
            8025
          ],
          "description": "a man in a tent with a backpack and a cup",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.18
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8011,
            8015
          ],
          "representative_frame": 8011,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9495038390159607,
              "bbox": [
                310.97930908203125,
                1.1951147317886353,
                624.8020629882812,
                349.0202331542969
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6450350284576416,
              "bbox": [
                268.1917419433594,
                303.92730712890625,
                326.71929931640625,
                359.1546630859375
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.4371529817581177,
              "bbox": [
                36.29724884033203,
                54.59129333496094,
                174.3241729736328,
                248.90908813476562
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.41516315937042236,
              "bbox": [
                1.8258076906204224,
                83.43616485595703,
                65.03755950927734,
                331.11126708984375
              ]
            }
          ],
          "unique_tracks": [
            577,
            598,
            549,
            611
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            8016,
            8020
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8021,
            8025
          ],
          "representative_frame": 8021,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9347538352012634,
              "bbox": [
                313.4991149902344,
                0.8780788779258728,
                631.536865234375,
                352.5781555175781
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6963168382644653,
              "bbox": [
                160.5066680908203,
                340.02899169921875,
                230.87673950195312,
                360.0
              ]
            },
            {
              "track_id": 646,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.3374529480934143,
              "bbox": [
                111.78490447998047,
                146.08285522460938,
                188.99293518066406,
                210.5769500732422
              ]
            },
            {
              "track_id": 647,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.35461899638175964,
              "bbox": [
                119.99447631835938,
                175.26507568359375,
                210.46316528320312,
                274.6095886230469
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.34637847542762756,
              "bbox": [
                164.5900421142578,
                133.71368408203125,
                255.81585693359375,
                333.37005615234375
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6810886859893799,
              "bbox": [
                266.79803466796875,
                304.60614013671875,
                328.3543395996094,
                359.2446594238281
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.6565223336219788,
              "bbox": [
                37.22441101074219,
                56.80027770996094,
                174.95834350585938,
                248.15028381347656
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3756777048110962,
              "bbox": [
                0.9243791699409485,
                85.02125549316406,
                64.27743530273438,
                332.6090087890625
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            646,
            647,
            650,
            598,
            549,
            611
          ],
          "total_detections": 8
        },
        {
          "group_index": 3,
          "frame_range": [
            8026,
            8030
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8031,
            8035
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9385920166969299,
              "bbox": [
                306.5524597167969,
                0.22226236760616302,
                628.9182739257812,
                353.9943542480469
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.70845627784729,
              "bbox": [
                160.678955078125,
                340.03619384765625,
                231.02999877929688,
                360.0
              ]
            },
            {
              "track_id": 646,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.2101489007472992,
              "bbox": [
                111.87105560302734,
                146.0838165283203,
                188.8012237548828,
                210.3255615234375
              ]
            },
            {
              "track_id": 647,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.25086545944213867,
              "bbox": [
                120.33035278320312,
                175.32054138183594,
                210.9259033203125,
                274.8006286621094
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.20139570534229279,
              "bbox": [
                165.41090393066406,
                137.67596435546875,
                254.80763244628906,
                333.22869873046875
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.719292938709259,
              "bbox": [
                265.5951843261719,
                304.914306640625,
                329.6181640625,
                359.2928466796875
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.5663294196128845,
              "bbox": [
                36.8721923828125,
                57.526058197021484,
                175.51251220703125,
                248.22801208496094
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.45769673585891724,
              "bbox": [
                0.8382664918899536,
                85.7662582397461,
                64.53602600097656,
                333.7569274902344
              ]
            },
            {
              "track_id": 651,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.38455072045326233,
              "bbox": [
                285.735107421875,
                278.2958679199219,
                330.384033203125,
                343.3463439941406
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            646,
            647,
            650,
            598,
            549,
            611,
            651
          ],
          "total_detections": 9
        },
        {
          "group_index": 5,
          "frame_range": [
            8036,
            8040
          ],
          "representative_frame": 8036,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 66
    },
    {
      "second": 268,
      "time_range": [
        268,
        268.999
      ],
      "frame_range": [
        8041,
        8070
      ],
      "unified_description": "30 seconds of video featuring a man with a fishing rod inside a tent. The scene also includes multiple sports balls scattered around him.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:29",
        "processing_time": 2.97,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8055,
          "frame_range": [
            8051,
            8055
          ],
          "description": "a man in a hat and jacket is sitting next to a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.34
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8041,
            8045
          ],
          "representative_frame": 8041,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9383443593978882,
              "bbox": [
                299.9027099609375,
                0.4486452043056488,
                625.7906494140625,
                354.6112976074219
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7185695171356201,
              "bbox": [
                160.6860809326172,
                340.0345764160156,
                231.0509033203125,
                360.0
              ]
            },
            {
              "track_id": 646,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.1782827377319336,
              "bbox": [
                112.0142822265625,
                146.10946655273438,
                188.70907592773438,
                210.12600708007812
              ]
            },
            {
              "track_id": 647,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.14900141954421997,
              "bbox": [
                120.53988647460938,
                175.27304077148438,
                211.2177734375,
                274.84051513671875
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.13458985090255737,
              "bbox": [
                165.54217529296875,
                138.0707550048828,
                254.66844177246094,
                332.9001159667969
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7294853329658508,
              "bbox": [
                264.40753173828125,
                304.8670959472656,
                330.6588134765625,
                359.2572937011719
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.42906466126441956,
              "bbox": [
                36.01852035522461,
                57.674869537353516,
                175.8178253173828,
                248.3496551513672
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4679699242115021,
              "bbox": [
                1.2297269105911255,
                85.9064712524414,
                65.43782806396484,
                334.29779052734375
              ]
            },
            {
              "track_id": 651,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3731842637062073,
              "bbox": [
                285.41595458984375,
                278.12225341796875,
                330.6414794921875,
                344.031005859375
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.35604071617126465,
              "bbox": [
                277.3768310546875,
                196.67111206054688,
                353.4567565917969,
                266.2159423828125
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            646,
            647,
            650,
            598,
            549,
            611,
            651,
            653
          ],
          "total_detections": 10
        },
        {
          "group_index": 1,
          "frame_range": [
            8046,
            8050
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8051,
            8055
          ],
          "representative_frame": 8051,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8983263969421387,
              "bbox": [
                322.1054382324219,
                0.05025646090507507,
                640.0,
                355.4842224121094
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7177516222000122,
              "bbox": [
                160.61392211914062,
                340.01544189453125,
                231.06048583984375,
                360.0
              ]
            },
            {
              "track_id": 646,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.21083451807498932,
              "bbox": [
                112.7548828125,
                146.01663208007812,
                188.2949981689453,
                208.9998779296875
              ]
            },
            {
              "track_id": 647,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.12469696253538132,
              "bbox": [
                120.59027862548828,
                175.1923370361328,
                211.3203125,
                274.833740234375
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.1420917510986328,
              "bbox": [
                164.5265350341797,
                133.68955993652344,
                255.7467498779297,
                333.1707458496094
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5884374380111694,
              "bbox": [
                263.39251708984375,
                304.56884765625,
                331.6753234863281,
                359.1527404785156
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.5992873311042786,
              "bbox": [
                36.05835723876953,
                57.647132873535156,
                176.5907745361328,
                248.1451416015625
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.33091384172439575,
              "bbox": [
                0.9067584276199341,
                85.74657440185547,
                65.56268310546875,
                335.1447448730469
              ]
            },
            {
              "track_id": 651,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.36925023794174194,
              "bbox": [
                285.3174743652344,
                278.1474304199219,
                330.4917907714844,
                343.9823913574219
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.259699285030365,
              "bbox": [
                277.2196960449219,
                196.15122985839844,
                354.1013488769531,
                266.3919372558594
              ]
            },
            {
              "track_id": 659,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3309248089790344,
              "bbox": [
                239.18727111816406,
                262.8521423339844,
                264.32794189453125,
                296.92803955078125
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            646,
            647,
            650,
            598,
            549,
            611,
            651,
            653,
            659
          ],
          "total_detections": 11
        },
        {
          "group_index": 3,
          "frame_range": [
            8056,
            8060
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8061,
            8065
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.859757661819458,
              "bbox": [
                326.5896301269531,
                0.5601310729980469,
                640.0,
                355.9991760253906
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6887543201446533,
              "bbox": [
                160.5790557861328,
                340.02166748046875,
                231.01531982421875,
                359.9981994628906
              ]
            },
            {
              "track_id": 646,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.22723999619483948,
              "bbox": [
                113.01802062988281,
                145.98580932617188,
                188.19581604003906,
                208.57960510253906
              ]
            },
            {
              "track_id": 647,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.13491332530975342,
              "bbox": [
                120.64825439453125,
                175.15145874023438,
                211.37977600097656,
                274.8081359863281
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.15864160656929016,
              "bbox": [
                164.26409912109375,
                132.46957397460938,
                255.99452209472656,
                333.1331481933594
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.522554337978363,
              "bbox": [
                262.808837890625,
                304.4588928222656,
                332.69122314453125,
                359.1156921386719
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.5649957060813904,
              "bbox": [
                35.545982360839844,
                57.44453048706055,
                177.058349609375,
                248.17774963378906
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.36163529753685,
              "bbox": [
                1.0091758966445923,
                85.65120697021484,
                65.94821166992188,
                335.0978088378906
              ]
            },
            {
              "track_id": 651,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.30734360218048096,
              "bbox": [
                285.3262634277344,
                278.14349365234375,
                330.45916748046875,
                343.9186096191406
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.1961495727300644,
              "bbox": [
                277.1480407714844,
                195.9325408935547,
                354.3869934082031,
                266.446533203125
              ]
            },
            {
              "track_id": 659,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3202872574329376,
              "bbox": [
                239.20887756347656,
                262.9393310546875,
                264.3111572265625,
                296.95257568359375
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            646,
            647,
            650,
            598,
            549,
            611,
            651,
            653,
            659
          ],
          "total_detections": 11
        },
        {
          "group_index": 5,
          "frame_range": [
            8066,
            8070
          ],
          "representative_frame": 8066,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 67
    },
    {
      "second": 269,
      "time_range": [
        269,
        269.999
      ],
      "frame_range": [
        8071,
        8100
      ],
      "unified_description": "1-second video featuring a man wearing glasses, a hat, and possibly in a military uniform sitting next to a tent. There is also an item with a red lid present in the scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:30",
        "processing_time": 3.54,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8085,
          "frame_range": [
            8081,
            8085
          ],
          "description": "a man in a military uniform is sitting next to a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8071,
            8075
          ],
          "representative_frame": 8071,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8514448404312134,
              "bbox": [
                321.5810852050781,
                0.0,
                640.0,
                356.1910095214844
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.743587851524353,
              "bbox": [
                160.80747985839844,
                340.0617980957031,
                231.08709716796875,
                359.9900817871094
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.24023526906967163,
              "bbox": [
                165.0554656982422,
                136.07772827148438,
                255.1336669921875,
                332.8147277832031
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6028187870979309,
              "bbox": [
                262.7891540527344,
                304.3929443359375,
                334.0854187011719,
                359.1031188964844
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.22073671221733093,
              "bbox": [
                34.1169319152832,
                57.05022048950195,
                177.0792999267578,
                248.76834106445312
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2685353755950928,
              "bbox": [
                1.8059515953063965,
                85.6388168334961,
                66.9951400756836,
                333.8293762207031
              ]
            },
            {
              "track_id": 651,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.10268690437078476,
              "bbox": [
                285.2955017089844,
                278.22412109375,
                330.52935791015625,
                344.16668701171875
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2565721273422241,
              "bbox": [
                276.814208984375,
                195.3539581298828,
                354.64501953125,
                266.3569030761719
              ]
            },
            {
              "track_id": 659,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2961989641189575,
              "bbox": [
                239.71234130859375,
                263.1175231933594,
                264.2769775390625,
                296.38275146484375
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            650,
            598,
            549,
            611,
            651,
            653,
            659
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            8076,
            8080
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8081,
            8085
          ],
          "representative_frame": 8081,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9328076839447021,
              "bbox": [
                315.3712158203125,
                0.15476812422275543,
                638.098388671875,
                356.30743408203125
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7290010452270508,
              "bbox": [
                160.83865356445312,
                340.0501403808594,
                231.16665649414062,
                359.99261474609375
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2115788757801056,
              "bbox": [
                165.3726348876953,
                137.43319702148438,
                254.95309448242188,
                332.7576904296875
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.44960877299308777,
              "bbox": [
                257.48876953125,
                304.1228942871094,
                328.2451477050781,
                358.9582824707031
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.2770785391330719,
              "bbox": [
                33.28230285644531,
                56.932334899902344,
                177.11097717285156,
                248.85020446777344
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.33537527918815613,
              "bbox": [
                1.7749550342559814,
                85.25150299072266,
                67.50923919677734,
                333.9721984863281
              ]
            },
            {
              "track_id": 651,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.18492470681667328,
              "bbox": [
                285.6001892089844,
                278.5963134765625,
                330.0461120605469,
                343.3623352050781
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2975195646286011,
              "bbox": [
                276.71063232421875,
                195.4772186279297,
                354.4578552246094,
                266.3573913574219
              ]
            },
            {
              "track_id": 659,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.24169959127902985,
              "bbox": [
                239.69398498535156,
                263.20965576171875,
                264.1924133300781,
                296.35797119140625
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            650,
            598,
            549,
            611,
            651,
            653,
            659
          ],
          "total_detections": 9
        },
        {
          "group_index": 3,
          "frame_range": [
            8086,
            8090
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8091,
            8095
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8927926421165466,
              "bbox": [
                346.8075866699219,
                0.43130114674568176,
                640.0,
                356.0892639160156
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7499568462371826,
              "bbox": [
                160.84034729003906,
                340.0540466308594,
                231.1736297607422,
                359.9972839355469
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.2811225950717926,
              "bbox": [
                165.46922302246094,
                138.3148193359375,
                254.837158203125,
                332.83380126953125
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7135522961616516,
              "bbox": [
                260.02972412109375,
                304.2004699707031,
                331.91058349609375,
                359.05206298828125
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.5255730748176575,
              "bbox": [
                33.04704284667969,
                57.07278060913086,
                177.6902313232422,
                249.4958038330078
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3738633990287781,
              "bbox": [
                1.3884432315826416,
                84.92070007324219,
                67.47298431396484,
                333.9981994628906
              ]
            },
            {
              "track_id": 651,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.14509962499141693,
              "bbox": [
                285.7803039550781,
                278.8202209472656,
                329.8724670410156,
                343.0423583984375
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.27313700318336487,
              "bbox": [
                276.5315246582031,
                195.47874450683594,
                354.31121826171875,
                266.3570251464844
              ]
            },
            {
              "track_id": 659,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.26962918043136597,
              "bbox": [
                239.63523864746094,
                263.0598449707031,
                264.24627685546875,
                296.33782958984375
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            650,
            598,
            549,
            611,
            651,
            653,
            659
          ],
          "total_detections": 9
        },
        {
          "group_index": 5,
          "frame_range": [
            8096,
            8100
          ],
          "representative_frame": 8096,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 67
    },
    {
      "second": 270,
      "time_range": [
        270,
        270.999
      ],
      "frame_range": [
        8101,
        8130
      ],
      "unified_description": "1-second scene with a man sitting next to a green object holding by another man in a hat. The main person is wearing glasses and there are other people present as well.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:32",
        "processing_time": 3.45,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8115,
          "frame_range": [
            8111,
            8115
          ],
          "description": "a man in a tent with a backpack and a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.8
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8101,
            8105
          ],
          "representative_frame": 8101,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9447904229164124,
              "bbox": [
                329.689697265625,
                0.7298304438591003,
                640.0,
                354.9380798339844
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7409225702285767,
              "bbox": [
                160.8096160888672,
                340.04620361328125,
                231.17044067382812,
                359.9990539550781
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.3665713667869568,
              "bbox": [
                165.1295928955078,
                136.8960418701172,
                255.26004028320312,
                332.8912353515625
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7405303716659546,
              "bbox": [
                260.70086669921875,
                304.2088928222656,
                333.63006591796875,
                359.12176513671875
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.33412694931030273,
              "bbox": [
                32.08954620361328,
                56.94122314453125,
                177.39503479003906,
                249.44717407226562
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3781096339225769,
              "bbox": [
                1.252553105354309,
                84.8447265625,
                67.5353012084961,
                333.7138671875
              ]
            },
            {
              "track_id": 651,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.17230795323848724,
              "bbox": [
                285.8486328125,
                278.9329833984375,
                329.8294677734375,
                342.9439392089844
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.1968296617269516,
              "bbox": [
                276.40740966796875,
                195.3868408203125,
                354.2628173828125,
                266.31011962890625
              ]
            },
            {
              "track_id": 659,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2234199047088623,
              "bbox": [
                239.60093688964844,
                262.9795837402344,
                264.2921447753906,
                296.3420104980469
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            650,
            598,
            549,
            611,
            651,
            653,
            659
          ],
          "total_detections": 9
        },
        {
          "group_index": 1,
          "frame_range": [
            8106,
            8110
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8111,
            8115
          ],
          "representative_frame": 8111,
          "detections": [
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.909260094165802,
              "bbox": [
                313.3771667480469,
                1.146308422088623,
                630.8642578125,
                354.88824462890625
              ]
            },
            {
              "track_id": 644,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7436057329177856,
              "bbox": [
                160.8348846435547,
                340.0467834472656,
                231.1919403076172,
                359.99969482421875
              ]
            },
            {
              "track_id": 650,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.22883670032024384,
              "bbox": [
                164.97821044921875,
                136.4132080078125,
                255.38687133789062,
                332.76580810546875
              ]
            },
            {
              "track_id": 598,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7470622658729553,
              "bbox": [
                260.74530029296875,
                304.1885986328125,
                334.60614013671875,
                359.155029296875
              ]
            },
            {
              "track_id": 549,
              "class_id": 19,
              "class_name": "cow",
              "confidence": 0.38706520199775696,
              "bbox": [
                32.054805755615234,
                56.91496276855469,
                177.75555419921875,
                249.34225463867188
              ]
            },
            {
              "track_id": 611,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.38300633430480957,
              "bbox": [
                0.968189001083374,
                84.33783721923828,
                67.53019714355469,
                333.6414489746094
              ]
            },
            {
              "track_id": 651,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.15013976395130157,
              "bbox": [
                285.8249816894531,
                278.9306335449219,
                329.8511962890625,
                342.9665222167969
              ]
            },
            {
              "track_id": 653,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6094152331352234,
              "bbox": [
                276.7596740722656,
                196.034423828125,
                354.1123046875,
                266.3790283203125
              ]
            },
            {
              "track_id": 659,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.1899891048669815,
              "bbox": [
                239.4189453125,
                262.5805358886719,
                264.5299987792969,
                296.5281982421875
              ]
            },
            {
              "track_id": 664,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3373177945613861,
              "bbox": [
                361.00335693359375,
                278.00372314453125,
                412.08050537109375,
                310.3976135253906
              ]
            },
            {
              "track_id": 665,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.38157349824905396,
              "bbox": [
                28.626142501831055,
                56.5316047668457,
                179.64620971679688,
                249.93914794921875
              ]
            }
          ],
          "unique_tracks": [
            577,
            644,
            650,
            598,
            549,
            611,
            651,
            653,
            659,
            664,
            665
          ],
          "total_detections": 11
        },
        {
          "group_index": 3,
          "frame_range": [
            8116,
            8120
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8121,
            8125
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            8126,
            8130
          ],
          "representative_frame": 8126,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 67
    },
    {
      "second": 271,
      "time_range": [
        271,
        271.999
      ],
      "frame_range": [
        8131,
        8160
      ],
      "unified_description": "3D object tracking and image stabilization methods can provide more accurate and detailed descriptions of this scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:33",
        "processing_time": 2.99,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8145,
          "frame_range": [
            8141,
            8145
          ],
          "description": "a group of people are gathered around a stove",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.99
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8131,
            8135
          ],
          "representative_frame": 8131,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            8136,
            8140
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8141,
            8145
          ],
          "representative_frame": 8141,
          "detections": [
            {
              "track_id": 671,
              "class_id": 61,
              "class_name": "toilet",
              "confidence": 0.40502026677131653,
              "bbox": [
                228.294921875,
                47.965576171875,
                440.50689697265625,
                312.4706115722656
              ]
            }
          ],
          "unique_tracks": [
            671
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            8146,
            8150
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8151,
            8155
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 671,
              "class_id": 61,
              "class_name": "toilet",
              "confidence": 0.23577980697155,
              "bbox": [
                258.1995849609375,
                9.99492073059082,
                489.98883056640625,
                298.0068664550781
              ]
            },
            {
              "track_id": 639,
              "class_id": 61,
              "class_name": "toilet",
              "confidence": 0.40917307138442993,
              "bbox": [
                438.8185119628906,
                308.2851867675781,
                577.9846801757812,
                359.4863586425781
              ]
            },
            {
              "track_id": 577,
              "class_id": 61,
              "class_name": "toilet",
              "confidence": 0.36396849155426025,
              "bbox": [
                268.3017883300781,
                1.4933847188949585,
                590.361572265625,
                355.6514587402344
              ]
            }
          ],
          "unique_tracks": [
            671,
            639,
            577
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8156,
            8160
          ],
          "representative_frame": 8156,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 67
    },
    {
      "second": 272,
      "time_range": [
        272,
        272.999
      ],
      "frame_range": [
        8161,
        8190
      ],
      "unified_description": "3rd person perspective of someone placing a black frisbee on top of another frisbee. The scene takes place outdoors with some additional items nearby such as a backpack and a red, white and blue object in the foreground.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:35",
        "processing_time": 3.25,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8175,
          "frame_range": [
            8171,
            8175
          ],
          "description": "a man is putting a bucket with a blue bucket",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.04
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8161,
            8165
          ],
          "representative_frame": 8161,
          "detections": [
            {
              "track_id": 671,
              "class_id": 61,
              "class_name": "toilet",
              "confidence": 0.10355758666992188,
              "bbox": [
                262.89019775390625,
                19.68854522705078,
                482.1932373046875,
                291.12420654296875
              ]
            },
            {
              "track_id": 673,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4975804388523102,
              "bbox": [
                482.5943603515625,
                9.338061332702637,
                625.3853759765625,
                150.99044799804688
              ]
            },
            {
              "track_id": 674,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4772900938987732,
              "bbox": [
                168.36282348632812,
                313.0674133300781,
                300.2247314453125,
                359.67388916015625
              ]
            },
            {
              "track_id": 639,
              "class_id": 61,
              "class_name": "toilet",
              "confidence": 0.21374349296092987,
              "bbox": [
                434.2660827636719,
                306.1713562011719,
                584.9154663085938,
                359.5401611328125
              ]
            }
          ],
          "unique_tracks": [
            671,
            673,
            674,
            639
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            8166,
            8170
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8171,
            8175
          ],
          "representative_frame": 8171,
          "detections": [
            {
              "track_id": 673,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6623270511627197,
              "bbox": [
                473.4820861816406,
                21.41168785095215,
                614.237060546875,
                159.8958740234375
              ]
            },
            {
              "track_id": 674,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4128812849521637,
              "bbox": [
                162.09439086914062,
                312.7708740234375,
                294.39776611328125,
                359.5982971191406
              ]
            },
            {
              "track_id": 639,
              "class_id": 61,
              "class_name": "toilet",
              "confidence": 0.21796061098575592,
              "bbox": [
                430.3311462402344,
                306.02484130859375,
                585.7534790039062,
                359.2520751953125
              ]
            }
          ],
          "unique_tracks": [
            673,
            674,
            639
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8176,
            8180
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8181,
            8185
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.6907257437705994,
              "bbox": [
                499.7606201171875,
                185.05349731445312,
                626.7178955078125,
                336.5383605957031
              ]
            }
          ],
          "unique_tracks": [
            600
          ],
          "total_detections": 1
        },
        {
          "group_index": 5,
          "frame_range": [
            8186,
            8190
          ],
          "representative_frame": 8186,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 68
    },
    {
      "second": 273,
      "time_range": [
        273,
        273.999
      ],
      "frame_range": [
        8191,
        8220
      ],
      "unified_description": "360 video of camping site with man present",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:36",
        "processing_time": 3.09,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8205,
          "frame_range": [
            8201,
            8205
          ],
          "description": "a man is putting a cup in the ground",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.78
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8191,
            8195
          ],
          "representative_frame": 8191,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7715901732444763,
              "bbox": [
                419.7798767089844,
                227.16973876953125,
                521.2611694335938,
                318.98675537109375
              ]
            },
            {
              "track_id": 680,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.45889022946357727,
              "bbox": [
                236.22906494140625,
                144.47071838378906,
                442.6356506347656,
                330.958984375
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.3886028528213501,
              "bbox": [
                498.8221435546875,
                186.03599548339844,
                631.23779296875,
                337.7335510253906
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8196,
            8200
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8201,
            8205
          ],
          "representative_frame": 8201,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7599921822547913,
              "bbox": [
                419.9873046875,
                227.55429077148438,
                521.1891479492188,
                319.1032409667969
              ]
            },
            {
              "track_id": 680,
              "class_id": 29,
              "class_name": "frisbee",
              "confidence": 0.38338878750801086,
              "bbox": [
                236.07135009765625,
                147.77755737304688,
                441.5894470214844,
                333.3359375
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.48289158940315247,
              "bbox": [
                498.47869873046875,
                187.96441650390625,
                632.4344482421875,
                336.2998046875
              ]
            },
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6085454821586609,
              "bbox": [
                1.0232553482055664,
                10.058880805969238,
                378.55914306640625,
                351.37139892578125
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600,
            682
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            8206,
            8210
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8211,
            8215
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8860388398170471,
              "bbox": [
                419.83099365234375,
                227.43881225585938,
                521.2083740234375,
                319.1211242675781
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7275215983390808,
              "bbox": [
                231.909912109375,
                138.6117401123047,
                443.85906982421875,
                330.1499938964844
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.5746181011199951,
              "bbox": [
                496.4182434082031,
                188.0586395263672,
                633.4818115234375,
                336.4581604003906
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8216,
            8220
          ],
          "representative_frame": 8216,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 68
    },
    {
      "second": 274,
      "time_range": [
        274,
        274.999
      ],
      "frame_range": [
        8221,
        8250
      ],
      "unified_description": "1-second scene with an assortment of items outdoors including pots, bowls, backpacks, a person cooking, and some bottles.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:37",
        "processing_time": 3.21,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8235,
          "frame_range": [
            8231,
            8235
          ],
          "description": "a man is cooking food in a pot",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.73
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8221,
            8225
          ],
          "representative_frame": 8221,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8887909650802612,
              "bbox": [
                419.84332275390625,
                227.4036865234375,
                521.244384765625,
                319.07537841796875
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6459640264511108,
              "bbox": [
                231.22850036621094,
                136.34510803222656,
                443.9661560058594,
                328.80157470703125
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.5802865624427795,
              "bbox": [
                494.8475341796875,
                187.68479919433594,
                634.3840942382812,
                336.32958984375
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8226,
            8230
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8231,
            8235
          ],
          "representative_frame": 8231,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8632297515869141,
              "bbox": [
                419.706787109375,
                227.32159423828125,
                521.3927001953125,
                319.231689453125
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5951364636421204,
              "bbox": [
                231.18960571289062,
                135.4635772705078,
                444.48980712890625,
                328.7242431640625
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.3789713382720947,
              "bbox": [
                494.01007080078125,
                187.64593505859375,
                634.7186889648438,
                335.41107177734375
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8236,
            8240
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8241,
            8245
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8821757435798645,
              "bbox": [
                419.700439453125,
                227.23594665527344,
                521.4200439453125,
                319.15069580078125
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6559593677520752,
              "bbox": [
                230.81741333007812,
                135.5743408203125,
                443.2489013671875,
                328.1915588378906
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.3114747107028961,
              "bbox": [
                493.1903076171875,
                187.28343200683594,
                635.0178833007812,
                334.47320556640625
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8246,
            8250
          ],
          "representative_frame": 8246,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 68
    },
    {
      "second": 275,
      "time_range": [
        275,
        275.999
      ],
      "frame_range": [
        8251,
        8280
      ],
      "unified_description": "1-second video showing a person cooking some food on a camping trip. The camera is positioned overhead, capturing the scene from above. There are multiple objects in the image, including a tent, cooking pot, bowls, and various personal belongings. The video also features an interesting array of backpacks, indicating that this might be a backpacking or hiking adventure.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:39",
        "processing_time": 3.55,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8265,
          "frame_range": [
            8261,
            8265
          ],
          "description": "a man cooking food in a pot",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.79
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8251,
            8255
          ],
          "representative_frame": 8251,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.9072585701942444,
              "bbox": [
                419.7293395996094,
                227.31187438964844,
                521.3622436523438,
                319.0994567871094
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7953140139579773,
              "bbox": [
                231.6116180419922,
                134.2996368408203,
                444.4041748046875,
                327.72052001953125
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.35890188813209534,
              "bbox": [
                491.4747314453125,
                186.0122833251953,
                636.7249145507812,
                335.9140930175781
              ]
            },
            {
              "track_id": 635,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6049836874008179,
              "bbox": [
                0.0,
                185.79302978515625,
                303.0506591796875,
                355.9292907714844
              ]
            },
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.343718558549881,
              "bbox": [
                0.0,
                1.8646413087844849,
                331.8852233886719,
                350.34320068359375
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600,
            635,
            682
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            8256,
            8260
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8261,
            8265
          ],
          "representative_frame": 8261,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8990572690963745,
              "bbox": [
                419.5184020996094,
                227.2092742919922,
                521.3477783203125,
                319.1208801269531
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7914568781852722,
              "bbox": [
                230.37026977539062,
                134.42361450195312,
                442.76251220703125,
                327.6429138183594
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.37823861837387085,
              "bbox": [
                489.9778747558594,
                184.48220825195312,
                637.9656982421875,
                336.7066955566406
              ]
            },
            {
              "track_id": 693,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3228192627429962,
              "bbox": [
                163.31321716308594,
                232.11268615722656,
                200.51712036132812,
                297.80963134765625
              ]
            },
            {
              "track_id": 635,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6093676686286926,
              "bbox": [
                0.0,
                182.77401733398438,
                280.108642578125,
                355.90765380859375
              ]
            },
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.529945969581604,
              "bbox": [
                0.0,
                1.7106844186782837,
                336.70904541015625,
                351.978759765625
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600,
            693,
            635,
            682
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            8266,
            8270
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8271,
            8275
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.9073889851570129,
              "bbox": [
                419.4505615234375,
                227.13198852539062,
                521.3936157226562,
                319.1035461425781
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.9021164774894714,
              "bbox": [
                230.39068603515625,
                135.43756103515625,
                440.9078063964844,
                326.8916015625
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.33431708812713623,
              "bbox": [
                489.18524169921875,
                183.95924377441406,
                638.5169677734375,
                337.1451416015625
              ]
            },
            {
              "track_id": 693,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.35786837339401245,
              "bbox": [
                163.4328155517578,
                232.030517578125,
                200.50033569335938,
                297.47052001953125
              ]
            },
            {
              "track_id": 635,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.60030597448349,
              "bbox": [
                0.0,
                182.0198974609375,
                262.7467346191406,
                355.9869384765625
              ]
            },
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.654940128326416,
              "bbox": [
                0.0,
                18.783266067504883,
                324.7594299316406,
                352.7079162597656
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600,
            693,
            635,
            682
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            8276,
            8280
          ],
          "representative_frame": 8276,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 68
    },
    {
      "second": 276,
      "time_range": [
        276,
        276.999
      ],
      "frame_range": [
        8281,
        8310
      ],
      "unified_description": "360-degree image with an overhead view, capturing multiple objects including a yellow pan, blue backpacks, and other items.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:40",
        "processing_time": 3.82,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8295,
          "frame_range": [
            8291,
            8295
          ],
          "description": "a group of people sitting under a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.83
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8281,
            8285
          ],
          "representative_frame": 8281,
          "detections": [
            {
              "track_id": 678,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8672164082527161,
              "bbox": [
                419.453125,
                227.5155487060547,
                521.4509887695312,
                319.541015625
              ]
            },
            {
              "track_id": 680,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8573867678642273,
              "bbox": [
                232.0493621826172,
                136.7130889892578,
                441.732177734375,
                327.8148498535156
              ]
            },
            {
              "track_id": 600,
              "class_id": 16,
              "class_name": "dog",
              "confidence": 0.1677524894475937,
              "bbox": [
                482.0130920410156,
                163.67510986328125,
                640.0,
                333.7101745605469
              ]
            },
            {
              "track_id": 693,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2426934540271759,
              "bbox": [
                162.9453125,
                231.5080108642578,
                200.4344940185547,
                297.7569274902344
              ]
            },
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5841145515441895,
              "bbox": [
                0.0,
                14.225756645202637,
                320.4797058105469,
                352.8753356933594
              ]
            },
            {
              "track_id": 698,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5652976036071777,
              "bbox": [
                587.1342163085938,
                283.06121826171875,
                640.0,
                358.66229248046875
              ]
            }
          ],
          "unique_tracks": [
            678,
            680,
            600,
            693,
            682,
            698
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            8286,
            8290
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8291,
            8295
          ],
          "representative_frame": 8291,
          "detections": [
            {
              "track_id": 680,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.13636229932308197,
              "bbox": [
                213.64532470703125,
                150.32518005371094,
                433.9620361328125,
                347.11328125
              ]
            }
          ],
          "unique_tracks": [
            680
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            8296,
            8300
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8301,
            8305
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4272075295448303,
              "bbox": [
                268.33111572265625,
                0.603424072265625,
                440.5166931152344,
                173.4474334716797
              ]
            },
            {
              "track_id": 705,
              "class_id": 28,
              "class_name": "suitcase",
              "confidence": 0.445965439081192,
              "bbox": [
                466.2825622558594,
                35.64337921142578,
                562.7267456054688,
                100.0042495727539
              ]
            }
          ],
          "unique_tracks": [
            701,
            705
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            8306,
            8310
          ],
          "representative_frame": 8306,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 69
    },
    {
      "second": 277,
      "time_range": [
        277,
        277.999
      ],
      "frame_range": [
        8311,
        8340
      ],
      "unified_description": "1 second video with multiple objects and a person.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:41",
        "processing_time": 3.76,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8325,
          "frame_range": [
            8321,
            8325
          ],
          "description": "a man is kneeling down to a small child",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.65
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8311,
            8315
          ],
          "representative_frame": 8311,
          "detections": [
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5744313597679138,
              "bbox": [
                264.35736083984375,
                0.958890974521637,
                453.8680419921875,
                190.62742614746094
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5114699602127075,
              "bbox": [
                314.7013244628906,
                172.41746520996094,
                538.88037109375,
                356.6984558105469
              ]
            },
            {
              "track_id": 680,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3324994742870331,
              "bbox": [
                218.79037475585938,
                171.3256072998047,
                426.96875,
                355.3582763671875
              ]
            }
          ],
          "unique_tracks": [
            701,
            577,
            680
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8316,
            8320
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8321,
            8325
          ],
          "representative_frame": 8321,
          "detections": [
            {
              "track_id": 647,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.526203453540802,
              "bbox": [
                80.35899353027344,
                179.9204559326172,
                179.03451538085938,
                282.05706787109375
              ]
            }
          ],
          "unique_tracks": [
            647
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            8326,
            8330
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8331,
            8335
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 647,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.49859169125556946,
              "bbox": [
                56.49880599975586,
                176.49176025390625,
                175.44189453125,
                300.2080383300781
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2886229455471039,
              "bbox": [
                306.50152587890625,
                183.2107391357422,
                514.86572265625,
                356.5336608886719
              ]
            }
          ],
          "unique_tracks": [
            647,
            577
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            8336,
            8340
          ],
          "representative_frame": 8336,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 69
    },
    {
      "second": 278,
      "time_range": [
        278,
        278.999
      ],
      "frame_range": [
        8341,
        8370
      ],
      "unified_description": "3rd person perspective video of a man with a green hat holding a black frisbee inside a white bowl.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:43",
        "processing_time": 2.84,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8355,
          "frame_range": [
            8351,
            8355
          ],
          "description": "a man is sitting under a tent with a dog",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.04
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8341,
            8345
          ],
          "representative_frame": 8341,
          "detections": [
            {
              "track_id": 647,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.32130172848701477,
              "bbox": [
                34.635581970214844,
                164.5151824951172,
                169.9696807861328,
                307.0030517578125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.44250601530075073,
              "bbox": [
                314.8825378417969,
                2.6395263671875,
                583.1942749023438,
                295.9870300292969
              ]
            },
            {
              "track_id": 577,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2128419727087021,
              "bbox": [
                295.24102783203125,
                172.2912139892578,
                517.8662719726562,
                355.9223327636719
              ]
            }
          ],
          "unique_tracks": [
            647,
            715,
            577
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8346,
            8350
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8351,
            8355
          ],
          "representative_frame": 8351,
          "detections": [
            {
              "track_id": 647,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.17545238137245178,
              "bbox": [
                22.287738800048828,
                166.4137420654297,
                156.27357482910156,
                308.79376220703125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2572386562824249,
              "bbox": [
                309.56817626953125,
                1.8953096866607666,
                564.221435546875,
                279.80242919921875
              ]
            },
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.184891015291214,
              "bbox": [
                303.7881164550781,
                167.9728546142578,
                506.6920471191406,
                337.985595703125
              ]
            }
          ],
          "unique_tracks": [
            647,
            715,
            577
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8356,
            8360
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8361,
            8365
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.34533172845840454,
              "bbox": [
                317.001220703125,
                1.7392675876617432,
                576.7523193359375,
                283.37335205078125
              ]
            },
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4611983299255371,
              "bbox": [
                301.8240966796875,
                169.36178588867188,
                504.07562255859375,
                341.9311218261719
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.39181458950042725,
              "bbox": [
                495.9150390625,
                126.61155700683594,
                640.0,
                297.1492004394531
              ]
            }
          ],
          "unique_tracks": [
            715,
            577,
            600
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8366,
            8370
          ],
          "representative_frame": 8366,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 69
    },
    {
      "second": 279,
      "time_range": [
        279,
        279.999
      ],
      "frame_range": [
        8371,
        8400
      ],
      "unified_description": "\nThis image appears to be from a first-person perspective camera mounted on the person's helmet, showing them holding a bowl with a knife in it. The scene takes place outdoors, likely during a camping trip. There are two other people present in the scene, one of whom is also holding a camera. Various objects such as bowls, knives, and cameras can be seen in the image along with some backpacks placed around the area.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:45",
        "processing_time": 3.82,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8385,
          "frame_range": [
            8381,
            8385
          ],
          "description": "a man is sitting in the grass with a knife",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8371,
            8375
          ],
          "representative_frame": 8371,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4618159532546997,
              "bbox": [
                308.7461853027344,
                151.8022003173828,
                516.3775634765625,
                331.1743469238281
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5912972092628479,
              "bbox": [
                477.04718017578125,
                122.66627502441406,
                640.0,
                307.6696472167969
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.752717912197113,
              "bbox": [
                162.16787719726562,
                1.0691297054290771,
                484.0007019042969,
                328.40191650390625
              ]
            }
          ],
          "unique_tracks": [
            577,
            600,
            701
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8376,
            8380
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8381,
            8385
          ],
          "representative_frame": 8381,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5138702392578125,
              "bbox": [
                308.16119384765625,
                144.00758361816406,
                518.0050659179688,
                326.0974426269531
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.2848127484321594,
              "bbox": [
                477.4794006347656,
                118.00899505615234,
                640.0,
                305.511474609375
              ]
            },
            {
              "track_id": 719,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.5395159125328064,
              "bbox": [
                487.6485900878906,
                71.42515563964844,
                580.83251953125,
                129.50759887695312
              ]
            },
            {
              "track_id": 721,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.47850292921066284,
              "bbox": [
                47.951168060302734,
                62.9456787109375,
                579.990478515625,
                352.05157470703125
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7856190204620361,
              "bbox": [
                152.9789276123047,
                1.289709448814392,
                478.1614685058594,
                336.64312744140625
              ]
            }
          ],
          "unique_tracks": [
            577,
            600,
            719,
            721,
            701
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            8386,
            8390
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8391,
            8395
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3910767734050751,
              "bbox": [
                312.6521911621094,
                146.31317138671875,
                517.3936157226562,
                324.65411376953125
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.3671460747718811,
              "bbox": [
                486.97100830078125,
                125.76296997070312,
                640.0,
                300.20599365234375
              ]
            },
            {
              "track_id": 719,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.48407402634620667,
              "bbox": [
                487.7420349121094,
                72.06672668457031,
                581.8087158203125,
                130.75094604492188
              ]
            },
            {
              "track_id": 721,
              "class_id": 3,
              "class_name": "motorcycle",
              "confidence": 0.17653438448905945,
              "bbox": [
                0.0,
                11.973152160644531,
                621.149169921875,
                350.84423828125
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7905701398849487,
              "bbox": [
                158.45635986328125,
                1.586763620376587,
                456.6051025390625,
                306.9786682128906
              ]
            }
          ],
          "unique_tracks": [
            577,
            600,
            719,
            721,
            701
          ],
          "total_detections": 5
        },
        {
          "group_index": 5,
          "frame_range": [
            8396,
            8400
          ],
          "representative_frame": 8396,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 69
    },
    {
      "second": 280,
      "time_range": [
        280,
        280.999
      ],
      "frame_range": [
        8401,
        8430
      ],
      "unified_description": "30 seconds of footage featuring a person cooking in a tent. The scene includes multiple objects like bowls, blue plates, pots, bottles, backpacks, and an oven. The camera's perspective is first-person, providing a close-up view of the cooking process.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:47",
        "processing_time": 4.87,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8415,
          "frame_range": [
            8411,
            8415
          ],
          "description": "a man is cooking food in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.58
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8401,
            8405
          ],
          "representative_frame": 8401,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4902665615081787,
              "bbox": [
                308.1658935546875,
                158.9306640625,
                509.0430603027344,
                331.8301696777344
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6282799243927002,
              "bbox": [
                478.8171691894531,
                40.861454010009766,
                640.0,
                267.82232666015625
              ]
            },
            {
              "track_id": 719,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.37701237201690674,
              "bbox": [
                492.8141174316406,
                73.91069030761719,
                579.959716796875,
                128.18003845214844
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7612797021865845,
              "bbox": [
                172.62564086914062,
                1.6293494701385498,
                454.2549743652344,
                286.53802490234375
              ]
            },
            {
              "track_id": 674,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6506497859954834,
              "bbox": [
                35.9478645324707,
                244.8920135498047,
                326.12835693359375,
                358.51519775390625
              ]
            }
          ],
          "unique_tracks": [
            577,
            600,
            719,
            701,
            674
          ],
          "total_detections": 5
        },
        {
          "group_index": 1,
          "frame_range": [
            8406,
            8410
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8411,
            8415
          ],
          "representative_frame": 8411,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.46236303448677063,
              "bbox": [
                313.95928955078125,
                154.2886962890625,
                517.34033203125,
                330.7557373046875
              ]
            },
            {
              "track_id": 719,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.15343071520328522,
              "bbox": [
                500.6068115234375,
                77.19068908691406,
                570.9297485351562,
                120.60025024414062
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5027593970298767,
              "bbox": [
                175.01275634765625,
                1.6494863033294678,
                452.1273193359375,
                281.5623779296875
              ]
            }
          ],
          "unique_tracks": [
            577,
            719,
            701
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8416,
            8420
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8421,
            8425
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4609783887863159,
              "bbox": [
                328.3043518066406,
                154.0300750732422,
                526.981689453125,
                328.14691162109375
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6800786256790161,
              "bbox": [
                208.76718139648438,
                1.3990789651870728,
                435.1009216308594,
                223.67259216308594
              ]
            },
            {
              "track_id": 730,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4859764277935028,
              "bbox": [
                520.715087890625,
                95.58621215820312,
                638.23095703125,
                225.108154296875
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.47477707266807556,
              "bbox": [
                485.02459716796875,
                6.3365278244018555,
                640.0,
                232.6030731201172
              ]
            }
          ],
          "unique_tracks": [
            577,
            701,
            730,
            600
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            8426,
            8430
          ],
          "representative_frame": 8426,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 70
    },
    {
      "second": 281,
      "time_range": [
        281,
        281.999
      ],
      "frame_range": [
        8431,
        8460
      ],
      "unified_description": "32 frames of video input needed for accurate representation of scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:48",
        "processing_time": 4.26,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8445,
          "frame_range": [
            8441,
            8445
          ],
          "description": "a man is cooking food in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.62
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8431,
            8435
          ],
          "representative_frame": 8431,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5005574226379395,
              "bbox": [
                346.1760559082031,
                157.2196044921875,
                540.966552734375,
                330.2109069824219
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7041968703269958,
              "bbox": [
                230.32183837890625,
                1.2454559803009033,
                416.58636474609375,
                179.60537719726562
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5108651518821716,
              "bbox": [
                448.23382568359375,
                0.10980909317731857,
                640.0,
                248.48951721191406
              ]
            }
          ],
          "unique_tracks": [
            577,
            701,
            600
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8436,
            8440
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8441,
            8445
          ],
          "representative_frame": 8441,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6114435791969299,
              "bbox": [
                376.3225402832031,
                163.2926788330078,
                563.56396484375,
                331.3927001953125
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4970749020576477,
              "bbox": [
                443.0359191894531,
                35.84638595581055,
                622.6973266601562,
                243.62789916992188
              ]
            }
          ],
          "unique_tracks": [
            577,
            600
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            8446,
            8450
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8451,
            8455
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 577,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5310240983963013,
              "bbox": [
                391.31732177734375,
                168.60789489746094,
                574.8035888671875,
                334.28790283203125
              ]
            },
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7816324234008789,
              "bbox": [
                442.64276123046875,
                9.857368469238281,
                618.9537353515625,
                207.33787536621094
              ]
            },
            {
              "track_id": 743,
              "class_id": 48,
              "class_name": "sandwich",
              "confidence": 0.5294140577316284,
              "bbox": [
                261.8804931640625,
                91.23816680908203,
                351.46002197265625,
                175.75775146484375
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.4756387174129486,
              "bbox": [
                265.79864501953125,
                0.9498291611671448,
                426.2525329589844,
                151.1443328857422
              ]
            }
          ],
          "unique_tracks": [
            577,
            600,
            743,
            701
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            8456,
            8460
          ],
          "representative_frame": 8456,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 70
    },
    {
      "second": 282,
      "time_range": [
        282,
        282.999
      ],
      "frame_range": [
        8461,
        8490
      ],
      "unified_description": "2 people in a tent, one adult male and one young boy. They appear to be eating food and discussing something. The adult man is wearing glasses which can be seen clearly. There is also a baseball cap visible in the scene. The tent appears to be a mess tent as there are numerous bowls, spoons, and a backpack present. The image captures their daily life and interaction with each other while sharing a meal inside the tent.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:50",
        "processing_time": 3.87,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8475,
          "frame_range": [
            8471,
            8475
          ],
          "description": "a man in a tent with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.91
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8461,
            8465
          ],
          "representative_frame": 8461,
          "detections": [
            {
              "track_id": 600,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.635389506816864,
              "bbox": [
                461.4066467285156,
                1.14967679977417,
                626.8309936523438,
                184.2535400390625
              ]
            },
            {
              "track_id": 701,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6334195137023926,
              "bbox": [
                259.2773132324219,
                0.4213605225086212,
                447.4657897949219,
                176.5860137939453
              ]
            }
          ],
          "unique_tracks": [
            600,
            701
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            8466,
            8470
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8471,
            8475
          ],
          "representative_frame": 8471,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8189634084701538,
              "bbox": [
                33.6370964050293,
                44.43655776977539,
                328.28753662109375,
                353.44744873046875
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.6937017440795898,
              "bbox": [
                345.83135986328125,
                1.3944975137710571,
                640.0,
                352.10906982421875
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            8476,
            8480
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8481,
            8485
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7572672367095947,
              "bbox": [
                53.03411102294922,
                45.3379020690918,
                322.8703918457031,
                352.07843017578125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7001845836639404,
              "bbox": [
                349.8866271972656,
                8.426109313964844,
                640.0,
                355.20751953125
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            8486,
            8490
          ],
          "representative_frame": 8486,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 70
    },
    {
      "second": 283,
      "time_range": [
        283,
        283.999
      ],
      "frame_range": [
        8491,
        8520
      ],
      "unified_description": "2 men are having conversation while one is eating food in a tent. Camera was placed on a tripod with wide-angle lens, capturing the entire scene.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:51",
        "processing_time": 3.52,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8505,
          "frame_range": [
            8501,
            8505
          ],
          "description": "two men sitting in a tent with a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.96
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8491,
            8495
          ],
          "representative_frame": 8491,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7193369269371033,
              "bbox": [
                59.31637191772461,
                45.531715393066406,
                313.7701110839844,
                352.4110412597656
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9137688279151917,
              "bbox": [
                384.610107421875,
                3.6454195976257324,
                640.0,
                357.5373840332031
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            8496,
            8500
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8501,
            8505
          ],
          "representative_frame": 8501,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7003128528594971,
              "bbox": [
                63.62644958496094,
                45.03269958496094,
                307.26226806640625,
                353.7634582519531
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9067030549049377,
              "bbox": [
                402.3805236816406,
                1.4448202848434448,
                640.0,
                357.2315368652344
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            8506,
            8510
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8511,
            8515
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7570958733558655,
              "bbox": [
                68.29850769042969,
                44.939353942871094,
                302.17669677734375,
                353.802001953125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9430510401725769,
              "bbox": [
                409.10382080078125,
                1.1100302934646606,
                640.0,
                357.3575134277344
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            8516,
            8520
          ],
          "representative_frame": 8516,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 70
    },
    {
      "second": 284,
      "time_range": [
        284,
        284.999
      ],
      "frame_range": [
        8521,
        8550
      ],
      "unified_description": "2 people in a tent, one is likely to be a young boy. They are sitting down and having food from bowls. There is a man holding a blue bowl and talking to the other person. The scene takes place in an outdoor setting with a visible backpack nearby.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:53",
        "processing_time": 4.29,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8535,
          "frame_range": [
            8531,
            8535
          ],
          "description": "two men are sitting in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.73
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8521,
            8525
          ],
          "representative_frame": 8521,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7832171320915222,
              "bbox": [
                70.71913146972656,
                45.593772888183594,
                296.3458557128906,
                353.0531921386719
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9456557035446167,
              "bbox": [
                409.611572265625,
                0.7806121706962585,
                640.0,
                356.3418884277344
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            8526,
            8530
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8531,
            8535
          ],
          "representative_frame": 8531,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8162623047828674,
              "bbox": [
                67.50647735595703,
                46.045082092285156,
                288.5345153808594,
                353.3917236328125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9279364943504333,
              "bbox": [
                412.5677795410156,
                0.5387188792228699,
                640.0,
                355.34051513671875
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            8536,
            8540
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8541,
            8545
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7777233719825745,
              "bbox": [
                65.12696838378906,
                45.330833435058594,
                283.48211669921875,
                353.9430236816406
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9459239840507507,
              "bbox": [
                415.4972839355469,
                0.5613887906074524,
                640.0,
                355.6762390136719
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            8546,
            8550
          ],
          "representative_frame": 8546,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 71
    },
    {
      "second": 285,
      "time_range": [
        285,
        285.999
      ],
      "frame_range": [
        8551,
        8580
      ],
      "unified_description": "2 men are sitting down under a tent while eating something out of a bowl.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:54",
        "processing_time": 3.05,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8565,
          "frame_range": [
            8561,
            8565
          ],
          "description": "two men in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.88
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8551,
            8555
          ],
          "representative_frame": 8551,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.7085879445075989,
              "bbox": [
                73.93081665039062,
                37.827754974365234,
                291.0812683105469,
                353.801025390625
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9274218678474426,
              "bbox": [
                407.85150146484375,
                0.3288797438144684,
                640.0,
                355.0831298828125
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            8556,
            8560
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8561,
            8565
          ],
          "representative_frame": 8561,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8675175905227661,
              "bbox": [
                79.11580657958984,
                35.002159118652344,
                292.4574279785156,
                353.5606994628906
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9399844408035278,
              "bbox": [
                414.764404296875,
                0.3177465498447418,
                640.0,
                354.16729736328125
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7842220664024353,
              "bbox": [
                463.6563720703125,
                203.34786987304688,
                525.0075073242188,
                230.76992797851562
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8566,
            8570
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8571,
            8575
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8527374863624573,
              "bbox": [
                82.85652160644531,
                34.360355377197266,
                291.4578857421875,
                353.0081481933594
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.93369060754776,
              "bbox": [
                411.584228515625,
                0.4037875831127167,
                640.0,
                354.9322814941406
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8023021221160889,
              "bbox": [
                462.8555908203125,
                206.2093048095703,
                524.263427734375,
                233.5117645263672
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8576,
            8580
          ],
          "representative_frame": 8576,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 71
    },
    {
      "second": 286,
      "time_range": [
        286,
        286.999
      ],
      "frame_range": [
        8581,
        8610
      ],
      "unified_description": "2 men are sitting under a tent and eating. One man is wearing a hat with letters on it while the other man is sitting next to him. A bowl can be seen in front of them, and they seem to be enjoying their meal together.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:56",
        "processing_time": 3.45,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8595,
          "frame_range": [
            8591,
            8595
          ],
          "description": "two men sitting in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.95
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8581,
            8585
          ],
          "representative_frame": 8581,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8456036448478699,
              "bbox": [
                85.22021484375,
                34.13063049316406,
                289.8560791015625,
                352.98736572265625
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9355683326721191,
              "bbox": [
                405.9984130859375,
                0.41338202357292175,
                640.0,
                354.9429016113281
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6487619876861572,
              "bbox": [
                461.7823791503906,
                204.8396453857422,
                526.7835693359375,
                233.59552001953125
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8586,
            8590
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8591,
            8595
          ],
          "representative_frame": 8591,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8488779664039612,
              "bbox": [
                86.87686920166016,
                33.95787048339844,
                287.97088623046875,
                353.01043701171875
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9455877542495728,
              "bbox": [
                412.9900817871094,
                0.9673503041267395,
                640.0,
                355.7232971191406
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            8596,
            8600
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8601,
            8605
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.839895486831665,
              "bbox": [
                88.5030746459961,
                33.826194763183594,
                286.4043884277344,
                353.01470947265625
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9446759223937988,
              "bbox": [
                409.9608154296875,
                0.8556731939315796,
                640.0,
                355.66265869140625
              ]
            },
            {
              "track_id": 759,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.7259524464607239,
              "bbox": [
                464.9008483886719,
                171.54617309570312,
                548.384521484375,
                199.11378479003906
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            759
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8606,
            8610
          ],
          "representative_frame": 8606,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 71
    },
    {
      "second": 287,
      "time_range": [
        287,
        287.999
      ],
      "frame_range": [
        8611,
        8640
      ],
      "unified_description": "3D model of a man and boy eating inside a tent.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:57",
        "processing_time": 3.02,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8625,
          "frame_range": [
            8621,
            8625
          ],
          "description": "a man in a tent with a child",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.85
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8611,
            8615
          ],
          "representative_frame": 8611,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8422041535377502,
              "bbox": [
                88.70318603515625,
                35.19291305541992,
                284.1007385253906,
                354.2685241699219
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9156575202941895,
              "bbox": [
                427.8829345703125,
                0.6649968028068542,
                640.0,
                354.2335205078125
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7317802309989929,
              "bbox": [
                467.89349365234375,
                198.9252166748047,
                552.0379638671875,
                236.32229614257812
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8616,
            8620
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8621,
            8625
          ],
          "representative_frame": 8621,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.816788375377655,
              "bbox": [
                88.86784362792969,
                36.35239791870117,
                281.3891906738281,
                354.3350830078125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9046206474304199,
              "bbox": [
                433.9285583496094,
                0.5778802633285522,
                640.0,
                354.46209716796875
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.776271641254425,
              "bbox": [
                470.542724609375,
                200.1566162109375,
                553.1212768554688,
                236.90992736816406
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8626,
            8630
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8631,
            8635
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8440826535224915,
              "bbox": [
                88.84568786621094,
                38.850433349609375,
                278.4687805175781,
                354.5103454589844
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9122850298881531,
              "bbox": [
                440.0517883300781,
                0.6097180843353271,
                640.0,
                354.3954772949219
              ]
            },
            {
              "track_id": 752,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.656849205493927,
              "bbox": [
                471.0250549316406,
                201.4739532470703,
                555.156494140625,
                238.955078125
              ]
            },
            {
              "track_id": 763,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5201357007026672,
              "bbox": [
                469.4204406738281,
                202.04994201660156,
                553.7750854492188,
                239.02850341796875
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752,
            763
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            8636,
            8640
          ],
          "representative_frame": 8636,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 71
    },
    {
      "second": 288,
      "time_range": [
        288,
        288.999
      ],
      "frame_range": [
        8641,
        8670
      ],
      "unified_description": "360-degree video of a father and son camping with a pot and food in front of them.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:32:58",
        "processing_time": 3.14,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8655,
          "frame_range": [
            8651,
            8655
          ],
          "description": "a man and a boy are sitting in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8641,
            8645
          ],
          "representative_frame": 8641,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8495498299598694,
              "bbox": [
                88.97891998291016,
                40.80047607421875,
                276.20867919921875,
                354.4305725097656
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9026899337768555,
              "bbox": [
                441.5154113769531,
                0.8926835060119629,
                640.0,
                354.6441650390625
              ]
            },
            {
              "track_id": 752,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.4565008580684662,
              "bbox": [
                468.2552185058594,
                202.44366455078125,
                553.8851928710938,
                240.8988037109375
              ]
            },
            {
              "track_id": 763,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7620696425437927,
              "bbox": [
                465.6752014160156,
                202.82542419433594,
                552.0367431640625,
                240.77630615234375
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752,
            763
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            8646,
            8650
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8651,
            8655
          ],
          "representative_frame": 8651,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8456276655197144,
              "bbox": [
                88.96011352539062,
                39.093101501464844,
                275.8426513671875,
                353.7221984863281
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.908703088760376,
              "bbox": [
                443.06005859375,
                0.6649316549301147,
                640.0,
                354.0298767089844
              ]
            },
            {
              "track_id": 752,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.41688382625579834,
              "bbox": [
                465.94805908203125,
                203.41708374023438,
                557.1975708007812,
                244.8612060546875
              ]
            },
            {
              "track_id": 763,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7960022687911987,
              "bbox": [
                462.5259094238281,
                203.85711669921875,
                555.377197265625,
                244.86305236816406
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752,
            763
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            8656,
            8660
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8661,
            8665
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8554278612136841,
              "bbox": [
                88.0731201171875,
                37.20601272583008,
                276.0299377441406,
                354.4512023925781
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.906449019908905,
              "bbox": [
                444.3797912597656,
                0.6359472274780273,
                640.0,
                353.605224609375
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7995142936706543,
              "bbox": [
                464.2357177734375,
                203.77716064453125,
                555.8631591796875,
                245.91915893554688
              ]
            },
            {
              "track_id": 763,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.40838250517845154,
              "bbox": [
                461.25750732421875,
                204.13128662109375,
                556.6185913085938,
                246.53016662597656
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752,
            763
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            8666,
            8670
          ],
          "representative_frame": 8666,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 72
    },
    {
      "second": 289,
      "time_range": [
        289,
        289.999
      ],
      "frame_range": [
        8671,
        8700
      ],
      "unified_description": "1 second of a young man eating while an older man watches him. They are both sitting in a tent with various objects around them.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:33:00",
        "processing_time": 2.91,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8685,
          "frame_range": [
            8681,
            8685
          ],
          "description": "two men are sitting in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.9
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8671,
            8675
          ],
          "representative_frame": 8671,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8871050477027893,
              "bbox": [
                73.20134735107422,
                34.74254608154297,
                264.8244934082031,
                354.36376953125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9571120738983154,
              "bbox": [
                380.9923400878906,
                1.5040154457092285,
                605.701171875,
                353.72674560546875
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            8676,
            8680
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8681,
            8685
          ],
          "representative_frame": 8681,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8757275342941284,
              "bbox": [
                66.75669860839844,
                33.5145263671875,
                260.9463806152344,
                354.0548095703125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9536450505256653,
              "bbox": [
                344.92462158203125,
                1.68590247631073,
                583.8524780273438,
                353.60174560546875
              ]
            },
            {
              "track_id": 766,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.7807235717773438,
              "bbox": [
                216.04867553710938,
                164.69056701660156,
                327.7060852050781,
                210.07667541503906
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            766
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8686,
            8690
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8691,
            8695
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8792321681976318,
              "bbox": [
                63.801177978515625,
                33.051849365234375,
                259.9656677246094,
                353.876708984375
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9584642052650452,
              "bbox": [
                322.0100402832031,
                0.587548017501831,
                576.3458862304688,
                354.53900146484375
              ]
            },
            {
              "track_id": 766,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6851165890693665,
              "bbox": [
                211.98846435546875,
                164.7470245361328,
                328.4535827636719,
                212.16419982910156
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            766
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8696,
            8700
          ],
          "representative_frame": 8696,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 72
    },
    {
      "second": 290,
      "time_range": [
        290,
        290.999
      ],
      "frame_range": [
        8701,
        8730
      ],
      "unified_description": "4 unique objects, 6 groups, 1 second",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:33:01",
        "processing_time": 2.8,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8715,
          "frame_range": [
            8711,
            8715
          ],
          "description": "a man and a boy are eating food in a tent",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.03
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8701,
            8705
          ],
          "representative_frame": 8701,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8877875804901123,
              "bbox": [
                62.450927734375,
                32.78465270996094,
                260.4859924316406,
                353.9217224121094
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9576496481895447,
              "bbox": [
                324.8580627441406,
                1.578284740447998,
                587.596923828125,
                354.2195739746094
              ]
            },
            {
              "track_id": 766,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.44481605291366577,
              "bbox": [
                209.75682067871094,
                166.4156494140625,
                327.0044860839844,
                214.2496795654297
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            766
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8706,
            8710
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8711,
            8715
          ],
          "representative_frame": 8711,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8989514708518982,
              "bbox": [
                65.22457885742188,
                31.81869888305664,
                264.4819030761719,
                353.897705078125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9591394662857056,
              "bbox": [
                327.9871520996094,
                1.275492548942566,
                598.3626098632812,
                354.46990966796875
              ]
            },
            {
              "track_id": 766,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.2934466004371643,
              "bbox": [
                206.97190856933594,
                167.15475463867188,
                323.9527893066406,
                215.01817321777344
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            766
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8716,
            8720
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8721,
            8725
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8471513390541077,
              "bbox": [
                99.41919708251953,
                61.257598876953125,
                271.5440979003906,
                343.6888427734375
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9355133771896362,
              "bbox": [
                387.7048034667969,
                35.79396057128906,
                630.47314453125,
                355.9689636230469
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6536519527435303,
              "bbox": [
                479.4382019042969,
                206.95204162597656,
                538.3621826171875,
                233.5693817138672
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8726,
            8730
          ],
          "representative_frame": 8726,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 72
    },
    {
      "second": 291,
      "time_range": [
        291,
        291.999
      ],
      "frame_range": [
        8731,
        8760
      ],
      "unified_description": "2 men in a tent, one is holding a bowl while eating, the other is looking at him. The tent appears to be a mess tent as there are various objects scattered around, such as bottles, sandwiches, a knife, a backpack and a handbag. There's also a cell phone on the table. The scene seems to capture a casual moment between these two men as they share a meal together in their tent.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:33:03",
        "processing_time": 3.97,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8745,
          "frame_range": [
            8741,
            8745
          ],
          "description": "two men sitting in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.61
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8731,
            8735
          ],
          "representative_frame": 8731,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8269533514976501,
              "bbox": [
                112.20684814453125,
                75.87142181396484,
                271.2862548828125,
                338.7926025390625
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9370195865631104,
              "bbox": [
                410.6921081542969,
                48.47621536254883,
                640.0,
                356.4241943359375
              ]
            },
            {
              "track_id": 752,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.339901864528656,
              "bbox": [
                484.1343078613281,
                209.93234252929688,
                537.8399047851562,
                233.47244262695312
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 1,
          "frame_range": [
            8736,
            8740
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8741,
            8745
          ],
          "representative_frame": 8741,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8412433862686157,
              "bbox": [
                116.76189422607422,
                81.29547119140625,
                270.5773620605469,
                336.99884033203125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9412896633148193,
              "bbox": [
                419.18804931640625,
                52.10540008544922,
                640.0,
                356.65423583984375
              ]
            },
            {
              "track_id": 752,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6571595072746277,
              "bbox": [
                479.1544494628906,
                212.8522491455078,
                533.1324462890625,
                236.4110565185547
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 3,
          "frame_range": [
            8746,
            8750
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8751,
            8755
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8419924974441528,
              "bbox": [
                118.38742065429688,
                82.89058685302734,
                270.04058837890625,
                336.54486083984375
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9437013864517212,
              "bbox": [
                422.6565246582031,
                52.64371109008789,
                640.0,
                356.8370361328125
              ]
            },
            {
              "track_id": 752,
              "class_id": 67,
              "class_name": "cell phone",
              "confidence": 0.21617437899112701,
              "bbox": [
                480.20703125,
                213.5102081298828,
                533.9969482421875,
                236.79954528808594
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            752
          ],
          "total_detections": 3
        },
        {
          "group_index": 5,
          "frame_range": [
            8756,
            8760
          ],
          "representative_frame": 8756,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 72
    },
    {
      "second": 292,
      "time_range": [
        292,
        292.999
      ],
      "frame_range": [
        8761,
        8790
      ],
      "unified_description": "2 men are shown having a meal together in a tent with a backpack nearby.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:33:04",
        "processing_time": 3.57,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8775,
          "frame_range": [
            8771,
            8775
          ],
          "description": "two men sitting in a tent eating food",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.69
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8761,
            8765
          ],
          "representative_frame": 8761,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8494242429733276,
              "bbox": [
                119.18309020996094,
                83.39457702636719,
                269.7894592285156,
                336.74371337890625
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9491853713989258,
              "bbox": [
                424.1156921386719,
                51.79049301147461,
                640.0,
                356.31707763671875
              ]
            }
          ],
          "unique_tracks": [
            682,
            715
          ],
          "total_detections": 2
        },
        {
          "group_index": 1,
          "frame_range": [
            8766,
            8770
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8771,
            8775
          ],
          "representative_frame": 8771,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8260519504547119,
              "bbox": [
                118.79362487792969,
                82.09675598144531,
                269.688720703125,
                337.47271728515625
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9541914463043213,
              "bbox": [
                422.05267333984375,
                50.493595123291016,
                640.0,
                356.1273498535156
              ]
            },
            {
              "track_id": 772,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3327616751194,
              "bbox": [
                352.79254150390625,
                309.3744812011719,
                396.6261291503906,
                359.5536804199219
              ]
            },
            {
              "track_id": 774,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.3447723686695099,
              "bbox": [
                6.270752429962158,
                2.085980176925659,
                638.5624389648438,
                353.2785949707031
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            772,
            774
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            8776,
            8780
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8781,
            8785
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8497476577758789,
              "bbox": [
                118.94120788574219,
                82.35594177246094,
                269.25299072265625,
                337.8666687011719
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9420079588890076,
              "bbox": [
                423.91436767578125,
                50.26322937011719,
                640.0,
                355.8131103515625
              ]
            },
            {
              "track_id": 772,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3042689561843872,
              "bbox": [
                352.8448181152344,
                309.41949462890625,
                396.61517333984375,
                359.52178955078125
              ]
            },
            {
              "track_id": 774,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.36647525429725647,
              "bbox": [
                5.628697872161865,
                2.0315451622009277,
                637.5360717773438,
                352.9956970214844
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            772,
            774
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            8786,
            8790
          ],
          "representative_frame": 8786,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 73
    },
    {
      "second": 293,
      "time_range": [
        293,
        293.999
      ],
      "frame_range": [
        8791,
        8820
      ],
      "unified_description": "2 people are seen sitting in a tent. One person is looking into something while holding a blue object. There are several bags around them, including backpacks and a handbag. The tent appears to be their campsite where they have settled down for a break.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:33:06",
        "processing_time": 3.91,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8805,
          "frame_range": [
            8801,
            8805
          ],
          "description": "two men sitting in a tent with a drink",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.86
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8791,
            8795
          ],
          "representative_frame": 8791,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8436102271080017,
              "bbox": [
                119.12120819091797,
                81.07514953613281,
                269.0320739746094,
                337.1544189453125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9483200907707214,
              "bbox": [
                425.73529052734375,
                51.01835632324219,
                640.0,
                355.6471252441406
              ]
            },
            {
              "track_id": 772,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.325162410736084,
              "bbox": [
                352.8658752441406,
                309.45928955078125,
                396.59503173828125,
                359.5070495605469
              ]
            },
            {
              "track_id": 774,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.3468056917190552,
              "bbox": [
                6.436812877655029,
                1.904168963432312,
                638.80322265625,
                353.1677551269531
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            772,
            774
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            8796,
            8800
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8801,
            8805
          ],
          "representative_frame": 8801,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8557202816009521,
              "bbox": [
                117.2483139038086,
                82.0352783203125,
                266.40472412109375,
                337.369873046875
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9298546314239502,
              "bbox": [
                433.7127685546875,
                60.68293380737305,
                640.0,
                355.3185119628906
              ]
            },
            {
              "track_id": 772,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3489897847175598,
              "bbox": [
                352.9105224609375,
                309.47003173828125,
                396.6701354980469,
                359.5496520996094
              ]
            },
            {
              "track_id": 774,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.17952439188957214,
              "bbox": [
                5.588088035583496,
                2.0254080295562744,
                637.4659423828125,
                352.96270751953125
              ]
            },
            {
              "track_id": 778,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4594060182571411,
              "bbox": [
                351.4233093261719,
                235.2530517578125,
                422.1129150390625,
                293.4020080566406
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            772,
            774,
            778
          ],
          "total_detections": 5
        },
        {
          "group_index": 3,
          "frame_range": [
            8806,
            8810
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8811,
            8815
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8702453374862671,
              "bbox": [
                116.4498291015625,
                82.35992431640625,
                265.31451416015625,
                337.7427062988281
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8802894353866577,
              "bbox": [
                441.92303466796875,
                61.54030990600586,
                640.0,
                354.55072021484375
              ]
            },
            {
              "track_id": 772,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3078908324241638,
              "bbox": [
                352.9468078613281,
                309.58135986328125,
                396.6362609863281,
                359.56866455078125
              ]
            },
            {
              "track_id": 774,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.2561250925064087,
              "bbox": [
                5.221530914306641,
                2.068392753601074,
                636.969482421875,
                352.8699035644531
              ]
            },
            {
              "track_id": 778,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4681071937084198,
              "bbox": [
                351.42181396484375,
                235.37196350097656,
                422.07415771484375,
                293.48828125
              ]
            },
            {
              "track_id": 779,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.40730810165405273,
              "bbox": [
                476.73046875,
                283.84600830078125,
                526.0992431640625,
                329.7958984375
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            772,
            774,
            778,
            779
          ],
          "total_detections": 6
        },
        {
          "group_index": 5,
          "frame_range": [
            8816,
            8820
          ],
          "representative_frame": 8816,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 73
    },
    {
      "second": 294,
      "time_range": [
        294,
        294.999
      ],
      "frame_range": [
        8821,
        8850
      ],
      "unified_description": "2 men eating food inside their tent. The first man is seated on the left side of the tent while the second man is sitting on the right side, closer to the foreground. A dog is also present in the scene, adding to the cozy atmosphere of the camping site.\n\nThe tent appears to be a messy bivou, with various items scattered around, such as a backpack near the left wall and another one further away on the right side. There are two cups placed near each other in the center area, and a bottle is located closer to the front of the tent. The overall scene depicts a relaxed moment shared between the two men as they enjoy their meal in the company of their dog.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:33:08",
        "processing_time": 4.63,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8835,
          "frame_range": [
            8831,
            8835
          ],
          "description": "two men sitting in a tent with a dog",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.97
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8821,
            8825
          ],
          "representative_frame": 8821,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8669565916061401,
              "bbox": [
                115.47954559326172,
                79.9287109375,
                265.620361328125,
                338.43682861328125
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9103055000305176,
              "bbox": [
                436.7196960449219,
                58.35385513305664,
                640.0,
                355.4434814453125
              ]
            },
            {
              "track_id": 772,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.3185895085334778,
              "bbox": [
                352.953857421875,
                309.6424255371094,
                396.6175537109375,
                359.5787353515625
              ]
            },
            {
              "track_id": 774,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.3030654489994049,
              "bbox": [
                5.419304847717285,
                1.973803997039795,
                636.555419921875,
                352.33001708984375
              ]
            },
            {
              "track_id": 778,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.43029722571372986,
              "bbox": [
                351.3587646484375,
                235.41275024414062,
                422.0413513183594,
                293.5528869628906
              ]
            },
            {
              "track_id": 779,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4228099286556244,
              "bbox": [
                476.7105407714844,
                284.90191650390625,
                527.3590698242188,
                331.9117126464844
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            772,
            774,
            778,
            779
          ],
          "total_detections": 6
        },
        {
          "group_index": 1,
          "frame_range": [
            8826,
            8830
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8831,
            8835
          ],
          "representative_frame": 8831,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8526851534843445,
              "bbox": [
                115.86040496826172,
                78.3760757446289,
                266.7349548339844,
                338.9038391113281
              ]
            },
            {
              "track_id": 715,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9342955350875854,
              "bbox": [
                431.69110107421875,
                56.93640899658203,
                640.0,
                356.0322570800781
              ]
            },
            {
              "track_id": 772,
              "class_id": 41,
              "class_name": "cup",
              "confidence": 0.2858963906764984,
              "bbox": [
                352.9417419433594,
                309.630615234375,
                396.62689208984375,
                359.56854248046875
              ]
            },
            {
              "track_id": 774,
              "class_id": 25,
              "class_name": "umbrella",
              "confidence": 0.35241419076919556,
              "bbox": [
                5.613714694976807,
                1.8441274166107178,
                637.4974975585938,
                352.6356201171875
              ]
            },
            {
              "track_id": 778,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.4402325749397278,
              "bbox": [
                351.3723449707031,
                235.47555541992188,
                421.96356201171875,
                293.5420227050781
              ]
            },
            {
              "track_id": 779,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.6014470458030701,
              "bbox": [
                476.0260009765625,
                285.2490539550781,
                530.2195434570312,
                335.41143798828125
              ]
            }
          ],
          "unique_tracks": [
            682,
            715,
            772,
            774,
            778,
            779
          ],
          "total_detections": 6
        },
        {
          "group_index": 3,
          "frame_range": [
            8836,
            8840
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8841,
            8845
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8959181308746338,
              "bbox": [
                100.67201232910156,
                20.800600051879883,
                640.0,
                355.0097961425781
              ]
            },
            {
              "track_id": 778,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.8505604863166809,
              "bbox": [
                366.1095275878906,
                236.9126739501953,
                426.78546142578125,
                286.3656311035156
              ]
            }
          ],
          "unique_tracks": [
            774,
            778
          ],
          "total_detections": 2
        },
        {
          "group_index": 5,
          "frame_range": [
            8846,
            8850
          ],
          "representative_frame": 8846,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 73
    },
    {
      "second": 295,
      "time_range": [
        295,
        295.999
      ],
      "frame_range": [
        8851,
        8880
      ],
      "unified_description": "\n- A white-haired man is sitting down with a green background behind him.\n- The man holds a round item in his hands.\n- There are two bottles nearby, one close to the man and another further away.\n- A backpack can be seen next to the man, placed on the ground.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:33:10",
        "processing_time": 5.25,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8865,
          "frame_range": [
            8861,
            8865
          ],
          "description": "a man sitting in a tent with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.11
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8851,
            8855
          ],
          "representative_frame": 8851,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9119630455970764,
              "bbox": [
                158.57443237304688,
                26.042665481567383,
                640.0,
                355.0865478515625
              ]
            },
            {
              "track_id": 780,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.4602694511413574,
              "bbox": [
                80.28254699707031,
                134.4978485107422,
                166.61227416992188,
                356.9146423339844
              ]
            },
            {
              "track_id": 781,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.3692761957645416,
              "bbox": [
                179.94712829589844,
                210.2213592529297,
                248.62835693359375,
                271.7645568847656
              ]
            },
            {
              "track_id": 782,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3281539976596832,
              "bbox": [
                38.73257064819336,
                169.66146850585938,
                109.67972564697266,
                209.533447265625
              ]
            }
          ],
          "unique_tracks": [
            774,
            780,
            781,
            782
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            8856,
            8860
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8861,
            8865
          ],
          "representative_frame": 8861,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8599078059196472,
              "bbox": [
                156.79507446289062,
                30.819156646728516,
                640.0,
                355.88592529296875
              ]
            },
            {
              "track_id": 780,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5992517471313477,
              "bbox": [
                79.39742279052734,
                129.6020965576172,
                167.24755859375,
                356.541748046875
              ]
            },
            {
              "track_id": 781,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.34920430183410645,
              "bbox": [
                179.849853515625,
                210.10589599609375,
                248.779541015625,
                271.88250732421875
              ]
            },
            {
              "track_id": 782,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3201660215854645,
              "bbox": [
                38.69478225708008,
                169.58860778808594,
                109.67981719970703,
                209.4812774658203
              ]
            }
          ],
          "unique_tracks": [
            774,
            780,
            781,
            782
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            8866,
            8870
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8871,
            8875
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9338117837905884,
              "bbox": [
                159.94717407226562,
                35.79563522338867,
                640.0,
                356.2485046386719
              ]
            },
            {
              "track_id": 780,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.6086471676826477,
              "bbox": [
                79.90455627441406,
                131.89793395996094,
                166.6183319091797,
                356.5959167480469
              ]
            },
            {
              "track_id": 781,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.44178637862205505,
              "bbox": [
                179.76422119140625,
                210.1644744873047,
                248.62840270996094,
                271.90478515625
              ]
            },
            {
              "track_id": 782,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.332722932100296,
              "bbox": [
                39.09781265258789,
                169.44400024414062,
                108.93684387207031,
                208.67684936523438
              ]
            }
          ],
          "unique_tracks": [
            774,
            780,
            781,
            782
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            8876,
            8880
          ],
          "representative_frame": 8876,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 73
    },
    {
      "second": 296,
      "time_range": [
        296,
        296.999
      ],
      "frame_range": [
        8881,
        8910
      ],
      "unified_description": "1-second scene featuring a man sitting near objects such as a cup and a backpack.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:33:12",
        "processing_time": 5.21,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8895,
          "frame_range": [
            8891,
            8895
          ],
          "description": "a man in a tent with a backpack",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.71
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8881,
            8885
          ],
          "representative_frame": 8881,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9435821175575256,
              "bbox": [
                179.1053009033203,
                35.57624053955078,
                640.0,
                356.7399597167969
              ]
            },
            {
              "track_id": 780,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5998051762580872,
              "bbox": [
                79.36986541748047,
                128.38148498535156,
                167.1797637939453,
                356.9918212890625
              ]
            },
            {
              "track_id": 781,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5122541785240173,
              "bbox": [
                179.6302490234375,
                210.22482299804688,
                248.739013671875,
                272.2237243652344
              ]
            },
            {
              "track_id": 782,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.3483733832836151,
              "bbox": [
                39.620094299316406,
                169.37261962890625,
                108.29988098144531,
                207.91006469726562
              ]
            }
          ],
          "unique_tracks": [
            774,
            780,
            781,
            782
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            8886,
            8890
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8891,
            8895
          ],
          "representative_frame": 8891,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9281983971595764,
              "bbox": [
                191.33506774902344,
                30.586666107177734,
                640.0,
                356.1870422363281
              ]
            },
            {
              "track_id": 780,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5278052091598511,
              "bbox": [
                79.07437133789062,
                124.6951904296875,
                167.623779296875,
                356.63604736328125
              ]
            },
            {
              "track_id": 781,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.557097852230072,
              "bbox": [
                179.8948974609375,
                210.18304443359375,
                248.59124755859375,
                271.85113525390625
              ]
            },
            {
              "track_id": 782,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.297606498003006,
              "bbox": [
                39.554443359375,
                169.47384643554688,
                108.2675552368164,
                207.9921112060547
              ]
            }
          ],
          "unique_tracks": [
            774,
            780,
            781,
            782
          ],
          "total_detections": 4
        },
        {
          "group_index": 3,
          "frame_range": [
            8896,
            8900
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8901,
            8905
          ],
          "representative_frame": null,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.897192656993866,
              "bbox": [
                194.65338134765625,
                34.7344970703125,
                629.25048828125,
                356.6764221191406
              ]
            },
            {
              "track_id": 780,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.560452401638031,
              "bbox": [
                79.27781677246094,
                123.96952056884766,
                167.47557067871094,
                356.5153503417969
              ]
            },
            {
              "track_id": 781,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.5202021598815918,
              "bbox": [
                180.0912322998047,
                210.24664306640625,
                248.49710083007812,
                271.6898193359375
              ]
            },
            {
              "track_id": 782,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.2786591649055481,
              "bbox": [
                39.594730377197266,
                169.52134704589844,
                108.24137878417969,
                207.95416259765625
              ]
            }
          ],
          "unique_tracks": [
            774,
            780,
            781,
            782
          ],
          "total_detections": 4
        },
        {
          "group_index": 5,
          "frame_range": [
            8906,
            8910
          ],
          "representative_frame": 8906,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 74
    },
    {
      "second": 297,
      "time_range": [
        297,
        297.999
      ],
      "frame_range": [
        8911,
        8940
      ],
      "unified_description": "31-second video of a middle-aged man in a tent, possibly a camper or soldier, holding up a multi-tool with a pen in his mouth. The image has a shaky camera perspective, indicating it could have been recorded from the first-person perspective, or mounted on the person's body or backpack. The video also features several objects such as a bottle, cup, and book in close proximity to the man.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:33:14",
        "processing_time": 4.01,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8925,
          "frame_range": [
            8921,
            8925
          ],
          "description": "a man in a tent with a knife and a knife",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.21
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8911,
            8915
          ],
          "representative_frame": 8911,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9340123534202576,
              "bbox": [
                201.25433349609375,
                36.86934280395508,
                617.0166015625,
                356.6185302734375
              ]
            },
            {
              "track_id": 780,
              "class_id": 39,
              "class_name": "bottle",
              "confidence": 0.5836701393127441,
              "bbox": [
                80.58267211914062,
                128.25558471679688,
                166.55914306640625,
                356.211181640625
              ]
            },
            {
              "track_id": 781,
              "class_id": 45,
              "class_name": "bowl",
              "confidence": 0.37071824073791504,
              "bbox": [
                180.24005126953125,
                210.39385986328125,
                248.27943420410156,
                271.5232849121094
              ]
            },
            {
              "track_id": 782,
              "class_id": 24,
              "class_name": "backpack",
              "confidence": 0.28033846616744995,
              "bbox": [
                39.86457824707031,
                169.45069885253906,
                108.0157241821289,
                207.51829528808594
              ]
            }
          ],
          "unique_tracks": [
            774,
            780,
            781,
            782
          ],
          "total_detections": 4
        },
        {
          "group_index": 1,
          "frame_range": [
            8916,
            8920
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8921,
            8925
          ],
          "representative_frame": 8921,
          "detections": [
            {
              "track_id": 774,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.8943515419960022,
              "bbox": [
                199.10687255859375,
                38.57217025756836,
                597.2200317382812,
                355.5400695800781
              ]
            },
            {
              "track_id": 782,
              "class_id": 2,
              "class_name": "car",
              "confidence": 0.13365255296230316,
              "bbox": [
                39.1379280090332,
                173.16348266601562,
                106.57443237304688,
                210.86669921875
              ]
            }
          ],
          "unique_tracks": [
            774,
            782
          ],
          "total_detections": 2
        },
        {
          "group_index": 3,
          "frame_range": [
            8926,
            8930
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8931,
            8935
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            8936,
            8940
          ],
          "representative_frame": 8936,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 74
    },
    {
      "second": 298,
      "time_range": [
        298,
        298.999
      ],
      "frame_range": [
        8941,
        8970
      ],
      "unified_description": "3-second shot of someone holding a blue bowl while wearing winter gear.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:33:14",
        "processing_time": 2.93,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8955,
          "frame_range": [
            8951,
            8955
          ],
          "description": "a man in a hat and jacket is holding a knife",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 1.18
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8941,
            8945
          ],
          "representative_frame": 8941,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            8946,
            8950
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8951,
            8955
          ],
          "representative_frame": 8951,
          "detections": [
            {
              "track_id": 763,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.5861160755157471,
              "bbox": [
                404.8348083496094,
                227.7129669189453,
                522.16552734375,
                290.0976867675781
              ]
            }
          ],
          "unique_tracks": [
            763
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            8956,
            8960
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8961,
            8965
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            8966,
            8970
          ],
          "representative_frame": 8966,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 74
    },
    {
      "second": 299,
      "time_range": [
        299,
        299.999
      ],
      "frame_range": [
        8971,
        9000
      ],
      "unified_description": "3rd person perspective showing someone's hand and lap with various items such as bowls, bags, and a backpack.",
      "llava_metadata": {
        "model": "bakllava",
        "timestamp": "2025-11-11T12:33:15",
        "processing_time": 2.87,
        "images_sent": 1,
        "note": "LLaVA processed with both text and images"
      },
      "blip_descriptions": [
        {
          "group_index": 2,
          "frame_number": 8985,
          "frame_range": [
            8981,
            8985
          ],
          "description": "a person is standing in the woods with a blue hat",
          "blip_metadata": {
            "model": "Salesforce/blip-image-captioning-base",
            "processing_time": 0.98
          }
        }
      ],
      "detection_groups": [
        {
          "group_index": 0,
          "frame_range": [
            8971,
            8975
          ],
          "representative_frame": 8971,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 1,
          "frame_range": [
            8976,
            8980
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 2,
          "frame_range": [
            8981,
            8985
          ],
          "representative_frame": 8981,
          "detections": [
            {
              "track_id": 682,
              "class_id": 0,
              "class_name": "person",
              "confidence": 0.9263936877250671,
              "bbox": [
                121.02526092529297,
                1.9876787662506104,
                352.47119140625,
                355.36383056640625
              ]
            }
          ],
          "unique_tracks": [
            682
          ],
          "total_detections": 1
        },
        {
          "group_index": 3,
          "frame_range": [
            8986,
            8990
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 4,
          "frame_range": [
            8991,
            8995
          ],
          "representative_frame": null,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        },
        {
          "group_index": 5,
          "frame_range": [
            8996,
            9000
          ],
          "representative_frame": 8996,
          "detections": [],
          "unique_tracks": [],
          "total_detections": 0
        }
      ],
      "transcription_id": 74
    }
  ],
  "transcriptions": [
    {
      "id": 0,
      "time_range": [
        0,
        5
      ],
      "transcription": "Luke here with the Outdoor Boys YouTube channel and welcome to Alaska. Me and my boys are gonna",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 11.84
      }
    },
    {
      "id": 1,
      "time_range": [
        4,
        9
      ],
      "transcription": "Me and my boys are going to be dropped off by a float plane and camp here for the next three days. We're going to be",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 4.66
      }
    },
    {
      "id": 2,
      "time_range": [
        8,
        13
      ],
      "transcription": "We're gonna be fishing for Dolly Vardin, Lake Trout, an Arctic Grailing, hiking.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.46
      }
    },
    {
      "id": 3,
      "time_range": [
        12,
        17
      ],
      "transcription": "Hiking, pack rafting, and exploring the homestead of Dick Prennicky, the original bush",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.44
      }
    },
    {
      "id": 4,
      "time_range": [
        16,
        21
      ],
      "transcription": "the original bush crafting youtuber.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.25
      }
    },
    {
      "id": 5,
      "time_range": [
        20,
        25
      ],
      "transcription": "There's your plane.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.24
      }
    },
    {
      "id": 6,
      "time_range": [
        24,
        29
      ],
      "transcription": "fair",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.81
      }
    },
    {
      "id": 7,
      "time_range": [
        28,
        33
      ],
      "transcription": "Let's just wait and see how this works",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.08
      }
    },
    {
      "id": 8,
      "time_range": [
        32,
        37
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.2
      }
    },
    {
      "id": 9,
      "time_range": [
        36,
        41
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.24
      }
    },
    {
      "id": 10,
      "time_range": [
        40,
        45
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.22
      }
    },
    {
      "id": 11,
      "time_range": [
        44,
        49
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.23
      }
    },
    {
      "id": 12,
      "time_range": [
        48,
        53
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.24
      }
    },
    {
      "id": 13,
      "time_range": [
        52,
        57
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.23
      }
    },
    {
      "id": 14,
      "time_range": [
        56,
        61
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 65.33
      }
    },
    {
      "id": 15,
      "time_range": [
        60,
        65
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.27
      }
    },
    {
      "id": 16,
      "time_range": [
        64,
        69
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.37
      }
    },
    {
      "id": 17,
      "time_range": [
        68,
        73
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.36
      }
    },
    {
      "id": 18,
      "time_range": [
        72,
        77
      ],
      "transcription": "Well guys that's it we're all by our side.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.41
      }
    },
    {
      "id": 19,
      "time_range": [
        76,
        81
      ],
      "transcription": "We're all by ourselves. He's not going to come and get us for three days. Welcome to Twins.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.63
      }
    },
    {
      "id": 20,
      "time_range": [
        80,
        85
      ],
      "transcription": "Welcome to Twin Lakes We had to fly about an hour",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.44
      }
    },
    {
      "id": 21,
      "time_range": [
        84,
        89
      ],
      "transcription": "to fly about an hour and a half in a float plane to get here and this is very much room",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.54
      }
    },
    {
      "id": 22,
      "time_range": [
        88,
        93
      ],
      "transcription": "very much remote Alaskan wilderness. Okay, whether forecast is is gonna be raining on.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.52
      }
    },
    {
      "id": 23,
      "time_range": [
        92,
        97
      ],
      "transcription": "going to be raining on and off so I don't want to find a place to build my shelter.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.52
      }
    },
    {
      "id": 24,
      "time_range": [
        96,
        101
      ],
      "transcription": "All right, you guys like this spot huh?",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.4
      }
    },
    {
      "id": 25,
      "time_range": [
        100,
        105
      ],
      "transcription": "this spot huh let's drop it you guys think you can go grab the other stuff",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.5
      }
    },
    {
      "id": 26,
      "time_range": [
        104,
        109
      ],
      "transcription": "stuff.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.27
      }
    },
    {
      "id": 27,
      "time_range": [
        108,
        113
      ],
      "transcription": "Yes.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.68
      }
    },
    {
      "id": 28,
      "time_range": [
        112,
        117
      ],
      "transcription": "Come on. Rightind.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.17
      }
    },
    {
      "id": 29,
      "time_range": [
        116,
        121
      ],
      "transcription": "bu arm",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.76
      }
    },
    {
      "id": 30,
      "time_range": [
        120,
        125
      ],
      "transcription": "Tommy, you're going fishing? Grab your bear spray.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.47
      }
    },
    {
      "id": 31,
      "time_range": [
        124,
        129
      ],
      "transcription": "of your bear spray.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.76
      }
    },
    {
      "id": 32,
      "time_range": [
        128,
        133
      ],
      "transcription": "It's nothing toob.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.37
      }
    },
    {
      "id": 33,
      "time_range": [
        132,
        137
      ],
      "transcription": "want.' WOW, yes! get in there. YEEE YEE",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.6
      }
    },
    {
      "id": 34,
      "time_range": [
        136,
        141
      ],
      "transcription": "Get in there. Yes! Hurry, get in the wall! Yes! Yes!",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.79
      }
    },
    {
      "id": 35,
      "time_range": [
        140,
        145
      ],
      "transcription": "Yeah! Oh yeah! Oh, I need to...",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.76
      }
    },
    {
      "id": 36,
      "time_range": [
        144,
        149
      ],
      "transcription": "Let's have line out, let's have line out. That is a chart, that's a dollar.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.61
      }
    },
    {
      "id": 37,
      "time_range": [
        148,
        153
      ],
      "transcription": "That's a Dolly Barton. You ready to eat it for dinner? Yep. Okay. Also I can bonk them.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.7
      }
    },
    {
      "id": 38,
      "time_range": [
        152,
        157
      ],
      "transcription": "Also I can bump behind it. I have a fish blancher now. So that right there, that's a deli varten.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.71
      }
    },
    {
      "id": 39,
      "time_range": [
        156,
        161
      ],
      "transcription": "to Dolly Barton. See how he's got the pink spot? Oh yeah. He's a member of the char family. Okay.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.73
      }
    },
    {
      "id": 40,
      "time_range": [
        160,
        165
      ],
      "transcription": "Okay, there you go. Go, go.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.45
      }
    },
    {
      "id": 41,
      "time_range": [
        164,
        169
      ],
      "transcription": "There you go, there's your dinner buddy. Yeah!",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.49
      }
    },
    {
      "id": 42,
      "time_range": [
        168,
        173
      ],
      "transcription": "Oh, there's a dolly isn't it? Yeah, there's a dolly of art. Nice.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.72
      }
    },
    {
      "id": 43,
      "time_range": [
        172,
        177
      ],
      "transcription": "Got it! L Probably not?",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 3.23
      }
    },
    {
      "id": 44,
      "time_range": [
        176,
        181
      ],
      "transcription": "Tom, let me see what you got. You got a dolly.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.56
      }
    },
    {
      "id": 45,
      "time_range": [
        180,
        185
      ],
      "transcription": "Oh, it's another lovely dolly Sharon let this one go. This is weird",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.55
      }
    },
    {
      "id": 46,
      "time_range": [
        184,
        189
      ],
      "transcription": "This one goes, it's we already got a fish.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.48
      }
    },
    {
      "id": 47,
      "time_range": [
        188,
        193
      ],
      "transcription": "It's definitely never mind Hey, ey",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.59
      }
    },
    {
      "id": 48,
      "time_range": [
        192,
        197
      ],
      "transcription": "Hey, nice. Alright, we'll get another one.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.51
      }
    },
    {
      "id": 49,
      "time_range": [
        196,
        201
      ],
      "transcription": "Hey Tommy I want to make a",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.41
      }
    },
    {
      "id": 50,
      "time_range": [
        200,
        205
      ],
      "transcription": "Hey Tommy, I'm gonna make lunch, you wanna stay in fish? Yup.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.6
      }
    },
    {
      "id": 51,
      "time_range": [
        204,
        209
      ],
      "transcription": "looking toward the sky.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.98
      }
    },
    {
      "id": 52,
      "time_range": [
        208,
        213
      ],
      "transcription": "Alright, what are with this guy's been eating his stomachs full? Little...",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.57
      }
    },
    {
      "id": 53,
      "time_range": [
        212,
        217
      ],
      "transcription": "little mosquitoes and flies just thousands and thousands of bugs",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.46
      }
    },
    {
      "id": 54,
      "time_range": [
        216,
        221
      ],
      "transcription": "There we go.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.38
      }
    },
    {
      "id": 55,
      "time_range": [
        220,
        225
      ],
      "transcription": "done",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.96
      }
    },
    {
      "id": 56,
      "time_range": [
        224,
        229
      ],
      "transcription": "Hi, forgot.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.39
      }
    },
    {
      "id": 57,
      "time_range": [
        228,
        233
      ],
      "transcription": "I think you're full. That's what chocolate makes. You're a bit like...",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.68
      }
    },
    {
      "id": 58,
      "time_range": [
        232,
        237
      ],
      "transcription": "You're just like That's hot. I just hold it no",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.54
      }
    },
    {
      "id": 59,
      "time_range": [
        236,
        241
      ],
      "transcription": "Just hold it and the warm up your hands first.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.49
      }
    },
    {
      "id": 60,
      "time_range": [
        240,
        245
      ],
      "transcription": "Oh my god, my hair is sticky. Put all your shells in here so we don't attract bears and stuff.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 27.58
      }
    },
    {
      "id": 61,
      "time_range": [
        244,
        249
      ],
      "transcription": "garden, stop. Yeah.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.02
      }
    },
    {
      "id": 62,
      "time_range": [
        248,
        253
      ],
      "transcription": "I'm sure you guys are pretty hungry, right? Oh yeah, please.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.59
      }
    },
    {
      "id": 63,
      "time_range": [
        252,
        257
      ],
      "transcription": "please yeah and then at the other bite",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.5
      }
    },
    {
      "id": 64,
      "time_range": [
        256,
        261
      ],
      "transcription": "Salted and dung, yeah.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.1
      }
    },
    {
      "id": 65,
      "time_range": [
        260,
        265
      ],
      "transcription": "Let's blow... We need to hold it like this in place.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 1.32
      }
    },
    {
      "id": 66,
      "time_range": [
        264,
        269
      ],
      "transcription": "Put that fish in there.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.44
      }
    },
    {
      "id": 67,
      "time_range": [
        268,
        273
      ],
      "transcription": "fish in the oiling broth.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.48
      }
    },
    {
      "id": 68,
      "time_range": [
        272,
        277
      ],
      "transcription": "after",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.89
      }
    },
    {
      "id": 69,
      "time_range": [
        276,
        281
      ],
      "transcription": "Are you ready for some some ramen flavored dolly here?",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.53
      }
    },
    {
      "id": 70,
      "time_range": [
        280,
        285
      ],
      "transcription": "Yeah, that's good. Wing. Dolly tastes a lot like a trowel or something.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.72
      }
    },
    {
      "id": 71,
      "time_range": [
        284,
        289
      ],
      "transcription": "I got a trout or salmon. Yeah. Do you want a little salt on them?",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.66
      }
    },
    {
      "id": 72,
      "time_range": [
        288,
        293
      ],
      "transcription": "Salt there? Oh yeah, little salt and pepper",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.53
      }
    },
    {
      "id": 73,
      "time_range": [
        292,
        297
      ],
      "transcription": "A little salt and pepper is good. Oh. Alright.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.68
      }
    },
    {
      "id": 74,
      "time_range": [
        296,
        300.0
      ],
      "transcription": "Alright, I'll do some dishes.",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.51
      }
    },
    {
      "id": 75,
      "time_range": [
        300,
        300.0
      ],
      "transcription": "",
      "metadata": {
        "model": "base",
        "language": "en",
        "processing_time": 0.26,
        "error": "Audio file too small (136 bytes), likely empty or invalid"
      }
    }
  ],
  "hierarchical_tree": {
    "root": {
      "node_id": "node_6_0",
      "time_range": [
        0.0,
        299.999
      ],
      "duration": 299.999,
      "keywords": [
        "00",
        "01",
        "03",
        "08",
        "10",
        "12345",
        "15",
        "19",
        "1k",
        "20",
        "2015",
        "27",
        "2d",
        "2k",
        "2nd",
        "30",
        "31",
        "32",
        "34",
        "35",
        "360",
        "365",
        "3d",
        "3rd",
        "45",
        "48",
        "4k",
        "54",
        "56",
        "57",
        "58",
        "59",
        "62",
        "64",
        "67",
        "7373",
        "79",
        "above",
        "accurate",
        "across",
        "action",
        "actions",
        "activities",
        "activity",
        "adding",
        "addition",
        "additional",
        "additionally",
        "admiring",
        "adult",
        "adventure",
        "aerial",
        "after",
        "aged",
        "ago",
        "ahead",
        "aid",
        "air",
        "aircraft",
        "airplane",
        "alaska",
        "alaskan",
        "allowing",
        "allows",
        "along",
        "alright",
        "altitude",
        "aluminum",
        "amazing",
        "angle",
        "angler",
        "angles",
        "animal",
        "animals",
        "another",
        "appears",
        "appreciate",
        "appropriate",
        "arctic",
        "area",
        "areas",
        "arm",
        "around",
        "array",
        "art",
        "artifacts",
        "assortment",
        "atmosphere",
        "attached",
        "attire",
        "attract",
        "available",
        "aviation",
        "away",
        "axe",
        "baby",
        "back",
        "background",
        "backpack",
        "backpacking",
        "backpacks",
        "bag",
        "bags",
        "bait",
        "ball",
        "balls",
        "bank",
        "barton",
        "baseball",
        "based",
        "beach",
        "bear",
        "beard",
        "bears",
        "beautiful",
        "beauty",
        "beer",
        "before",
        "behavior",
        "behind",
        "belongings",
        "below",
        "bend",
        "bending",
        "bent",
        "beside",
        "between",
        "bicycles",
        "bird",
        "birds",
        "bit",
        "bite",
        "bivou",
        "black",
        "blancher",
        "blanket",
        "blankets",
        "blow",
        "blowing",
        "blue",
        "blur",
        "blurred",
        "blurry",
        "board",
        "boat",
        "boats",
        "body",
        "boiling",
        "bonk",
        "book",
        "bottle",
        "bottles",
        "bowl",
        "bowls",
        "boy",
        "boys",
        "brightest",
        "broader",
        "broth",
        "brown",
        "bu",
        "bucket",
        "buddy",
        "bugs",
        "building",
        "bump",
        "bus",
        "bush",
        "buttons",
        "cabin",
        "calm",
        "camera",
        "cameras",
        "camp",
        "camper",
        "campfire",
        "camping",
        "campsite",
        "candle",
        "canister",
        "canopy",
        "canvas",
        "cap",
        "capture",
        "captured",
        "captures",
        "capturing",
        "car",
        "carrying",
        "cars",
        "cast",
        "casting",
        "casts",
        "casual",
        "catching",
        "cause",
        "causing",
        "cell",
        "center",
        "chairs",
        "channel",
        "channels",
        "char",
        "characteristics",
        "chart",
        "chest",
        "child",
        "children",
        "chocolate",
        "cleaning",
        "clear",
        "clearer",
        "clearly",
        "clip",
        "close",
        "closely",
        "closer",
        "clothes",
        "clothing",
        "cloudy",
        "coat",
        "coats",
        "cockpit",
        "coffee",
        "color",
        "colored",
        "colors",
        "communication",
        "companions",
        "company",
        "compose",
        "compression",
        "conditions",
        "connected",
        "contain",
        "container",
        "contains",
        "context",
        "contribute",
        "control",
        "controls",
        "conversation",
        "cooking",
        "corner",
        "countryside",
        "couple",
        "covering",
        "cozy",
        "craft",
        "crafting",
        "creates",
        "creating",
        "crucial",
        "cup",
        "cups",
        "daily",
        "dark",
        "dashboard",
        "dashcam",
        "daughter",
        "day",
        "days",
        "daytime",
        "dead",
        "debris",
        "deep",
        "definitely",
        "definition",
        "degree",
        "deli",
        "departure",
        "depicting",
        "depicts",
        "description",
        "descriptions",
        "detail",
        "detailed",
        "details",
        "detected",
        "detection",
        "detections",
        "device",
        "dick",
        "different",
        "dinner",
        "dirty",
        "discussing",
        "disembark",
        "dishes",
        "distance",
        "distinct",
        "distortion",
        "documentation",
        "dog",
        "dollar",
        "dolly",
        "done",
        "door",
        "down",
        "dress",
        "dressed",
        "drinking",
        "driver",
        "drivers",
        "driving",
        "drop",
        "dropped",
        "due",
        "dung",
        "dynamic",
        "earth",
        "eating",
        "edge",
        "edges",
        "edit",
        "editing",
        "effect",
        "either",
        "elements",
        "else",
        "emphasize",
        "engaged",
        "engaging",
        "enjoy",
        "enjoying",
        "enjoys",
        "entire",
        "environment",
        "essence",
        "etc",
        "everyday",
        "evidenced",
        "exchange",
        "excited",
        "excitement",
        "expansive",
        "expedition",
        "experience",
        "experiencing",
        "explaining",
        "exploring",
        "expression",
        "ey",
        "eye",
        "face",
        "facial",
        "fair",
        "family",
        "father",
        "features",
        "featuring",
        "field",
        "fiji",
        "file",
        "filled",
        "film",
        "filming",
        "finger",
        "finished",
        "fire",
        "fish",
        "fisherman",
        "fishermen",
        "fisheye",
        "fishing",
        "flare",
        "flavored",
        "flies",
        "flight",
        "float",
        "floor",
        "fly",
        "flying",
        "focal",
        "focus",
        "focused",
        "focusing",
        "following",
        "food",
        "footage",
        "forecast",
        "foreground",
        "forest",
        "forgot",
        "format",
        "forward",
        "frame",
        "frames",
        "frisbee",
        "front",
        "frying",
        "full",
        "further",
        "garden",
        "gathered",
        "gauges",
        "gear",
        "gentleman",
        "girl",
        "giving",
        "glasses",
        "glimpse",
        "god",
        "goes",
        "going",
        "gonna",
        "good",
        "gopro",
        "grab",
        "grabbing",
        "grailing",
        "grainy",
        "grassy",
        "gravel",
        "gravelly",
        "gray",
        "green",
        "grey",
        "ground",
        "group",
        "groups",
        "gun",
        "guy",
        "guys",
        "hair",
        "haired",
        "half",
        "hand",
        "handbag",
        "handing",
        "handling",
        "hands",
        "handshake",
        "hanging",
        "happy",
        "harness",
        "hat",
        "head",
        "headphones",
        "held",
        "helicopter",
        "helmet",
        "hey",
        "hi",
        "high",
        "higher",
        "hiking",
        "hillside",
        "himself",
        "hold",
        "holding",
        "holds",
        "hole",
        "homestead",
        "hood",
        "hooded",
        "hoodie",
        "hook",
        "hot",
        "hour",
        "house",
        "hugged",
        "huh",
        "hungry",
        "hurry",
        "identified",
        "image",
        "immersive",
        "includes",
        "indicate",
        "indicates",
        "indicating",
        "individual",
        "individuals",
        "information",
        "input",
        "inside",
        "instruments",
        "interacting",
        "interaction",
        "interactions",
        "interacts",
        "interest",
        "interesting",
        "interior",
        "involved",
        "island",
        "isn",
        "item",
        "items",
        "jacket",
        "jackets",
        "jeans",
        "jumpsuit",
        "jumpsuits",
        "kaleidoscope",
        "kettle",
        "kids",
        "kite",
        "km",
        "knee",
        "kneeling",
        "knife",
        "knives",
        "knots",
        "lake",
        "lakes",
        "landscape",
        "lantern",
        "lap",
        "lapse",
        "laptop",
        "large",
        "laying",
        "leather",
        "leaves",
        "leisure",
        "length",
        "lens",
        "letters",
        "lid",
        "life",
        "light",
        "lighting",
        "lights",
        "like",
        "likely",
        "line",
        "little",
        "ll",
        "located",
        "location",
        "locations",
        "log",
        "long",
        "looking",
        "looks",
        "loss",
        "lot",
        "lovely",
        "low",
        "luke",
        "lunch",
        "lure",
        "lures",
        "machinery",
        "main",
        "makes",
        "making",
        "male",
        "man",
        "market",
        "marshy",
        "meal",
        "meals",
        "mean",
        "member",
        "men",
        "mess",
        "messy",
        "methods",
        "middle",
        "military",
        "mind",
        "miscellaneous",
        "model",
        "molding",
        "moment",
        "mosquitoes",
        "motion",
        "mountain",
        "mountainous",
        "mountains",
        "mounted",
        "mouth",
        "movement",
        "movements",
        "much",
        "mug",
        "multi",
        "multiple",
        "muted",
        "natural",
        "navigates",
        "navigating",
        "near",
        "nearby",
        "nearer",
        "never",
        "next",
        "nh",
        "nice",
        "nothing",
        "noticeable",
        "notices",
        "number",
        "numerous",
        "object",
        "objects",
        "observe",
        "observer",
        "observing",
        "occurring",
        "ocean",
        "off",
        "offering",
        "oh",
        "oiling",
        "okay",
        "older",
        "operating",
        "orange",
        "original",
        "others",
        "ourselves",
        "out",
        "outdoor",
        "outdoors",
        "outfit",
        "outside",
        "oven",
        "over",
        "overall",
        "overcast",
        "overexposed",
        "overhead",
        "pack",
        "pan",
        "panoramic",
        "pants",
        "part",
        "passenger",
        "patch",
        "path",
        "pebble",
        "pebbly",
        "pen",
        "people",
        "pepper",
        "per",
        "person",
        "personal",
        "persons",
        "perspective",
        "perspectives",
        "phone",
        "photo",
        "photography",
        "pick",
        "picking",
        "picture",
        "picturesque",
        "piece",
        "pieces",
        "pilot",
        "pink",
        "place",
        "placed",
        "placing",
        "plane",
        "plants",
        "plates",
        "playing",
        "please",
        "pockets",
        "point",
        "pointing",
        "pole",
        "pontoon",
        "positioned",
        "positioning",
        "positions",
        "possibly",
        "pot",
        "potentially",
        "pots",
        "pouring",
        "pov",
        "prennicky",
        "preparing",
        "presence",
        "present",
        "presented",
        "pretty",
        "primary",
        "probably",
        "process",
        "production",
        "provide",
        "provides",
        "providing",
        "proximity",
        "purposes",
        "radio",
        "raft",
        "rafting",
        "rain",
        "raincoat",
        "raincoats",
        "raining",
        "rainy",
        "ramen",
        "range",
        "raw",
        "re",
        "reaching",
        "ready",
        "rear",
        "recommended",
        "recorded",
        "recreational",
        "red",
        "reeling",
        "relatively",
        "relaxed",
        "releasing",
        "remote",
        "repair",
        "representation",
        "resolution",
        "respective",
        "resting",
        "resulting",
        "retrieve",
        "right",
        "rightind",
        "river",
        "riverbank",
        "rivers",
        "road",
        "rock",
        "rocks",
        "rocky",
        "rod",
        "rods",
        "room",
        "rope",
        "round",
        "salmon",
        "salt",
        "salted",
        "sand",
        "sandwich",
        "sandwiches",
        "saying",
        "says",
        "scattered",
        "scene",
        "scenery",
        "scenes",
        "scenic",
        "screen",
        "seaplane",
        "seat",
        "seated",
        "seats",
        "seconds",
        "seems",
        "seen",
        "sense",
        "sensor",
        "serving",
        "setting",
        "settled",
        "setup",
        "several",
        "shaky",
        "share",
        "shared",
        "sharing",
        "sharon",
        "sheet",
        "shells",
        "shelter",
        "shirt",
        "shore",
        "shoreline",
        "shot",
        "shots",
        "shoulder",
        "showcases",
        "showcasing",
        "showing",
        "shown",
        "shows",
        "shutter",
        "side",
        "similar",
        "simply",
        "single",
        "sips",
        "site",
        "siting",
        "sits",
        "sitting",
        "situated",
        "situation",
        "six",
        "ski",
        "skies",
        "sky",
        "sleeping",
        "slight",
        "slightly",
        "slow",
        "small",
        "smartphone",
        "smiling",
        "snacks",
        "snowsuit",
        "snowy",
        "soars",
        "soldier",
        "someone",
        "something",
        "somewhat",
        "son",
        "sons",
        "sort",
        "spaghetti",
        "specific",
        "speed",
        "speedometer",
        "spoons",
        "sports",
        "spot",
        "spray",
        "stability",
        "stabilization",
        "stable",
        "stall",
        "standing",
        "stands",
        "steering",
        "sticky",
        "stomachs",
        "stool",
        "strapped",
        "stream",
        "structure",
        "structures",
        "stuck",
        "stuff",
        "stuffed",
        "stump",
        "stunning",
        "style",
        "subject",
        "subjects",
        "suggesting",
        "suggests",
        "suit",
        "summary",
        "sunglasses",
        "supplies",
        "sure",
        "surface",
        "surfaces",
        "surrounded",
        "surrounding",
        "surroundings",
        "survival",
        "switches",
        "system",
        "table",
        "taken",
        "takes",
        "taking",
        "talking",
        "tan",
        "tank",
        "tastes",
        "technical",
        "techniques",
        "tent",
        "tents",
        "terrain",
        "thousands",
        "tie",
        "time",
        "timelapse",
        "tips",
        "toddler",
        "together",
        "tom",
        "tommy",
        "toob",
        "tool",
        "top",
        "total",
        "toward",
        "toys",
        "tracking",
        "tracks",
        "trail",
        "travel",
        "tree",
        "trees",
        "tricks",
        "trip",
        "tripod",
        "trout",
        "trowel",
        "turbulence",
        "turned",
        "twigs",
        "twin",
        "twins",
        "type",
        "ultra",
        "umbrella",
        "under",
        "understanding",
        "unfolds",
        "uniform",
        "unique",
        "unsteady",
        "upcoming",
        "upper",
        "using",
        "valley",
        "valleys",
        "vantage",
        "vardin",
        "various",
        "varten",
        "vastness",
        "vehicle",
        "video",
        "videos",
        "view",
        "viewed",
        "viewer",
        "viewers",
        "views",
        "visible",
        "visual",
        "visuals",
        "vlog",
        "waders",
        "walking",
        "walks",
        "wall",
        "wanna",
        "warm",
        "watches",
        "watching",
        "water",
        "way",
        "wearing",
        "weather",
        "weird",
        "welcome",
        "well",
        "wet",
        "wetlands",
        "wheel",
        "white",
        "wide",
        "wider",
        "wilderness",
        "wildlife",
        "window",
        "wing",
        "wings",
        "winter",
        "within",
        "witness",
        "woman",
        "wooded",
        "wooden",
        "woods",
        "working",
        "works",
        "wow",
        "writing",
        "yeah",
        "yee",
        "yeee",
        "yellow",
        "yep",
        "yes",
        "young",
        "youtube",
        "youtuber",
        "yup"
      ],
      "keyword_count": 986,
      "children": [
        "node_5_0",
        "node_5_1"
      ],
      "level": 6,
      "parent": null
    },
    "nodes": {
      "leaf_0": {
        "node_id": "leaf_0",
        "time_range": [
          0.0,
          5.0
        ],
        "duration": 5.0,
        "keywords": [
          "360",
          "action",
          "air",
          "airplane",
          "alaska",
          "appears",
          "area",
          "back",
          "background",
          "beautiful",
          "behind",
          "blue",
          "boys",
          "camera",
          "camp",
          "captures",
          "channel",
          "days",
          "degree",
          "dropped",
          "environment",
          "excitement",
          "experience",
          "fiji",
          "flight",
          "float",
          "flying",
          "going",
          "gonna",
          "gopro",
          "green",
          "hat",
          "helicopter",
          "hillside",
          "image",
          "indicating",
          "lake",
          "likely",
          "luke",
          "man",
          "mountain",
          "mountainous",
          "mountains",
          "next",
          "off",
          "outdoor",
          "over",
          "person",
          "perspective",
          "plane",
          "pointing",
          "pov",
          "providing",
          "re",
          "saying",
          "scene",
          "seems",
          "shaky",
          "shirt",
          "shot",
          "showing",
          "similar",
          "slightly",
          "small",
          "something",
          "standing",
          "stands",
          "sunglasses",
          "taken",
          "top",
          "video",
          "view",
          "water",
          "welcome",
          "within",
          "writing",
          "youtube"
        ],
        "keyword_count": 77,
        "children": null,
        "level": 0,
        "parent": "node_1_0",
        "source_seconds": [
          0,
          1,
          2,
          3,
          4
        ],
        "source_transcriptions": [
          0,
          1
        ],
        "visual_text": "360-degree first-person POV shot showing a man in sunglasses pointing at something off camera. He is standing on a hillside with mountains behind him. The image appears to be slightly shaky, indicating that it was likely taken with a GoPro or similar action camera. 360-degree video shot by a man in a green shirt and hat, pointing at the camera as he stands on a mountain top with a beautiful blue lake in the background. \nIn the image, there is a person who appears to be flying a helicopter over a mountainous area. The camera perspective seems to be from within the helicopter, providing a first-person view of the experience. The scene captures the beautiful outdoor environment and the excitement of the flight. \nA small airplane in the water with a writing in the back of it saying Fiji Air.",
        "audio_text": "Luke here with the Outdoor Boys YouTube channel and welcome to Alaska. Me and my boys are gonna Me and my boys are going to be dropped off by a float plane and camp here for the next three days. We're going to be",
        "combined_text": "360-degree first-person POV shot showing a man in sunglasses pointing at something off camera. He is standing on a hillside with mountains behind him. The image appears to be slightly shaky, indicating that it was likely taken with a GoPro or similar action camera. 360-degree video shot by a man in a green shirt and hat, pointing at the camera as he stands on a mountain top with a beautiful blue lake in the background. \nIn the image, there is a person who appears to be flying a helicopter over a mountainous area. The camera perspective seems to be from within the helicopter, providing a first-person view of the experience. The scene captures the beautiful outdoor environment and the excitement of the flight. \nA small airplane in the water with a writing in the back of it saying Fiji Air. Luke here with the Outdoor Boys YouTube channel and welcome to Alaska. Me and my boys are gonna Me and my boys are going to be dropped off by a float plane and camp here for the next three days. We're going to be"
      },
      "leaf_1": {
        "node_id": "leaf_1",
        "time_range": [
          5.0,
          10.0
        ],
        "duration": 5.0,
        "keywords": [
          "30",
          "alaska",
          "angle",
          "another",
          "arctic",
          "away",
          "backpack",
          "black",
          "boat",
          "boats",
          "boys",
          "camera",
          "camp",
          "cap",
          "captures",
          "casting",
          "cause",
          "channel",
          "close",
          "days",
          "distance",
          "distortion",
          "dolly",
          "dropped",
          "edges",
          "enjoying",
          "featuring",
          "fish",
          "fishing",
          "float",
          "frame",
          "further",
          "glasses",
          "going",
          "gonna",
          "grailing",
          "green",
          "grey",
          "hand",
          "hiking",
          "holding",
          "hoodie",
          "image",
          "immersive",
          "includes",
          "lake",
          "line",
          "looking",
          "luke",
          "man",
          "meal",
          "men",
          "near",
          "nearby",
          "next",
          "objects",
          "off",
          "out",
          "outdoor",
          "outdoors",
          "people",
          "person",
          "perspective",
          "plane",
          "positioned",
          "providing",
          "re",
          "right",
          "rocks",
          "scene",
          "seems",
          "setting",
          "several",
          "shirt",
          "shore",
          "shot",
          "showing",
          "side",
          "standing",
          "tent",
          "timelapse",
          "together",
          "tree",
          "trout",
          "vardin",
          "video",
          "view",
          "water",
          "way",
          "wearing",
          "welcome",
          "wide",
          "youtube"
        ],
        "keyword_count": 93,
        "children": null,
        "level": 0,
        "parent": "node_1_0",
        "source_seconds": [
          5,
          6,
          7,
          8,
          9
        ],
        "source_transcriptions": [
          0,
          1,
          2
        ],
        "visual_text": "1-second video showing a man in an outdoor setting with a tent and water nearby. 30 second timelapse of a man in a grey hoodie, black glasses and cap, standing next to a tree. The image includes several objects: backpack, tent, and two other people in the distance. It is shot in a wide-angle perspective which may cause distortion near the edges of the frame. 3 men are enjoying a meal together outdoors. 1-second scene featuring a man casting a fishing line from shore while standing on rocks next to boats. One boat is positioned close to the shore and another further away on the right side. The scene captures the man's perspective, providing an immersive view of the outdoors.  A person is holding a fish out to the camera and also wearing a green shirt. The camera is positioned in such a way that it seems as if we are looking through the person's hand to see the fish up close.",
        "audio_text": "Luke here with the Outdoor Boys YouTube channel and welcome to Alaska. Me and my boys are gonna Me and my boys are going to be dropped off by a float plane and camp here for the next three days. We're going to be We're gonna be fishing for Dolly Vardin, Lake Trout, an Arctic Grailing, hiking.",
        "combined_text": "1-second video showing a man in an outdoor setting with a tent and water nearby. 30 second timelapse of a man in a grey hoodie, black glasses and cap, standing next to a tree. The image includes several objects: backpack, tent, and two other people in the distance. It is shot in a wide-angle perspective which may cause distortion near the edges of the frame. 3 men are enjoying a meal together outdoors. 1-second scene featuring a man casting a fishing line from shore while standing on rocks next to boats. One boat is positioned close to the shore and another further away on the right side. The scene captures the man's perspective, providing an immersive view of the outdoors.  A person is holding a fish out to the camera and also wearing a green shirt. The camera is positioned in such a way that it seems as if we are looking through the person's hand to see the fish up close. Luke here with the Outdoor Boys YouTube channel and welcome to Alaska. Me and my boys are gonna Me and my boys are going to be dropped off by a float plane and camp here for the next three days. We're going to be We're gonna be fishing for Dolly Vardin, Lake Trout, an Arctic Grailing, hiking."
      },
      "leaf_2": {
        "node_id": "leaf_2",
        "time_range": [
          10.0,
          15.0
        ],
        "duration": 5.0,
        "keywords": [
          "08",
          "360",
          "3rd",
          "angle",
          "arctic",
          "back",
          "boy",
          "bush",
          "camera",
          "capturing",
          "description",
          "detection",
          "dick",
          "dolly",
          "environment",
          "exploring",
          "expression",
          "facial",
          "featuring",
          "fish",
          "fishing",
          "frame",
          "gonna",
          "grailing",
          "ground",
          "guys",
          "hat",
          "hiking",
          "holding",
          "hole",
          "homestead",
          "inside",
          "lake",
          "lens",
          "looking",
          "man",
          "mountains",
          "next",
          "object",
          "original",
          "out",
          "overhead",
          "pack",
          "person",
          "perspective",
          "positioned",
          "prennicky",
          "rafting",
          "re",
          "relatively",
          "river",
          "rocks",
          "scene",
          "seconds",
          "showing",
          "sitting",
          "small",
          "stable",
          "standing",
          "structure",
          "surrounding",
          "trout",
          "vardin",
          "video",
          "wide",
          "wooden",
          "young"
        ],
        "keyword_count": 67,
        "children": null,
        "level": 0,
        "parent": "node_1_1",
        "source_seconds": [
          10,
          11,
          12,
          13,
          14
        ],
        "source_transcriptions": [
          2,
          3
        ],
        "visual_text": "1-second scene featuring a young boy holding a fish while standing on rocks. The camera is positioned overhead, capturing the boy and the fish in the frame. 360 video from a first person perspective showing a man holding a fish next to a river. 2 guys hiking in the mountains with a lake in the back ground. 08 Seconds of Video with Object Detection and Description 3rd person perspective of a man in a hat looking out of a small hole in a wooden structure while sitting inside of it. The camera is positioned relatively stable, capturing the scene with a wide-angle lens, showing the man's facial expression and the surrounding environment.",
        "audio_text": "We're gonna be fishing for Dolly Vardin, Lake Trout, an Arctic Grailing, hiking. Hiking, pack rafting, and exploring the homestead of Dick Prennicky, the original bush",
        "combined_text": "1-second scene featuring a young boy holding a fish while standing on rocks. The camera is positioned overhead, capturing the boy and the fish in the frame. 360 video from a first person perspective showing a man holding a fish next to a river. 2 guys hiking in the mountains with a lake in the back ground. 08 Seconds of Video with Object Detection and Description 3rd person perspective of a man in a hat looking out of a small hole in a wooden structure while sitting inside of it. The camera is positioned relatively stable, capturing the scene with a wide-angle lens, showing the man's facial expression and the surrounding environment. We're gonna be fishing for Dolly Vardin, Lake Trout, an Arctic Grailing, hiking. Hiking, pack rafting, and exploring the homestead of Dick Prennicky, the original bush"
      },
      "leaf_3": {
        "node_id": "leaf_3",
        "time_range": [
          15.0,
          20.0
        ],
        "duration": 5.0,
        "keywords": [
          "3d",
          "3rd",
          "angle",
          "axe",
          "bush",
          "cabin",
          "coffee",
          "crafting",
          "cup",
          "dick",
          "exploring",
          "filming",
          "flying",
          "forest",
          "front",
          "frying",
          "hiking",
          "holding",
          "homestead",
          "inside",
          "kaleidoscope",
          "kite",
          "large",
          "lens",
          "log",
          "man",
          "mountain",
          "mug",
          "near",
          "next",
          "original",
          "outdoors",
          "outside",
          "over",
          "pack",
          "pan",
          "person",
          "perspective",
          "plane",
          "prennicky",
          "rafting",
          "river",
          "scene",
          "seen",
          "showing",
          "sitting",
          "standing",
          "stool",
          "stuck",
          "stump",
          "tree",
          "video",
          "view",
          "wide",
          "youtuber"
        ],
        "keyword_count": 55,
        "children": null,
        "level": 0,
        "parent": "node_1_1",
        "source_seconds": [
          15,
          16,
          17,
          18,
          19
        ],
        "source_transcriptions": [
          3,
          4,
          5
        ],
        "visual_text": "3rd person perspective of a man standing outside of a log cabin, holding a coffee cup 3rd person perspective of a man sitting on a stool outside a log cabin with a wide-angle lens used for filming. 1-second video showing a man holding a coffee mug outdoors next to a log cabin with a frying pan inside. 1-second scene including a large axe stuck in a tree stump 3D view of a mountain scene as seen through a kaleidoscope. A kite is flying over a river near a forest. A person is standing in front of a tree with an axe stuck in it.",
        "audio_text": "Hiking, pack rafting, and exploring the homestead of Dick Prennicky, the original bush the original bush crafting youtuber. There's your plane.",
        "combined_text": "3rd person perspective of a man standing outside of a log cabin, holding a coffee cup 3rd person perspective of a man sitting on a stool outside a log cabin with a wide-angle lens used for filming. 1-second video showing a man holding a coffee mug outdoors next to a log cabin with a frying pan inside. 1-second scene including a large axe stuck in a tree stump 3D view of a mountain scene as seen through a kaleidoscope. A kite is flying over a river near a forest. A person is standing in front of a tree with an axe stuck in it. Hiking, pack rafting, and exploring the homestead of Dick Prennicky, the original bush the original bush crafting youtuber. There's your plane."
      },
      "leaf_4": {
        "node_id": "leaf_4",
        "time_range": [
          20.0,
          25.0
        ],
        "duration": 5.0,
        "keywords": [
          "12345",
          "27",
          "30",
          "3rd",
          "appears",
          "beside",
          "black",
          "boy",
          "boys",
          "bush",
          "camera",
          "captures",
          "car",
          "child",
          "crafting",
          "dashcam",
          "driver",
          "drivers",
          "driving",
          "everyday",
          "fair",
          "features",
          "footage",
          "gopro",
          "group",
          "image",
          "interior",
          "large",
          "life",
          "likely",
          "long",
          "looking",
          "man",
          "moment",
          "original",
          "out",
          "outdoor",
          "outdoors",
          "part",
          "person",
          "perspective",
          "photo",
          "plane",
          "red",
          "road",
          "says",
          "seated",
          "seconds",
          "showing",
          "stump",
          "surroundings",
          "top",
          "tree",
          "trip",
          "vehicle",
          "video",
          "visible",
          "well",
          "white",
          "window",
          "writing",
          "young",
          "youtuber"
        ],
        "keyword_count": 63,
        "children": null,
        "level": 0,
        "parent": "node_1_2",
        "source_seconds": [
          20,
          21,
          22,
          23,
          24
        ],
        "source_transcriptions": [
          4,
          5,
          6
        ],
        "visual_text": "30 second long black and white photo with red writing that says Outdoor Boys. The image features a large tree stump with a GoPro on top of it. 12345 2 boys are outdoors and are part of the Outdoor Boys group 27 seconds of dashcam footage from a drivers perspective in a vehicle. 3rd person perspective video showing a man driving a vehicle with a young boy seated beside him. The driver is looking at the camera while the child appears to be looking out the window. The car's interior is visible, as well as some of its surroundings. The image likely captures a moment from a road trip or everyday life.",
        "audio_text": "the original bush crafting youtuber. There's your plane. fair",
        "combined_text": "30 second long black and white photo with red writing that says Outdoor Boys. The image features a large tree stump with a GoPro on top of it. 12345 2 boys are outdoors and are part of the Outdoor Boys group 27 seconds of dashcam footage from a drivers perspective in a vehicle. 3rd person perspective video showing a man driving a vehicle with a young boy seated beside him. The driver is looking at the camera while the child appears to be looking out the window. The car's interior is visible, as well as some of its surroundings. The image likely captures a moment from a road trip or everyday life. the original bush crafting youtuber. There's your plane. fair"
      },
      "leaf_5": {
        "node_id": "leaf_5",
        "time_range": [
          25.0,
          30.0
        ],
        "duration": 5.0,
        "keywords": [
          "32",
          "35",
          "360",
          "additionally",
          "aircraft",
          "another",
          "appears",
          "back",
          "bags",
          "behind",
          "bottle",
          "boy",
          "camera",
          "car",
          "carrying",
          "center",
          "chairs",
          "characteristics",
          "closer",
          "day",
          "degree",
          "detected",
          "elements",
          "fair",
          "frame",
          "front",
          "glasses",
          "head",
          "helicopter",
          "himself",
          "image",
          "inside",
          "located",
          "locations",
          "looks",
          "machinery",
          "man",
          "market",
          "near",
          "next",
          "objects",
          "operating",
          "out",
          "people",
          "person",
          "personal",
          "perspective",
          "piece",
          "pilot",
          "plane",
          "possibly",
          "rainy",
          "repair",
          "respective",
          "right",
          "scene",
          "seat",
          "seated",
          "seats",
          "seems",
          "several",
          "showing",
          "side",
          "sitting",
          "situated",
          "small",
          "someone",
          "something",
          "stall",
          "stands",
          "suggesting",
          "sunglasses",
          "talking",
          "turned",
          "under",
          "unique",
          "various",
          "vehicle",
          "video",
          "view",
          "visible",
          "wearing",
          "within",
          "works",
          "young"
        ],
        "keyword_count": 85,
        "children": null,
        "level": 0,
        "parent": "node_1_2",
        "source_seconds": [
          25,
          26,
          27,
          28,
          29
        ],
        "source_transcriptions": [
          5,
          6,
          7
        ],
        "visual_text": "360-degree view of man sitting in a vehicle, possibly talking to someone 32 second video showing a person carrying several bags in front of an open market stall on a rainy day. 4 unique objects are detected in the image with their respective locations and characteristics. \nA man wearing sunglasses stands next to a piece of machinery. His head is turned to the side as he looks at something out of frame. The image has several unique elements, including a car that seems to be under repair, possibly by the man himself. There are two other people in the scene, one near the center and another towards the left.\n\nAdditionally, there are two chairs visible in the image, with one situated at the back-left of the scene and another closer to the center. 35 second video of a man sitting inside a small aircraft. The aircraft appears to be a personal helicopter with two seats, one in front and one behind. A young boy is seated behind the man. There are various objects within the scene such as a bottle located towards the right side of the image. Additionally, the camera perspective seems to be first-person, suggesting that the man wearing glasses is the one operating the camera while sitting in the pilot's seat.",
        "audio_text": "There's your plane. fair Let's just wait and see how this works",
        "combined_text": "360-degree view of man sitting in a vehicle, possibly talking to someone 32 second video showing a person carrying several bags in front of an open market stall on a rainy day. 4 unique objects are detected in the image with their respective locations and characteristics. \nA man wearing sunglasses stands next to a piece of machinery. His head is turned to the side as he looks at something out of frame. The image has several unique elements, including a car that seems to be under repair, possibly by the man himself. There are two other people in the scene, one near the center and another towards the left.\n\nAdditionally, there are two chairs visible in the image, with one situated at the back-left of the scene and another closer to the center. 35 second video of a man sitting inside a small aircraft. The aircraft appears to be a personal helicopter with two seats, one in front and one behind. A young boy is seated behind the man. There are various objects within the scene such as a bottle located towards the right side of the image. Additionally, the camera perspective seems to be first-person, suggesting that the man wearing glasses is the one operating the camera while sitting in the pilot's seat. There's your plane. fair Let's just wait and see how this works"
      },
      "leaf_6": {
        "node_id": "leaf_6",
        "time_range": [
          30.0,
          35.0
        ],
        "duration": 5.0,
        "keywords": [
          "above",
          "adding",
          "aid",
          "airplane",
          "along",
          "altitude",
          "appears",
          "background",
          "ball",
          "board",
          "boat",
          "buttons",
          "camera",
          "cap",
          "capturing",
          "car",
          "cockpit",
          "context",
          "control",
          "controls",
          "crucial",
          "dynamic",
          "elements",
          "engaging",
          "experience",
          "features",
          "filled",
          "flies",
          "flight",
          "flying",
          "footage",
          "helicopter",
          "helmet",
          "holding",
          "house",
          "image",
          "information",
          "inside",
          "interesting",
          "laptop",
          "low",
          "making",
          "man",
          "mounted",
          "multiple",
          "navigates",
          "near",
          "ocean",
          "person",
          "pilot",
          "plane",
          "possibly",
          "providing",
          "relatively",
          "river",
          "scene",
          "screen",
          "serving",
          "several",
          "shot",
          "shoulder",
          "showing",
          "sits",
          "sitting",
          "small",
          "speedometer",
          "stable",
          "steering",
          "surfaces",
          "switches",
          "trees",
          "tripod",
          "view",
          "viewers",
          "visible",
          "visual",
          "water",
          "wearing",
          "wheel",
          "within",
          "works"
        ],
        "keyword_count": 81,
        "children": null,
        "level": 0,
        "parent": "node_1_3",
        "source_seconds": [
          30,
          31,
          32,
          33,
          34
        ],
        "source_transcriptions": [
          7,
          8
        ],
        "visual_text": "\n\nA small airplane with one person on board. The pilot is sitting in the cockpit, which features several control surfaces, such as a steering wheel and multiple buttons and switches. There is also a speedometer visible within the cockpit. The airplane appears to be flying at a relatively low altitude above water, possibly near some trees. 1-second scene showing the ocean with a boat and house in the background. The camera is mounted on a tripod for stable footage. 1 second of footage shot with a camera mounted on a person's shoulder capturing the view from inside a boat. There is also a car visible in the background, adding context to the scene. \n\nA man is sitting in a small boat or plane cockpit, holding a control or steering wheel. He has a camera mounted on his helmet, capturing his experience as he flies or navigates through the water. The image also features a laptop screen, possibly providing crucial flight information or serving as a visual aid for the pilot. The scene is dynamic and filled with interesting elements, making it an engaging watch for viewers. \n\nA person wearing a ball cap sits at the controls of a helicopter, flying along a river.",
        "audio_text": "Let's just wait and see how this works",
        "combined_text": "A small airplane with one person on board. The pilot is sitting in the cockpit, which features several control surfaces, such as a steering wheel and multiple buttons and switches. There is also a speedometer visible within the cockpit. The airplane appears to be flying at a relatively low altitude above water, possibly near some trees. 1-second scene showing the ocean with a boat and house in the background. The camera is mounted on a tripod for stable footage. 1 second of footage shot with a camera mounted on a person's shoulder capturing the view from inside a boat. There is also a car visible in the background, adding context to the scene. \n\nA man is sitting in a small boat or plane cockpit, holding a control or steering wheel. He has a camera mounted on his helmet, capturing his experience as he flies or navigates through the water. The image also features a laptop screen, possibly providing crucial flight information or serving as a visual aid for the pilot. The scene is dynamic and filled with interesting elements, making it an engaging watch for viewers. \n\nA person wearing a ball cap sits at the controls of a helicopter, flying along a river. Let's just wait and see how this works"
      },
      "leaf_7": {
        "node_id": "leaf_7",
        "time_range": [
          35.0,
          40.0
        ],
        "duration": 5.0,
        "keywords": [
          "10",
          "aerial",
          "aircraft",
          "airplane",
          "area",
          "around",
          "below",
          "birds",
          "body",
          "building",
          "bus",
          "camera",
          "captured",
          "car",
          "cars",
          "cockpit",
          "day",
          "edge",
          "eye",
          "field",
          "flying",
          "front",
          "helicopter",
          "image",
          "inside",
          "instruments",
          "island",
          "landscape",
          "located",
          "long",
          "lot",
          "middle",
          "near",
          "over",
          "overcast",
          "part",
          "person",
          "perspective",
          "plane",
          "providing",
          "scene",
          "seen",
          "shoreline",
          "shot",
          "showing",
          "shows",
          "small",
          "surroundings",
          "tracks",
          "using",
          "video",
          "view",
          "visible",
          "water",
          "wing"
        ],
        "keyword_count": 55,
        "children": null,
        "level": 0,
        "parent": "node_1_3",
        "source_seconds": [
          35,
          36,
          37,
          38,
          39
        ],
        "source_transcriptions": [
          8,
          9,
          10
        ],
        "visual_text": "1-second scene showing a body of water with an island in the middle, a building on the shoreline, and a few cars and a bus located around the area. The image is captured from an aircraft perspective, providing an aerial view of the landscape below. 1-second scene with a airplane flying over water. The image shows a birds eye view of the plane. There is also a car visible near the water's edge. 10-second video of a person inside a helicopter 1-second scene of a plane flying over a body of water on an overcast day. The image was captured using a first-person camera perspective, showing the cockpit view of the plane's instruments and surroundings. 1 second long shot of an airplane flying over a field with a lot of small tracks in it. The plane is seen from the front (cockpit view) showing part of its wing and some of the landscape below.",
        "audio_text": "",
        "combined_text": "1-second scene showing a body of water with an island in the middle, a building on the shoreline, and a few cars and a bus located around the area. The image is captured from an aircraft perspective, providing an aerial view of the landscape below. 1-second scene with a airplane flying over water. The image shows a birds eye view of the plane. There is also a car visible near the water's edge. 10-second video of a person inside a helicopter 1-second scene of a plane flying over a body of water on an overcast day. The image was captured using a first-person camera perspective, showing the cockpit view of the plane's instruments and surroundings. 1 second long shot of an airplane flying over a field with a lot of small tracks in it. The plane is seen from the front (cockpit view) showing part of its wing and some of the landscape below."
      },
      "leaf_8": {
        "node_id": "leaf_8",
        "time_range": [
          40.0,
          45.0
        ],
        "duration": 5.0,
        "keywords": [
          "above",
          "aerial",
          "airplane",
          "altitude",
          "angle",
          "appreciate",
          "area",
          "beauty",
          "below",
          "boys",
          "camera",
          "captures",
          "capturing",
          "channels",
          "cockpit",
          "communication",
          "connected",
          "corner",
          "documentation",
          "due",
          "earth",
          "effect",
          "expansive",
          "featuring",
          "filled",
          "filming",
          "fisheye",
          "flying",
          "focus",
          "giving",
          "headphones",
          "helicopter",
          "image",
          "indicates",
          "jackets",
          "landscape",
          "lens",
          "marshy",
          "men",
          "moment",
          "natural",
          "noticeable",
          "over",
          "perspective",
          "plane",
          "point",
          "possibly",
          "providing",
          "purposes",
          "radio",
          "recreational",
          "red",
          "right",
          "river",
          "rivers",
          "scene",
          "scenic",
          "seats",
          "sense",
          "shaky",
          "showcasing",
          "shows",
          "side",
          "sitting",
          "slightly",
          "system",
          "taken",
          "turbulence",
          "unique",
          "upper",
          "valley",
          "vantage",
          "vastness",
          "video",
          "view",
          "viewed",
          "viewers",
          "visible",
          "water",
          "wearing",
          "wetlands",
          "white",
          "wide",
          "wing",
          "young"
        ],
        "keyword_count": 85,
        "children": null,
        "level": 0,
        "parent": "node_1_4",
        "source_seconds": [
          40,
          41,
          42,
          43,
          44
        ],
        "source_transcriptions": [
          9,
          10,
          11
        ],
        "visual_text": "\nThe image shows the point of view from the cockpit of an airplane flying over a marshy area with many rivers. The airplane's wing is visible in the upper right corner, providing a sense of altitude and perspective. The focus of the image is on the expansive landscape below, which is filled with water channels, showcasing the natural beauty of the wetlands from above. The video has a wide-angle perspective that captures the vastness of the scene, giving viewers a unique, aerial vantage point to appreciate the Earth's landscape. 2 young boys sit side by side in the cockpit of an airplane with red and white jackets. They are wearing headphones and there is a noticeable fisheye effect due to the wide-angle lens used for filming. 2 boys are sitting in the cockpit of an airplane with red seats. They are wearing headphones that may be connected to a radio communication system. The camera is capturing this moment, possibly for documentation or recreational purposes. 1-second scene featuring a scenic river valley viewed from a plane's cockpit. The image is slightly shaky, which indicates that it was taken during turbulence. 2 men in a helicopter with headphones on",
        "audio_text": "",
        "combined_text": "The image shows the point of view from the cockpit of an airplane flying over a marshy area with many rivers. The airplane's wing is visible in the upper right corner, providing a sense of altitude and perspective. The focus of the image is on the expansive landscape below, which is filled with water channels, showcasing the natural beauty of the wetlands from above. The video has a wide-angle perspective that captures the vastness of the scene, giving viewers a unique, aerial vantage point to appreciate the Earth's landscape. 2 young boys sit side by side in the cockpit of an airplane with red and white jackets. They are wearing headphones and there is a noticeable fisheye effect due to the wide-angle lens used for filming. 2 boys are sitting in the cockpit of an airplane with red seats. They are wearing headphones that may be connected to a radio communication system. The camera is capturing this moment, possibly for documentation or recreational purposes. 1-second scene featuring a scenic river valley viewed from a plane's cockpit. The image is slightly shaky, which indicates that it was taken during turbulence. 2 men in a helicopter with headphones on"
      },
      "leaf_9": {
        "node_id": "leaf_9",
        "time_range": [
          45.0,
          50.0
        ],
        "duration": 5.0,
        "keywords": [
          "3rd",
          "above",
          "aircraft",
          "airplane",
          "amazing",
          "angle",
          "area",
          "beautiful",
          "before",
          "camera",
          "captures",
          "countryside",
          "distortion",
          "experience",
          "features",
          "filled",
          "fisheye",
          "flying",
          "focused",
          "front",
          "giving",
          "green",
          "image",
          "immersive",
          "inside",
          "landscape",
          "lens",
          "long",
          "making",
          "mountain",
          "mountains",
          "navigating",
          "outside",
          "over",
          "passenger",
          "person",
          "perspective",
          "pilot",
          "plane",
          "plants",
          "providing",
          "range",
          "scene",
          "scenic",
          "seems",
          "seen",
          "shot",
          "showing",
          "small",
          "snowy",
          "stunning",
          "unfolds",
          "valleys",
          "video",
          "view",
          "viewer",
          "views",
          "visual",
          "wide",
          "wider",
          "window",
          "within"
        ],
        "keyword_count": 62,
        "children": null,
        "level": 0,
        "parent": "node_1_4",
        "source_seconds": [
          45,
          46,
          47,
          48,
          49
        ],
        "source_transcriptions": [
          10,
          11,
          12
        ],
        "visual_text": "1-second scene showing the outside of a passenger airplane flying over a green countryside filled with mountains. 3rd person perspective of a plane flying over snowy mountains and green valleys. The camera captures the scenic views from the airplane window, making it an amazing visual experience. 1 second long video showing a person flying a plane over a mountain range with wide-angle distortion 1 second long shot of some plants and snowy mountains seen from above with a fisheye lens giving a wider view of the area.  The image features a pilot inside a small plane, flying in front of a beautiful snowy mountain range. The camera's perspective is from within the airplane, providing an immersive experience for the viewer. The pilot seems focused on navigating the aircraft, while the stunning landscape unfolds before him.",
        "audio_text": "",
        "combined_text": "1-second scene showing the outside of a passenger airplane flying over a green countryside filled with mountains. 3rd person perspective of a plane flying over snowy mountains and green valleys. The camera captures the scenic views from the airplane window, making it an amazing visual experience. 1 second long video showing a person flying a plane over a mountain range with wide-angle distortion 1 second long shot of some plants and snowy mountains seen from above with a fisheye lens giving a wider view of the area.  The image features a pilot inside a small plane, flying in front of a beautiful snowy mountain range. The camera's perspective is from within the airplane, providing an immersive experience for the viewer. The pilot seems focused on navigating the aircraft, while the stunning landscape unfolds before him."
      },
      "leaf_10": {
        "node_id": "leaf_10",
        "time_range": [
          50.0,
          55.0
        ],
        "duration": 5.0,
        "keywords": [
          "15",
          "360",
          "airplane",
          "angle",
          "appears",
          "area",
          "back",
          "background",
          "beautiful",
          "blue",
          "camera",
          "captures",
          "capturing",
          "clear",
          "cockpit",
          "degree",
          "description",
          "distortion",
          "flying",
          "footage",
          "front",
          "gopro",
          "green",
          "head",
          "headphones",
          "identified",
          "image",
          "includes",
          "inside",
          "jacket",
          "lake",
          "landscape",
          "long",
          "mountainous",
          "mountains",
          "mounted",
          "movement",
          "objects",
          "over",
          "passenger",
          "people",
          "person",
          "perspective",
          "pilot",
          "plane",
          "possibly",
          "providing",
          "red",
          "scenery",
          "seconds",
          "shot",
          "showing",
          "sitting",
          "sky",
          "small",
          "soars",
          "specific",
          "stable",
          "structures",
          "stunning",
          "taken",
          "top",
          "view",
          "visible",
          "water",
          "wearing",
          "wide",
          "wildlife"
        ],
        "keyword_count": 68,
        "children": null,
        "level": 0,
        "parent": "node_1_5",
        "source_seconds": [
          50,
          51,
          52,
          53,
          54
        ],
        "source_transcriptions": [
          12,
          13
        ],
        "visual_text": "\nThis is an image with a green background showing a mountainous area from the sky. It appears to be taken from inside a plane or cockpit, as there is no camera movement visible. The camera captures a wide-angle view of the landscape, which includes mountains and possibly some wildlife or structures. There are no people or specific objects identified in this image description. 15 seconds of footage from a first-person perspective inside a small airplane with a pilot flying the plane while wearing headphones. There is also a passenger sitting in the back, wearing a red jacket. 1 second long shot of a plane in front of some water. The camera is mounted on top of a person's head. 360-degree footage from a plane flying over a blue lake with green mountains in the background. The camera is stable, capturing the stunning landscape with no distortion.  A GoPro camera is capturing the view from inside an airplane flying over a beautiful lake with mountains in the background. The camera is stable, providing a clear view of the stunning scenery as the plane soars through the sky.",
        "audio_text": "",
        "combined_text": "This is an image with a green background showing a mountainous area from the sky. It appears to be taken from inside a plane or cockpit, as there is no camera movement visible. The camera captures a wide-angle view of the landscape, which includes mountains and possibly some wildlife or structures. There are no people or specific objects identified in this image description. 15 seconds of footage from a first-person perspective inside a small airplane with a pilot flying the plane while wearing headphones. There is also a passenger sitting in the back, wearing a red jacket. 1 second long shot of a plane in front of some water. The camera is mounted on top of a person's head. 360-degree footage from a plane flying over a blue lake with green mountains in the background. The camera is stable, capturing the stunning landscape with no distortion.  A GoPro camera is capturing the view from inside an airplane flying over a beautiful lake with mountains in the background. The camera is stable, providing a clear view of the stunning scenery as the plane soars through the sky."
      },
      "leaf_11": {
        "node_id": "leaf_11",
        "time_range": [
          55.0,
          60.0
        ],
        "duration": 5.0,
        "keywords": [
          "10",
          "3rd",
          "aircraft",
          "airplane",
          "angle",
          "background",
          "beautiful",
          "boat",
          "camera",
          "captured",
          "capturing",
          "car",
          "cockpit",
          "controls",
          "creates",
          "dashboard",
          "descriptions",
          "distortion",
          "driving",
          "featuring",
          "flying",
          "gauges",
          "hat",
          "image",
          "includes",
          "indicating",
          "inside",
          "lake",
          "lens",
          "looking",
          "man",
          "mountain",
          "mountains",
          "mounted",
          "out",
          "over",
          "person",
          "perspective",
          "pilot",
          "plane",
          "possibly",
          "potentially",
          "pov",
          "river",
          "scene",
          "shot",
          "showing",
          "suggests",
          "trees",
          "using",
          "vehicle",
          "video",
          "view",
          "wearing",
          "wide",
          "wings"
        ],
        "keyword_count": 56,
        "children": null,
        "level": 0,
        "parent": "node_1_5",
        "source_seconds": [
          55,
          56,
          57,
          58,
          59
        ],
        "source_transcriptions": [
          13,
          14,
          15
        ],
        "visual_text": "1-second scene showing a aircraft with a camera mounted on its wings, capturing a beautiful view of a lake and mountains in the background. 10-second descriptions for each image are needed. 3rd person perspective showing a pilot inside the cockpit of a plane flying over a mountain lake. 1-second scene featuring a man wearing a hat, potentially flying a plane or driving a boat. The camera perspective suggests that it could be a first-person POV shot. The image also includes a river, trees in the background, and possibly some gauges or controls inside the vehicle. 1-second scene with a person inside a vehicle looking out. The video was captured using a wide-angle lens, which creates some distortion. There is a dashboard view, indicating that the person could be in a car or an airplane.",
        "audio_text": "",
        "combined_text": "1-second scene showing a aircraft with a camera mounted on its wings, capturing a beautiful view of a lake and mountains in the background. 10-second descriptions for each image are needed. 3rd person perspective showing a pilot inside the cockpit of a plane flying over a mountain lake. 1-second scene featuring a man wearing a hat, potentially flying a plane or driving a boat. The camera perspective suggests that it could be a first-person POV shot. The image also includes a river, trees in the background, and possibly some gauges or controls inside the vehicle. 1-second scene with a person inside a vehicle looking out. The video was captured using a wide-angle lens, which creates some distortion. There is a dashboard view, indicating that the person could be in a car or an airplane."
      },
      "leaf_12": {
        "node_id": "leaf_12",
        "time_range": [
          60.0,
          65.0
        ],
        "duration": 5.0,
        "keywords": [
          "3rd",
          "45",
          "7373",
          "activity",
          "admiring",
          "aircraft",
          "airplane",
          "another",
          "appears",
          "area",
          "aviation",
          "background",
          "behind",
          "blue",
          "boat",
          "body",
          "camera",
          "captures",
          "capturing",
          "craft",
          "departure",
          "device",
          "door",
          "excited",
          "featuring",
          "flying",
          "footage",
          "front",
          "glasses",
          "glimpse",
          "hat",
          "helicopter",
          "image",
          "interesting",
          "jacket",
          "lake",
          "large",
          "life",
          "likely",
          "man",
          "men",
          "mounted",
          "near",
          "next",
          "number",
          "outdoor",
          "people",
          "person",
          "persons",
          "perspective",
          "plane",
          "point",
          "pontoon",
          "possibly",
          "preparing",
          "providing",
          "raft",
          "ready",
          "rear",
          "red",
          "scene",
          "seconds",
          "seen",
          "setting",
          "shore",
          "showing",
          "side",
          "ski",
          "small",
          "smiling",
          "standing",
          "stands",
          "style",
          "surrounding",
          "top",
          "view",
          "water",
          "wearing",
          "white"
        ],
        "keyword_count": 79,
        "children": null,
        "level": 0,
        "parent": "node_1_6",
        "source_seconds": [
          60,
          61,
          62,
          63,
          64
        ],
        "source_transcriptions": [
          14,
          15,
          16
        ],
        "visual_text": "3rd person perspective of a man standing behind a helicopter. The camera is mounted on the persons body, capturing the surrounding area. \nA man wearing glasses stands near the rear door of a small blue plane. The camera captures the scene from his point of view, showing the plane's number 7373. Another person can be seen in the background by the water, likely admiring the aircraft or preparing for departure. 45 seconds of footage featuring a man with glasses and a hat standing in front of a small airplane. He appears to be smiling, possibly excited about flying the plane. The image captures the outdoor setting, providing an interesting glimpse into aviation. 4 people on a raft next to a large blue and white plane 1-second scene featuring people preparing to water ski, with a pontoon-style water craft on the left side of the image and a boat in the background. There are two men on the shore of a lake, one man standing in the water and another man standing on the pontoon-style water craft. The third man is wearing a red life jacket, standing on top of the water ski device as they get ready for the activity.",
        "audio_text": "",
        "combined_text": "3rd person perspective of a man standing behind a helicopter. The camera is mounted on the persons body, capturing the surrounding area. \nA man wearing glasses stands near the rear door of a small blue plane. The camera captures the scene from his point of view, showing the plane's number 7373. Another person can be seen in the background by the water, likely admiring the aircraft or preparing for departure. 45 seconds of footage featuring a man with glasses and a hat standing in front of a small airplane. He appears to be smiling, possibly excited about flying the plane. The image captures the outdoor setting, providing an interesting glimpse into aviation. 4 people on a raft next to a large blue and white plane 1-second scene featuring people preparing to water ski, with a pontoon-style water craft on the left side of the image and a boat in the background. There are two men on the shore of a lake, one man standing in the water and another man standing on the pontoon-style water craft. The third man is wearing a red life jacket, standing on top of the water ski device as they get ready for the activity."
      },
      "leaf_13": {
        "node_id": "leaf_13",
        "time_range": [
          65.0,
          70.0
        ],
        "duration": 5.0,
        "keywords": [
          "30",
          "airplane",
          "blue",
          "boat",
          "canister",
          "day",
          "disembark",
          "featuring",
          "hanging",
          "holding",
          "hook",
          "image",
          "lake",
          "lapse",
          "man",
          "next",
          "orange",
          "overcast",
          "people",
          "person",
          "preparing",
          "rope",
          "scene",
          "seaplane",
          "shot",
          "showing",
          "side",
          "sitting",
          "small",
          "stands",
          "tank",
          "time",
          "video",
          "visible",
          "water",
          "white"
        ],
        "keyword_count": 36,
        "children": null,
        "level": 0,
        "parent": "node_1_6",
        "source_seconds": [
          65,
          66,
          67,
          68,
          69
        ],
        "source_transcriptions": [
          15,
          16,
          17
        ],
        "visual_text": "4 people are visible in the image, with one person on a boat holding an orange canister. \nA man stands on the side of a small white and blue airplane holding an orange tank, while preparing to disembark. 1-second scene featuring a small airplane that is sitting on the water. A rope is hanging from a hook next to the airplane. 30-second time-lapse shot of a seaplane on a lake on an overcast day. 1 second video showing a blue and white airplane that is sitting on the water.",
        "audio_text": "",
        "combined_text": "4 people are visible in the image, with one person on a boat holding an orange canister. \nA man stands on the side of a small white and blue airplane holding an orange tank, while preparing to disembark. 1-second scene featuring a small airplane that is sitting on the water. A rope is hanging from a hook next to the airplane. 30-second time-lapse shot of a seaplane on a lake on an overcast day. 1 second video showing a blue and white airplane that is sitting on the water."
      },
      "leaf_14": {
        "node_id": "leaf_14",
        "time_range": [
          70.0,
          75.0
        ],
        "duration": 5.0,
        "keywords": [
          "10",
          "angle",
          "blurry",
          "body",
          "camera",
          "capturing",
          "cloudy",
          "colors",
          "conditions",
          "dark",
          "day",
          "edge",
          "family",
          "fishing",
          "grey",
          "guys",
          "hand",
          "image",
          "lake",
          "large",
          "light",
          "likely",
          "looking",
          "low",
          "man",
          "muted",
          "ocean",
          "out",
          "over",
          "overcast",
          "people",
          "perspective",
          "placed",
          "possibly",
          "re",
          "rod",
          "scene",
          "showing",
          "shutter",
          "side",
          "skies",
          "slow",
          "somewhat",
          "speed",
          "stability",
          "standing",
          "suggesting",
          "taken",
          "tripod",
          "video",
          "water",
          "well",
          "wide"
        ],
        "keyword_count": 53,
        "children": null,
        "level": 0,
        "parent": "node_1_7",
        "source_seconds": [
          70,
          71,
          72,
          73,
          74
        ],
        "source_transcriptions": [
          17,
          18
        ],
        "visual_text": "10 second video of a man looking out over a body of water, possibly a lake or ocean. 3 people standing by a large body of water, likely a lake. The image is somewhat blurry, suggesting that it may have been taken with a slow shutter speed or in low light conditions. 1-second video showing a family at a lake on an overcast day with dark skies, grey water, and muted colors. 1-second scene showing a man standing by the water's edge on a cloudy day with a fishing rod in his hand. The camera is placed on a tripod for stability, capturing the scene in wide-angle perspective.",
        "audio_text": "Well guys that's it we're all by our side.",
        "combined_text": "10 second video of a man looking out over a body of water, possibly a lake or ocean. 3 people standing by a large body of water, likely a lake. The image is somewhat blurry, suggesting that it may have been taken with a slow shutter speed or in low light conditions. 1-second video showing a family at a lake on an overcast day with dark skies, grey water, and muted colors. 1-second scene showing a man standing by the water's edge on a cloudy day with a fishing rod in his hand. The camera is placed on a tripod for stability, capturing the scene in wide-angle perspective. Well guys that's it we're all by our side."
      },
      "leaf_15": {
        "node_id": "leaf_15",
        "time_range": [
          75.0,
          80.0
        ],
        "duration": 5.0,
        "keywords": [
          "48",
          "angle",
          "appears",
          "background",
          "backpack",
          "beach",
          "beside",
          "bicycles",
          "boy",
          "calm",
          "center",
          "daughter",
          "days",
          "dressed",
          "father",
          "fly",
          "frame",
          "girl",
          "going",
          "gravel",
          "guys",
          "hands",
          "hat",
          "hour",
          "image",
          "lake",
          "lakes",
          "located",
          "location",
          "man",
          "men",
          "near",
          "ourselves",
          "outdoors",
          "perspective",
          "picturesque",
          "pockets",
          "positioned",
          "re",
          "right",
          "seems",
          "shore",
          "shoreline",
          "shot",
          "side",
          "son",
          "standing",
          "stands",
          "suggesting",
          "timelapse",
          "travel",
          "trees",
          "twin",
          "twins",
          "video",
          "water",
          "wearing",
          "welcome",
          "well",
          "wide",
          "young"
        ],
        "keyword_count": 61,
        "children": null,
        "level": 0,
        "parent": "node_1_7",
        "source_seconds": [
          75,
          76,
          77,
          78,
          79
        ],
        "source_transcriptions": [
          18,
          19,
          20
        ],
        "visual_text": "\nA man is standing by the water with his hands in his pockets. 2 men are standing on a gravel shore beside a calm lake with trees in the background 1-second video with a father and son on the beach. 48-hour timelapse of a man and boy on the beach. \nA man stands on the shoreline of a calm lake with his young daughter. They are positioned near the center of the image, which seems to be shot in a wide-angle perspective. The man appears to be wearing a hat, and both he and the girl are dressed for the outdoors. There is a backpack and two bicycles located on the right side of the frame, suggesting that they may have been used to travel to this picturesque location.",
        "audio_text": "Well guys that's it we're all by our side. We're all by ourselves. He's not going to come and get us for three days. Welcome to Twins. Welcome to Twin Lakes We had to fly about an hour",
        "combined_text": "A man is standing by the water with his hands in his pockets. 2 men are standing on a gravel shore beside a calm lake with trees in the background 1-second video with a father and son on the beach. 48-hour timelapse of a man and boy on the beach. \nA man stands on the shoreline of a calm lake with his young daughter. They are positioned near the center of the image, which seems to be shot in a wide-angle perspective. The man appears to be wearing a hat, and both he and the girl are dressed for the outdoors. There is a backpack and two bicycles located on the right side of the frame, suggesting that they may have been used to travel to this picturesque location. Well guys that's it we're all by our side. We're all by ourselves. He's not going to come and get us for three days. Welcome to Twins. Welcome to Twin Lakes We had to fly about an hour"
      },
      "leaf_16": {
        "node_id": "leaf_16",
        "time_range": [
          80.0,
          85.0
        ],
        "duration": 5.0,
        "keywords": [
          "31",
          "360",
          "365",
          "adventure",
          "ago",
          "alaska",
          "angle",
          "another",
          "appears",
          "area",
          "backpack",
          "beautiful",
          "body",
          "camera",
          "captured",
          "capturing",
          "days",
          "degree",
          "float",
          "fly",
          "footage",
          "glasses",
          "going",
          "gravel",
          "green",
          "half",
          "hat",
          "hiking",
          "hour",
          "image",
          "immersive",
          "jacket",
          "lakes",
          "landscape",
          "lens",
          "man",
          "mouth",
          "much",
          "near",
          "nearby",
          "next",
          "ocean",
          "older",
          "orange",
          "ourselves",
          "panoramic",
          "part",
          "person",
          "perspective",
          "plane",
          "providing",
          "re",
          "rocky",
          "room",
          "scene",
          "seconds",
          "shore",
          "someone",
          "stable",
          "standing",
          "surrounding",
          "talking",
          "travel",
          "twin",
          "twins",
          "using",
          "view",
          "vlog",
          "water",
          "wearing",
          "welcome",
          "wide"
        ],
        "keyword_count": 72,
        "children": null,
        "level": 0,
        "parent": "node_1_8",
        "source_seconds": [
          80,
          81,
          82,
          83,
          84
        ],
        "source_transcriptions": [
          19,
          20,
          21
        ],
        "visual_text": "365 days ago, someone captured this scene where a man is standing on a rocky shore next to a body of water. The camera was stable, with a wide-angle lens capturing the beautiful landscape and the man wearing glasses. This footage could be part of a travel vlog or a hiking adventure. \nA man with glasses is standing near water wearing a green jacket and hat. There is also another person in an orange jacket nearby. 31 seconds of camera footage from a first-person perspective in Alaska. 360-degree panoramic image of a man standing on gravel near a body of water. He appears to be wearing a backpack and talking into a camera. The image was captured using a first-person perspective, providing an immersive view of the surrounding area. 360-degree image with an older man standing by the ocean. He has his mouth open, and there is a wide-angle lens being used.",
        "audio_text": "We're all by ourselves. He's not going to come and get us for three days. Welcome to Twins. Welcome to Twin Lakes We had to fly about an hour to fly about an hour and a half in a float plane to get here and this is very much room",
        "combined_text": "365 days ago, someone captured this scene where a man is standing on a rocky shore next to a body of water. The camera was stable, with a wide-angle lens capturing the beautiful landscape and the man wearing glasses. This footage could be part of a travel vlog or a hiking adventure. \nA man with glasses is standing near water wearing a green jacket and hat. There is also another person in an orange jacket nearby. 31 seconds of camera footage from a first-person perspective in Alaska. 360-degree panoramic image of a man standing on gravel near a body of water. He appears to be wearing a backpack and talking into a camera. The image was captured using a first-person perspective, providing an immersive view of the surrounding area. 360-degree image with an older man standing by the ocean. He has his mouth open, and there is a wide-angle lens being used. We're all by ourselves. He's not going to come and get us for three days. Welcome to Twins. Welcome to Twin Lakes We had to fly about an hour to fly about an hour and a half in a float plane to get here and this is very much room"
      },
      "leaf_17": {
        "node_id": "leaf_17",
        "time_range": [
          85.0,
          90.0
        ],
        "duration": 5.0,
        "keywords": [
          "4k",
          "across",
          "action",
          "alaskan",
          "along",
          "another",
          "appears",
          "areas",
          "back",
          "background",
          "backpack",
          "backpacks",
          "boat",
          "body",
          "brightest",
          "camera",
          "camping",
          "causing",
          "detail",
          "edge",
          "float",
          "fly",
          "forecast",
          "frame",
          "gonna",
          "half",
          "hat",
          "hiking",
          "hour",
          "image",
          "jacket",
          "km",
          "lake",
          "lakes",
          "long",
          "looking",
          "loss",
          "man",
          "mounted",
          "much",
          "near",
          "next",
          "nh",
          "okay",
          "overexposed",
          "patch",
          "people",
          "person",
          "picture",
          "plane",
          "present",
          "raincoat",
          "raining",
          "remote",
          "room",
          "says",
          "scene",
          "shore",
          "showing",
          "slightly",
          "standing",
          "suggesting",
          "taken",
          "tents",
          "twin",
          "video",
          "water",
          "wearing",
          "welcome",
          "wilderness"
        ],
        "keyword_count": 70,
        "children": null,
        "level": 0,
        "parent": "node_1_8",
        "source_seconds": [
          85,
          86,
          87,
          88,
          89
        ],
        "source_transcriptions": [
          20,
          21,
          22
        ],
        "visual_text": "1 second long video showing a man wearing a hat standing next to the water. He has a patch on his jacket that says \"KM\". In the background there are tents suggesting that he is camping by the lake. \nA man standing by the water with an NH jacket on looking back at the camera. In the background there is a backpack and another person near the edge of the frame. \n\nA man wearing a hat and a raincoat is standing by a body of water. He appears to be looking towards the camera as if having his picture taken. There are a few other people present in the background, along with some backpacks and a boat on the water. The image is slightly overexposed, causing some loss of detail in the brightest areas. 4K video taken with an action camera mounted on a backpack while hiking near a body of water. 1-second scene showing a man standing on the shore next to a lake with a backpack on his back and another person across the water.",
        "audio_text": "Welcome to Twin Lakes We had to fly about an hour to fly about an hour and a half in a float plane to get here and this is very much room very much remote Alaskan wilderness. Okay, whether forecast is is gonna be raining on.",
        "combined_text": "1 second long video showing a man wearing a hat standing next to the water. He has a patch on his jacket that says \"KM\". In the background there are tents suggesting that he is camping by the lake. \nA man standing by the water with an NH jacket on looking back at the camera. In the background there is a backpack and another person near the edge of the frame. \n\nA man wearing a hat and a raincoat is standing by a body of water. He appears to be looking towards the camera as if having his picture taken. There are a few other people present in the background, along with some backpacks and a boat on the water. The image is slightly overexposed, causing some loss of detail in the brightest areas. 4K video taken with an action camera mounted on a backpack while hiking near a body of water. 1-second scene showing a man standing on the shore next to a lake with a backpack on his back and another person across the water. Welcome to Twin Lakes We had to fly about an hour to fly about an hour and a half in a float plane to get here and this is very much room very much remote Alaskan wilderness. Okay, whether forecast is is gonna be raining on."
      },
      "leaf_18": {
        "node_id": "leaf_18",
        "time_range": [
          90.0,
          95.0
        ],
        "duration": 5.0,
        "keywords": [
          "03",
          "2nd",
          "3rd",
          "59",
          "64",
          "above",
          "adventure",
          "aged",
          "alaskan",
          "backpack",
          "beard",
          "camera",
          "capturing",
          "cloudy",
          "day",
          "face",
          "forecast",
          "forward",
          "front",
          "going",
          "gonna",
          "grey",
          "hat",
          "lake",
          "looking",
          "looks",
          "man",
          "middle",
          "mountain",
          "mounted",
          "mouth",
          "much",
          "near",
          "nearby",
          "next",
          "off",
          "okay",
          "outdoor",
          "person",
          "place",
          "positioned",
          "possibly",
          "pov",
          "raining",
          "remote",
          "river",
          "rocky",
          "shelter",
          "shore",
          "shot",
          "shoulder",
          "standing",
          "stands",
          "strapped",
          "sunglasses",
          "toward",
          "water",
          "wearing",
          "wilderness"
        ],
        "keyword_count": 59,
        "children": null,
        "level": 0,
        "parent": "node_1_9",
        "source_seconds": [
          90,
          91,
          92,
          93,
          94
        ],
        "source_transcriptions": [
          22,
          23
        ],
        "visual_text": "0:59 to 0:64: A man wearing sunglasses. 1-second shot of a man standing in front of a mountain with a lake nearby. The camera is positioned above the man's shoulder, capturing his face as he looks toward the water. 3rd person POV of a middle-aged man with a beard standing near water on a cloudy day. The camera is possibly mounted on his backpack, capturing his outdoor adventure. 03 - A man wearing sunglasses and a grey hat stands near a river. 2nd person POV shot of a man standing on rocky shore next to a lake with mouth open, looking forward with a backpack strapped on.",
        "audio_text": "very much remote Alaskan wilderness. Okay, whether forecast is is gonna be raining on. going to be raining on and off so I don't want to find a place to build my shelter.",
        "combined_text": "0:59 to 0:64: A man wearing sunglasses. 1-second shot of a man standing in front of a mountain with a lake nearby. The camera is positioned above the man's shoulder, capturing his face as he looks toward the water. 3rd person POV of a middle-aged man with a beard standing near water on a cloudy day. The camera is possibly mounted on his backpack, capturing his outdoor adventure. 03 - A man wearing sunglasses and a grey hat stands near a river. 2nd person POV shot of a man standing on rocky shore next to a lake with mouth open, looking forward with a backpack strapped on. very much remote Alaskan wilderness. Okay, whether forecast is is gonna be raining on. going to be raining on and off so I don't want to find a place to build my shelter."
      },
      "leaf_19": {
        "node_id": "leaf_19",
        "time_range": [
          95.0,
          100.0
        ],
        "duration": 5.0,
        "keywords": [
          "00",
          "01",
          "57",
          "59",
          "along",
          "backpack",
          "backpacks",
          "bag",
          "carrying",
          "coat",
          "down",
          "drop",
          "enjoying",
          "forest",
          "glasses",
          "going",
          "grab",
          "gravel",
          "grey",
          "guys",
          "hat",
          "huh",
          "jackets",
          "lake",
          "like",
          "man",
          "men",
          "mouth",
          "off",
          "orange",
          "outdoors",
          "path",
          "people",
          "place",
          "raining",
          "red",
          "right",
          "shelter",
          "shoreline",
          "spot",
          "stands",
          "stuff",
          "time",
          "walking",
          "water",
          "wearing"
        ],
        "keyword_count": 46,
        "children": null,
        "level": 0,
        "parent": "node_1_9",
        "source_seconds": [
          95,
          96,
          97,
          98,
          99
        ],
        "source_transcriptions": [
          23,
          24,
          25
        ],
        "visual_text": "00:57-01:59 - A man with glasses and a hat on stands on the shoreline of a lake with his mouth open. 3 people wearing red jackets are walking on gravel along a shoreline by a lake 2 men are walking by the water. One is carrying a red bag while the other is wearing a backpack. They seem to be enjoying their time outdoors. 2 people walking by the water with backpacks, one is wearing an orange coat. \nA man is carrying a grey backpack while walking down a path in the forest.",
        "audio_text": "going to be raining on and off so I don't want to find a place to build my shelter. All right, you guys like this spot huh? this spot huh let's drop it you guys think you can go grab the other stuff",
        "combined_text": "00:57-01:59 - A man with glasses and a hat on stands on the shoreline of a lake with his mouth open. 3 people wearing red jackets are walking on gravel along a shoreline by a lake 2 men are walking by the water. One is carrying a red bag while the other is wearing a backpack. They seem to be enjoying their time outdoors. 2 people walking by the water with backpacks, one is wearing an orange coat. \nA man is carrying a grey backpack while walking down a path in the forest. going to be raining on and off so I don't want to find a place to build my shelter. All right, you guys like this spot huh? this spot huh let's drop it you guys think you can go grab the other stuff"
      },
      "leaf_20": {
        "node_id": "leaf_20",
        "time_range": [
          100.0,
          105.0
        ],
        "duration": 5.0,
        "keywords": [
          "360",
          "3rd",
          "4k",
          "angle",
          "area",
          "back",
          "backpack",
          "blue",
          "camera",
          "carrying",
          "characteristics",
          "coat",
          "coats",
          "contains",
          "details",
          "distortion",
          "drop",
          "field",
          "grab",
          "grassy",
          "guys",
          "hiking",
          "huh",
          "image",
          "jacket",
          "jeans",
          "large",
          "lens",
          "like",
          "man",
          "mounted",
          "people",
          "person",
          "perspective",
          "rain",
          "red",
          "resolution",
          "right",
          "showing",
          "spot",
          "stuff",
          "trees",
          "video",
          "view",
          "walking",
          "wearing",
          "wide",
          "woods"
        ],
        "keyword_count": 48,
        "children": null,
        "level": 0,
        "parent": "node_1_10",
        "source_seconds": [
          100,
          101,
          102,
          103,
          104
        ],
        "source_transcriptions": [
          24,
          25,
          26
        ],
        "visual_text": "3rd person perspective showing a man hiking in the woods with a red jacket on his back. 4K resolution, camera mounted on backpack, wide-angle lens with distortion, first-person perspective 2 people wearing red coats are walking through grassy area with trees 360 video of a person in a red coat and blue jeans walking in the rain with a backpack on. 3rd person perspective of a man walking in the woods carrying a large backpack. The image also contains details about camera perspective, field of view, and lens characteristics.",
        "audio_text": "All right, you guys like this spot huh? this spot huh let's drop it you guys think you can go grab the other stuff stuff.",
        "combined_text": "3rd person perspective showing a man hiking in the woods with a red jacket on his back. 4K resolution, camera mounted on backpack, wide-angle lens with distortion, first-person perspective 2 people wearing red coats are walking through grassy area with trees 360 video of a person in a red coat and blue jeans walking in the rain with a backpack on. 3rd person perspective of a man walking in the woods carrying a large backpack. The image also contains details about camera perspective, field of view, and lens characteristics. All right, you guys like this spot huh? this spot huh let's drop it you guys think you can go grab the other stuff stuff."
      },
      "leaf_21": {
        "node_id": "leaf_21",
        "time_range": [
          105.0,
          110.0
        ],
        "duration": 5.0,
        "keywords": [
          "3rd",
          "appears",
          "area",
          "back",
          "backpack",
          "brown",
          "camera",
          "carrying",
          "drop",
          "grab",
          "guys",
          "hat",
          "huh",
          "looking",
          "man",
          "men",
          "near",
          "next",
          "off",
          "pants",
          "people",
          "person",
          "perspective",
          "scene",
          "sheet",
          "showing",
          "something",
          "spot",
          "standing",
          "stuff",
          "tan",
          "tent",
          "tree",
          "trees",
          "umbrella",
          "wearing",
          "wilderness",
          "wooded",
          "woods",
          "yes"
        ],
        "keyword_count": 40,
        "children": null,
        "level": 0,
        "parent": "node_1_10",
        "source_seconds": [
          105,
          106,
          107,
          108,
          109
        ],
        "source_transcriptions": [
          25,
          26,
          27
        ],
        "visual_text": "3rd person perspective showing a man standing in the woods with a backpack on his back. He is near many trees and appears to be looking at something off-camera. 1-second scene showing a man wearing a brown hat and tan pants standing next to a tree with a backpack in the wilderness. 2 men are standing near a tent in the woods 2 men are near an umbrella in a wooded area 3 people are in a wooded area, with one man wearing tan pants and carrying a sheet.",
        "audio_text": "this spot huh let's drop it you guys think you can go grab the other stuff stuff. Yes.",
        "combined_text": "3rd person perspective showing a man standing in the woods with a backpack on his back. He is near many trees and appears to be looking at something off-camera. 1-second scene showing a man wearing a brown hat and tan pants standing next to a tree with a backpack in the wilderness. 2 men are standing near a tent in the woods 2 men are near an umbrella in a wooded area 3 people are in a wooded area, with one man wearing tan pants and carrying a sheet. this spot huh let's drop it you guys think you can go grab the other stuff stuff. Yes."
      },
      "leaf_22": {
        "node_id": "leaf_22",
        "time_range": [
          110.0,
          115.0
        ],
        "duration": 5.0,
        "keywords": [
          "30",
          "adult",
          "black",
          "blanket",
          "camera",
          "canopy",
          "captured",
          "characteristics",
          "children",
          "clip",
          "context",
          "contribute",
          "details",
          "detections",
          "elements",
          "field",
          "gear",
          "glasses",
          "helmet",
          "hugged",
          "indicate",
          "inside",
          "jacket",
          "jackets",
          "lens",
          "male",
          "man",
          "men",
          "mounted",
          "multiple",
          "near",
          "object",
          "orange",
          "outdoors",
          "overall",
          "people",
          "person",
          "perspective",
          "photo",
          "positioning",
          "presence",
          "presented",
          "production",
          "providing",
          "red",
          "right",
          "rightind",
          "scene",
          "setting",
          "showing",
          "sitting",
          "someone",
          "something",
          "standing",
          "style",
          "subject",
          "taking",
          "technical",
          "tent",
          "tree",
          "umbrella",
          "under",
          "understanding",
          "various",
          "video",
          "view",
          "viewer",
          "wearing",
          "white",
          "within",
          "working",
          "yes"
        ],
        "keyword_count": 72,
        "children": null,
        "level": 0,
        "parent": "node_1_11",
        "source_seconds": [
          110,
          111,
          112,
          113,
          114
        ],
        "source_transcriptions": [
          27,
          28
        ],
        "visual_text": "1-second video showing a man in an orange jacket doing something with two other people in orange jackets who are working on a tree. 30 second video clip with an adult male subject. The man is wearing a black jacket and is standing outdoors under a tree. Multiple object detections indicate the presence of various elements within the scene, providing context and setting for the viewer. Technical details on camera perspective, positioning, field of view, lens characteristics, and video production style contribute to an overall understanding of how the scene was captured and presented in the clip. \nA man wearing glasses is being hugged by someone under an umbrella. 3 people are under a white canopy, with the man on the right and two children on the left. There is a red blanket near them. 3 men are sitting inside a tent with their gear, while one person is taking a photo with the camera mounted on his helmet.",
        "audio_text": "Yes. Come on. Rightind.",
        "combined_text": "1-second video showing a man in an orange jacket doing something with two other people in orange jackets who are working on a tree. 30 second video clip with an adult male subject. The man is wearing a black jacket and is standing outdoors under a tree. Multiple object detections indicate the presence of various elements within the scene, providing context and setting for the viewer. Technical details on camera perspective, positioning, field of view, lens characteristics, and video production style contribute to an overall understanding of how the scene was captured and presented in the clip. \nA man wearing glasses is being hugged by someone under an umbrella. 3 people are under a white canopy, with the man on the right and two children on the left. There is a red blanket near them. 3 men are sitting inside a tent with their gear, while one person is taking a photo with the camera mounted on his helmet. Yes. Come on. Rightind."
      },
      "leaf_23": {
        "node_id": "leaf_23",
        "time_range": [
          115.0,
          120.0
        ],
        "duration": 5.0,
        "keywords": [
          "10",
          "30",
          "along",
          "areas",
          "arm",
          "background",
          "bear",
          "behind",
          "black",
          "blankets",
          "bu",
          "camera",
          "camping",
          "family",
          "fisherman",
          "fishing",
          "forest",
          "frame",
          "going",
          "grab",
          "gravel",
          "grey",
          "hood",
          "image",
          "jacket",
          "jumpsuits",
          "looking",
          "man",
          "mounted",
          "near",
          "objects",
          "outdoors",
          "people",
          "perspective",
          "pole",
          "providing",
          "re",
          "red",
          "rightind",
          "riverbank",
          "rocky",
          "scene",
          "seen",
          "showing",
          "sitting",
          "spray",
          "standing",
          "stream",
          "tent",
          "tents",
          "tommy",
          "trees",
          "trip",
          "unique",
          "video",
          "water",
          "wearing"
        ],
        "keyword_count": 57,
        "children": null,
        "level": 0,
        "parent": "node_1_11",
        "source_seconds": [
          115,
          116,
          117,
          118,
          119
        ],
        "source_transcriptions": [
          28,
          29,
          30
        ],
        "visual_text": "1 second video of a family on a camping trip. They are sitting on blankets in a tent. \nIn the image, there is a man wearing a black jacket with grey hood who is looking behind him while standing in the forest. The camera is mounted on a pole, providing a unique perspective of the scene. Trees can be seen in the background, along with other objects or people in the frame. 30 second video of a man outdoors 4 fisherman standing on gravel by stream with tents in background 10-second video showing people in red jumpsuits near water and rocky areas, with tents set up on the riverbank.",
        "audio_text": "Come on. Rightind. bu arm Tommy, you're going fishing? Grab your bear spray.",
        "combined_text": "1 second video of a family on a camping trip. They are sitting on blankets in a tent. \nIn the image, there is a man wearing a black jacket with grey hood who is looking behind him while standing in the forest. The camera is mounted on a pole, providing a unique perspective of the scene. Trees can be seen in the background, along with other objects or people in the frame. 30 second video of a man outdoors 4 fisherman standing on gravel by stream with tents in background 10-second video showing people in red jumpsuits near water and rocky areas, with tents set up on the riverbank. Come on. Rightind. bu arm Tommy, you're going fishing? Grab your bear spray."
      },
      "leaf_24": {
        "node_id": "leaf_24",
        "time_range": [
          120.0,
          125.0
        ],
        "duration": 5.0,
        "keywords": [
          "4k",
          "along",
          "arm",
          "background",
          "beach",
          "bear",
          "body",
          "bu",
          "camera",
          "capturing",
          "definition",
          "distance",
          "fishermen",
          "fishing",
          "going",
          "grab",
          "gravel",
          "harness",
          "high",
          "holding",
          "jacket",
          "lake",
          "mountain",
          "mountains",
          "mounted",
          "near",
          "next",
          "ocean",
          "pebble",
          "person",
          "perspective",
          "point",
          "range",
          "re",
          "red",
          "road",
          "rods",
          "showing",
          "someone",
          "spray",
          "standing",
          "stream",
          "taken",
          "tommy",
          "ultra",
          "video",
          "view",
          "waders",
          "walking",
          "water",
          "wearing",
          "woman"
        ],
        "keyword_count": 52,
        "children": null,
        "level": 0,
        "parent": "node_1_12",
        "source_seconds": [
          120,
          121,
          122,
          123,
          124
        ],
        "source_transcriptions": [
          29,
          30,
          31
        ],
        "visual_text": "3 fishermen standing by a stream, wearing waders and holding fishing rods 1-second video showing a woman wearing a red jacket walking next to the ocean. 1 second video taken from a first-person perspective showing someone in red standing on a pebble beach next to the ocean. 1 second video showing someone standing on gravel near water with a mountain range in the background. 4K ultra high definition camera mounted on a body harness capturing a woman's point of view while walking along a gravel road near a lake with mountains in the distance.",
        "audio_text": "bu arm Tommy, you're going fishing? Grab your bear spray. of your bear spray.",
        "combined_text": "3 fishermen standing by a stream, wearing waders and holding fishing rods 1-second video showing a woman wearing a red jacket walking next to the ocean. 1 second video taken from a first-person perspective showing someone in red standing on a pebble beach next to the ocean. 1 second video showing someone standing on gravel near water with a mountain range in the background. 4K ultra high definition camera mounted on a body harness capturing a woman's point of view while walking along a gravel road near a lake with mountains in the distance. bu arm Tommy, you're going fishing? Grab your bear spray. of your bear spray."
      },
      "leaf_25": {
        "node_id": "leaf_25",
        "time_range": [
          125.0,
          130.0
        ],
        "duration": 5.0,
        "keywords": [
          "00",
          "01",
          "another",
          "appears",
          "area",
          "bear",
          "behind",
          "black",
          "blue",
          "conversation",
          "daytime",
          "down",
          "fishing",
          "forest",
          "front",
          "going",
          "grab",
          "gravel",
          "ground",
          "gun",
          "hand",
          "hat",
          "holding",
          "image",
          "jacket",
          "man",
          "men",
          "nothing",
          "object",
          "outdoors",
          "person",
          "raincoat",
          "re",
          "red",
          "rod",
          "scene",
          "showing",
          "sitting",
          "spray",
          "standing",
          "suit",
          "tent",
          "tommy",
          "toob",
          "video",
          "wearing"
        ],
        "keyword_count": 46,
        "children": null,
        "level": 0,
        "parent": "node_1_12",
        "source_seconds": [
          125,
          126,
          127,
          128,
          129
        ],
        "source_transcriptions": [
          30,
          31,
          32
        ],
        "visual_text": "0:01 to 1:00 \n\nIn the image, there is a person wearing a red raincoat standing in front of a blue tent with a fishing rod in hand. Behind him, there is an area with gravel on the ground. The scene appears to be set outdoors during the daytime. 1-second video showing a man with a gun in the forest 2 men are outdoors, one wearing a red suit and hat, while another is sitting down in a black jacket with a raincoat, holding a blue object. They seem to be having a conversation.",
        "audio_text": "Tommy, you're going fishing? Grab your bear spray. of your bear spray. It's nothing toob.",
        "combined_text": "0:01 to 1:00 \n\nIn the image, there is a person wearing a red raincoat standing in front of a blue tent with a fishing rod in hand. Behind him, there is an area with gravel on the ground. The scene appears to be set outdoors during the daytime. 1-second video showing a man with a gun in the forest 2 men are outdoors, one wearing a red suit and hat, while another is sitting down in a black jacket with a raincoat, holding a blue object. They seem to be having a conversation. Tommy, you're going fishing? Grab your bear spray. of your bear spray. It's nothing toob."
      },
      "leaf_26": {
        "node_id": "leaf_26",
        "time_range": [
          130.0,
          135.0
        ],
        "duration": 5.0,
        "keywords": [
          "4k",
          "activities",
          "activity",
          "addition",
          "additional",
          "adventure",
          "along",
          "another",
          "around",
          "backpack",
          "backpacks",
          "bait",
          "beside",
          "between",
          "cameras",
          "capturing",
          "child",
          "close",
          "colored",
          "container",
          "covering",
          "detail",
          "different",
          "down",
          "editing",
          "file",
          "filled",
          "fish",
          "fishing",
          "gear",
          "gravel",
          "ground",
          "hand",
          "holding",
          "indicating",
          "individual",
          "interest",
          "kneeling",
          "lake",
          "looks",
          "lot",
          "lure",
          "main",
          "man",
          "multiple",
          "nearby",
          "nearer",
          "next",
          "nothing",
          "objects",
          "observer",
          "observing",
          "outdoor",
          "people",
          "person",
          "pieces",
          "placed",
          "present",
          "purposes",
          "raw",
          "red",
          "rocks",
          "scattered",
          "scene",
          "scenes",
          "seen",
          "several",
          "showing",
          "snowsuit",
          "sports",
          "standing",
          "stream",
          "subjects",
          "suggesting",
          "supplies",
          "toob",
          "various",
          "video",
          "videos",
          "visible",
          "water",
          "wearing",
          "within",
          "wow",
          "yee",
          "yeee",
          "yes"
        ],
        "keyword_count": 87,
        "children": null,
        "level": 0,
        "parent": "node_1_13",
        "source_seconds": [
          130,
          131,
          132,
          133,
          134
        ],
        "source_transcriptions": [
          32,
          33
        ],
        "visual_text": "1-second video showing a man and a child fishing by a stream of water. The man is holding a fishing lure in his hand while the child looks on with interest. A container filled with different colored bait can be seen between them, along with several individual pieces of bait scattered around. There are multiple fish visible within the scene, indicating that they have already caught some fish.\n\nIn addition to the fishing activity, there are two backpacks in the scene, one close to the man and another close to the child, suggesting that they may have brought supplies and gear for their outdoor adventure. 1-second video showing a man and a child fishing by a stream of water. The man is kneeling down beside a container with bait in it, while the child is observing. There are several fish nearby, and an additional two people are present, one close to the observer and another nearer objects. A backpack can be seen placed on the ground next to the main subjects.\n\n cameras used for capturing the scene: 1-second videos covering various outdoor scenes, such as fishing, sports, and other activities \nA person wearing a red snowsuit is standing in the gravel. \nA man is fishing on a lake and there are some rocks nearby. 4K raw file with a lot of detail for editing purposes",
        "audio_text": "It's nothing toob. want.' WOW, yes! get in there. YEEE YEE",
        "combined_text": "1-second video showing a man and a child fishing by a stream of water. The man is holding a fishing lure in his hand while the child looks on with interest. A container filled with different colored bait can be seen between them, along with several individual pieces of bait scattered around. There are multiple fish visible within the scene, indicating that they have already caught some fish.\n\nIn addition to the fishing activity, there are two backpacks in the scene, one close to the man and another close to the child, suggesting that they may have brought supplies and gear for their outdoor adventure. 1-second video showing a man and a child fishing by a stream of water. The man is kneeling down beside a container with bait in it, while the child is observing. There are several fish nearby, and an additional two people are present, one close to the observer and another nearer objects. A backpack can be seen placed on the ground next to the main subjects.\n\n cameras used for capturing the scene: 1-second videos covering various outdoor scenes, such as fishing, sports, and other activities \nA person wearing a red snowsuit is standing in the gravel. \nA man is fishing on a lake and there are some rocks nearby. 4K raw file with a lot of detail for editing purposes It's nothing toob. want.' WOW, yes! get in there. YEEE YEE"
      },
      "leaf_27": {
        "node_id": "leaf_27",
        "time_range": [
          135.0,
          140.0
        ],
        "duration": 5.0,
        "keywords": [
          "00",
          "01",
          "360",
          "actions",
          "another",
          "appears",
          "background",
          "black",
          "body",
          "camera",
          "captured",
          "captures",
          "chest",
          "degree",
          "distance",
          "enjoying",
          "environment",
          "fish",
          "fishing",
          "fly",
          "following",
          "footage",
          "gray",
          "helmet",
          "holding",
          "hurry",
          "image",
          "includes",
          "jacket",
          "lake",
          "man",
          "mean",
          "mountain",
          "mountains",
          "mounted",
          "next",
          "objects",
          "oh",
          "outdoors",
          "part",
          "person",
          "perspective",
          "point",
          "possibly",
          "red",
          "rock",
          "rocks",
          "rod",
          "scene",
          "simply",
          "sky",
          "standing",
          "stands",
          "stream",
          "suggests",
          "surrounding",
          "using",
          "video",
          "view",
          "wall",
          "water",
          "wearing",
          "wow",
          "yeah",
          "yee",
          "yeee",
          "yes"
        ],
        "keyword_count": 67,
        "children": null,
        "level": 0,
        "parent": "node_1_13",
        "source_seconds": [
          135,
          136,
          137,
          138,
          139
        ],
        "source_transcriptions": [
          33,
          34,
          35
        ],
        "visual_text": "360-degree view of a man standing on a rock in the water, wearing a black jacket. \nA man standing on rocks next to a body of water holding a fishing rod. 00:01: A person is fishing with a red fish in the water \nA man in a black jacket stands in a stream with a fishing rod. The image captures a 1-second scene that includes the following objects and actions: \n\n1. Person: A man wearing a black jacket is holding a fishing rod. He appears to be standing in a body of water, possibly fishing or simply enjoying the outdoors. \n2. Camera: The camera perspective suggests that the video was captured using a first-person point of view. This could mean that the camera is mounted on the person's helmet, chest, or another part of their body. \n3. Environment: The surrounding environment includes water and possibly mountains in the distance. 360 footage of man fly fishing on mountain lake with gray sky in background.",
        "audio_text": "want.' WOW, yes! get in there. YEEE YEE Get in there. Yes! Hurry, get in the wall! Yes! Yes! Yeah! Oh yeah! Oh, I need to...",
        "combined_text": "360-degree view of a man standing on a rock in the water, wearing a black jacket. \nA man standing on rocks next to a body of water holding a fishing rod. 00:01: A person is fishing with a red fish in the water \nA man in a black jacket stands in a stream with a fishing rod. The image captures a 1-second scene that includes the following objects and actions: \n\n1. Person: A man wearing a black jacket is holding a fishing rod. He appears to be standing in a body of water, possibly fishing or simply enjoying the outdoors. \n2. Camera: The camera perspective suggests that the video was captured using a first-person point of view. This could mean that the camera is mounted on the person's helmet, chest, or another part of their body. \n3. Environment: The surrounding environment includes water and possibly mountains in the distance. 360 footage of man fly fishing on mountain lake with gray sky in background. want.' WOW, yes! get in there. YEEE YEE Get in there. Yes! Hurry, get in the wall! Yes! Yes! Yeah! Oh yeah! Oh, I need to..."
      },
      "leaf_28": {
        "node_id": "leaf_28",
        "time_range": [
          140.0,
          145.0
        ],
        "duration": 5.0,
        "keywords": [
          "360",
          "along",
          "area",
          "behind",
          "boy",
          "camera",
          "chart",
          "child",
          "degree",
          "dollar",
          "featuring",
          "fishing",
          "fly",
          "hat",
          "holding",
          "hurry",
          "jacket",
          "line",
          "man",
          "oh",
          "orange",
          "out",
          "outfit",
          "people",
          "person",
          "perspective",
          "positioning",
          "rain",
          "red",
          "river",
          "riverbank",
          "rocky",
          "rod",
          "rods",
          "scene",
          "showing",
          "stable",
          "standing",
          "stream",
          "suit",
          "video",
          "waders",
          "wall",
          "water",
          "wearing",
          "yeah",
          "yes",
          "young"
        ],
        "keyword_count": 48,
        "children": null,
        "level": 0,
        "parent": "node_1_14",
        "source_seconds": [
          140,
          141,
          142,
          143,
          144
        ],
        "source_transcriptions": [
          34,
          35,
          36
        ],
        "visual_text": "2 people standing by a river with their fishing rods. 1-second scene featuring a boy in an orange rain suit standing by a river and holding a fishing rod. 1 second video showing young child wearing red jacket, waders and hat while fishing along riverbank in rocky area. Camera perspective is from behind the boy with stable camera positioning. 360-degree video of a person fishing in a stream of water. 1-second scene of a man in a red outfit fishing on a rocky stream with a fly fishing rod.",
        "audio_text": "Get in there. Yes! Hurry, get in the wall! Yes! Yes! Yeah! Oh yeah! Oh, I need to... Let's have line out, let's have line out. That is a chart, that's a dollar.",
        "combined_text": "2 people standing by a river with their fishing rods. 1-second scene featuring a boy in an orange rain suit standing by a river and holding a fishing rod. 1 second video showing young child wearing red jacket, waders and hat while fishing along riverbank in rocky area. Camera perspective is from behind the boy with stable camera positioning. 360-degree video of a person fishing in a stream of water. 1-second scene of a man in a red outfit fishing on a rocky stream with a fly fishing rod. Get in there. Yes! Hurry, get in the wall! Yes! Yes! Yeah! Oh yeah! Oh, I need to... Let's have line out, let's have line out. That is a chart, that's a dollar."
      },
      "leaf_29": {
        "node_id": "leaf_29",
        "time_range": [
          145.0,
          150.0
        ],
        "duration": 5.0,
        "keywords": [
          "20",
          "action",
          "allowing",
          "allows",
          "angle",
          "area",
          "around",
          "backpack",
          "barton",
          "behavior",
          "bird",
          "black",
          "body",
          "bonk",
          "bottle",
          "camera",
          "captured",
          "capturing",
          "chart",
          "closely",
          "daily",
          "dinner",
          "documentation",
          "dog",
          "dollar",
          "dolly",
          "environment",
          "features",
          "fishing",
          "focus",
          "footage",
          "green",
          "ground",
          "held",
          "helmet",
          "immersive",
          "indicates",
          "lens",
          "life",
          "line",
          "man",
          "mounted",
          "movements",
          "near",
          "next",
          "observe",
          "oh",
          "okay",
          "out",
          "outdoor",
          "outdoors",
          "person",
          "perspective",
          "positioned",
          "positioning",
          "ready",
          "road",
          "rocks",
          "scene",
          "seconds",
          "showcases",
          "showing",
          "small",
          "standing",
          "style",
          "suggests",
          "surroundings",
          "taken",
          "video",
          "viewers",
          "visible",
          "vlog",
          "walking",
          "walks",
          "way",
          "wide",
          "within",
          "yeah",
          "yep"
        ],
        "keyword_count": 79,
        "children": null,
        "level": 0,
        "parent": "node_1_14",
        "source_seconds": [
          145,
          146,
          147,
          148,
          149
        ],
        "source_transcriptions": [
          35,
          36,
          37
        ],
        "visual_text": "1 second video of a man fishing next to rocks. \nAn outdoor scene captured with a wide-angle lens that showcases the area's surroundings. A small black dog is visible, walking on the ground. The camera positioning indicates it might be mounted on a backpack or body, allowing for an immersive perspective. The video style suggests this could be a vlog or documentation of daily life. 20 seconds of footage taken outdoors with a focus on a small dog. The camera is positioned in such a way that it is capturing the dog's movements as it walks around on the ground. This perspective allows viewers to closely observe the dog's features and behavior within its environment. 5-second scene captured by an action camera mounted on a helmet, showing a bird standing on the ground near a road. 1-second scene from a first-person perspective, showing a green bottle being held up.",
        "audio_text": "Yeah! Oh yeah! Oh, I need to... Let's have line out, let's have line out. That is a chart, that's a dollar. That's a Dolly Barton. You ready to eat it for dinner? Yep. Okay. Also I can bonk them.",
        "combined_text": "1 second video of a man fishing next to rocks. \nAn outdoor scene captured with a wide-angle lens that showcases the area's surroundings. A small black dog is visible, walking on the ground. The camera positioning indicates it might be mounted on a backpack or body, allowing for an immersive perspective. The video style suggests this could be a vlog or documentation of daily life. 20 seconds of footage taken outdoors with a focus on a small dog. The camera is positioned in such a way that it is capturing the dog's movements as it walks around on the ground. This perspective allows viewers to closely observe the dog's features and behavior within its environment. 5-second scene captured by an action camera mounted on a helmet, showing a bird standing on the ground near a road. 1-second scene from a first-person perspective, showing a green bottle being held up. Yeah! Oh yeah! Oh, I need to... Let's have line out, let's have line out. That is a chart, that's a dollar. That's a Dolly Barton. You ready to eat it for dinner? Yep. Okay. Also I can bonk them."
      },
      "leaf_30": {
        "node_id": "leaf_30",
        "time_range": [
          150.0,
          155.0
        ],
        "duration": 5.0,
        "keywords": [
          "34",
          "3d",
          "48",
          "angle",
          "angles",
          "barton",
          "beach",
          "behind",
          "bent",
          "blancher",
          "bonk",
          "bump",
          "camera",
          "captured",
          "clothing",
          "deli",
          "description",
          "different",
          "dinner",
          "dolly",
          "etc",
          "fish",
          "fishing",
          "focal",
          "gravelly",
          "holding",
          "length",
          "line",
          "men",
          "motion",
          "object",
          "okay",
          "orange",
          "over",
          "people",
          "person",
          "perspective",
          "perspectives",
          "pole",
          "positioning",
          "ready",
          "red",
          "right",
          "river",
          "rocks",
          "rocky",
          "scene",
          "seconds",
          "several",
          "shore",
          "shots",
          "showing",
          "standing",
          "terrain",
          "tracking",
          "various",
          "varten",
          "video",
          "wearing",
          "white",
          "wide",
          "yep"
        ],
        "keyword_count": 62,
        "children": null,
        "level": 0,
        "parent": "node_1_15",
        "source_seconds": [
          150,
          151,
          152,
          153,
          154
        ],
        "source_transcriptions": [
          37,
          38
        ],
        "visual_text": "48 seconds of video with one person in red clothing bent over by rocks. The scene is set on the shore of a river with gravelly terrain. There are several different angles captured, including first-person perspective, wide-angle shots, and various other camera perspectives. 2 men in red and white are at a rocky beach 1 person wearing orange is standing on rocks and holding a fishing pole 34 second video showing two people on rocks with a fishing line 3D object tracking and description (including camera positioning, focal length, object motion, etc.)",
        "audio_text": "That's a Dolly Barton. You ready to eat it for dinner? Yep. Okay. Also I can bonk them. Also I can bump behind it. I have a fish blancher now. So that right there, that's a deli varten.",
        "combined_text": "48 seconds of video with one person in red clothing bent over by rocks. The scene is set on the shore of a river with gravelly terrain. There are several different angles captured, including first-person perspective, wide-angle shots, and various other camera perspectives. 2 men in red and white are at a rocky beach 1 person wearing orange is standing on rocks and holding a fishing pole 34 second video showing two people on rocks with a fishing line 3D object tracking and description (including camera positioning, focal length, object motion, etc.) That's a Dolly Barton. You ready to eat it for dinner? Yep. Okay. Also I can bonk them. Also I can bump behind it. I have a fish blancher now. So that right there, that's a deli varten."
      },
      "leaf_31": {
        "node_id": "leaf_31",
        "time_range": [
          155.0,
          160.0
        ],
        "duration": 5.0,
        "keywords": [
          "action",
          "angle",
          "another",
          "attached",
          "background",
          "barton",
          "behind",
          "blancher",
          "boy",
          "broader",
          "bump",
          "camera",
          "capturing",
          "char",
          "deli",
          "depicting",
          "detected",
          "distinct",
          "distortion",
          "dolly",
          "excitement",
          "family",
          "features",
          "featuring",
          "fish",
          "fishing",
          "focusing",
          "frames",
          "giving",
          "groups",
          "hand",
          "held",
          "holding",
          "hook",
          "image",
          "jacket",
          "large",
          "line",
          "long",
          "man",
          "member",
          "moment",
          "motion",
          "near",
          "objects",
          "oh",
          "okay",
          "outdoors",
          "person",
          "perspective",
          "pink",
          "present",
          "red",
          "right",
          "rocks",
          "scene",
          "shot",
          "six",
          "someone",
          "spot",
          "total",
          "tracks",
          "varten",
          "video",
          "water",
          "wide",
          "yeah",
          "young"
        ],
        "keyword_count": 68,
        "children": null,
        "level": 0,
        "parent": "node_1_15",
        "source_seconds": [
          155,
          156,
          157,
          158,
          159
        ],
        "source_transcriptions": [
          38,
          39,
          40
        ],
        "visual_text": "\nAn action camera is capturing a person's hand holding up a fish. The image features a first-person perspective, focusing on the fish being held up. There are two distinct tracks in the video, with a total of six groups of objects detected. 1 second long fishing line that is attached to a large hook and being held by someone. The hook has a fish on it and there are rocks in the background. 2 frames of a man holding a fish outdoors 1-second scene featuring a young boy holding a fish in his hand. Shot with an action camera, capturing the excitement and motion of the moment. 1-second video depicting a boy in a red jacket holding up a fish near water. Another person is also present in the scene. The image features wide-angle distortion, giving the scene a broader perspective.",
        "audio_text": "Also I can bump behind it. I have a fish blancher now. So that right there, that's a deli varten. to Dolly Barton. See how he's got the pink spot? Oh yeah. He's a member of the char family. Okay. Okay, there you go. Go, go.",
        "combined_text": "An action camera is capturing a person's hand holding up a fish. The image features a first-person perspective, focusing on the fish being held up. There are two distinct tracks in the video, with a total of six groups of objects detected. 1 second long fishing line that is attached to a large hook and being held by someone. The hook has a fish on it and there are rocks in the background. 2 frames of a man holding a fish outdoors 1-second scene featuring a young boy holding a fish in his hand. Shot with an action camera, capturing the excitement and motion of the moment. 1-second video depicting a boy in a red jacket holding up a fish near water. Another person is also present in the scene. The image features wide-angle distortion, giving the scene a broader perspective. Also I can bump behind it. I have a fish blancher now. So that right there, that's a deli varten. to Dolly Barton. See how he's got the pink spot? Oh yeah. He's a member of the char family. Okay. Okay, there you go. Go, go."
      },
      "leaf_32": {
        "node_id": "leaf_32",
        "time_range": [
          160.0,
          165.0
        ],
        "duration": 5.0,
        "keywords": [
          "1k",
          "2k",
          "3rd",
          "above",
          "ahead",
          "angle",
          "appears",
          "area",
          "barton",
          "brown",
          "buddy",
          "camera",
          "captured",
          "capturing",
          "char",
          "child",
          "coat",
          "context",
          "detected",
          "dinner",
          "dolly",
          "down",
          "family",
          "featuring",
          "fish",
          "fishing",
          "frame",
          "frames",
          "giving",
          "grab",
          "grainy",
          "holding",
          "image",
          "jackets",
          "laying",
          "lens",
          "man",
          "member",
          "near",
          "oh",
          "okay",
          "out",
          "people",
          "per",
          "person",
          "perspective",
          "pink",
          "positioned",
          "possibly",
          "reaching",
          "red",
          "reeling",
          "resolution",
          "river",
          "rocks",
          "rods",
          "scene",
          "sense",
          "sensor",
          "shirt",
          "shoulder",
          "showing",
          "something",
          "spot",
          "standing",
          "water",
          "white",
          "wide",
          "wooded",
          "yeah"
        ],
        "keyword_count": 70,
        "children": null,
        "level": 0,
        "parent": "node_1_16",
        "source_seconds": [
          160,
          161,
          162,
          163,
          164
        ],
        "source_transcriptions": [
          39,
          40,
          41
        ],
        "visual_text": "2 people in red jackets are standing by a river holding fishing rods and reeling in fish 1-second scene featuring a person standing on rocks that are brown and white, possibly in a wooded area. The camera is positioned above the person's shoulder, capturing their perspective as they look ahead. 3rd person perspective showing a child in a red coat reaching down to grab something out of frame. The image is grainy and appears to be captured with a wide-angle lens, giving a sense of context to the scene. 3rd person perspective of a man in a red shirt who appears to be laying down by some rocks, possibly near water. 4 frames per second 2k x 1k resolution sensor detected",
        "audio_text": "to Dolly Barton. See how he's got the pink spot? Oh yeah. He's a member of the char family. Okay. Okay, there you go. Go, go. There you go, there's your dinner buddy. Yeah!",
        "combined_text": "2 people in red jackets are standing by a river holding fishing rods and reeling in fish 1-second scene featuring a person standing on rocks that are brown and white, possibly in a wooded area. The camera is positioned above the person's shoulder, capturing their perspective as they look ahead. 3rd person perspective showing a child in a red coat reaching down to grab something out of frame. The image is grainy and appears to be captured with a wide-angle lens, giving a sense of context to the scene. 3rd person perspective of a man in a red shirt who appears to be laying down by some rocks, possibly near water. 4 frames per second 2k x 1k resolution sensor detected to Dolly Barton. See how he's got the pink spot? Oh yeah. He's a member of the char family. Okay. Okay, there you go. Go, go. There you go, there's your dinner buddy. Yeah!"
      },
      "leaf_33": {
        "node_id": "leaf_33",
        "time_range": [
          165.0,
          170.0
        ],
        "duration": 5.0,
        "keywords": [
          "30",
          "3d",
          "3rd",
          "art",
          "boy",
          "bucket",
          "buddy",
          "child",
          "clothing",
          "dinner",
          "dolly",
          "down",
          "enjoying",
          "fishing",
          "gravel",
          "ground",
          "isn",
          "jacket",
          "looking",
          "model",
          "molding",
          "nice",
          "oh",
          "okay",
          "orange",
          "outdoors",
          "outside",
          "people",
          "person",
          "perspective",
          "playing",
          "pole",
          "red",
          "rocks",
          "sand",
          "seconds",
          "snowsuit",
          "standing",
          "stream",
          "toddler",
          "video",
          "water",
          "yeah",
          "young"
        ],
        "keyword_count": 44,
        "children": null,
        "level": 0,
        "parent": "node_1_16",
        "source_seconds": [
          165,
          166,
          167,
          168,
          169
        ],
        "source_transcriptions": [
          40,
          41,
          42
        ],
        "visual_text": "3D model of a toddler in an orange snowsuit playing with rocks outdoors. 30 seconds left of video. 3rd person perspective of a child playing outside by the stream of water. The boy has a sand molding bucket and is playing with it while enjoying the water. 1 second of a young boy in a red jacket looking down at rocks and gravel on the ground with a fishing pole. 2 people with orange clothing standing by some water.",
        "audio_text": "Okay, there you go. Go, go. There you go, there's your dinner buddy. Yeah! Oh, there's a dolly isn't it? Yeah, there's a dolly of art. Nice.",
        "combined_text": "3D model of a toddler in an orange snowsuit playing with rocks outdoors. 30 seconds left of video. 3rd person perspective of a child playing outside by the stream of water. The boy has a sand molding bucket and is playing with it while enjoying the water. 1 second of a young boy in a red jacket looking down at rocks and gravel on the ground with a fishing pole. 2 people with orange clothing standing by some water. Okay, there you go. Go, go. There you go, there's your dinner buddy. Yeah! Oh, there's a dolly isn't it? Yeah, there's a dolly of art. Nice."
      },
      "leaf_34": {
        "node_id": "leaf_34",
        "time_range": [
          170.0,
          175.0
        ],
        "duration": 5.0,
        "keywords": [
          "360",
          "art",
          "beach",
          "black",
          "body",
          "boy",
          "boys",
          "camera",
          "cell",
          "clothes",
          "deep",
          "degree",
          "dolly",
          "edge",
          "experiencing",
          "fish",
          "fishing",
          "footage",
          "holding",
          "isn",
          "jumpsuit",
          "knee",
          "lake",
          "making",
          "man",
          "moment",
          "near",
          "nearby",
          "nice",
          "oh",
          "person",
          "perspective",
          "phone",
          "playing",
          "point",
          "possibly",
          "probably",
          "raincoats",
          "recorded",
          "red",
          "river",
          "rod",
          "scene",
          "seen",
          "showing",
          "shows",
          "standing",
          "talking",
          "video",
          "view",
          "viewer",
          "watches",
          "water",
          "wearing",
          "within",
          "yeah",
          "young"
        ],
        "keyword_count": 57,
        "children": null,
        "level": 0,
        "parent": "node_1_17",
        "source_seconds": [
          170,
          171,
          172,
          173,
          174
        ],
        "source_transcriptions": [
          42,
          43
        ],
        "visual_text": "2 boys on the beach near some water. One boy is wearing a red jumpsuit while the other is wearing black clothes. They are playing by the water's edge and also talking to each other. A cell phone can be seen in the scene, possibly being used or recorded by one of the boys. 2 young boys in red raincoats are by a lake, one of them holding a fish while the other watches 3 boys standing by a body of water, one of whom has a fishing rod 1-second video showing a person standing knee deep in a river with a fish nearby. The camera's perspective is from the person's point of view, making it appear as if the viewer is experiencing the scene from within the moment. 360-degree footage shows a man fishing in a lake.",
        "audio_text": "Oh, there's a dolly isn't it? Yeah, there's a dolly of art. Nice. Got it! L Probably not?",
        "combined_text": "2 boys on the beach near some water. One boy is wearing a red jumpsuit while the other is wearing black clothes. They are playing by the water's edge and also talking to each other. A cell phone can be seen in the scene, possibly being used or recorded by one of the boys. 2 young boys in red raincoats are by a lake, one of them holding a fish while the other watches 3 boys standing by a body of water, one of whom has a fishing rod 1-second video showing a person standing knee deep in a river with a fish nearby. The camera's perspective is from the person's point of view, making it appear as if the viewer is experiencing the scene from within the moment. 360-degree footage shows a man fishing in a lake. Oh, there's a dolly isn't it? Yeah, there's a dolly of art. Nice. Got it! L Probably not?"
      },
      "leaf_35": {
        "node_id": "leaf_35",
        "time_range": [
          175.0,
          180.0
        ],
        "duration": 5.0,
        "keywords": [
          "3rd",
          "action",
          "another",
          "appears",
          "artifacts",
          "blur",
          "blurred",
          "blurry",
          "boy",
          "camera",
          "captured",
          "capturing",
          "compression",
          "depicting",
          "dolly",
          "emphasize",
          "experience",
          "featuring",
          "fisherman",
          "fisheye",
          "fishing",
          "flare",
          "flies",
          "footage",
          "hands",
          "image",
          "immersive",
          "indicating",
          "lake",
          "lens",
          "location",
          "long",
          "lovely",
          "man",
          "men",
          "motion",
          "near",
          "offering",
          "oh",
          "outdoor",
          "outdoors",
          "outside",
          "person",
          "perspective",
          "possibly",
          "present",
          "probably",
          "river",
          "rod",
          "rods",
          "scene",
          "sharon",
          "slightly",
          "standing",
          "technical",
          "tom",
          "unsteady",
          "video",
          "water",
          "weird"
        ],
        "keyword_count": 60,
        "children": null,
        "level": 0,
        "parent": "node_1_17",
        "source_seconds": [
          175,
          176,
          177,
          178,
          179
        ],
        "source_transcriptions": [
          43,
          44,
          45
        ],
        "visual_text": "1 second of video featuring a person fishing with a rod. The footage appears to be slightly blurry, indicating motion or unsteady camera work. The scene is set in an outdoor location, possibly near a lake or river. 1 second long, an action camera video depicting a man fishing in the water with a rod. The video has some technical artifacts present, such as motion blur, lens flare, and compression artifacts. It's captured from the first-person perspective, offering an immersive experience of the outdoors. 3rd person perspective of a boy fishing with his flies. The image has been slightly blurred to emphasize the motion of the fisherman and the water. 1-second video capturing a person fishing in a river with a fisheye perspective. 2 men are standing outside near water with fishing rods in their hands.",
        "audio_text": "Got it! L Probably not? Tom, let me see what you got. You got a dolly. Oh, it's another lovely dolly Sharon let this one go. This is weird",
        "combined_text": "1 second of video featuring a person fishing with a rod. The footage appears to be slightly blurry, indicating motion or unsteady camera work. The scene is set in an outdoor location, possibly near a lake or river. 1 second long, an action camera video depicting a man fishing in the water with a rod. The video has some technical artifacts present, such as motion blur, lens flare, and compression artifacts. It's captured from the first-person perspective, offering an immersive experience of the outdoors. 3rd person perspective of a boy fishing with his flies. The image has been slightly blurred to emphasize the motion of the fisherman and the water. 1-second video capturing a person fishing in a river with a fisheye perspective. 2 men are standing outside near water with fishing rods in their hands. Got it! L Probably not? Tom, let me see what you got. You got a dolly. Oh, it's another lovely dolly Sharon let this one go. This is weird"
      },
      "leaf_36": {
        "node_id": "leaf_36",
        "time_range": [
          180.0,
          185.0
        ],
        "duration": 5.0,
        "keywords": [
          "10",
          "3rd",
          "another",
          "backpack",
          "bend",
          "between",
          "book",
          "camera",
          "capturing",
          "dolly",
          "down",
          "dropped",
          "fish",
          "floor",
          "goes",
          "green",
          "ground",
          "hand",
          "head",
          "location",
          "lovely",
          "mounted",
          "object",
          "oh",
          "outdoor",
          "people",
          "person",
          "perspective",
          "picking",
          "retrieve",
          "river",
          "sharon",
          "showing",
          "side",
          "standing",
          "stream",
          "surface",
          "tom",
          "trees",
          "video",
          "walking",
          "weird",
          "wet"
        ],
        "keyword_count": 43,
        "children": null,
        "level": 0,
        "parent": "node_1_18",
        "source_seconds": [
          180,
          181,
          182,
          183,
          184
        ],
        "source_transcriptions": [
          44,
          45,
          46
        ],
        "visual_text": "2 people are standing by a river with a fish between them \nA person walking on wet ground. The camera is mounted on a backpack. 3rd person perspective of a wet ground surface. 10-second video with a hand picking up a book from the floor, set in an outdoor location. The camera is mounted on the person's head, capturing their first-person perspective as they bend down to retrieve the dropped object. 3rd person perspective showing a stream with green trees on the side.",
        "audio_text": "Tom, let me see what you got. You got a dolly. Oh, it's another lovely dolly Sharon let this one go. This is weird This one goes, it's we already got a fish.",
        "combined_text": "2 people are standing by a river with a fish between them \nA person walking on wet ground. The camera is mounted on a backpack. 3rd person perspective of a wet ground surface. 10-second video with a hand picking up a book from the floor, set in an outdoor location. The camera is mounted on the person's head, capturing their first-person perspective as they bend down to retrieve the dropped object. 3rd person perspective showing a stream with green trees on the side. Tom, let me see what you got. You got a dolly. Oh, it's another lovely dolly Sharon let this one go. This is weird This one goes, it's we already got a fish."
      },
      "leaf_37": {
        "node_id": "leaf_37",
        "time_range": [
          185.0,
          190.0
        ],
        "duration": 5.0,
        "keywords": [
          "365",
          "action",
          "angle",
          "another",
          "around",
          "back",
          "boat",
          "body",
          "camera",
          "capturing",
          "casts",
          "creating",
          "days",
          "definitely",
          "dolly",
          "edge",
          "effect",
          "ey",
          "features",
          "featuring",
          "fish",
          "fishing",
          "further",
          "goes",
          "gopro",
          "hey",
          "holding",
          "image",
          "lake",
          "lens",
          "line",
          "long",
          "lovely",
          "man",
          "men",
          "mind",
          "moment",
          "near",
          "never",
          "next",
          "oh",
          "overhead",
          "panoramic",
          "people",
          "person",
          "perspective",
          "positioned",
          "rain",
          "river",
          "rocks",
          "scene",
          "sharon",
          "shore",
          "showing",
          "shows",
          "single",
          "standing",
          "stands",
          "talking",
          "tripod",
          "video",
          "water",
          "weird",
          "wide"
        ],
        "keyword_count": 64,
        "children": null,
        "level": 0,
        "parent": "node_1_18",
        "source_seconds": [
          185,
          186,
          187,
          188,
          189
        ],
        "source_transcriptions": [
          45,
          46,
          47
        ],
        "visual_text": "1 second long video that shows two people fishing next to a body of water with rocks in it. The camera is capturing the action from an overhead perspective. 1-second scene featuring two men fishing with one man holding a fish near the water's edge while another man stands further back on the shore 4 people are standing around in the rain next to a lake and talking. The camera is positioned on an overhead tripod and is capturing the scene with a wide-angle lens, creating a panoramic effect. The image also features fish and a boat on the water. 365 days of fishing on a lake, capturing a single moment where a man casts his line into the water. 1-second video showing a person fishing at the edge of a river with a GoPro camera capturing the moment.",
        "audio_text": "Oh, it's another lovely dolly Sharon let this one go. This is weird This one goes, it's we already got a fish. It's definitely never mind Hey, ey",
        "combined_text": "1 second long video that shows two people fishing next to a body of water with rocks in it. The camera is capturing the action from an overhead perspective. 1-second scene featuring two men fishing with one man holding a fish near the water's edge while another man stands further back on the shore 4 people are standing around in the rain next to a lake and talking. The camera is positioned on an overhead tripod and is capturing the scene with a wide-angle lens, creating a panoramic effect. The image also features fish and a boat on the water. 365 days of fishing on a lake, capturing a single moment where a man casts his line into the water. 1-second video showing a person fishing at the edge of a river with a GoPro camera capturing the moment. Oh, it's another lovely dolly Sharon let this one go. This is weird This one goes, it's we already got a fish. It's definitely never mind Hey, ey"
      },
      "leaf_38": {
        "node_id": "leaf_38",
        "time_range": [
          190.0,
          195.0
        ],
        "duration": 5.0,
        "keywords": [
          "3rd",
          "action",
          "activities",
          "along",
          "alright",
          "another",
          "appears",
          "appropriate",
          "attire",
          "background",
          "backpack",
          "beach",
          "bending",
          "black",
          "blur",
          "bottle",
          "camera",
          "captured",
          "capturing",
          "definitely",
          "distortion",
          "dressed",
          "edge",
          "ey",
          "featuring",
          "fisherman",
          "fisheye",
          "fishing",
          "focused",
          "gravel",
          "ground",
          "hey",
          "holding",
          "image",
          "interacting",
          "jacket",
          "lake",
          "large",
          "ll",
          "man",
          "mind",
          "motion",
          "mountain",
          "mounted",
          "near",
          "nearby",
          "never",
          "nice",
          "object",
          "over",
          "pebbly",
          "people",
          "person",
          "perspective",
          "pick",
          "pole",
          "positioned",
          "providing",
          "raincoat",
          "red",
          "resulting",
          "scene",
          "seen",
          "shore",
          "shoreline",
          "side",
          "slight",
          "stable",
          "standing",
          "stands",
          "stream",
          "subjects",
          "surroundings",
          "using",
          "video",
          "water",
          "wearing",
          "weather",
          "young"
        ],
        "keyword_count": 79,
        "children": null,
        "level": 0,
        "parent": "node_1_19",
        "source_seconds": [
          190,
          191,
          192,
          193,
          194
        ],
        "source_transcriptions": [
          47,
          48
        ],
        "visual_text": "1 person standing near the water's edge holding a fishing pole and interacting with the ground. 2 people on a gravel beach with one wearing a red jacket and the other a black jacket. The person in the red jacket is bending over to pick up an object while the other person stands nearby. A bottle can also be seen in the scene. 1-second video with two people standing by the water on a pebbly beach. One person is wearing a red raincoat while the other is dressed in weather-appropriate attire. The camera capturing the scene appears to be mounted on a backpack, providing a stable perspective as the subjects go about their activities on the shoreline. 1-second scene featuring a young man fishing along the shore of a large lake with a mountain in the background. The image was captured using an action camera, resulting in some fisheye distortion and slight motion blur. 3rd person perspective of a man fishing by a stream of water. The camera is positioned on the left side of the scene, focused on the fisherman and his surroundings.",
        "audio_text": "It's definitely never mind Hey, ey Hey, nice. Alright, we'll get another one.",
        "combined_text": "1 person standing near the water's edge holding a fishing pole and interacting with the ground. 2 people on a gravel beach with one wearing a red jacket and the other a black jacket. The person in the red jacket is bending over to pick up an object while the other person stands nearby. A bottle can also be seen in the scene. 1-second video with two people standing by the water on a pebbly beach. One person is wearing a red raincoat while the other is dressed in weather-appropriate attire. The camera capturing the scene appears to be mounted on a backpack, providing a stable perspective as the subjects go about their activities on the shoreline. 1-second scene featuring a young man fishing along the shore of a large lake with a mountain in the background. The image was captured using an action camera, resulting in some fisheye distortion and slight motion blur. 3rd person perspective of a man fishing by a stream of water. The camera is positioned on the left side of the scene, focused on the fisherman and his surroundings. It's definitely never mind Hey, ey Hey, nice. Alright, we'll get another one."
      },
      "leaf_39": {
        "node_id": "leaf_39",
        "time_range": [
          195.0,
          200.0
        ],
        "duration": 5.0,
        "keywords": [
          "2d",
          "365",
          "alright",
          "another",
          "available",
          "bank",
          "boat",
          "book",
          "captured",
          "cell",
          "days",
          "field",
          "fish",
          "fishing",
          "gonna",
          "hey",
          "holding",
          "image",
          "jacket",
          "ll",
          "lunch",
          "man",
          "nice",
          "person",
          "perspective",
          "phone",
          "photography",
          "pole",
          "rain",
          "river",
          "rod",
          "scene",
          "showing",
          "standing",
          "techniques",
          "tips",
          "tommy",
          "tricks",
          "video",
          "view",
          "wanna",
          "water",
          "wearing",
          "wide",
          "yup"
        ],
        "keyword_count": 45,
        "children": null,
        "level": 0,
        "parent": "node_1_19",
        "source_seconds": [
          195,
          196,
          197,
          198,
          199
        ],
        "source_transcriptions": [
          48,
          49,
          50
        ],
        "visual_text": "1-second video showing a person standing in the water with their fishing pole. 2d scene with a man wearing a jacket and holding a cell phone standing on a river bank. The image is captured from the first-person perspective and has a wide field of view. 365 days of photography tips, tricks, and techniques book: (Not Available) 1 second of a man fishing from a boat on the water.  A man standing in the rain holding a fishing rod.",
        "audio_text": "Hey, nice. Alright, we'll get another one. Hey Tommy I want to make a Hey Tommy, I'm gonna make lunch, you wanna stay in fish? Yup.",
        "combined_text": "1-second video showing a person standing in the water with their fishing pole. 2d scene with a man wearing a jacket and holding a cell phone standing on a river bank. The image is captured from the first-person perspective and has a wide field of view. 365 days of photography tips, tricks, and techniques book: (Not Available) 1 second of a man fishing from a boat on the water.  A man standing in the rain holding a fishing rod. Hey, nice. Alright, we'll get another one. Hey Tommy I want to make a Hey Tommy, I'm gonna make lunch, you wanna stay in fish? Yup."
      },
      "leaf_40": {
        "node_id": "leaf_40",
        "time_range": [
          200.0,
          205.0
        ],
        "duration": 5.0,
        "keywords": [
          "10",
          "30",
          "360",
          "adventure",
          "angler",
          "appears",
          "beside",
          "body",
          "boy",
          "camera",
          "captures",
          "close",
          "coat",
          "degree",
          "distance",
          "enjoys",
          "essence",
          "fish",
          "fishing",
          "footage",
          "gear",
          "gonna",
          "head",
          "hey",
          "holding",
          "hooded",
          "image",
          "jacket",
          "lake",
          "little",
          "looking",
          "lunch",
          "man",
          "mountains",
          "next",
          "objects",
          "orange",
          "outdoor",
          "people",
          "person",
          "perspective",
          "positioned",
          "rain",
          "raincoat",
          "red",
          "river",
          "rod",
          "scene",
          "seconds",
          "shore",
          "shot",
          "showing",
          "sky",
          "standing",
          "stands",
          "taken",
          "time",
          "tommy",
          "toward",
          "video",
          "view",
          "visible",
          "wanna",
          "water",
          "wearing",
          "young",
          "yup"
        ],
        "keyword_count": 67,
        "children": null,
        "level": 0,
        "parent": "node_1_20",
        "source_seconds": [
          200,
          201,
          202,
          203,
          204
        ],
        "source_transcriptions": [
          49,
          50,
          51
        ],
        "visual_text": " A boy stands on the shore of a river wearing a red jacket and fishing gear. The image captures the essence of an outdoor adventure as the young angler enjoys his time by the water. 10-second scene of a little boy wearing a jacket and standing on the shore of a lake. 1-second video of a man standing by the water wearing a raincoat while holding a fishing rod. 360-degree footage of a person in a hooded raincoat, standing next to a body of water with a view of the mountains in the distance. 30 seconds of footage showing a person in an orange rain coat holding a fishing rod beside some water. The shot appears to be taken from the first-person perspective, with the camera positioned close to the person's head. There are no other objects or people visible in the scene.",
        "audio_text": "Hey Tommy I want to make a Hey Tommy, I'm gonna make lunch, you wanna stay in fish? Yup. looking toward the sky.",
        "combined_text": "A boy stands on the shore of a river wearing a red jacket and fishing gear. The image captures the essence of an outdoor adventure as the young angler enjoys his time by the water. 10-second scene of a little boy wearing a jacket and standing on the shore of a lake. 1-second video of a man standing by the water wearing a raincoat while holding a fishing rod. 360-degree footage of a person in a hooded raincoat, standing next to a body of water with a view of the mountains in the distance. 30 seconds of footage showing a person in an orange rain coat holding a fishing rod beside some water. The shot appears to be taken from the first-person perspective, with the camera positioned close to the person's head. There are no other objects or people visible in the scene. Hey Tommy I want to make a Hey Tommy, I'm gonna make lunch, you wanna stay in fish? Yup. looking toward the sky."
      },
      "leaf_41": {
        "node_id": "leaf_41",
        "time_range": [
          205.0,
          210.0
        ],
        "duration": 5.0,
        "keywords": [
          "30",
          "4k",
          "action",
          "alright",
          "angle",
          "area",
          "back",
          "backpack",
          "black",
          "body",
          "camera",
          "captured",
          "captures",
          "close",
          "eating",
          "edge",
          "either",
          "fish",
          "fishing",
          "footage",
          "full",
          "gonna",
          "guy",
          "hand",
          "hey",
          "hiking",
          "holding",
          "hooded",
          "image",
          "immersive",
          "includes",
          "indicating",
          "individual",
          "jacket",
          "lake",
          "likely",
          "little",
          "looking",
          "lunch",
          "man",
          "mounted",
          "natural",
          "next",
          "objects",
          "outdoor",
          "person",
          "perspective",
          "pole",
          "possibly",
          "providing",
          "rain",
          "raincoat",
          "raw",
          "releasing",
          "river",
          "rocks",
          "setting",
          "shore",
          "shows",
          "sky",
          "standing",
          "stomachs",
          "suggests",
          "surrounding",
          "taken",
          "tommy",
          "toward",
          "trail",
          "trees",
          "various",
          "video",
          "view",
          "visible",
          "walking",
          "wanna",
          "water",
          "wearing",
          "wide",
          "wooded",
          "yup"
        ],
        "keyword_count": 80,
        "children": null,
        "level": 0,
        "parent": "node_1_20",
        "source_seconds": [
          205,
          206,
          207,
          208,
          209
        ],
        "source_transcriptions": [
          50,
          51,
          52
        ],
        "visual_text": " A man wearing a raincoat standing by the water and holding a pole. The image is taken from the man's perspective, providing an immersive view of the surrounding area. 4K raw footage of a hiking trail next to a lake, a man in a black rain jacket is visible. 30-second video with a man in a black hooded raincoat walking through a wooded area with trees. 1 second video of a man standing on the shore of a lake fishing. He is wearing a black jacket and holding a fish. The image has a wide-angle perspective which captures the surrounding area and shows the man's fishing pole in action. \nA person in a black jacket is standing by a river and holding a fish in their hand. They are wearing a backpack and seem to be either fishing or releasing the fish back into the water. The camera perspective suggests that it might be a first-person view, possibly captured with an action camera mounted on the individual's body. The image includes various objects such as trees and rocks, indicating that the person is in a natural outdoor setting, likely close to the water's edge.",
        "audio_text": "Hey Tommy, I'm gonna make lunch, you wanna stay in fish? Yup. looking toward the sky. Alright, what are with this guy's been eating his stomachs full? Little...",
        "combined_text": "A man wearing a raincoat standing by the water and holding a pole. The image is taken from the man's perspective, providing an immersive view of the surrounding area. 4K raw footage of a hiking trail next to a lake, a man in a black rain jacket is visible. 30-second video with a man in a black hooded raincoat walking through a wooded area with trees. 1 second video of a man standing on the shore of a lake fishing. He is wearing a black jacket and holding a fish. The image has a wide-angle perspective which captures the surrounding area and shows the man's fishing pole in action. \nA person in a black jacket is standing by a river and holding a fish in their hand. They are wearing a backpack and seem to be either fishing or releasing the fish back into the water. The camera perspective suggests that it might be a first-person view, possibly captured with an action camera mounted on the individual's body. The image includes various objects such as trees and rocks, indicating that the person is in a natural outdoor setting, likely close to the water's edge. Hey Tommy, I'm gonna make lunch, you wanna stay in fish? Yup. looking toward the sky. Alright, what are with this guy's been eating his stomachs full? Little..."
      },
      "leaf_42": {
        "node_id": "leaf_42",
        "time_range": [
          210.0,
          215.0
        ],
        "duration": 5.0,
        "keywords": [
          "3d",
          "3rd",
          "across",
          "action",
          "activity",
          "alright",
          "bait",
          "bugs",
          "camera",
          "cast",
          "catching",
          "close",
          "dead",
          "eating",
          "either",
          "environment",
          "experience",
          "filled",
          "film",
          "fish",
          "fisheye",
          "fishing",
          "flies",
          "focused",
          "full",
          "green",
          "guy",
          "hand",
          "hands",
          "holding",
          "immersive",
          "lens",
          "little",
          "man",
          "mosquitoes",
          "multiple",
          "next",
          "person",
          "perspective",
          "positions",
          "provides",
          "retrieve",
          "river",
          "rod",
          "scattered",
          "scene",
          "seems",
          "showing",
          "small",
          "someone",
          "something",
          "standing",
          "stomachs",
          "surrounding",
          "thousands",
          "using",
          "various",
          "video",
          "viewers",
          "visible",
          "water",
          "within",
          "witness"
        ],
        "keyword_count": 63,
        "children": null,
        "level": 0,
        "parent": "node_1_21",
        "source_seconds": [
          210,
          211,
          212,
          213,
          214
        ],
        "source_transcriptions": [
          52,
          53
        ],
        "visual_text": "\n\nA man with a fishing rod in his hands, standing next to a river filled with fish. The man seems to be focused on catching fish and might be using the fishing rod to either cast or retrieve bait. There are multiple fish visible in the water, scattered across various positions within the scene. The camera perspective provides an immersive experience for viewers, as they can witness the fishing activity up close. 3rd person perspective of a man fishing in a river with a green surrounding environment. 3D video with a fisheye lens showing a hand holding something. 1-second scene where someone is holding a dead fish. \nAn action camera is being used to film a hand holding a small fish.",
        "audio_text": "Alright, what are with this guy's been eating his stomachs full? Little... little mosquitoes and flies just thousands and thousands of bugs",
        "combined_text": "A man with a fishing rod in his hands, standing next to a river filled with fish. The man seems to be focused on catching fish and might be using the fishing rod to either cast or retrieve bait. There are multiple fish visible in the water, scattered across various positions within the scene. The camera perspective provides an immersive experience for viewers, as they can witness the fishing activity up close. 3rd person perspective of a man fishing in a river with a green surrounding environment. 3D video with a fisheye lens showing a hand holding something. 1-second scene where someone is holding a dead fish. \nAn action camera is being used to film a hand holding a small fish. Alright, what are with this guy's been eating his stomachs full? Little... little mosquitoes and flies just thousands and thousands of bugs"
      },
      "leaf_43": {
        "node_id": "leaf_43",
        "time_range": [
          215.0,
          220.0
        ],
        "duration": 5.0,
        "keywords": [
          "01",
          "4k",
          "action",
          "animal",
          "backpack",
          "body",
          "bugs",
          "camera",
          "captured",
          "captures",
          "clearer",
          "debris",
          "dirty",
          "done",
          "entire",
          "fish",
          "fishing",
          "flies",
          "ground",
          "hand",
          "higher",
          "holding",
          "includes",
          "leaves",
          "line",
          "little",
          "long",
          "man",
          "mosquitoes",
          "mounted",
          "near",
          "object",
          "over",
          "people",
          "person",
          "perspective",
          "positioned",
          "recommended",
          "resolution",
          "rods",
          "scattered",
          "scene",
          "setup",
          "shot",
          "showing",
          "sort",
          "standing",
          "taken",
          "thousands",
          "twigs",
          "using",
          "visuals",
          "water",
          "way"
        ],
        "keyword_count": 54,
        "children": null,
        "level": 0,
        "parent": "node_1_21",
        "source_seconds": [
          215,
          216,
          217,
          218,
          219
        ],
        "source_transcriptions": [
          53,
          54,
          55
        ],
        "visual_text": "0:01 second long shot showing a hand holding some sort of dirty animal. The camera is positioned in such a way that it captures the entire scene which includes the ground with twigs, leaves, and debris scattered all over. This first-person perspective shot might have been taken using a body-mounted or backpack-mounted camera. 1-second scene where a person is standing in water with an object in their hand. 4k or higher resolution is recommended for clearer visuals. 2 people fishing with rods and line, and they caught a fish. 1-second scene that includes a man holding a fish near water, captured with an action camera setup.",
        "audio_text": "little mosquitoes and flies just thousands and thousands of bugs There we go. done",
        "combined_text": "0:01 second long shot showing a hand holding some sort of dirty animal. The camera is positioned in such a way that it captures the entire scene which includes the ground with twigs, leaves, and debris scattered all over. This first-person perspective shot might have been taken using a body-mounted or backpack-mounted camera. 1-second scene where a person is standing in water with an object in their hand. 4k or higher resolution is recommended for clearer visuals. 2 people fishing with rods and line, and they caught a fish. 1-second scene that includes a man holding a fish near water, captured with an action camera setup. little mosquitoes and flies just thousands and thousands of bugs There we go. done"
      },
      "leaf_44": {
        "node_id": "leaf_44",
        "time_range": [
          220.0,
          225.0
        ],
        "duration": 5.0,
        "keywords": [
          "00",
          "19",
          "30",
          "actions",
          "area",
          "background",
          "backpack",
          "based",
          "black",
          "body",
          "boy",
          "camera",
          "camping",
          "campsite",
          "capturing",
          "chest",
          "child",
          "compose",
          "descriptions",
          "done",
          "edit",
          "effect",
          "either",
          "elements",
          "experiencing",
          "fisheye",
          "foreground",
          "forgot",
          "frame",
          "gun",
          "hi",
          "holding",
          "hoodie",
          "image",
          "includes",
          "jacket",
          "location",
          "looking",
          "looks",
          "making",
          "man",
          "mounted",
          "next",
          "objects",
          "outdoor",
          "people",
          "person",
          "perspective",
          "point",
          "pointing",
          "positioned",
          "possibly",
          "red",
          "scene",
          "seems",
          "setting",
          "showing",
          "single",
          "sitting",
          "something",
          "tent",
          "tree",
          "trees",
          "under",
          "video",
          "view",
          "viewer",
          "visible",
          "water",
          "wearing"
        ],
        "keyword_count": 70,
        "children": null,
        "level": 0,
        "parent": "node_1_22",
        "source_seconds": [
          220,
          221,
          222,
          223,
          224
        ],
        "source_transcriptions": [
          54,
          55,
          56
        ],
        "visual_text": "00:19 second scene showing a man wearing a black hoodie looking up. The image has a fisheye effect, and there is a tree in the background. 1-second video of a man and a boy with a gun in the foreground. The man is pointing at something with the camera while the boy looks on. 30-second edit showing a man and a child sitting in a camping area under a tent. The scene includes a backpack, trees, and possibly some outdoor elements such as a body of water or a campsite. The camera is positioned either on the person's chest or mounted on a backpack, capturing the scene from that perspective. \nBased on these descriptions, what objects, people, actions, and location compose this single frame? 1 person is visible in the image. They are in an outdoor setting and wearing a black jacket. This person is holding something red while being next to a backpack. The image seems to have a first-person perspective, making it appear as if the viewer is experiencing the scene from the person's point of view.",
        "audio_text": "There we go. done Hi, forgot.",
        "combined_text": "00:19 second scene showing a man wearing a black hoodie looking up. The image has a fisheye effect, and there is a tree in the background. 1-second video of a man and a boy with a gun in the foreground. The man is pointing at something with the camera while the boy looks on. 30-second edit showing a man and a child sitting in a camping area under a tent. The scene includes a backpack, trees, and possibly some outdoor elements such as a body of water or a campsite. The camera is positioned either on the person's chest or mounted on a backpack, capturing the scene from that perspective. \nBased on these descriptions, what objects, people, actions, and location compose this single frame? 1 person is visible in the image. They are in an outdoor setting and wearing a black jacket. This person is holding something red while being next to a backpack. The image seems to have a first-person perspective, making it appear as if the viewer is experiencing the scene from the person's point of view. There we go. done Hi, forgot."
      },
      "leaf_45": {
        "node_id": "leaf_45",
        "time_range": [
          225.0,
          230.0
        ],
        "duration": 5.0,
        "keywords": [
          "3d",
          "additionally",
          "adventure",
          "aluminum",
          "appears",
          "around",
          "atmosphere",
          "backpack",
          "backpacks",
          "behind",
          "between",
          "bit",
          "bottle",
          "bottles",
          "boy",
          "camera",
          "camping",
          "canopy",
          "captured",
          "captures",
          "chocolate",
          "coat",
          "detected",
          "done",
          "else",
          "food",
          "foreground",
          "forgot",
          "front",
          "full",
          "gopro",
          "grabbing",
          "happy",
          "hi",
          "holding",
          "image",
          "indicating",
          "individuals",
          "jacket",
          "large",
          "like",
          "main",
          "makes",
          "man",
          "meal",
          "men",
          "moment",
          "mounted",
          "multiple",
          "near",
          "next",
          "object",
          "outdoor",
          "people",
          "person",
          "persons",
          "perspective",
          "placed",
          "possibly",
          "pot",
          "preparing",
          "re",
          "red",
          "scene",
          "seems",
          "setting",
          "share",
          "shown",
          "shows",
          "sitting",
          "smiling",
          "someone",
          "standing",
          "suggesting",
          "tent",
          "tents",
          "together",
          "trip",
          "under",
          "video",
          "visible",
          "warm",
          "watching",
          "water",
          "wearing",
          "white",
          "young"
        ],
        "keyword_count": 87,
        "children": null,
        "level": 0,
        "parent": "node_1_22",
        "source_seconds": [
          225,
          226,
          227,
          228,
          229
        ],
        "source_transcriptions": [
          55,
          56,
          57
        ],
        "visual_text": "2 men are shown in an outdoor setting with tents. \n\nThe image shows a man sitting next to a young boy under a large tent. Both individuals are smiling as they share a moment together. A pot is placed in front of them, possibly indicating that they are having a meal or preparing food together. The scene captures a warm and happy atmosphere between the two persons. Additionally, there are multiple backpacks around them, suggesting that they may be on a camping trip or outdoor adventure. 1 second video that shows someone wearing a red jacket holding a bottle while two other bottles are visible in the foreground. The camera perspective is from behind the person in the red coat. 3 people are standing under a white canopy. A man in a red jacket is holding an aluminum bottle while someone else is grabbing a red water bottle. A third person seems to be watching them, and there is also a backpack in the scene. The image appears to have been captured with a GoPro camera mounted on a backpack. 3d object detected near the main person, but it's just an object in the scene",
        "audio_text": "done Hi, forgot. I think you're full. That's what chocolate makes. You're a bit like...",
        "combined_text": "2 men are shown in an outdoor setting with tents. \n\nThe image shows a man sitting next to a young boy under a large tent. Both individuals are smiling as they share a moment together. A pot is placed in front of them, possibly indicating that they are having a meal or preparing food together. The scene captures a warm and happy atmosphere between the two persons. Additionally, there are multiple backpacks around them, suggesting that they may be on a camping trip or outdoor adventure. 1 second video that shows someone wearing a red jacket holding a bottle while two other bottles are visible in the foreground. The camera perspective is from behind the person in the red coat. 3 people are standing under a white canopy. A man in a red jacket is holding an aluminum bottle while someone else is grabbing a red water bottle. A third person seems to be watching them, and there is also a backpack in the scene. The image appears to have been captured with a GoPro camera mounted on a backpack. 3d object detected near the main person, but it's just an object in the scene done Hi, forgot. I think you're full. That's what chocolate makes. You're a bit like..."
      },
      "leaf_46": {
        "node_id": "leaf_46",
        "time_range": [
          230.0,
          235.0
        ],
        "duration": 5.0,
        "keywords": [
          "56",
          "58",
          "67",
          "79",
          "along",
          "angle",
          "another",
          "appears",
          "area",
          "around",
          "backpacks",
          "bit",
          "black",
          "blue",
          "blur",
          "boiling",
          "bottle",
          "camera",
          "camping",
          "campsite",
          "capture",
          "captured",
          "chocolate",
          "closer",
          "coffee",
          "color",
          "companions",
          "contains",
          "cups",
          "dress",
          "drinking",
          "due",
          "entire",
          "experience",
          "fishing",
          "format",
          "full",
          "gentleman",
          "green",
          "hand",
          "hold",
          "holding",
          "hot",
          "image",
          "items",
          "kettle",
          "lantern",
          "large",
          "lights",
          "like",
          "makes",
          "man",
          "motion",
          "mug",
          "multiple",
          "nearby",
          "objects",
          "older",
          "people",
          "person",
          "perspective",
          "placed",
          "point",
          "providing",
          "re",
          "rod",
          "scene",
          "seems",
          "seen",
          "setting",
          "shaky",
          "showcasing",
          "sips",
          "sitting",
          "tent",
          "umbrella",
          "under",
          "various",
          "view",
          "water",
          "wearing",
          "wide",
          "young"
        ],
        "keyword_count": 83,
        "children": null,
        "level": 0,
        "parent": "node_1_23",
        "source_seconds": [
          230,
          231,
          232,
          233,
          234
        ],
        "source_transcriptions": [
          57,
          58
        ],
        "visual_text": "0:58 to 0:67, A man wearing black color dress is seen in the image. 5 people are sitting under a large tent, one person is holding a bottle in hand, and the camera is placed at an angle to capture the scene. 0:56 to 0:79 - A man is boiling water in a green kettle. 3 people are sitting around a campsite. One man is drinking from a blue coffee mug, while another man lights a lantern. There are various objects around them including two backpacks, a tent, and a fishing rod. The scene appears to be captured in a first-person perspective, with some motion blur due to the shaky camera. 3 people in a camping setting. A man sips coffee while his young companions sit nearby. The image contains multiple objects including two cups, one of which is closer to the older gentleman. There are three backpacks placed around the campsite along with a bottle and some other items such as an umbrella.\n\nThe camera perspective seems to be from the man's point of view as he sips coffee, providing a first-person experience. The scene appears to be captured in wide-angle format, showcasing the entire campsite area.",
        "audio_text": "I think you're full. That's what chocolate makes. You're a bit like... You're just like That's hot. I just hold it no",
        "combined_text": "0:58 to 0:67, A man wearing black color dress is seen in the image. 5 people are sitting under a large tent, one person is holding a bottle in hand, and the camera is placed at an angle to capture the scene. 0:56 to 0:79 - A man is boiling water in a green kettle. 3 people are sitting around a campsite. One man is drinking from a blue coffee mug, while another man lights a lantern. There are various objects around them including two backpacks, a tent, and a fishing rod. The scene appears to be captured in a first-person perspective, with some motion blur due to the shaky camera. 3 people in a camping setting. A man sips coffee while his young companions sit nearby. The image contains multiple objects including two cups, one of which is closer to the older gentleman. There are three backpacks placed around the campsite along with a bottle and some other items such as an umbrella.\n\nThe camera perspective seems to be from the man's point of view as he sips coffee, providing a first-person experience. The scene appears to be captured in wide-angle format, showcasing the entire campsite area. I think you're full. That's what chocolate makes. You're a bit like... You're just like That's hot. I just hold it no"
      },
      "leaf_47": {
        "node_id": "leaf_47",
        "time_range": [
          235.0,
          240.0
        ],
        "duration": 5.0,
        "keywords": [
          "animals",
          "another",
          "appears",
          "area",
          "attract",
          "baby",
          "background",
          "backpack",
          "backpacks",
          "bears",
          "beer",
          "between",
          "black",
          "bottle",
          "bottles",
          "camping",
          "campsite",
          "children",
          "coat",
          "contain",
          "conversation",
          "couple",
          "cups",
          "depicting",
          "depicts",
          "down",
          "engaging",
          "evidenced",
          "exchange",
          "family",
          "focus",
          "food",
          "foreground",
          "front",
          "god",
          "green",
          "group",
          "guys",
          "hair",
          "handbag",
          "hands",
          "handshake",
          "hold",
          "holding",
          "hot",
          "image",
          "includes",
          "individuals",
          "inside",
          "jacket",
          "lap",
          "leather",
          "letters",
          "like",
          "likely",
          "looking",
          "main",
          "man",
          "mess",
          "multiple",
          "nearby",
          "notices",
          "object",
          "occurring",
          "oh",
          "older",
          "out",
          "outdoors",
          "people",
          "person",
          "place",
          "placed",
          "playing",
          "possibly",
          "presence",
          "present",
          "primary",
          "re",
          "red",
          "scene",
          "several",
          "shells",
          "sitting",
          "something",
          "sticky",
          "stuff",
          "stuffed",
          "subject",
          "summary",
          "supplies",
          "takes",
          "tent",
          "toys",
          "trip",
          "various",
          "video",
          "visible",
          "warm",
          "wearing",
          "within"
        ],
        "keyword_count": 100,
        "children": null,
        "level": 0,
        "parent": "node_1_23",
        "source_seconds": [
          235,
          236,
          237,
          238,
          239
        ],
        "source_transcriptions": [
          58,
          59,
          60
        ],
        "visual_text": "3 people, one of them holding something out to another person. The scene takes place inside a tent with two backpacks visible in the background. A handshake is occurring between the individuals as they exchange an object. 3 guys outdoors having a conversation in front of a campsite. The man in the foreground is wearing a black leather jacket. \nA man, possibly an older man, is sitting down in front of a tent. He is wearing a black coat with red letters on it. The tent appears to be a mess tent, as there are a few other people present in the area, some of whom may also be engaging with the main subject. There's an open backpack nearby which could contain food or other supplies for the camping trip.\n\nIn summary, this image depicts a group of people on a camping trip, with the primary focus being an older man in a black coat with red letters on it. The scene likely takes place within a tent or a mess tent, as evidenced by the presence of various individuals and the open backpack. 3 people inside a tent with a green baby sitting on the lap of a man. A handbag is placed nearby and there are a couple of cups and bottles in the scene. 1-second video depicting a family playing with green stuffed animals. A man in a tent is looking down at his beer when he notices the children playing. The scene includes multiple people, a bottle of beer, and several toys.",
        "audio_text": "You're just like That's hot. I just hold it no Just hold it and the warm up your hands first. Oh my god, my hair is sticky. Put all your shells in here so we don't attract bears and stuff.",
        "combined_text": "3 people, one of them holding something out to another person. The scene takes place inside a tent with two backpacks visible in the background. A handshake is occurring between the individuals as they exchange an object. 3 guys outdoors having a conversation in front of a campsite. The man in the foreground is wearing a black leather jacket. \nA man, possibly an older man, is sitting down in front of a tent. He is wearing a black coat with red letters on it. The tent appears to be a mess tent, as there are a few other people present in the area, some of whom may also be engaging with the main subject. There's an open backpack nearby which could contain food or other supplies for the camping trip.\n\nIn summary, this image depicts a group of people on a camping trip, with the primary focus being an older man in a black coat with red letters on it. The scene likely takes place within a tent or a mess tent, as evidenced by the presence of various individuals and the open backpack. 3 people inside a tent with a green baby sitting on the lap of a man. A handbag is placed nearby and there are a couple of cups and bottles in the scene. 1-second video depicting a family playing with green stuffed animals. A man in a tent is looking down at his beer when he notices the children playing. The scene includes multiple people, a bottle of beer, and several toys. You're just like That's hot. I just hold it no Just hold it and the warm up your hands first. Oh my god, my hair is sticky. Put all your shells in here so we don't attract bears and stuff."
      },
      "leaf_48": {
        "node_id": "leaf_48",
        "time_range": [
          240.0,
          245.0
        ],
        "duration": 5.0,
        "keywords": [
          "activity",
          "adult",
          "adventure",
          "another",
          "around",
          "artifacts",
          "attract",
          "backpacks",
          "ball",
          "bears",
          "blur",
          "body",
          "boy",
          "boys",
          "camera",
          "canister",
          "capturing",
          "children",
          "conversation",
          "cooking",
          "details",
          "engaging",
          "entire",
          "father",
          "flare",
          "following",
          "food",
          "foreground",
          "garden",
          "god",
          "ground",
          "hair",
          "handing",
          "hands",
          "helmet",
          "hold",
          "holding",
          "indicate",
          "inside",
          "involved",
          "items",
          "leisure",
          "lens",
          "little",
          "looking",
          "male",
          "man",
          "motion",
          "mounted",
          "near",
          "oh",
          "outdoor",
          "overhead",
          "people",
          "person",
          "placed",
          "positioned",
          "pot",
          "preparing",
          "present",
          "red",
          "scene",
          "seated",
          "several",
          "shells",
          "showing",
          "sitting",
          "situation",
          "something",
          "sons",
          "sports",
          "sticky",
          "stuff",
          "surrounded",
          "survival",
          "technical",
          "tent",
          "time",
          "together",
          "tool",
          "type",
          "upcoming",
          "video",
          "warm",
          "yeah"
        ],
        "keyword_count": 85,
        "children": null,
        "level": 0,
        "parent": "node_1_24",
        "source_seconds": [
          240,
          241,
          242,
          243,
          244
        ],
        "source_transcriptions": [
          59,
          60,
          61
        ],
        "visual_text": "3 people are seated around a cooking pot inside a tent. A man is sitting near a little boy and another person. They seem to be engaging in a conversation or preparing food together. There is a sports ball present that might indicate leisure time or an upcoming activity. The camera is positioned overhead, capturing the entire scene with some technical artifacts such as motion blur and lens flare. 3 people in a tent, a father and his two sons. The boy in the foreground is holding a red canister. 3 people, an adult male and two boys, are inside a tent. The man is showing something to one of the children. 3 people inside a tent and they are looking at something. 1-second video with the following details: A man is in a tent and is handing a boy some type of canister or tool. They are surrounded by several backpacks and other items that indicate they might be preparing for an outdoor adventure or are involved in a survival situation. The camera capturing this scene may have been mounted on a helmet, body-mounted, or placed on the ground.",
        "audio_text": "Just hold it and the warm up your hands first. Oh my god, my hair is sticky. Put all your shells in here so we don't attract bears and stuff. garden, stop. Yeah.",
        "combined_text": "3 people are seated around a cooking pot inside a tent. A man is sitting near a little boy and another person. They seem to be engaging in a conversation or preparing food together. There is a sports ball present that might indicate leisure time or an upcoming activity. The camera is positioned overhead, capturing the entire scene with some technical artifacts such as motion blur and lens flare. 3 people in a tent, a father and his two sons. The boy in the foreground is holding a red canister. 3 people, an adult male and two boys, are inside a tent. The man is showing something to one of the children. 3 people inside a tent and they are looking at something. 1-second video with the following details: A man is in a tent and is handing a boy some type of canister or tool. They are surrounded by several backpacks and other items that indicate they might be preparing for an outdoor adventure or are involved in a survival situation. The camera capturing this scene may have been mounted on a helmet, body-mounted, or placed on the ground. Just hold it and the warm up your hands first. Oh my god, my hair is sticky. Put all your shells in here so we don't attract bears and stuff. garden, stop. Yeah."
      },
      "leaf_49": {
        "node_id": "leaf_49",
        "time_range": [
          245.0,
          250.0
        ],
        "duration": 5.0,
        "keywords": [
          "54",
          "62",
          "activity",
          "around",
          "assortment",
          "attract",
          "backpack",
          "bags",
          "bears",
          "body",
          "bottles",
          "bowls",
          "boy",
          "boys",
          "camera",
          "capturing",
          "chairs",
          "child",
          "cups",
          "eating",
          "either",
          "frying",
          "garden",
          "god",
          "guys",
          "hair",
          "hands",
          "hat",
          "holding",
          "hungry",
          "immersive",
          "inside",
          "items",
          "knots",
          "located",
          "man",
          "miscellaneous",
          "moment",
          "mounted",
          "next",
          "objects",
          "oh",
          "pan",
          "people",
          "placed",
          "please",
          "pots",
          "pretty",
          "providing",
          "right",
          "scene",
          "seated",
          "seen",
          "several",
          "shells",
          "showing",
          "siting",
          "snacks",
          "standing",
          "sticky",
          "stuff",
          "sure",
          "surrounded",
          "tent",
          "tie",
          "various",
          "view",
          "wearing",
          "yeah",
          "young"
        ],
        "keyword_count": 70,
        "children": null,
        "level": 0,
        "parent": "node_1_24",
        "source_seconds": [
          245,
          246,
          247,
          248,
          249
        ],
        "source_transcriptions": [
          60,
          61,
          62
        ],
        "visual_text": "0:54 to 0:62, Man wearing a hat in the tent 3 people in a tent eating snacks while holding items such as bottles and bags. 3 boys siting inside a tent while holding their bowls. \nA scene of a man and a young boy with a frying pan in their hands, standing next to each other. The man is showing the child how to use the pan. They are located inside a tent, surrounded by other people, some of which are seated on chairs. Various items such as bowls can be seen placed around them. 3 people are in a tent. A man is showing two young boys how to tie knots. They have several items around them including pots, bowls, cups, and an assortment of miscellaneous objects. The camera capturing this moment is either a body-mounted or backpack-mounted camera, providing an immersive view of the activity.",
        "audio_text": "Oh my god, my hair is sticky. Put all your shells in here so we don't attract bears and stuff. garden, stop. Yeah. I'm sure you guys are pretty hungry, right? Oh yeah, please.",
        "combined_text": "0:54 to 0:62, Man wearing a hat in the tent 3 people in a tent eating snacks while holding items such as bottles and bags. 3 boys siting inside a tent while holding their bowls. \nA scene of a man and a young boy with a frying pan in their hands, standing next to each other. The man is showing the child how to use the pan. They are located inside a tent, surrounded by other people, some of which are seated on chairs. Various items such as bowls can be seen placed around them. 3 people are in a tent. A man is showing two young boys how to tie knots. They have several items around them including pots, bowls, cups, and an assortment of miscellaneous objects. The camera capturing this moment is either a body-mounted or backpack-mounted camera, providing an immersive view of the activity. Oh my god, my hair is sticky. Put all your shells in here so we don't attract bears and stuff. garden, stop. Yeah. I'm sure you guys are pretty hungry, right? Oh yeah, please."
      },
      "leaf_50": {
        "node_id": "leaf_50",
        "time_range": [
          250.0,
          255.0
        ],
        "duration": 5.0,
        "keywords": [
          "around",
          "bite",
          "blue",
          "bowls",
          "camera",
          "campfire",
          "captures",
          "children",
          "cooking",
          "cups",
          "eating",
          "explaining",
          "finished",
          "food",
          "gathered",
          "group",
          "guys",
          "hand",
          "handing",
          "handling",
          "holding",
          "hungry",
          "indicating",
          "interacting",
          "interesting",
          "kids",
          "man",
          "meal",
          "moment",
          "object",
          "objects",
          "oh",
          "outdoor",
          "pan",
          "people",
          "please",
          "preparing",
          "pretty",
          "right",
          "sandwich",
          "scene",
          "seems",
          "setting",
          "showing",
          "sitting",
          "something",
          "spaghetti",
          "spoons",
          "sure",
          "tent",
          "under",
          "using",
          "video",
          "visible",
          "yeah"
        ],
        "keyword_count": 55,
        "children": null,
        "level": 0,
        "parent": "node_1_25",
        "source_seconds": [
          250,
          251,
          252,
          253,
          254
        ],
        "source_transcriptions": [
          62,
          63
        ],
        "visual_text": "1-second video showing a man interacting with children and handling objects in an outdoor setting. 1-second video showing a man handing a blue object to one of three kids in a tent. 3 people are gathered under a tent. A man is holding a spaghetti sandwich in his hand. The camera captures this interesting moment with the group sitting around the man who seems to be explaining something to them. 1-second video showing a group of people in a tent, with a man cooking food using a pan. There are also bowls, cups, and spoons visible in the scene, indicating that they may be preparing to eat or have just finished eating their meal. 3 people are gathered around a campfire for cooking.",
        "audio_text": "I'm sure you guys are pretty hungry, right? Oh yeah, please. please yeah and then at the other bite",
        "combined_text": "1-second video showing a man interacting with children and handling objects in an outdoor setting. 1-second video showing a man handing a blue object to one of three kids in a tent. 3 people are gathered under a tent. A man is holding a spaghetti sandwich in his hand. The camera captures this interesting moment with the group sitting around the man who seems to be explaining something to them. 1-second video showing a group of people in a tent, with a man cooking food using a pan. There are also bowls, cups, and spoons visible in the scene, indicating that they may be preparing to eat or have just finished eating their meal. 3 people are gathered around a campfire for cooking. I'm sure you guys are pretty hungry, right? Oh yeah, please. please yeah and then at the other bite"
      },
      "leaf_51": {
        "node_id": "leaf_51",
        "time_range": [
          255.0,
          260.0
        ],
        "duration": 5.0,
        "keywords": [
          "30",
          "activities",
          "appears",
          "bite",
          "blow",
          "bowls",
          "camping",
          "canvas",
          "captures",
          "conditions",
          "dung",
          "eating",
          "elements",
          "engaged",
          "family",
          "filming",
          "fishing",
          "flying",
          "hold",
          "image",
          "inside",
          "interactions",
          "kite",
          "lighting",
          "like",
          "lures",
          "man",
          "meals",
          "men",
          "natural",
          "others",
          "out",
          "outdoor",
          "outdoors",
          "people",
          "place",
          "playing",
          "please",
          "possibly",
          "resting",
          "salted",
          "scene",
          "showing",
          "shown",
          "sleeping",
          "smartphone",
          "structure",
          "surroundings",
          "tent",
          "tents",
          "trip",
          "using",
          "various",
          "video",
          "white",
          "yeah"
        ],
        "keyword_count": 56,
        "children": null,
        "level": 0,
        "parent": "node_1_25",
        "source_seconds": [
          255,
          256,
          257,
          258,
          259
        ],
        "source_transcriptions": [
          63,
          64,
          65
        ],
        "visual_text": "30 second video showing a man eating outdoors while inside a tent. 4 men are in tents, two of them are having their meals while others are resting or sleeping. The tents have a white canvas structure, and the scene appears to be outdoors with natural lighting conditions. 3 men are eating out of bowls in a tent, one man is filming 3 people are inside a tent and playing with their fishing lures. 3 people are shown in this image, possibly a family on a camping trip. They are engaged in various activities, such as using a smartphone and flying a kite. The image captures their interactions and surroundings, which include a tent and outdoor elements.",
        "audio_text": "please yeah and then at the other bite Salted and dung, yeah. Let's blow... We need to hold it like this in place.",
        "combined_text": "30 second video showing a man eating outdoors while inside a tent. 4 men are in tents, two of them are having their meals while others are resting or sleeping. The tents have a white canvas structure, and the scene appears to be outdoors with natural lighting conditions. 3 men are eating out of bowls in a tent, one man is filming 3 people are inside a tent and playing with their fishing lures. 3 people are shown in this image, possibly a family on a camping trip. They are engaged in various activities, such as using a smartphone and flying a kite. The image captures their interactions and surroundings, which include a tent and outdoor elements. please yeah and then at the other bite Salted and dung, yeah. Let's blow... We need to hold it like this in place."
      },
      "leaf_52": {
        "node_id": "leaf_52",
        "time_range": [
          260.0,
          265.0
        ],
        "duration": 5.0,
        "keywords": [
          "activities",
          "around",
          "backpack",
          "bags",
          "blow",
          "blowing",
          "blue",
          "bottle",
          "bowl",
          "bowls",
          "boy",
          "camera",
          "camping",
          "campsite",
          "candle",
          "captures",
          "capturing",
          "container",
          "cooking",
          "cups",
          "dung",
          "enjoying",
          "family",
          "fire",
          "fish",
          "food",
          "footage",
          "front",
          "ground",
          "handbag",
          "hold",
          "holding",
          "image",
          "inside",
          "interacts",
          "items",
          "like",
          "man",
          "men",
          "mounted",
          "next",
          "object",
          "objects",
          "older",
          "out",
          "outdoors",
          "over",
          "people",
          "person",
          "place",
          "possibly",
          "pouring",
          "providing",
          "red",
          "salted",
          "scene",
          "seen",
          "shows",
          "sitting",
          "small",
          "spoons",
          "stable",
          "tent",
          "tents",
          "time",
          "together",
          "tripod",
          "various",
          "visible",
          "watching",
          "water",
          "way",
          "yeah"
        ],
        "keyword_count": 73,
        "children": null,
        "level": 0,
        "parent": "node_1_26",
        "source_seconds": [
          260,
          261,
          262,
          263,
          264
        ],
        "source_transcriptions": [
          64,
          65,
          66
        ],
        "visual_text": "3 men, a boy, and an older man at a campsite with tents, food cooking over a fire, and various objects like cups, bowls, and spoons in front of them. 3 people are seen in this image which shows them sitting on the ground inside a tent. A man is holding a can while a boy is blowing out a candle. They have various items with them, such as cups, bowls and a backpack. The camera capturing this scene is mounted on a tripod, providing stable footage of the family enjoying their time together in the tent. 3 people in the scene. One is pouring water into a blue container while the other two are watching. 3 people in tents camping outdoors with bowls and bags visible around them. \nIn the image, a person can be seen sitting on the ground in front of various objects. There is a blue bowl next to a red object, possibly a water bottle or a small red backpack. Other items, including a handbag, are also visible in the scene. The camera is set up in such a way that it captures the man's activities, as he interacts with these objects around him.",
        "audio_text": "Salted and dung, yeah. Let's blow... We need to hold it like this in place. Put that fish in there.",
        "combined_text": "3 men, a boy, and an older man at a campsite with tents, food cooking over a fire, and various objects like cups, bowls, and spoons in front of them. 3 people are seen in this image which shows them sitting on the ground inside a tent. A man is holding a can while a boy is blowing out a candle. They have various items with them, such as cups, bowls and a backpack. The camera capturing this scene is mounted on a tripod, providing stable footage of the family enjoying their time together in the tent. 3 people in the scene. One is pouring water into a blue container while the other two are watching. 3 people in tents camping outdoors with bowls and bags visible around them. \nIn the image, a person can be seen sitting on the ground in front of various objects. There is a blue bowl next to a red object, possibly a water bottle or a small red backpack. Other items, including a handbag, are also visible in the scene. The camera is set up in such a way that it captures the man's activities, as he interacts with these objects around him. Salted and dung, yeah. Let's blow... We need to hold it like this in place. Put that fish in there."
      },
      "leaf_53": {
        "node_id": "leaf_53",
        "time_range": [
          265.0,
          270.0
        ],
        "duration": 5.0,
        "keywords": [
          "2015",
          "30",
          "around",
          "backpack",
          "balls",
          "blow",
          "blue",
          "bottle",
          "bowls",
          "broth",
          "camping",
          "cleaning",
          "cup",
          "expedition",
          "featuring",
          "finger",
          "fish",
          "fishing",
          "glasses",
          "hand",
          "hat",
          "hold",
          "holding",
          "includes",
          "indicating",
          "inside",
          "item",
          "lid",
          "like",
          "man",
          "military",
          "multiple",
          "nearby",
          "next",
          "oiling",
          "outdoors",
          "outside",
          "person",
          "place",
          "pointing",
          "possibly",
          "present",
          "red",
          "rod",
          "scattered",
          "scene",
          "seconds",
          "showing",
          "sitting",
          "something",
          "sports",
          "standing",
          "tent",
          "trip",
          "uniform",
          "video",
          "wearing"
        ],
        "keyword_count": 57,
        "children": null,
        "level": 0,
        "parent": "node_1_26",
        "source_seconds": [
          265,
          266,
          267,
          268,
          269
        ],
        "source_transcriptions": [
          65,
          66,
          67
        ],
        "visual_text": "1 second video showing a person cleaning a fish outdoors. There are blue bowls present and a backpack nearby indicating it might be a camping trip or fishing expedition. 1-second video with a person cleaning a fish outside in 2015. \nA man wearing glasses is pointing at something with his finger while holding a bottle in his hand. He is standing next to a backpack and a cup. 30 seconds of video featuring a man with a fishing rod inside a tent. The scene also includes multiple sports balls scattered around him. 1-second video featuring a man wearing glasses, a hat, and possibly in a military uniform sitting next to a tent. There is also an item with a red lid present in the scene.",
        "audio_text": "Let's blow... We need to hold it like this in place. Put that fish in there. fish in the oiling broth.",
        "combined_text": "1 second video showing a person cleaning a fish outdoors. There are blue bowls present and a backpack nearby indicating it might be a camping trip or fishing expedition. 1-second video with a person cleaning a fish outside in 2015. \nA man wearing glasses is pointing at something with his finger while holding a bottle in his hand. He is standing next to a backpack and a cup. 30 seconds of video featuring a man with a fishing rod inside a tent. The scene also includes multiple sports balls scattered around him. 1-second video featuring a man wearing glasses, a hat, and possibly in a military uniform sitting next to a tent. There is also an item with a red lid present in the scene. Let's blow... We need to hold it like this in place. Put that fish in there. fish in the oiling broth."
      },
      "leaf_54": {
        "node_id": "leaf_54",
        "time_range": [
          270.0,
          275.0
        ],
        "duration": 5.0,
        "keywords": [
          "360",
          "3d",
          "3rd",
          "accurate",
          "additional",
          "after",
          "another",
          "assortment",
          "backpack",
          "backpacks",
          "black",
          "blue",
          "bottles",
          "bowls",
          "broth",
          "camping",
          "cooking",
          "descriptions",
          "detailed",
          "fish",
          "foreground",
          "frisbee",
          "glasses",
          "green",
          "hat",
          "holding",
          "image",
          "items",
          "main",
          "man",
          "methods",
          "nearby",
          "next",
          "object",
          "oiling",
          "outdoors",
          "people",
          "person",
          "perspective",
          "place",
          "placing",
          "pots",
          "present",
          "provide",
          "red",
          "scene",
          "site",
          "sitting",
          "someone",
          "stabilization",
          "takes",
          "top",
          "tracking",
          "video",
          "wearing",
          "well",
          "white"
        ],
        "keyword_count": 57,
        "children": null,
        "level": 0,
        "parent": "node_1_27",
        "source_seconds": [
          270,
          271,
          272,
          273,
          274
        ],
        "source_transcriptions": [
          67,
          68
        ],
        "visual_text": "1-second scene with a man sitting next to a green object holding by another man in a hat. The main person is wearing glasses and there are other people present as well. 3D object tracking and image stabilization methods can provide more accurate and detailed descriptions of this scene. 3rd person perspective of someone placing a black frisbee on top of another frisbee. The scene takes place outdoors with some additional items nearby such as a backpack and a red, white and blue object in the foreground. 360 video of camping site with man present 1-second scene with an assortment of items outdoors including pots, bowls, backpacks, a person cooking, and some bottles.",
        "audio_text": "fish in the oiling broth. after",
        "combined_text": "1-second scene with a man sitting next to a green object holding by another man in a hat. The main person is wearing glasses and there are other people present as well. 3D object tracking and image stabilization methods can provide more accurate and detailed descriptions of this scene. 3rd person perspective of someone placing a black frisbee on top of another frisbee. The scene takes place outdoors with some additional items nearby such as a backpack and a red, white and blue object in the foreground. 360 video of camping site with man present 1-second scene with an assortment of items outdoors including pots, bowls, backpacks, a person cooking, and some bottles. fish in the oiling broth. after"
      },
      "leaf_55": {
        "node_id": "leaf_55",
        "time_range": [
          275.0,
          280.0
        ],
        "duration": 5.0,
        "keywords": [
          "360",
          "3rd",
          "above",
          "adventure",
          "after",
          "along",
          "appears",
          "area",
          "around",
          "array",
          "backpacking",
          "backpacks",
          "belongings",
          "black",
          "blue",
          "bowl",
          "bowls",
          "camera",
          "cameras",
          "camping",
          "capturing",
          "cooking",
          "degree",
          "dolly",
          "features",
          "flavored",
          "food",
          "frisbee",
          "good",
          "green",
          "hat",
          "helmet",
          "hiking",
          "holding",
          "image",
          "indicating",
          "inside",
          "interesting",
          "items",
          "knife",
          "knives",
          "like",
          "likely",
          "lot",
          "man",
          "mounted",
          "multiple",
          "objects",
          "outdoors",
          "overhead",
          "pan",
          "people",
          "person",
          "personal",
          "perspective",
          "place",
          "placed",
          "positioned",
          "pot",
          "present",
          "ramen",
          "ready",
          "scene",
          "seen",
          "showing",
          "something",
          "takes",
          "tastes",
          "tent",
          "trip",
          "trowel",
          "various",
          "video",
          "view",
          "white",
          "wing",
          "yeah",
          "yellow"
        ],
        "keyword_count": 78,
        "children": null,
        "level": 0,
        "parent": "node_1_27",
        "source_seconds": [
          275,
          276,
          277,
          278,
          279
        ],
        "source_transcriptions": [
          68,
          69,
          70
        ],
        "visual_text": "1-second video showing a person cooking some food on a camping trip. The camera is positioned overhead, capturing the scene from above. There are multiple objects in the image, including a tent, cooking pot, bowls, and various personal belongings. The video also features an interesting array of backpacks, indicating that this might be a backpacking or hiking adventure. 360-degree image with an overhead view, capturing multiple objects including a yellow pan, blue backpacks, and other items. 1 second video with multiple objects and a person. 3rd person perspective video of a man with a green hat holding a black frisbee inside a white bowl. \nThis image appears to be from a first-person perspective camera mounted on the person's helmet, showing them holding a bowl with a knife in it. The scene takes place outdoors, likely during a camping trip. There are two other people present in the scene, one of whom is also holding a camera. Various objects such as bowls, knives, and cameras can be seen in the image along with some backpacks placed around the area.",
        "audio_text": "after Are you ready for some some ramen flavored dolly here? Yeah, that's good. Wing. Dolly tastes a lot like a trowel or something.",
        "combined_text": "1-second video showing a person cooking some food on a camping trip. The camera is positioned overhead, capturing the scene from above. There are multiple objects in the image, including a tent, cooking pot, bowls, and various personal belongings. The video also features an interesting array of backpacks, indicating that this might be a backpacking or hiking adventure. 360-degree image with an overhead view, capturing multiple objects including a yellow pan, blue backpacks, and other items. 1 second video with multiple objects and a person. 3rd person perspective video of a man with a green hat holding a black frisbee inside a white bowl. \nThis image appears to be from a first-person perspective camera mounted on the person's helmet, showing them holding a bowl with a knife in it. The scene takes place outdoors, likely during a camping trip. There are two other people present in the scene, one of whom is also holding a camera. Various objects such as bowls, knives, and cameras can be seen in the image along with some backpacks placed around the area. after Are you ready for some some ramen flavored dolly here? Yeah, that's good. Wing. Dolly tastes a lot like a trowel or something."
      },
      "leaf_56": {
        "node_id": "leaf_56",
        "time_range": [
          280.0,
          285.0
        ],
        "duration": 5.0,
        "keywords": [
          "30",
          "32",
          "accurate",
          "adult",
          "angle",
          "appears",
          "backpack",
          "backpacks",
          "baseball",
          "blue",
          "bottles",
          "bowl",
          "bowls",
          "boy",
          "camera",
          "cap",
          "captures",
          "capturing",
          "clearly",
          "close",
          "conversation",
          "cooking",
          "daily",
          "discussing",
          "dolly",
          "down",
          "eating",
          "entire",
          "featuring",
          "flavored",
          "food",
          "footage",
          "frames",
          "glasses",
          "good",
          "holding",
          "image",
          "includes",
          "input",
          "inside",
          "interaction",
          "lens",
          "life",
          "like",
          "likely",
          "little",
          "lot",
          "male",
          "man",
          "meal",
          "men",
          "mess",
          "multiple",
          "nearby",
          "numerous",
          "objects",
          "outdoor",
          "oven",
          "people",
          "person",
          "perspective",
          "place",
          "placed",
          "plates",
          "pots",
          "present",
          "process",
          "providing",
          "ramen",
          "ready",
          "representation",
          "salmon",
          "salt",
          "scene",
          "seconds",
          "seen",
          "setting",
          "sharing",
          "sitting",
          "something",
          "spoons",
          "takes",
          "talking",
          "tastes",
          "tent",
          "tripod",
          "trout",
          "trowel",
          "video",
          "view",
          "visible",
          "wearing",
          "wide",
          "wing",
          "yeah",
          "young"
        ],
        "keyword_count": 96,
        "children": null,
        "level": 0,
        "parent": "node_1_28",
        "source_seconds": [
          280,
          281,
          282,
          283,
          284
        ],
        "source_transcriptions": [
          69,
          70,
          71
        ],
        "visual_text": "30 seconds of footage featuring a person cooking in a tent. The scene includes multiple objects like bowls, blue plates, pots, bottles, backpacks, and an oven. The camera's perspective is first-person, providing a close-up view of the cooking process. 32 frames of video input needed for accurate representation of scene. 2 people in a tent, one adult male and one young boy. They appear to be eating food and discussing something. The adult man is wearing glasses which can be seen clearly. There is also a baseball cap visible in the scene. The tent appears to be a mess tent as there are numerous bowls, spoons, and a backpack present. The image captures their daily life and interaction with each other while sharing a meal inside the tent. 2 men are having conversation while one is eating food in a tent. Camera was placed on a tripod with wide-angle lens, capturing the entire scene. 2 people in a tent, one is likely to be a young boy. They are sitting down and having food from bowls. There is a man holding a blue bowl and talking to the other person. The scene takes place in an outdoor setting with a visible backpack nearby.",
        "audio_text": "Are you ready for some some ramen flavored dolly here? Yeah, that's good. Wing. Dolly tastes a lot like a trowel or something. I got a trout or salmon. Yeah. Do you want a little salt on them?",
        "combined_text": "30 seconds of footage featuring a person cooking in a tent. The scene includes multiple objects like bowls, blue plates, pots, bottles, backpacks, and an oven. The camera's perspective is first-person, providing a close-up view of the cooking process. 32 frames of video input needed for accurate representation of scene. 2 people in a tent, one adult male and one young boy. They appear to be eating food and discussing something. The adult man is wearing glasses which can be seen clearly. There is also a baseball cap visible in the scene. The tent appears to be a mess tent as there are numerous bowls, spoons, and a backpack present. The image captures their daily life and interaction with each other while sharing a meal inside the tent. 2 men are having conversation while one is eating food in a tent. Camera was placed on a tripod with wide-angle lens, capturing the entire scene. 2 people in a tent, one is likely to be a young boy. They are sitting down and having food from bowls. There is a man holding a blue bowl and talking to the other person. The scene takes place in an outdoor setting with a visible backpack nearby. Are you ready for some some ramen flavored dolly here? Yeah, that's good. Wing. Dolly tastes a lot like a trowel or something. I got a trout or salmon. Yeah. Do you want a little salt on them?"
      },
      "leaf_57": {
        "node_id": "leaf_57",
        "time_range": [
          285.0,
          290.0
        ],
        "duration": 5.0,
        "keywords": [
          "360",
          "3d",
          "around",
          "bowl",
          "boy",
          "camping",
          "degree",
          "dolly",
          "down",
          "eating",
          "enjoying",
          "father",
          "food",
          "front",
          "good",
          "hat",
          "inside",
          "letters",
          "like",
          "little",
          "lot",
          "man",
          "meal",
          "men",
          "model",
          "next",
          "objects",
          "oh",
          "older",
          "out",
          "pepper",
          "pot",
          "salmon",
          "salt",
          "seen",
          "sitting",
          "something",
          "son",
          "tastes",
          "tent",
          "together",
          "trout",
          "trowel",
          "under",
          "various",
          "video",
          "watches",
          "wearing",
          "wing",
          "yeah",
          "young"
        ],
        "keyword_count": 51,
        "children": null,
        "level": 0,
        "parent": "node_1_28",
        "source_seconds": [
          285,
          286,
          287,
          288,
          289
        ],
        "source_transcriptions": [
          70,
          71,
          72
        ],
        "visual_text": "2 men are sitting down under a tent while eating something out of a bowl. 2 men are sitting under a tent and eating. One man is wearing a hat with letters on it while the other man is sitting next to him. A bowl can be seen in front of them, and they seem to be enjoying their meal together. 3D model of a man and boy eating inside a tent. 360-degree video of a father and son camping with a pot and food in front of them. 1 second of a young man eating while an older man watches him. They are both sitting in a tent with various objects around them.",
        "audio_text": "Yeah, that's good. Wing. Dolly tastes a lot like a trowel or something. I got a trout or salmon. Yeah. Do you want a little salt on them? Salt there? Oh yeah, little salt and pepper",
        "combined_text": "2 men are sitting down under a tent while eating something out of a bowl. 2 men are sitting under a tent and eating. One man is wearing a hat with letters on it while the other man is sitting next to him. A bowl can be seen in front of them, and they seem to be enjoying their meal together. 3D model of a man and boy eating inside a tent. 360-degree video of a father and son camping with a pot and food in front of them. 1 second of a young man eating while an older man watches him. They are both sitting in a tent with various objects around them. Yeah, that's good. Wing. Dolly tastes a lot like a trowel or something. I got a trout or salmon. Yeah. Do you want a little salt on them? Salt there? Oh yeah, little salt and pepper"
      },
      "leaf_58": {
        "node_id": "leaf_58",
        "time_range": [
          290.0,
          295.0
        ],
        "duration": 5.0,
        "keywords": [
          "adding",
          "alright",
          "another",
          "appears",
          "area",
          "around",
          "atmosphere",
          "away",
          "backpack",
          "backpacks",
          "bags",
          "between",
          "bivou",
          "blue",
          "bottle",
          "bottles",
          "bowl",
          "camping",
          "campsite",
          "capture",
          "casual",
          "cell",
          "center",
          "closer",
          "company",
          "cozy",
          "cups",
          "depicts",
          "dog",
          "down",
          "eating",
          "enjoy",
          "food",
          "foreground",
          "front",
          "further",
          "good",
          "groups",
          "handbag",
          "holding",
          "inside",
          "items",
          "knife",
          "little",
          "located",
          "looking",
          "man",
          "meal",
          "men",
          "mess",
          "messy",
          "moment",
          "near",
          "nearby",
          "object",
          "objects",
          "oh",
          "overall",
          "people",
          "pepper",
          "person",
          "phone",
          "placed",
          "present",
          "relaxed",
          "right",
          "salt",
          "sandwiches",
          "scattered",
          "scene",
          "seated",
          "seems",
          "seen",
          "settled",
          "several",
          "share",
          "shared",
          "shown",
          "side",
          "site",
          "sitting",
          "something",
          "table",
          "tent",
          "together",
          "unique",
          "various",
          "wall",
          "yeah"
        ],
        "keyword_count": 89,
        "children": null,
        "level": 0,
        "parent": "node_1_29",
        "source_seconds": [
          290,
          291,
          292,
          293,
          294
        ],
        "source_transcriptions": [
          72,
          73
        ],
        "visual_text": "4 unique objects, 6 groups, 1 second 2 men in a tent, one is holding a bowl while eating, the other is looking at him. The tent appears to be a mess tent as there are various objects scattered around, such as bottles, sandwiches, a knife, a backpack and a handbag. There's also a cell phone on the table. The scene seems to capture a casual moment between these two men as they share a meal together in their tent. 2 men are shown having a meal together in a tent with a backpack nearby. 2 people are seen sitting in a tent. One person is looking into something while holding a blue object. There are several bags around them, including backpacks and a handbag. The tent appears to be their campsite where they have settled down for a break. 2 men eating food inside their tent. The first man is seated on the left side of the tent while the second man is sitting on the right side, closer to the foreground. A dog is also present in the scene, adding to the cozy atmosphere of the camping site.\n\nThe tent appears to be a messy bivou, with various items scattered around, such as a backpack near the left wall and another one further away on the right side. There are two cups placed near each other in the center area, and a bottle is located closer to the front of the tent. The overall scene depicts a relaxed moment shared between the two men as they enjoy their meal in the company of their dog.",
        "audio_text": "Salt there? Oh yeah, little salt and pepper A little salt and pepper is good. Oh. Alright.",
        "combined_text": "4 unique objects, 6 groups, 1 second 2 men in a tent, one is holding a bowl while eating, the other is looking at him. The tent appears to be a mess tent as there are various objects scattered around, such as bottles, sandwiches, a knife, a backpack and a handbag. There's also a cell phone on the table. The scene seems to capture a casual moment between these two men as they share a meal together in their tent. 2 men are shown having a meal together in a tent with a backpack nearby. 2 people are seen sitting in a tent. One person is looking into something while holding a blue object. There are several bags around them, including backpacks and a handbag. The tent appears to be their campsite where they have settled down for a break. 2 men eating food inside their tent. The first man is seated on the left side of the tent while the second man is sitting on the right side, closer to the foreground. A dog is also present in the scene, adding to the cozy atmosphere of the camping site.\n\nThe tent appears to be a messy bivou, with various items scattered around, such as a backpack near the left wall and another one further away on the right side. There are two cups placed near each other in the center area, and a bottle is located closer to the front of the tent. The overall scene depicts a relaxed moment shared between the two men as they enjoy their meal in the company of their dog. Salt there? Oh yeah, little salt and pepper A little salt and pepper is good. Oh. Alright."
      },
      "leaf_59": {
        "node_id": "leaf_59",
        "time_range": [
          295.0,
          299.999
        ],
        "duration": 4.999000000000024,
        "keywords": [
          "31",
          "3rd",
          "aged",
          "alright",
          "another",
          "away",
          "background",
          "backpack",
          "bags",
          "behind",
          "blue",
          "body",
          "book",
          "bottle",
          "bottles",
          "bowl",
          "bowls",
          "camera",
          "camper",
          "close",
          "cup",
          "dishes",
          "down",
          "features",
          "featuring",
          "further",
          "gear",
          "good",
          "green",
          "ground",
          "haired",
          "hand",
          "hands",
          "holding",
          "holds",
          "image",
          "indicating",
          "item",
          "items",
          "lap",
          "little",
          "ll",
          "man",
          "middle",
          "mounted",
          "mouth",
          "multi",
          "near",
          "nearby",
          "next",
          "objects",
          "oh",
          "pen",
          "pepper",
          "person",
          "perspective",
          "placed",
          "possibly",
          "proximity",
          "recorded",
          "round",
          "salt",
          "scene",
          "seen",
          "several",
          "shaky",
          "shot",
          "showing",
          "sitting",
          "soldier",
          "someone",
          "tent",
          "tool",
          "various",
          "video",
          "wearing",
          "white",
          "winter"
        ],
        "keyword_count": 78,
        "children": null,
        "level": 0,
        "parent": "node_1_29",
        "source_seconds": [
          295,
          296,
          297,
          298,
          299
        ],
        "source_transcriptions": [
          73,
          74
        ],
        "visual_text": "\n- A white-haired man is sitting down with a green background behind him.\n- The man holds a round item in his hands.\n- There are two bottles nearby, one close to the man and another further away.\n- A backpack can be seen next to the man, placed on the ground. 1-second scene featuring a man sitting near objects such as a cup and a backpack. 31-second video of a middle-aged man in a tent, possibly a camper or soldier, holding up a multi-tool with a pen in his mouth. The image has a shaky camera perspective, indicating it could have been recorded from the first-person perspective, or mounted on the person's body or backpack. The video also features several objects such as a bottle, cup, and book in close proximity to the man. 3-second shot of someone holding a blue bowl while wearing winter gear. 3rd person perspective showing someone's hand and lap with various items such as bowls, bags, and a backpack.",
        "audio_text": "A little salt and pepper is good. Oh. Alright. Alright, I'll do some dishes.",
        "combined_text": "- A white-haired man is sitting down with a green background behind him.\n- The man holds a round item in his hands.\n- There are two bottles nearby, one close to the man and another further away.\n- A backpack can be seen next to the man, placed on the ground. 1-second scene featuring a man sitting near objects such as a cup and a backpack. 31-second video of a middle-aged man in a tent, possibly a camper or soldier, holding up a multi-tool with a pen in his mouth. The image has a shaky camera perspective, indicating it could have been recorded from the first-person perspective, or mounted on the person's body or backpack. The video also features several objects such as a bottle, cup, and book in close proximity to the man. 3-second shot of someone holding a blue bowl while wearing winter gear. 3rd person perspective showing someone's hand and lap with various items such as bowls, bags, and a backpack. A little salt and pepper is good. Oh. Alright. Alright, I'll do some dishes."
      },
      "node_1_0": {
        "node_id": "node_1_0",
        "time_range": [
          0.0,
          10.0
        ],
        "duration": 10.0,
        "keywords": [
          "30",
          "360",
          "action",
          "air",
          "airplane",
          "alaska",
          "angle",
          "another",
          "appears",
          "arctic",
          "area",
          "away",
          "back",
          "background",
          "backpack",
          "beautiful",
          "behind",
          "black",
          "blue",
          "boat",
          "boats",
          "boys",
          "camera",
          "camp",
          "cap",
          "captures",
          "casting",
          "cause",
          "channel",
          "close",
          "days",
          "degree",
          "distance",
          "distortion",
          "dolly",
          "dropped",
          "edges",
          "enjoying",
          "environment",
          "excitement",
          "experience",
          "featuring",
          "fiji",
          "fish",
          "fishing",
          "flight",
          "float",
          "flying",
          "frame",
          "further",
          "glasses",
          "going",
          "gonna",
          "gopro",
          "grailing",
          "green",
          "grey",
          "hand",
          "hat",
          "helicopter",
          "hiking",
          "hillside",
          "holding",
          "hoodie",
          "image",
          "immersive",
          "includes",
          "indicating",
          "lake",
          "likely",
          "line",
          "looking",
          "luke",
          "man",
          "meal",
          "men",
          "mountain",
          "mountainous",
          "mountains",
          "near",
          "nearby",
          "next",
          "objects",
          "off",
          "out",
          "outdoor",
          "outdoors",
          "over",
          "people",
          "person",
          "perspective",
          "plane",
          "pointing",
          "positioned",
          "pov",
          "providing",
          "re",
          "right",
          "rocks",
          "saying",
          "scene",
          "seems",
          "setting",
          "several",
          "shaky",
          "shirt",
          "shore",
          "shot",
          "showing",
          "side",
          "similar",
          "slightly",
          "small",
          "something",
          "standing",
          "stands",
          "sunglasses",
          "taken",
          "tent",
          "timelapse",
          "together",
          "top",
          "tree",
          "trout",
          "vardin",
          "video",
          "view",
          "water",
          "way",
          "wearing",
          "welcome",
          "wide",
          "within",
          "writing",
          "youtube"
        ],
        "keyword_count": 135,
        "children": [
          "leaf_0",
          "leaf_1"
        ],
        "level": 1,
        "parent": "node_2_0"
      },
      "node_1_1": {
        "node_id": "node_1_1",
        "time_range": [
          10.0,
          20.0
        ],
        "duration": 10.0,
        "keywords": [
          "08",
          "360",
          "3d",
          "3rd",
          "angle",
          "arctic",
          "axe",
          "back",
          "boy",
          "bush",
          "cabin",
          "camera",
          "capturing",
          "coffee",
          "crafting",
          "cup",
          "description",
          "detection",
          "dick",
          "dolly",
          "environment",
          "exploring",
          "expression",
          "facial",
          "featuring",
          "filming",
          "fish",
          "fishing",
          "flying",
          "forest",
          "frame",
          "front",
          "frying",
          "gonna",
          "grailing",
          "ground",
          "guys",
          "hat",
          "hiking",
          "holding",
          "hole",
          "homestead",
          "inside",
          "kaleidoscope",
          "kite",
          "lake",
          "large",
          "lens",
          "log",
          "looking",
          "man",
          "mountain",
          "mountains",
          "mug",
          "near",
          "next",
          "object",
          "original",
          "out",
          "outdoors",
          "outside",
          "over",
          "overhead",
          "pack",
          "pan",
          "person",
          "perspective",
          "plane",
          "positioned",
          "prennicky",
          "rafting",
          "re",
          "relatively",
          "river",
          "rocks",
          "scene",
          "seconds",
          "seen",
          "showing",
          "sitting",
          "small",
          "stable",
          "standing",
          "stool",
          "structure",
          "stuck",
          "stump",
          "surrounding",
          "tree",
          "trout",
          "vardin",
          "video",
          "view",
          "wide",
          "wooden",
          "young",
          "youtuber"
        ],
        "keyword_count": 97,
        "children": [
          "leaf_2",
          "leaf_3"
        ],
        "level": 1,
        "parent": "node_2_0"
      },
      "node_1_2": {
        "node_id": "node_1_2",
        "time_range": [
          20.0,
          30.0
        ],
        "duration": 10.0,
        "keywords": [
          "12345",
          "27",
          "30",
          "32",
          "35",
          "360",
          "3rd",
          "additionally",
          "aircraft",
          "another",
          "appears",
          "back",
          "bags",
          "behind",
          "beside",
          "black",
          "bottle",
          "boy",
          "boys",
          "bush",
          "camera",
          "captures",
          "car",
          "carrying",
          "center",
          "chairs",
          "characteristics",
          "child",
          "closer",
          "crafting",
          "dashcam",
          "day",
          "degree",
          "detected",
          "driver",
          "drivers",
          "driving",
          "elements",
          "everyday",
          "fair",
          "features",
          "footage",
          "frame",
          "front",
          "glasses",
          "gopro",
          "group",
          "head",
          "helicopter",
          "himself",
          "image",
          "inside",
          "interior",
          "large",
          "life",
          "likely",
          "located",
          "locations",
          "long",
          "looking",
          "looks",
          "machinery",
          "man",
          "market",
          "moment",
          "near",
          "next",
          "objects",
          "operating",
          "original",
          "out",
          "outdoor",
          "outdoors",
          "part",
          "people",
          "person",
          "personal",
          "perspective",
          "photo",
          "piece",
          "pilot",
          "plane",
          "possibly",
          "rainy",
          "red",
          "repair",
          "respective",
          "right",
          "road",
          "says",
          "scene",
          "seat",
          "seated",
          "seats",
          "seconds",
          "seems",
          "several",
          "showing",
          "side",
          "sitting",
          "situated",
          "small",
          "someone",
          "something",
          "stall",
          "stands",
          "stump",
          "suggesting",
          "sunglasses",
          "surroundings",
          "talking",
          "top",
          "tree",
          "trip",
          "turned",
          "under",
          "unique",
          "various",
          "vehicle",
          "video",
          "view",
          "visible",
          "wearing",
          "well",
          "white",
          "window",
          "within",
          "works",
          "writing",
          "young",
          "youtuber"
        ],
        "keyword_count": 131,
        "children": [
          "leaf_4",
          "leaf_5"
        ],
        "level": 1,
        "parent": "node_2_1"
      },
      "node_1_3": {
        "node_id": "node_1_3",
        "time_range": [
          30.0,
          40.0
        ],
        "duration": 10.0,
        "keywords": [
          "10",
          "above",
          "adding",
          "aerial",
          "aid",
          "aircraft",
          "airplane",
          "along",
          "altitude",
          "appears",
          "area",
          "around",
          "background",
          "ball",
          "below",
          "birds",
          "board",
          "boat",
          "body",
          "building",
          "bus",
          "buttons",
          "camera",
          "cap",
          "captured",
          "capturing",
          "car",
          "cars",
          "cockpit",
          "context",
          "control",
          "controls",
          "crucial",
          "day",
          "dynamic",
          "edge",
          "elements",
          "engaging",
          "experience",
          "eye",
          "features",
          "field",
          "filled",
          "flies",
          "flight",
          "flying",
          "footage",
          "front",
          "helicopter",
          "helmet",
          "holding",
          "house",
          "image",
          "information",
          "inside",
          "instruments",
          "interesting",
          "island",
          "landscape",
          "laptop",
          "located",
          "long",
          "lot",
          "low",
          "making",
          "man",
          "middle",
          "mounted",
          "multiple",
          "navigates",
          "near",
          "ocean",
          "over",
          "overcast",
          "part",
          "person",
          "perspective",
          "pilot",
          "plane",
          "possibly",
          "providing",
          "relatively",
          "river",
          "scene",
          "screen",
          "seen",
          "serving",
          "several",
          "shoreline",
          "shot",
          "shoulder",
          "showing",
          "shows",
          "sits",
          "sitting",
          "small",
          "speedometer",
          "stable",
          "steering",
          "surfaces",
          "surroundings",
          "switches",
          "tracks",
          "trees",
          "tripod",
          "using",
          "video",
          "view",
          "viewers",
          "visible",
          "visual",
          "water",
          "wearing",
          "wheel",
          "wing",
          "within",
          "works"
        ],
        "keyword_count": 117,
        "children": [
          "leaf_6",
          "leaf_7"
        ],
        "level": 1,
        "parent": "node_2_1"
      },
      "node_1_4": {
        "node_id": "node_1_4",
        "time_range": [
          40.0,
          50.0
        ],
        "duration": 10.0,
        "keywords": [
          "3rd",
          "above",
          "aerial",
          "aircraft",
          "airplane",
          "altitude",
          "amazing",
          "angle",
          "appreciate",
          "area",
          "beautiful",
          "beauty",
          "before",
          "below",
          "boys",
          "camera",
          "captures",
          "capturing",
          "channels",
          "cockpit",
          "communication",
          "connected",
          "corner",
          "countryside",
          "distortion",
          "documentation",
          "due",
          "earth",
          "effect",
          "expansive",
          "experience",
          "features",
          "featuring",
          "filled",
          "filming",
          "fisheye",
          "flying",
          "focus",
          "focused",
          "front",
          "giving",
          "green",
          "headphones",
          "helicopter",
          "image",
          "immersive",
          "indicates",
          "inside",
          "jackets",
          "landscape",
          "lens",
          "long",
          "making",
          "marshy",
          "men",
          "moment",
          "mountain",
          "mountains",
          "natural",
          "navigating",
          "noticeable",
          "outside",
          "over",
          "passenger",
          "person",
          "perspective",
          "pilot",
          "plane",
          "plants",
          "point",
          "possibly",
          "providing",
          "purposes",
          "radio",
          "range",
          "recreational",
          "red",
          "right",
          "river",
          "rivers",
          "scene",
          "scenic",
          "seats",
          "seems",
          "seen",
          "sense",
          "shaky",
          "shot",
          "showcasing",
          "showing",
          "shows",
          "side",
          "sitting",
          "slightly",
          "small",
          "snowy",
          "stunning",
          "system",
          "taken",
          "turbulence",
          "unfolds",
          "unique",
          "upper",
          "valley",
          "valleys",
          "vantage",
          "vastness",
          "video",
          "view",
          "viewed",
          "viewer",
          "viewers",
          "views",
          "visible",
          "visual",
          "water",
          "wearing",
          "wetlands",
          "white",
          "wide",
          "wider",
          "window",
          "wing",
          "within",
          "young"
        ],
        "keyword_count": 125,
        "children": [
          "leaf_8",
          "leaf_9"
        ],
        "level": 1,
        "parent": "node_2_2"
      },
      "node_1_5": {
        "node_id": "node_1_5",
        "time_range": [
          50.0,
          60.0
        ],
        "duration": 10.0,
        "keywords": [
          "10",
          "15",
          "360",
          "3rd",
          "aircraft",
          "airplane",
          "angle",
          "appears",
          "area",
          "back",
          "background",
          "beautiful",
          "blue",
          "boat",
          "camera",
          "captured",
          "captures",
          "capturing",
          "car",
          "clear",
          "cockpit",
          "controls",
          "creates",
          "dashboard",
          "degree",
          "description",
          "descriptions",
          "distortion",
          "driving",
          "featuring",
          "flying",
          "footage",
          "front",
          "gauges",
          "gopro",
          "green",
          "hat",
          "head",
          "headphones",
          "identified",
          "image",
          "includes",
          "indicating",
          "inside",
          "jacket",
          "lake",
          "landscape",
          "lens",
          "long",
          "looking",
          "man",
          "mountain",
          "mountainous",
          "mountains",
          "mounted",
          "movement",
          "objects",
          "out",
          "over",
          "passenger",
          "people",
          "person",
          "perspective",
          "pilot",
          "plane",
          "possibly",
          "potentially",
          "pov",
          "providing",
          "red",
          "river",
          "scene",
          "scenery",
          "seconds",
          "shot",
          "showing",
          "sitting",
          "sky",
          "small",
          "soars",
          "specific",
          "stable",
          "structures",
          "stunning",
          "suggests",
          "taken",
          "top",
          "trees",
          "using",
          "vehicle",
          "video",
          "view",
          "visible",
          "water",
          "wearing",
          "wide",
          "wildlife",
          "wings"
        ],
        "keyword_count": 98,
        "children": [
          "leaf_10",
          "leaf_11"
        ],
        "level": 1,
        "parent": "node_2_2"
      },
      "node_1_6": {
        "node_id": "node_1_6",
        "time_range": [
          60.0,
          70.0
        ],
        "duration": 10.0,
        "keywords": [
          "30",
          "3rd",
          "45",
          "7373",
          "activity",
          "admiring",
          "aircraft",
          "airplane",
          "another",
          "appears",
          "area",
          "aviation",
          "background",
          "behind",
          "blue",
          "boat",
          "body",
          "camera",
          "canister",
          "captures",
          "capturing",
          "craft",
          "day",
          "departure",
          "device",
          "disembark",
          "door",
          "excited",
          "featuring",
          "flying",
          "footage",
          "front",
          "glasses",
          "glimpse",
          "hanging",
          "hat",
          "helicopter",
          "holding",
          "hook",
          "image",
          "interesting",
          "jacket",
          "lake",
          "lapse",
          "large",
          "life",
          "likely",
          "man",
          "men",
          "mounted",
          "near",
          "next",
          "number",
          "orange",
          "outdoor",
          "overcast",
          "people",
          "person",
          "persons",
          "perspective",
          "plane",
          "point",
          "pontoon",
          "possibly",
          "preparing",
          "providing",
          "raft",
          "ready",
          "rear",
          "red",
          "rope",
          "scene",
          "seaplane",
          "seconds",
          "seen",
          "setting",
          "shore",
          "shot",
          "showing",
          "side",
          "sitting",
          "ski",
          "small",
          "smiling",
          "standing",
          "stands",
          "style",
          "surrounding",
          "tank",
          "time",
          "top",
          "video",
          "view",
          "visible",
          "water",
          "wearing",
          "white"
        ],
        "keyword_count": 97,
        "children": [
          "leaf_12",
          "leaf_13"
        ],
        "level": 1,
        "parent": "node_2_3"
      },
      "node_1_7": {
        "node_id": "node_1_7",
        "time_range": [
          70.0,
          80.0
        ],
        "duration": 10.0,
        "keywords": [
          "10",
          "48",
          "angle",
          "appears",
          "background",
          "backpack",
          "beach",
          "beside",
          "bicycles",
          "blurry",
          "body",
          "boy",
          "calm",
          "camera",
          "capturing",
          "center",
          "cloudy",
          "colors",
          "conditions",
          "dark",
          "daughter",
          "day",
          "days",
          "dressed",
          "edge",
          "family",
          "father",
          "fishing",
          "fly",
          "frame",
          "girl",
          "going",
          "gravel",
          "grey",
          "guys",
          "hand",
          "hands",
          "hat",
          "hour",
          "image",
          "lake",
          "lakes",
          "large",
          "light",
          "likely",
          "located",
          "location",
          "looking",
          "low",
          "man",
          "men",
          "muted",
          "near",
          "ocean",
          "ourselves",
          "out",
          "outdoors",
          "over",
          "overcast",
          "people",
          "perspective",
          "picturesque",
          "placed",
          "pockets",
          "positioned",
          "possibly",
          "re",
          "right",
          "rod",
          "scene",
          "seems",
          "shore",
          "shoreline",
          "shot",
          "showing",
          "shutter",
          "side",
          "skies",
          "slow",
          "somewhat",
          "son",
          "speed",
          "stability",
          "standing",
          "stands",
          "suggesting",
          "taken",
          "timelapse",
          "travel",
          "trees",
          "tripod",
          "twin",
          "twins",
          "video",
          "water",
          "wearing",
          "welcome",
          "well",
          "wide",
          "young"
        ],
        "keyword_count": 100,
        "children": [
          "leaf_14",
          "leaf_15"
        ],
        "level": 1,
        "parent": "node_2_3"
      },
      "node_1_8": {
        "node_id": "node_1_8",
        "time_range": [
          80.0,
          90.0
        ],
        "duration": 10.0,
        "keywords": [
          "31",
          "360",
          "365",
          "4k",
          "across",
          "action",
          "adventure",
          "ago",
          "alaska",
          "alaskan",
          "along",
          "angle",
          "another",
          "appears",
          "area",
          "areas",
          "back",
          "background",
          "backpack",
          "backpacks",
          "beautiful",
          "boat",
          "body",
          "brightest",
          "camera",
          "camping",
          "captured",
          "capturing",
          "causing",
          "days",
          "degree",
          "detail",
          "edge",
          "float",
          "fly",
          "footage",
          "forecast",
          "frame",
          "glasses",
          "going",
          "gonna",
          "gravel",
          "green",
          "half",
          "hat",
          "hiking",
          "hour",
          "image",
          "immersive",
          "jacket",
          "km",
          "lake",
          "lakes",
          "landscape",
          "lens",
          "long",
          "looking",
          "loss",
          "man",
          "mounted",
          "mouth",
          "much",
          "near",
          "nearby",
          "next",
          "nh",
          "ocean",
          "okay",
          "older",
          "orange",
          "ourselves",
          "overexposed",
          "panoramic",
          "part",
          "patch",
          "people",
          "person",
          "perspective",
          "picture",
          "plane",
          "present",
          "providing",
          "raincoat",
          "raining",
          "re",
          "remote",
          "rocky",
          "room",
          "says",
          "scene",
          "seconds",
          "shore",
          "showing",
          "slightly",
          "someone",
          "stable",
          "standing",
          "suggesting",
          "surrounding",
          "taken",
          "talking",
          "tents",
          "travel",
          "twin",
          "twins",
          "using",
          "video",
          "view",
          "vlog",
          "water",
          "wearing",
          "welcome",
          "wide",
          "wilderness"
        ],
        "keyword_count": 114,
        "children": [
          "leaf_16",
          "leaf_17"
        ],
        "level": 1,
        "parent": "node_2_4"
      },
      "node_1_9": {
        "node_id": "node_1_9",
        "time_range": [
          90.0,
          100.0
        ],
        "duration": 10.0,
        "keywords": [
          "00",
          "01",
          "03",
          "2nd",
          "3rd",
          "57",
          "59",
          "64",
          "above",
          "adventure",
          "aged",
          "alaskan",
          "along",
          "backpack",
          "backpacks",
          "bag",
          "beard",
          "camera",
          "capturing",
          "carrying",
          "cloudy",
          "coat",
          "day",
          "down",
          "drop",
          "enjoying",
          "face",
          "forecast",
          "forest",
          "forward",
          "front",
          "glasses",
          "going",
          "gonna",
          "grab",
          "gravel",
          "grey",
          "guys",
          "hat",
          "huh",
          "jackets",
          "lake",
          "like",
          "looking",
          "looks",
          "man",
          "men",
          "middle",
          "mountain",
          "mounted",
          "mouth",
          "much",
          "near",
          "nearby",
          "next",
          "off",
          "okay",
          "orange",
          "outdoor",
          "outdoors",
          "path",
          "people",
          "person",
          "place",
          "positioned",
          "possibly",
          "pov",
          "raining",
          "red",
          "remote",
          "right",
          "river",
          "rocky",
          "shelter",
          "shore",
          "shoreline",
          "shot",
          "shoulder",
          "spot",
          "standing",
          "stands",
          "strapped",
          "stuff",
          "sunglasses",
          "time",
          "toward",
          "walking",
          "water",
          "wearing",
          "wilderness"
        ],
        "keyword_count": 90,
        "children": [
          "leaf_18",
          "leaf_19"
        ],
        "level": 1,
        "parent": "node_2_4"
      },
      "node_1_10": {
        "node_id": "node_1_10",
        "time_range": [
          100.0,
          110.0
        ],
        "duration": 10.0,
        "keywords": [
          "360",
          "3rd",
          "4k",
          "angle",
          "appears",
          "area",
          "back",
          "backpack",
          "blue",
          "brown",
          "camera",
          "carrying",
          "characteristics",
          "coat",
          "coats",
          "contains",
          "details",
          "distortion",
          "drop",
          "field",
          "grab",
          "grassy",
          "guys",
          "hat",
          "hiking",
          "huh",
          "image",
          "jacket",
          "jeans",
          "large",
          "lens",
          "like",
          "looking",
          "man",
          "men",
          "mounted",
          "near",
          "next",
          "off",
          "pants",
          "people",
          "person",
          "perspective",
          "rain",
          "red",
          "resolution",
          "right",
          "scene",
          "sheet",
          "showing",
          "something",
          "spot",
          "standing",
          "stuff",
          "tan",
          "tent",
          "tree",
          "trees",
          "umbrella",
          "video",
          "view",
          "walking",
          "wearing",
          "wide",
          "wilderness",
          "wooded",
          "woods",
          "yes"
        ],
        "keyword_count": 68,
        "children": [
          "leaf_20",
          "leaf_21"
        ],
        "level": 1,
        "parent": "node_2_5"
      },
      "node_1_11": {
        "node_id": "node_1_11",
        "time_range": [
          110.0,
          120.0
        ],
        "duration": 10.0,
        "keywords": [
          "10",
          "30",
          "adult",
          "along",
          "areas",
          "arm",
          "background",
          "bear",
          "behind",
          "black",
          "blanket",
          "blankets",
          "bu",
          "camera",
          "camping",
          "canopy",
          "captured",
          "characteristics",
          "children",
          "clip",
          "context",
          "contribute",
          "details",
          "detections",
          "elements",
          "family",
          "field",
          "fisherman",
          "fishing",
          "forest",
          "frame",
          "gear",
          "glasses",
          "going",
          "grab",
          "gravel",
          "grey",
          "helmet",
          "hood",
          "hugged",
          "image",
          "indicate",
          "inside",
          "jacket",
          "jackets",
          "jumpsuits",
          "lens",
          "looking",
          "male",
          "man",
          "men",
          "mounted",
          "multiple",
          "near",
          "object",
          "objects",
          "orange",
          "outdoors",
          "overall",
          "people",
          "person",
          "perspective",
          "photo",
          "pole",
          "positioning",
          "presence",
          "presented",
          "production",
          "providing",
          "re",
          "red",
          "right",
          "rightind",
          "riverbank",
          "rocky",
          "scene",
          "seen",
          "setting",
          "showing",
          "sitting",
          "someone",
          "something",
          "spray",
          "standing",
          "stream",
          "style",
          "subject",
          "taking",
          "technical",
          "tent",
          "tents",
          "tommy",
          "tree",
          "trees",
          "trip",
          "umbrella",
          "under",
          "understanding",
          "unique",
          "various",
          "video",
          "view",
          "viewer",
          "water",
          "wearing",
          "white",
          "within",
          "working",
          "yes"
        ],
        "keyword_count": 109,
        "children": [
          "leaf_22",
          "leaf_23"
        ],
        "level": 1,
        "parent": "node_2_5"
      },
      "node_1_12": {
        "node_id": "node_1_12",
        "time_range": [
          120.0,
          130.0
        ],
        "duration": 10.0,
        "keywords": [
          "00",
          "01",
          "4k",
          "along",
          "another",
          "appears",
          "area",
          "arm",
          "background",
          "beach",
          "bear",
          "behind",
          "black",
          "blue",
          "body",
          "bu",
          "camera",
          "capturing",
          "conversation",
          "daytime",
          "definition",
          "distance",
          "down",
          "fishermen",
          "fishing",
          "forest",
          "front",
          "going",
          "grab",
          "gravel",
          "ground",
          "gun",
          "hand",
          "harness",
          "hat",
          "high",
          "holding",
          "image",
          "jacket",
          "lake",
          "man",
          "men",
          "mountain",
          "mountains",
          "mounted",
          "near",
          "next",
          "nothing",
          "object",
          "ocean",
          "outdoors",
          "pebble",
          "person",
          "perspective",
          "point",
          "raincoat",
          "range",
          "re",
          "red",
          "road",
          "rod",
          "rods",
          "scene",
          "showing",
          "sitting",
          "someone",
          "spray",
          "standing",
          "stream",
          "suit",
          "taken",
          "tent",
          "tommy",
          "toob",
          "ultra",
          "video",
          "view",
          "waders",
          "walking",
          "water",
          "wearing",
          "woman"
        ],
        "keyword_count": 82,
        "children": [
          "leaf_24",
          "leaf_25"
        ],
        "level": 1,
        "parent": "node_2_6"
      },
      "node_1_13": {
        "node_id": "node_1_13",
        "time_range": [
          130.0,
          140.0
        ],
        "duration": 10.0,
        "keywords": [
          "00",
          "01",
          "360",
          "4k",
          "actions",
          "activities",
          "activity",
          "addition",
          "additional",
          "adventure",
          "along",
          "another",
          "appears",
          "around",
          "background",
          "backpack",
          "backpacks",
          "bait",
          "beside",
          "between",
          "black",
          "body",
          "camera",
          "cameras",
          "captured",
          "captures",
          "capturing",
          "chest",
          "child",
          "close",
          "colored",
          "container",
          "covering",
          "degree",
          "detail",
          "different",
          "distance",
          "down",
          "editing",
          "enjoying",
          "environment",
          "file",
          "filled",
          "fish",
          "fishing",
          "fly",
          "following",
          "footage",
          "gear",
          "gravel",
          "gray",
          "ground",
          "hand",
          "helmet",
          "holding",
          "hurry",
          "image",
          "includes",
          "indicating",
          "individual",
          "interest",
          "jacket",
          "kneeling",
          "lake",
          "looks",
          "lot",
          "lure",
          "main",
          "man",
          "mean",
          "mountain",
          "mountains",
          "mounted",
          "multiple",
          "nearby",
          "nearer",
          "next",
          "nothing",
          "objects",
          "observer",
          "observing",
          "oh",
          "outdoor",
          "outdoors",
          "part",
          "people",
          "person",
          "perspective",
          "pieces",
          "placed",
          "point",
          "possibly",
          "present",
          "purposes",
          "raw",
          "red",
          "rock",
          "rocks",
          "rod",
          "scattered",
          "scene",
          "scenes",
          "seen",
          "several",
          "showing",
          "simply",
          "sky",
          "snowsuit",
          "sports",
          "standing",
          "stands",
          "stream",
          "subjects",
          "suggesting",
          "suggests",
          "supplies",
          "surrounding",
          "toob",
          "using",
          "various",
          "video",
          "videos",
          "view",
          "visible",
          "wall",
          "water",
          "wearing",
          "within",
          "wow",
          "yeah",
          "yee",
          "yeee",
          "yes"
        ],
        "keyword_count": 133,
        "children": [
          "leaf_26",
          "leaf_27"
        ],
        "level": 1,
        "parent": "node_2_6"
      },
      "node_1_14": {
        "node_id": "node_1_14",
        "time_range": [
          140.0,
          150.0
        ],
        "duration": 10.0,
        "keywords": [
          "20",
          "360",
          "action",
          "allowing",
          "allows",
          "along",
          "angle",
          "area",
          "around",
          "backpack",
          "barton",
          "behavior",
          "behind",
          "bird",
          "black",
          "body",
          "bonk",
          "bottle",
          "boy",
          "camera",
          "captured",
          "capturing",
          "chart",
          "child",
          "closely",
          "daily",
          "degree",
          "dinner",
          "documentation",
          "dog",
          "dollar",
          "dolly",
          "environment",
          "features",
          "featuring",
          "fishing",
          "fly",
          "focus",
          "footage",
          "green",
          "ground",
          "hat",
          "held",
          "helmet",
          "holding",
          "hurry",
          "immersive",
          "indicates",
          "jacket",
          "lens",
          "life",
          "line",
          "man",
          "mounted",
          "movements",
          "near",
          "next",
          "observe",
          "oh",
          "okay",
          "orange",
          "out",
          "outdoor",
          "outdoors",
          "outfit",
          "people",
          "person",
          "perspective",
          "positioned",
          "positioning",
          "rain",
          "ready",
          "red",
          "river",
          "riverbank",
          "road",
          "rocks",
          "rocky",
          "rod",
          "rods",
          "scene",
          "seconds",
          "showcases",
          "showing",
          "small",
          "stable",
          "standing",
          "stream",
          "style",
          "suggests",
          "suit",
          "surroundings",
          "taken",
          "video",
          "viewers",
          "visible",
          "vlog",
          "waders",
          "walking",
          "walks",
          "wall",
          "water",
          "way",
          "wearing",
          "wide",
          "within",
          "yeah",
          "yep",
          "yes",
          "young"
        ],
        "keyword_count": 110,
        "children": [
          "leaf_28",
          "leaf_29"
        ],
        "level": 1,
        "parent": "node_2_7"
      },
      "node_1_15": {
        "node_id": "node_1_15",
        "time_range": [
          150.0,
          160.0
        ],
        "duration": 10.0,
        "keywords": [
          "34",
          "3d",
          "48",
          "action",
          "angle",
          "angles",
          "another",
          "attached",
          "background",
          "barton",
          "beach",
          "behind",
          "bent",
          "blancher",
          "bonk",
          "boy",
          "broader",
          "bump",
          "camera",
          "captured",
          "capturing",
          "char",
          "clothing",
          "deli",
          "depicting",
          "description",
          "detected",
          "different",
          "dinner",
          "distinct",
          "distortion",
          "dolly",
          "etc",
          "excitement",
          "family",
          "features",
          "featuring",
          "fish",
          "fishing",
          "focal",
          "focusing",
          "frames",
          "giving",
          "gravelly",
          "groups",
          "hand",
          "held",
          "holding",
          "hook",
          "image",
          "jacket",
          "large",
          "length",
          "line",
          "long",
          "man",
          "member",
          "men",
          "moment",
          "motion",
          "near",
          "object",
          "objects",
          "oh",
          "okay",
          "orange",
          "outdoors",
          "over",
          "people",
          "person",
          "perspective",
          "perspectives",
          "pink",
          "pole",
          "positioning",
          "present",
          "ready",
          "red",
          "right",
          "river",
          "rocks",
          "rocky",
          "scene",
          "seconds",
          "several",
          "shore",
          "shot",
          "shots",
          "showing",
          "six",
          "someone",
          "spot",
          "standing",
          "terrain",
          "total",
          "tracking",
          "tracks",
          "various",
          "varten",
          "video",
          "water",
          "wearing",
          "white",
          "wide",
          "yeah",
          "yep",
          "young"
        ],
        "keyword_count": 107,
        "children": [
          "leaf_30",
          "leaf_31"
        ],
        "level": 1,
        "parent": "node_2_7"
      },
      "node_1_16": {
        "node_id": "node_1_16",
        "time_range": [
          160.0,
          170.0
        ],
        "duration": 10.0,
        "keywords": [
          "1k",
          "2k",
          "30",
          "3d",
          "3rd",
          "above",
          "ahead",
          "angle",
          "appears",
          "area",
          "art",
          "barton",
          "boy",
          "brown",
          "bucket",
          "buddy",
          "camera",
          "captured",
          "capturing",
          "char",
          "child",
          "clothing",
          "coat",
          "context",
          "detected",
          "dinner",
          "dolly",
          "down",
          "enjoying",
          "family",
          "featuring",
          "fish",
          "fishing",
          "frame",
          "frames",
          "giving",
          "grab",
          "grainy",
          "gravel",
          "ground",
          "holding",
          "image",
          "isn",
          "jacket",
          "jackets",
          "laying",
          "lens",
          "looking",
          "man",
          "member",
          "model",
          "molding",
          "near",
          "nice",
          "oh",
          "okay",
          "orange",
          "out",
          "outdoors",
          "outside",
          "people",
          "per",
          "person",
          "perspective",
          "pink",
          "playing",
          "pole",
          "positioned",
          "possibly",
          "reaching",
          "red",
          "reeling",
          "resolution",
          "river",
          "rocks",
          "rods",
          "sand",
          "scene",
          "seconds",
          "sense",
          "sensor",
          "shirt",
          "shoulder",
          "showing",
          "snowsuit",
          "something",
          "spot",
          "standing",
          "stream",
          "toddler",
          "video",
          "water",
          "white",
          "wide",
          "wooded",
          "yeah",
          "young"
        ],
        "keyword_count": 97,
        "children": [
          "leaf_32",
          "leaf_33"
        ],
        "level": 1,
        "parent": "node_2_8"
      },
      "node_1_17": {
        "node_id": "node_1_17",
        "time_range": [
          170.0,
          180.0
        ],
        "duration": 10.0,
        "keywords": [
          "360",
          "3rd",
          "action",
          "another",
          "appears",
          "art",
          "artifacts",
          "beach",
          "black",
          "blur",
          "blurred",
          "blurry",
          "body",
          "boy",
          "boys",
          "camera",
          "captured",
          "capturing",
          "cell",
          "clothes",
          "compression",
          "deep",
          "degree",
          "depicting",
          "dolly",
          "edge",
          "emphasize",
          "experience",
          "experiencing",
          "featuring",
          "fish",
          "fisherman",
          "fisheye",
          "fishing",
          "flare",
          "flies",
          "footage",
          "hands",
          "holding",
          "image",
          "immersive",
          "indicating",
          "isn",
          "jumpsuit",
          "knee",
          "lake",
          "lens",
          "location",
          "long",
          "lovely",
          "making",
          "man",
          "men",
          "moment",
          "motion",
          "near",
          "nearby",
          "nice",
          "offering",
          "oh",
          "outdoor",
          "outdoors",
          "outside",
          "person",
          "perspective",
          "phone",
          "playing",
          "point",
          "possibly",
          "present",
          "probably",
          "raincoats",
          "recorded",
          "red",
          "river",
          "rod",
          "rods",
          "scene",
          "seen",
          "sharon",
          "showing",
          "shows",
          "slightly",
          "standing",
          "talking",
          "technical",
          "tom",
          "unsteady",
          "video",
          "view",
          "viewer",
          "watches",
          "water",
          "wearing",
          "weird",
          "within",
          "yeah",
          "young"
        ],
        "keyword_count": 98,
        "children": [
          "leaf_34",
          "leaf_35"
        ],
        "level": 1,
        "parent": "node_2_8"
      },
      "node_1_18": {
        "node_id": "node_1_18",
        "time_range": [
          180.0,
          190.0
        ],
        "duration": 10.0,
        "keywords": [
          "10",
          "365",
          "3rd",
          "action",
          "angle",
          "another",
          "around",
          "back",
          "backpack",
          "bend",
          "between",
          "boat",
          "body",
          "book",
          "camera",
          "capturing",
          "casts",
          "creating",
          "days",
          "definitely",
          "dolly",
          "down",
          "dropped",
          "edge",
          "effect",
          "ey",
          "features",
          "featuring",
          "fish",
          "fishing",
          "floor",
          "further",
          "goes",
          "gopro",
          "green",
          "ground",
          "hand",
          "head",
          "hey",
          "holding",
          "image",
          "lake",
          "lens",
          "line",
          "location",
          "long",
          "lovely",
          "man",
          "men",
          "mind",
          "moment",
          "mounted",
          "near",
          "never",
          "next",
          "object",
          "oh",
          "outdoor",
          "overhead",
          "panoramic",
          "people",
          "person",
          "perspective",
          "picking",
          "positioned",
          "rain",
          "retrieve",
          "river",
          "rocks",
          "scene",
          "sharon",
          "shore",
          "showing",
          "shows",
          "side",
          "single",
          "standing",
          "stands",
          "stream",
          "surface",
          "talking",
          "tom",
          "trees",
          "tripod",
          "video",
          "walking",
          "water",
          "weird",
          "wet",
          "wide"
        ],
        "keyword_count": 90,
        "children": [
          "leaf_36",
          "leaf_37"
        ],
        "level": 1,
        "parent": "node_2_9"
      },
      "node_1_19": {
        "node_id": "node_1_19",
        "time_range": [
          190.0,
          200.0
        ],
        "duration": 10.0,
        "keywords": [
          "2d",
          "365",
          "3rd",
          "action",
          "activities",
          "along",
          "alright",
          "another",
          "appears",
          "appropriate",
          "attire",
          "available",
          "background",
          "backpack",
          "bank",
          "beach",
          "bending",
          "black",
          "blur",
          "boat",
          "book",
          "bottle",
          "camera",
          "captured",
          "capturing",
          "cell",
          "days",
          "definitely",
          "distortion",
          "dressed",
          "edge",
          "ey",
          "featuring",
          "field",
          "fish",
          "fisherman",
          "fisheye",
          "fishing",
          "focused",
          "gonna",
          "gravel",
          "ground",
          "hey",
          "holding",
          "image",
          "interacting",
          "jacket",
          "lake",
          "large",
          "ll",
          "lunch",
          "man",
          "mind",
          "motion",
          "mountain",
          "mounted",
          "near",
          "nearby",
          "never",
          "nice",
          "object",
          "over",
          "pebbly",
          "people",
          "person",
          "perspective",
          "phone",
          "photography",
          "pick",
          "pole",
          "positioned",
          "providing",
          "rain",
          "raincoat",
          "red",
          "resulting",
          "river",
          "rod",
          "scene",
          "seen",
          "shore",
          "shoreline",
          "showing",
          "side",
          "slight",
          "stable",
          "standing",
          "stands",
          "stream",
          "subjects",
          "surroundings",
          "techniques",
          "tips",
          "tommy",
          "tricks",
          "using",
          "video",
          "view",
          "wanna",
          "water",
          "wearing",
          "weather",
          "wide",
          "young",
          "yup"
        ],
        "keyword_count": 105,
        "children": [
          "leaf_38",
          "leaf_39"
        ],
        "level": 1,
        "parent": "node_2_9"
      },
      "node_1_20": {
        "node_id": "node_1_20",
        "time_range": [
          200.0,
          210.0
        ],
        "duration": 10.0,
        "keywords": [
          "10",
          "30",
          "360",
          "4k",
          "action",
          "adventure",
          "alright",
          "angle",
          "angler",
          "appears",
          "area",
          "back",
          "backpack",
          "beside",
          "black",
          "body",
          "boy",
          "camera",
          "captured",
          "captures",
          "close",
          "coat",
          "degree",
          "distance",
          "eating",
          "edge",
          "either",
          "enjoys",
          "essence",
          "fish",
          "fishing",
          "footage",
          "full",
          "gear",
          "gonna",
          "guy",
          "hand",
          "head",
          "hey",
          "hiking",
          "holding",
          "hooded",
          "image",
          "immersive",
          "includes",
          "indicating",
          "individual",
          "jacket",
          "lake",
          "likely",
          "little",
          "looking",
          "lunch",
          "man",
          "mountains",
          "mounted",
          "natural",
          "next",
          "objects",
          "orange",
          "outdoor",
          "people",
          "person",
          "perspective",
          "pole",
          "positioned",
          "possibly",
          "providing",
          "rain",
          "raincoat",
          "raw",
          "red",
          "releasing",
          "river",
          "rocks",
          "rod",
          "scene",
          "seconds",
          "setting",
          "shore",
          "shot",
          "showing",
          "shows",
          "sky",
          "standing",
          "stands",
          "stomachs",
          "suggests",
          "surrounding",
          "taken",
          "time",
          "tommy",
          "toward",
          "trail",
          "trees",
          "various",
          "video",
          "view",
          "visible",
          "walking",
          "wanna",
          "water",
          "wearing",
          "wide",
          "wooded",
          "young",
          "yup"
        ],
        "keyword_count": 107,
        "children": [
          "leaf_40",
          "leaf_41"
        ],
        "level": 1,
        "parent": "node_2_10"
      },
      "node_1_21": {
        "node_id": "node_1_21",
        "time_range": [
          210.0,
          220.0
        ],
        "duration": 10.0,
        "keywords": [
          "01",
          "3d",
          "3rd",
          "4k",
          "across",
          "action",
          "activity",
          "alright",
          "animal",
          "backpack",
          "bait",
          "body",
          "bugs",
          "camera",
          "captured",
          "captures",
          "cast",
          "catching",
          "clearer",
          "close",
          "dead",
          "debris",
          "dirty",
          "done",
          "eating",
          "either",
          "entire",
          "environment",
          "experience",
          "filled",
          "film",
          "fish",
          "fisheye",
          "fishing",
          "flies",
          "focused",
          "full",
          "green",
          "ground",
          "guy",
          "hand",
          "hands",
          "higher",
          "holding",
          "immersive",
          "includes",
          "leaves",
          "lens",
          "line",
          "little",
          "long",
          "man",
          "mosquitoes",
          "mounted",
          "multiple",
          "near",
          "next",
          "object",
          "over",
          "people",
          "person",
          "perspective",
          "positioned",
          "positions",
          "provides",
          "recommended",
          "resolution",
          "retrieve",
          "river",
          "rod",
          "rods",
          "scattered",
          "scene",
          "seems",
          "setup",
          "shot",
          "showing",
          "small",
          "someone",
          "something",
          "sort",
          "standing",
          "stomachs",
          "surrounding",
          "taken",
          "thousands",
          "twigs",
          "using",
          "various",
          "video",
          "viewers",
          "visible",
          "visuals",
          "water",
          "way",
          "within",
          "witness"
        ],
        "keyword_count": 97,
        "children": [
          "leaf_42",
          "leaf_43"
        ],
        "level": 1,
        "parent": "node_2_10"
      },
      "node_1_22": {
        "node_id": "node_1_22",
        "time_range": [
          220.0,
          230.0
        ],
        "duration": 10.0,
        "keywords": [
          "00",
          "19",
          "30",
          "3d",
          "actions",
          "additionally",
          "adventure",
          "aluminum",
          "appears",
          "area",
          "around",
          "atmosphere",
          "background",
          "backpack",
          "backpacks",
          "based",
          "behind",
          "between",
          "bit",
          "black",
          "body",
          "bottle",
          "bottles",
          "boy",
          "camera",
          "camping",
          "campsite",
          "canopy",
          "captured",
          "captures",
          "capturing",
          "chest",
          "child",
          "chocolate",
          "coat",
          "compose",
          "descriptions",
          "detected",
          "done",
          "edit",
          "effect",
          "either",
          "elements",
          "else",
          "experiencing",
          "fisheye",
          "food",
          "foreground",
          "forgot",
          "frame",
          "front",
          "full",
          "gopro",
          "grabbing",
          "gun",
          "happy",
          "hi",
          "holding",
          "hoodie",
          "image",
          "includes",
          "indicating",
          "individuals",
          "jacket",
          "large",
          "like",
          "location",
          "looking",
          "looks",
          "main",
          "makes",
          "making",
          "man",
          "meal",
          "men",
          "moment",
          "mounted",
          "multiple",
          "near",
          "next",
          "object",
          "objects",
          "outdoor",
          "people",
          "person",
          "persons",
          "perspective",
          "placed",
          "point",
          "pointing",
          "positioned",
          "possibly",
          "pot",
          "preparing",
          "re",
          "red",
          "scene",
          "seems",
          "setting",
          "share",
          "showing",
          "shown",
          "shows",
          "single",
          "sitting",
          "smiling",
          "someone",
          "something",
          "standing",
          "suggesting",
          "tent",
          "tents",
          "together",
          "tree",
          "trees",
          "trip",
          "under",
          "video",
          "view",
          "viewer",
          "visible",
          "warm",
          "watching",
          "water",
          "wearing",
          "white",
          "young"
        ],
        "keyword_count": 127,
        "children": [
          "leaf_44",
          "leaf_45"
        ],
        "level": 1,
        "parent": "node_2_11"
      },
      "node_1_23": {
        "node_id": "node_1_23",
        "time_range": [
          230.0,
          240.0
        ],
        "duration": 10.0,
        "keywords": [
          "56",
          "58",
          "67",
          "79",
          "along",
          "angle",
          "animals",
          "another",
          "appears",
          "area",
          "around",
          "attract",
          "baby",
          "background",
          "backpack",
          "backpacks",
          "bears",
          "beer",
          "between",
          "bit",
          "black",
          "blue",
          "blur",
          "boiling",
          "bottle",
          "bottles",
          "camera",
          "camping",
          "campsite",
          "capture",
          "captured",
          "children",
          "chocolate",
          "closer",
          "coat",
          "coffee",
          "color",
          "companions",
          "contain",
          "contains",
          "conversation",
          "couple",
          "cups",
          "depicting",
          "depicts",
          "down",
          "dress",
          "drinking",
          "due",
          "engaging",
          "entire",
          "evidenced",
          "exchange",
          "experience",
          "family",
          "fishing",
          "focus",
          "food",
          "foreground",
          "format",
          "front",
          "full",
          "gentleman",
          "god",
          "green",
          "group",
          "guys",
          "hair",
          "hand",
          "handbag",
          "hands",
          "handshake",
          "hold",
          "holding",
          "hot",
          "image",
          "includes",
          "individuals",
          "inside",
          "items",
          "jacket",
          "kettle",
          "lantern",
          "lap",
          "large",
          "leather",
          "letters",
          "lights",
          "like",
          "likely",
          "looking",
          "main",
          "makes",
          "man",
          "mess",
          "motion",
          "mug",
          "multiple",
          "nearby",
          "notices",
          "object",
          "objects",
          "occurring",
          "oh",
          "older",
          "out",
          "outdoors",
          "people",
          "person",
          "perspective",
          "place",
          "placed",
          "playing",
          "point",
          "possibly",
          "presence",
          "present",
          "primary",
          "providing",
          "re",
          "red",
          "rod",
          "scene",
          "seems",
          "seen",
          "setting",
          "several",
          "shaky",
          "shells",
          "showcasing",
          "sips",
          "sitting",
          "something",
          "sticky",
          "stuff",
          "stuffed",
          "subject",
          "summary",
          "supplies",
          "takes",
          "tent",
          "toys",
          "trip",
          "umbrella",
          "under",
          "various",
          "video",
          "view",
          "visible",
          "warm",
          "water",
          "wearing",
          "wide",
          "within",
          "young"
        ],
        "keyword_count": 155,
        "children": [
          "leaf_46",
          "leaf_47"
        ],
        "level": 1,
        "parent": "node_2_11"
      },
      "node_1_24": {
        "node_id": "node_1_24",
        "time_range": [
          240.0,
          250.0
        ],
        "duration": 10.0,
        "keywords": [
          "54",
          "62",
          "activity",
          "adult",
          "adventure",
          "another",
          "around",
          "artifacts",
          "assortment",
          "attract",
          "backpack",
          "backpacks",
          "bags",
          "ball",
          "bears",
          "blur",
          "body",
          "bottles",
          "bowls",
          "boy",
          "boys",
          "camera",
          "canister",
          "capturing",
          "chairs",
          "child",
          "children",
          "conversation",
          "cooking",
          "cups",
          "details",
          "eating",
          "either",
          "engaging",
          "entire",
          "father",
          "flare",
          "following",
          "food",
          "foreground",
          "frying",
          "garden",
          "god",
          "ground",
          "guys",
          "hair",
          "handing",
          "hands",
          "hat",
          "helmet",
          "hold",
          "holding",
          "hungry",
          "immersive",
          "indicate",
          "inside",
          "involved",
          "items",
          "knots",
          "leisure",
          "lens",
          "little",
          "located",
          "looking",
          "male",
          "man",
          "miscellaneous",
          "moment",
          "motion",
          "mounted",
          "near",
          "next",
          "objects",
          "oh",
          "outdoor",
          "overhead",
          "pan",
          "people",
          "person",
          "placed",
          "please",
          "positioned",
          "pot",
          "pots",
          "preparing",
          "present",
          "pretty",
          "providing",
          "red",
          "right",
          "scene",
          "seated",
          "seen",
          "several",
          "shells",
          "showing",
          "siting",
          "sitting",
          "situation",
          "snacks",
          "something",
          "sons",
          "sports",
          "standing",
          "sticky",
          "stuff",
          "sure",
          "surrounded",
          "survival",
          "technical",
          "tent",
          "tie",
          "time",
          "together",
          "tool",
          "type",
          "upcoming",
          "various",
          "video",
          "view",
          "warm",
          "wearing",
          "yeah",
          "young"
        ],
        "keyword_count": 124,
        "children": [
          "leaf_48",
          "leaf_49"
        ],
        "level": 1,
        "parent": "node_2_12"
      },
      "node_1_25": {
        "node_id": "node_1_25",
        "time_range": [
          250.0,
          260.0
        ],
        "duration": 10.0,
        "keywords": [
          "30",
          "activities",
          "appears",
          "around",
          "bite",
          "blow",
          "blue",
          "bowls",
          "camera",
          "campfire",
          "camping",
          "canvas",
          "captures",
          "children",
          "conditions",
          "cooking",
          "cups",
          "dung",
          "eating",
          "elements",
          "engaged",
          "explaining",
          "family",
          "filming",
          "finished",
          "fishing",
          "flying",
          "food",
          "gathered",
          "group",
          "guys",
          "hand",
          "handing",
          "handling",
          "hold",
          "holding",
          "hungry",
          "image",
          "indicating",
          "inside",
          "interacting",
          "interactions",
          "interesting",
          "kids",
          "kite",
          "lighting",
          "like",
          "lures",
          "man",
          "meal",
          "meals",
          "men",
          "moment",
          "natural",
          "object",
          "objects",
          "oh",
          "others",
          "out",
          "outdoor",
          "outdoors",
          "pan",
          "people",
          "place",
          "playing",
          "please",
          "possibly",
          "preparing",
          "pretty",
          "resting",
          "right",
          "salted",
          "sandwich",
          "scene",
          "seems",
          "setting",
          "showing",
          "shown",
          "sitting",
          "sleeping",
          "smartphone",
          "something",
          "spaghetti",
          "spoons",
          "structure",
          "sure",
          "surroundings",
          "tent",
          "tents",
          "trip",
          "under",
          "using",
          "various",
          "video",
          "visible",
          "white",
          "yeah"
        ],
        "keyword_count": 97,
        "children": [
          "leaf_50",
          "leaf_51"
        ],
        "level": 1,
        "parent": "node_2_12"
      },
      "node_1_26": {
        "node_id": "node_1_26",
        "time_range": [
          260.0,
          270.0
        ],
        "duration": 10.0,
        "keywords": [
          "2015",
          "30",
          "activities",
          "around",
          "backpack",
          "bags",
          "balls",
          "blow",
          "blowing",
          "blue",
          "bottle",
          "bowl",
          "bowls",
          "boy",
          "broth",
          "camera",
          "camping",
          "campsite",
          "candle",
          "captures",
          "capturing",
          "cleaning",
          "container",
          "cooking",
          "cup",
          "cups",
          "dung",
          "enjoying",
          "expedition",
          "family",
          "featuring",
          "finger",
          "fire",
          "fish",
          "fishing",
          "food",
          "footage",
          "front",
          "glasses",
          "ground",
          "hand",
          "handbag",
          "hat",
          "hold",
          "holding",
          "image",
          "includes",
          "indicating",
          "inside",
          "interacts",
          "item",
          "items",
          "lid",
          "like",
          "man",
          "men",
          "military",
          "mounted",
          "multiple",
          "nearby",
          "next",
          "object",
          "objects",
          "oiling",
          "older",
          "out",
          "outdoors",
          "outside",
          "over",
          "people",
          "person",
          "place",
          "pointing",
          "possibly",
          "pouring",
          "present",
          "providing",
          "red",
          "rod",
          "salted",
          "scattered",
          "scene",
          "seconds",
          "seen",
          "showing",
          "shows",
          "sitting",
          "small",
          "something",
          "spoons",
          "sports",
          "stable",
          "standing",
          "tent",
          "tents",
          "time",
          "together",
          "trip",
          "tripod",
          "uniform",
          "various",
          "video",
          "visible",
          "watching",
          "water",
          "way",
          "wearing",
          "yeah"
        ],
        "keyword_count": 108,
        "children": [
          "leaf_52",
          "leaf_53"
        ],
        "level": 1,
        "parent": "node_2_13"
      },
      "node_1_27": {
        "node_id": "node_1_27",
        "time_range": [
          270.0,
          280.0
        ],
        "duration": 10.0,
        "keywords": [
          "360",
          "3d",
          "3rd",
          "above",
          "accurate",
          "additional",
          "adventure",
          "after",
          "along",
          "another",
          "appears",
          "area",
          "around",
          "array",
          "assortment",
          "backpack",
          "backpacking",
          "backpacks",
          "belongings",
          "black",
          "blue",
          "bottles",
          "bowl",
          "bowls",
          "broth",
          "camera",
          "cameras",
          "camping",
          "capturing",
          "cooking",
          "degree",
          "descriptions",
          "detailed",
          "dolly",
          "features",
          "fish",
          "flavored",
          "food",
          "foreground",
          "frisbee",
          "glasses",
          "good",
          "green",
          "hat",
          "helmet",
          "hiking",
          "holding",
          "image",
          "indicating",
          "inside",
          "interesting",
          "items",
          "knife",
          "knives",
          "like",
          "likely",
          "lot",
          "main",
          "man",
          "methods",
          "mounted",
          "multiple",
          "nearby",
          "next",
          "object",
          "objects",
          "oiling",
          "outdoors",
          "overhead",
          "pan",
          "people",
          "person",
          "personal",
          "perspective",
          "place",
          "placed",
          "placing",
          "positioned",
          "pot",
          "pots",
          "present",
          "provide",
          "ramen",
          "ready",
          "red",
          "scene",
          "seen",
          "showing",
          "site",
          "sitting",
          "someone",
          "something",
          "stabilization",
          "takes",
          "tastes",
          "tent",
          "top",
          "tracking",
          "trip",
          "trowel",
          "various",
          "video",
          "view",
          "wearing",
          "well",
          "white",
          "wing",
          "yeah",
          "yellow"
        ],
        "keyword_count": 109,
        "children": [
          "leaf_54",
          "leaf_55"
        ],
        "level": 1,
        "parent": "node_2_13"
      },
      "node_1_28": {
        "node_id": "node_1_28",
        "time_range": [
          280.0,
          290.0
        ],
        "duration": 10.0,
        "keywords": [
          "30",
          "32",
          "360",
          "3d",
          "accurate",
          "adult",
          "angle",
          "appears",
          "around",
          "backpack",
          "backpacks",
          "baseball",
          "blue",
          "bottles",
          "bowl",
          "bowls",
          "boy",
          "camera",
          "camping",
          "cap",
          "captures",
          "capturing",
          "clearly",
          "close",
          "conversation",
          "cooking",
          "daily",
          "degree",
          "discussing",
          "dolly",
          "down",
          "eating",
          "enjoying",
          "entire",
          "father",
          "featuring",
          "flavored",
          "food",
          "footage",
          "frames",
          "front",
          "glasses",
          "good",
          "hat",
          "holding",
          "image",
          "includes",
          "input",
          "inside",
          "interaction",
          "lens",
          "letters",
          "life",
          "like",
          "likely",
          "little",
          "lot",
          "male",
          "man",
          "meal",
          "men",
          "mess",
          "model",
          "multiple",
          "nearby",
          "next",
          "numerous",
          "objects",
          "oh",
          "older",
          "out",
          "outdoor",
          "oven",
          "people",
          "pepper",
          "person",
          "perspective",
          "place",
          "placed",
          "plates",
          "pot",
          "pots",
          "present",
          "process",
          "providing",
          "ramen",
          "ready",
          "representation",
          "salmon",
          "salt",
          "scene",
          "seconds",
          "seen",
          "setting",
          "sharing",
          "sitting",
          "something",
          "son",
          "spoons",
          "takes",
          "talking",
          "tastes",
          "tent",
          "together",
          "tripod",
          "trout",
          "trowel",
          "under",
          "various",
          "video",
          "view",
          "visible",
          "watches",
          "wearing",
          "wide",
          "wing",
          "yeah",
          "young"
        ],
        "keyword_count": 118,
        "children": [
          "leaf_56",
          "leaf_57"
        ],
        "level": 1,
        "parent": "node_2_14"
      },
      "node_1_29": {
        "node_id": "node_1_29",
        "time_range": [
          290.0,
          299.999
        ],
        "duration": 9.999000000000024,
        "keywords": [
          "31",
          "3rd",
          "adding",
          "aged",
          "alright",
          "another",
          "appears",
          "area",
          "around",
          "atmosphere",
          "away",
          "background",
          "backpack",
          "backpacks",
          "bags",
          "behind",
          "between",
          "bivou",
          "blue",
          "body",
          "book",
          "bottle",
          "bottles",
          "bowl",
          "bowls",
          "camera",
          "camper",
          "camping",
          "campsite",
          "capture",
          "casual",
          "cell",
          "center",
          "close",
          "closer",
          "company",
          "cozy",
          "cup",
          "cups",
          "depicts",
          "dishes",
          "dog",
          "down",
          "eating",
          "enjoy",
          "features",
          "featuring",
          "food",
          "foreground",
          "front",
          "further",
          "gear",
          "good",
          "green",
          "ground",
          "groups",
          "haired",
          "hand",
          "handbag",
          "hands",
          "holding",
          "holds",
          "image",
          "indicating",
          "inside",
          "item",
          "items",
          "knife",
          "lap",
          "little",
          "ll",
          "located",
          "looking",
          "man",
          "meal",
          "men",
          "mess",
          "messy",
          "middle",
          "moment",
          "mounted",
          "mouth",
          "multi",
          "near",
          "nearby",
          "next",
          "object",
          "objects",
          "oh",
          "overall",
          "pen",
          "people",
          "pepper",
          "person",
          "perspective",
          "phone",
          "placed",
          "possibly",
          "present",
          "proximity",
          "recorded",
          "relaxed",
          "right",
          "round",
          "salt",
          "sandwiches",
          "scattered",
          "scene",
          "seated",
          "seems",
          "seen",
          "settled",
          "several",
          "shaky",
          "share",
          "shared",
          "shot",
          "showing",
          "shown",
          "side",
          "site",
          "sitting",
          "soldier",
          "someone",
          "something",
          "table",
          "tent",
          "together",
          "tool",
          "unique",
          "various",
          "video",
          "wall",
          "wearing",
          "white",
          "winter",
          "yeah"
        ],
        "keyword_count": 137,
        "children": [
          "leaf_58",
          "leaf_59"
        ],
        "level": 1,
        "parent": "node_2_14"
      },
      "node_2_0": {
        "node_id": "node_2_0",
        "time_range": [
          0.0,
          20.0
        ],
        "duration": 20.0,
        "keywords": [
          "08",
          "30",
          "360",
          "3d",
          "3rd",
          "action",
          "air",
          "airplane",
          "alaska",
          "angle",
          "another",
          "appears",
          "arctic",
          "area",
          "away",
          "axe",
          "back",
          "background",
          "backpack",
          "beautiful",
          "behind",
          "black",
          "blue",
          "boat",
          "boats",
          "boy",
          "boys",
          "bush",
          "cabin",
          "camera",
          "camp",
          "cap",
          "captures",
          "capturing",
          "casting",
          "cause",
          "channel",
          "close",
          "coffee",
          "crafting",
          "cup",
          "days",
          "degree",
          "description",
          "detection",
          "dick",
          "distance",
          "distortion",
          "dolly",
          "dropped",
          "edges",
          "enjoying",
          "environment",
          "excitement",
          "experience",
          "exploring",
          "expression",
          "facial",
          "featuring",
          "fiji",
          "filming",
          "fish",
          "fishing",
          "flight",
          "float",
          "flying",
          "forest",
          "frame",
          "front",
          "frying",
          "further",
          "glasses",
          "going",
          "gonna",
          "gopro",
          "grailing",
          "green",
          "grey",
          "ground",
          "guys",
          "hand",
          "hat",
          "helicopter",
          "hiking",
          "hillside",
          "holding",
          "hole",
          "homestead",
          "hoodie",
          "image",
          "immersive",
          "includes",
          "indicating",
          "inside",
          "kaleidoscope",
          "kite",
          "lake",
          "large",
          "lens",
          "likely",
          "line",
          "log",
          "looking",
          "luke",
          "man",
          "meal",
          "men",
          "mountain",
          "mountainous",
          "mountains",
          "mug",
          "near",
          "nearby",
          "next",
          "object",
          "objects",
          "off",
          "original",
          "out",
          "outdoor",
          "outdoors",
          "outside",
          "over",
          "overhead",
          "pack",
          "pan",
          "people",
          "person",
          "perspective",
          "plane",
          "pointing",
          "positioned",
          "pov",
          "prennicky",
          "providing",
          "rafting",
          "re",
          "relatively",
          "right",
          "river",
          "rocks",
          "saying",
          "scene",
          "seconds",
          "seems",
          "seen",
          "setting",
          "several",
          "shaky",
          "shirt",
          "shore",
          "shot",
          "showing",
          "side",
          "similar",
          "sitting",
          "slightly",
          "small",
          "something",
          "stable",
          "standing",
          "stands",
          "stool",
          "structure",
          "stuck",
          "stump",
          "sunglasses",
          "surrounding",
          "taken",
          "tent",
          "timelapse",
          "together",
          "top",
          "tree",
          "trout",
          "vardin",
          "video",
          "view",
          "water",
          "way",
          "wearing",
          "welcome",
          "wide",
          "within",
          "wooden",
          "writing",
          "young",
          "youtube",
          "youtuber"
        ],
        "keyword_count": 189,
        "children": [
          "node_1_0",
          "node_1_1"
        ],
        "level": 2,
        "parent": "node_3_0"
      },
      "node_2_1": {
        "node_id": "node_2_1",
        "time_range": [
          20.0,
          40.0
        ],
        "duration": 20.0,
        "keywords": [
          "10",
          "12345",
          "27",
          "30",
          "32",
          "35",
          "360",
          "3rd",
          "above",
          "adding",
          "additionally",
          "aerial",
          "aid",
          "aircraft",
          "airplane",
          "along",
          "altitude",
          "another",
          "appears",
          "area",
          "around",
          "back",
          "background",
          "bags",
          "ball",
          "behind",
          "below",
          "beside",
          "birds",
          "black",
          "board",
          "boat",
          "body",
          "bottle",
          "boy",
          "boys",
          "building",
          "bus",
          "bush",
          "buttons",
          "camera",
          "cap",
          "captured",
          "captures",
          "capturing",
          "car",
          "carrying",
          "cars",
          "center",
          "chairs",
          "characteristics",
          "child",
          "closer",
          "cockpit",
          "context",
          "control",
          "controls",
          "crafting",
          "crucial",
          "dashcam",
          "day",
          "degree",
          "detected",
          "driver",
          "drivers",
          "driving",
          "dynamic",
          "edge",
          "elements",
          "engaging",
          "everyday",
          "experience",
          "eye",
          "fair",
          "features",
          "field",
          "filled",
          "flies",
          "flight",
          "flying",
          "footage",
          "frame",
          "front",
          "glasses",
          "gopro",
          "group",
          "head",
          "helicopter",
          "helmet",
          "himself",
          "holding",
          "house",
          "image",
          "information",
          "inside",
          "instruments",
          "interesting",
          "interior",
          "island",
          "landscape",
          "laptop",
          "large",
          "life",
          "likely",
          "located",
          "locations",
          "long",
          "looking",
          "looks",
          "lot",
          "low",
          "machinery",
          "making",
          "man",
          "market",
          "middle",
          "moment",
          "mounted",
          "multiple",
          "navigates",
          "near",
          "next",
          "objects",
          "ocean",
          "operating",
          "original",
          "out",
          "outdoor",
          "outdoors",
          "over",
          "overcast",
          "part",
          "people",
          "person",
          "personal",
          "perspective",
          "photo",
          "piece",
          "pilot",
          "plane",
          "possibly",
          "providing",
          "rainy",
          "red",
          "relatively",
          "repair",
          "respective",
          "right",
          "river",
          "road",
          "says",
          "scene",
          "screen",
          "seat",
          "seated",
          "seats",
          "seconds",
          "seems",
          "seen",
          "serving",
          "several",
          "shoreline",
          "shot",
          "shoulder",
          "showing",
          "shows",
          "side",
          "sits",
          "sitting",
          "situated",
          "small",
          "someone",
          "something",
          "speedometer",
          "stable",
          "stall",
          "stands",
          "steering",
          "stump",
          "suggesting",
          "sunglasses",
          "surfaces",
          "surroundings",
          "switches",
          "talking",
          "top",
          "tracks",
          "tree",
          "trees",
          "trip",
          "tripod",
          "turned",
          "under",
          "unique",
          "using",
          "various",
          "vehicle",
          "video",
          "view",
          "viewers",
          "visible",
          "visual",
          "water",
          "wearing",
          "well",
          "wheel",
          "white",
          "window",
          "wing",
          "within",
          "works",
          "writing",
          "young",
          "youtuber"
        ],
        "keyword_count": 214,
        "children": [
          "node_1_2",
          "node_1_3"
        ],
        "level": 2,
        "parent": "node_3_0"
      },
      "node_2_2": {
        "node_id": "node_2_2",
        "time_range": [
          40.0,
          60.0
        ],
        "duration": 20.0,
        "keywords": [
          "10",
          "15",
          "360",
          "3rd",
          "above",
          "aerial",
          "aircraft",
          "airplane",
          "altitude",
          "amazing",
          "angle",
          "appears",
          "appreciate",
          "area",
          "back",
          "background",
          "beautiful",
          "beauty",
          "before",
          "below",
          "blue",
          "boat",
          "boys",
          "camera",
          "captured",
          "captures",
          "capturing",
          "car",
          "channels",
          "clear",
          "cockpit",
          "communication",
          "connected",
          "controls",
          "corner",
          "countryside",
          "creates",
          "dashboard",
          "degree",
          "description",
          "descriptions",
          "distortion",
          "documentation",
          "driving",
          "due",
          "earth",
          "effect",
          "expansive",
          "experience",
          "features",
          "featuring",
          "filled",
          "filming",
          "fisheye",
          "flying",
          "focus",
          "focused",
          "footage",
          "front",
          "gauges",
          "giving",
          "gopro",
          "green",
          "hat",
          "head",
          "headphones",
          "helicopter",
          "identified",
          "image",
          "immersive",
          "includes",
          "indicates",
          "indicating",
          "inside",
          "jacket",
          "jackets",
          "lake",
          "landscape",
          "lens",
          "long",
          "looking",
          "making",
          "man",
          "marshy",
          "men",
          "moment",
          "mountain",
          "mountainous",
          "mountains",
          "mounted",
          "movement",
          "natural",
          "navigating",
          "noticeable",
          "objects",
          "out",
          "outside",
          "over",
          "passenger",
          "people",
          "person",
          "perspective",
          "pilot",
          "plane",
          "plants",
          "point",
          "possibly",
          "potentially",
          "pov",
          "providing",
          "purposes",
          "radio",
          "range",
          "recreational",
          "red",
          "right",
          "river",
          "rivers",
          "scene",
          "scenery",
          "scenic",
          "seats",
          "seconds",
          "seems",
          "seen",
          "sense",
          "shaky",
          "shot",
          "showcasing",
          "showing",
          "shows",
          "side",
          "sitting",
          "sky",
          "slightly",
          "small",
          "snowy",
          "soars",
          "specific",
          "stable",
          "structures",
          "stunning",
          "suggests",
          "system",
          "taken",
          "top",
          "trees",
          "turbulence",
          "unfolds",
          "unique",
          "upper",
          "using",
          "valley",
          "valleys",
          "vantage",
          "vastness",
          "vehicle",
          "video",
          "view",
          "viewed",
          "viewer",
          "viewers",
          "views",
          "visible",
          "visual",
          "water",
          "wearing",
          "wetlands",
          "white",
          "wide",
          "wider",
          "wildlife",
          "window",
          "wing",
          "wings",
          "within",
          "young"
        ],
        "keyword_count": 177,
        "children": [
          "node_1_4",
          "node_1_5"
        ],
        "level": 2,
        "parent": "node_3_1"
      },
      "node_2_3": {
        "node_id": "node_2_3",
        "time_range": [
          60.0,
          80.0
        ],
        "duration": 20.0,
        "keywords": [
          "10",
          "30",
          "3rd",
          "45",
          "48",
          "7373",
          "activity",
          "admiring",
          "aircraft",
          "airplane",
          "angle",
          "another",
          "appears",
          "area",
          "aviation",
          "background",
          "backpack",
          "beach",
          "behind",
          "beside",
          "bicycles",
          "blue",
          "blurry",
          "boat",
          "body",
          "boy",
          "calm",
          "camera",
          "canister",
          "captures",
          "capturing",
          "center",
          "cloudy",
          "colors",
          "conditions",
          "craft",
          "dark",
          "daughter",
          "day",
          "days",
          "departure",
          "device",
          "disembark",
          "door",
          "dressed",
          "edge",
          "excited",
          "family",
          "father",
          "featuring",
          "fishing",
          "fly",
          "flying",
          "footage",
          "frame",
          "front",
          "girl",
          "glasses",
          "glimpse",
          "going",
          "gravel",
          "grey",
          "guys",
          "hand",
          "hands",
          "hanging",
          "hat",
          "helicopter",
          "holding",
          "hook",
          "hour",
          "image",
          "interesting",
          "jacket",
          "lake",
          "lakes",
          "lapse",
          "large",
          "life",
          "light",
          "likely",
          "located",
          "location",
          "looking",
          "low",
          "man",
          "men",
          "mounted",
          "muted",
          "near",
          "next",
          "number",
          "ocean",
          "orange",
          "ourselves",
          "out",
          "outdoor",
          "outdoors",
          "over",
          "overcast",
          "people",
          "person",
          "persons",
          "perspective",
          "picturesque",
          "placed",
          "plane",
          "pockets",
          "point",
          "pontoon",
          "positioned",
          "possibly",
          "preparing",
          "providing",
          "raft",
          "re",
          "ready",
          "rear",
          "red",
          "right",
          "rod",
          "rope",
          "scene",
          "seaplane",
          "seconds",
          "seems",
          "seen",
          "setting",
          "shore",
          "shoreline",
          "shot",
          "showing",
          "shutter",
          "side",
          "sitting",
          "ski",
          "skies",
          "slow",
          "small",
          "smiling",
          "somewhat",
          "son",
          "speed",
          "stability",
          "standing",
          "stands",
          "style",
          "suggesting",
          "surrounding",
          "taken",
          "tank",
          "time",
          "timelapse",
          "top",
          "travel",
          "trees",
          "tripod",
          "twin",
          "twins",
          "video",
          "view",
          "visible",
          "water",
          "wearing",
          "welcome",
          "well",
          "white",
          "wide",
          "young"
        ],
        "keyword_count": 169,
        "children": [
          "node_1_6",
          "node_1_7"
        ],
        "level": 2,
        "parent": "node_3_1"
      },
      "node_2_4": {
        "node_id": "node_2_4",
        "time_range": [
          80.0,
          100.0
        ],
        "duration": 20.0,
        "keywords": [
          "00",
          "01",
          "03",
          "2nd",
          "31",
          "360",
          "365",
          "3rd",
          "4k",
          "57",
          "59",
          "64",
          "above",
          "across",
          "action",
          "adventure",
          "aged",
          "ago",
          "alaska",
          "alaskan",
          "along",
          "angle",
          "another",
          "appears",
          "area",
          "areas",
          "back",
          "background",
          "backpack",
          "backpacks",
          "bag",
          "beard",
          "beautiful",
          "boat",
          "body",
          "brightest",
          "camera",
          "camping",
          "captured",
          "capturing",
          "carrying",
          "causing",
          "cloudy",
          "coat",
          "day",
          "days",
          "degree",
          "detail",
          "down",
          "drop",
          "edge",
          "enjoying",
          "face",
          "float",
          "fly",
          "footage",
          "forecast",
          "forest",
          "forward",
          "frame",
          "front",
          "glasses",
          "going",
          "gonna",
          "grab",
          "gravel",
          "green",
          "grey",
          "guys",
          "half",
          "hat",
          "hiking",
          "hour",
          "huh",
          "image",
          "immersive",
          "jacket",
          "jackets",
          "km",
          "lake",
          "lakes",
          "landscape",
          "lens",
          "like",
          "long",
          "looking",
          "looks",
          "loss",
          "man",
          "men",
          "middle",
          "mountain",
          "mounted",
          "mouth",
          "much",
          "near",
          "nearby",
          "next",
          "nh",
          "ocean",
          "off",
          "okay",
          "older",
          "orange",
          "ourselves",
          "outdoor",
          "outdoors",
          "overexposed",
          "panoramic",
          "part",
          "patch",
          "path",
          "people",
          "person",
          "perspective",
          "picture",
          "place",
          "plane",
          "positioned",
          "possibly",
          "pov",
          "present",
          "providing",
          "raincoat",
          "raining",
          "re",
          "red",
          "remote",
          "right",
          "river",
          "rocky",
          "room",
          "says",
          "scene",
          "seconds",
          "shelter",
          "shore",
          "shoreline",
          "shot",
          "shoulder",
          "showing",
          "slightly",
          "someone",
          "spot",
          "stable",
          "standing",
          "stands",
          "strapped",
          "stuff",
          "suggesting",
          "sunglasses",
          "surrounding",
          "taken",
          "talking",
          "tents",
          "time",
          "toward",
          "travel",
          "twin",
          "twins",
          "using",
          "video",
          "view",
          "vlog",
          "walking",
          "water",
          "wearing",
          "welcome",
          "wide",
          "wilderness"
        ],
        "keyword_count": 170,
        "children": [
          "node_1_8",
          "node_1_9"
        ],
        "level": 2,
        "parent": "node_3_2"
      },
      "node_2_5": {
        "node_id": "node_2_5",
        "time_range": [
          100.0,
          120.0
        ],
        "duration": 20.0,
        "keywords": [
          "10",
          "30",
          "360",
          "3rd",
          "4k",
          "adult",
          "along",
          "angle",
          "appears",
          "area",
          "areas",
          "arm",
          "back",
          "background",
          "backpack",
          "bear",
          "behind",
          "black",
          "blanket",
          "blankets",
          "blue",
          "brown",
          "bu",
          "camera",
          "camping",
          "canopy",
          "captured",
          "carrying",
          "characteristics",
          "children",
          "clip",
          "coat",
          "coats",
          "contains",
          "context",
          "contribute",
          "details",
          "detections",
          "distortion",
          "drop",
          "elements",
          "family",
          "field",
          "fisherman",
          "fishing",
          "forest",
          "frame",
          "gear",
          "glasses",
          "going",
          "grab",
          "grassy",
          "gravel",
          "grey",
          "guys",
          "hat",
          "helmet",
          "hiking",
          "hood",
          "hugged",
          "huh",
          "image",
          "indicate",
          "inside",
          "jacket",
          "jackets",
          "jeans",
          "jumpsuits",
          "large",
          "lens",
          "like",
          "looking",
          "male",
          "man",
          "men",
          "mounted",
          "multiple",
          "near",
          "next",
          "object",
          "objects",
          "off",
          "orange",
          "outdoors",
          "overall",
          "pants",
          "people",
          "person",
          "perspective",
          "photo",
          "pole",
          "positioning",
          "presence",
          "presented",
          "production",
          "providing",
          "rain",
          "re",
          "red",
          "resolution",
          "right",
          "rightind",
          "riverbank",
          "rocky",
          "scene",
          "seen",
          "setting",
          "sheet",
          "showing",
          "sitting",
          "someone",
          "something",
          "spot",
          "spray",
          "standing",
          "stream",
          "stuff",
          "style",
          "subject",
          "taking",
          "tan",
          "technical",
          "tent",
          "tents",
          "tommy",
          "tree",
          "trees",
          "trip",
          "umbrella",
          "under",
          "understanding",
          "unique",
          "various",
          "video",
          "view",
          "viewer",
          "walking",
          "water",
          "wearing",
          "white",
          "wide",
          "wilderness",
          "within",
          "wooded",
          "woods",
          "working",
          "yes"
        ],
        "keyword_count": 147,
        "children": [
          "node_1_10",
          "node_1_11"
        ],
        "level": 2,
        "parent": "node_3_2"
      },
      "node_2_6": {
        "node_id": "node_2_6",
        "time_range": [
          120.0,
          140.0
        ],
        "duration": 20.0,
        "keywords": [
          "00",
          "01",
          "360",
          "4k",
          "actions",
          "activities",
          "activity",
          "addition",
          "additional",
          "adventure",
          "along",
          "another",
          "appears",
          "area",
          "arm",
          "around",
          "background",
          "backpack",
          "backpacks",
          "bait",
          "beach",
          "bear",
          "behind",
          "beside",
          "between",
          "black",
          "blue",
          "body",
          "bu",
          "camera",
          "cameras",
          "captured",
          "captures",
          "capturing",
          "chest",
          "child",
          "close",
          "colored",
          "container",
          "conversation",
          "covering",
          "daytime",
          "definition",
          "degree",
          "detail",
          "different",
          "distance",
          "down",
          "editing",
          "enjoying",
          "environment",
          "file",
          "filled",
          "fish",
          "fishermen",
          "fishing",
          "fly",
          "following",
          "footage",
          "forest",
          "front",
          "gear",
          "going",
          "grab",
          "gravel",
          "gray",
          "ground",
          "gun",
          "hand",
          "harness",
          "hat",
          "helmet",
          "high",
          "holding",
          "hurry",
          "image",
          "includes",
          "indicating",
          "individual",
          "interest",
          "jacket",
          "kneeling",
          "lake",
          "looks",
          "lot",
          "lure",
          "main",
          "man",
          "mean",
          "men",
          "mountain",
          "mountains",
          "mounted",
          "multiple",
          "near",
          "nearby",
          "nearer",
          "next",
          "nothing",
          "object",
          "objects",
          "observer",
          "observing",
          "ocean",
          "oh",
          "outdoor",
          "outdoors",
          "part",
          "pebble",
          "people",
          "person",
          "perspective",
          "pieces",
          "placed",
          "point",
          "possibly",
          "present",
          "purposes",
          "raincoat",
          "range",
          "raw",
          "re",
          "red",
          "road",
          "rock",
          "rocks",
          "rod",
          "rods",
          "scattered",
          "scene",
          "scenes",
          "seen",
          "several",
          "showing",
          "simply",
          "sitting",
          "sky",
          "snowsuit",
          "someone",
          "sports",
          "spray",
          "standing",
          "stands",
          "stream",
          "subjects",
          "suggesting",
          "suggests",
          "suit",
          "supplies",
          "surrounding",
          "taken",
          "tent",
          "tommy",
          "toob",
          "ultra",
          "using",
          "various",
          "video",
          "videos",
          "view",
          "visible",
          "waders",
          "walking",
          "wall",
          "water",
          "wearing",
          "within",
          "woman",
          "wow",
          "yeah",
          "yee",
          "yeee",
          "yes"
        ],
        "keyword_count": 173,
        "children": [
          "node_1_12",
          "node_1_13"
        ],
        "level": 2,
        "parent": "node_3_3"
      },
      "node_2_7": {
        "node_id": "node_2_7",
        "time_range": [
          140.0,
          160.0
        ],
        "duration": 20.0,
        "keywords": [
          "20",
          "34",
          "360",
          "3d",
          "48",
          "action",
          "allowing",
          "allows",
          "along",
          "angle",
          "angles",
          "another",
          "area",
          "around",
          "attached",
          "background",
          "backpack",
          "barton",
          "beach",
          "behavior",
          "behind",
          "bent",
          "bird",
          "black",
          "blancher",
          "body",
          "bonk",
          "bottle",
          "boy",
          "broader",
          "bump",
          "camera",
          "captured",
          "capturing",
          "char",
          "chart",
          "child",
          "closely",
          "clothing",
          "daily",
          "degree",
          "deli",
          "depicting",
          "description",
          "detected",
          "different",
          "dinner",
          "distinct",
          "distortion",
          "documentation",
          "dog",
          "dollar",
          "dolly",
          "environment",
          "etc",
          "excitement",
          "family",
          "features",
          "featuring",
          "fish",
          "fishing",
          "fly",
          "focal",
          "focus",
          "focusing",
          "footage",
          "frames",
          "giving",
          "gravelly",
          "green",
          "ground",
          "groups",
          "hand",
          "hat",
          "held",
          "helmet",
          "holding",
          "hook",
          "hurry",
          "image",
          "immersive",
          "indicates",
          "jacket",
          "large",
          "length",
          "lens",
          "life",
          "line",
          "long",
          "man",
          "member",
          "men",
          "moment",
          "motion",
          "mounted",
          "movements",
          "near",
          "next",
          "object",
          "objects",
          "observe",
          "oh",
          "okay",
          "orange",
          "out",
          "outdoor",
          "outdoors",
          "outfit",
          "over",
          "people",
          "person",
          "perspective",
          "perspectives",
          "pink",
          "pole",
          "positioned",
          "positioning",
          "present",
          "rain",
          "ready",
          "red",
          "right",
          "river",
          "riverbank",
          "road",
          "rocks",
          "rocky",
          "rod",
          "rods",
          "scene",
          "seconds",
          "several",
          "shore",
          "shot",
          "shots",
          "showcases",
          "showing",
          "six",
          "small",
          "someone",
          "spot",
          "stable",
          "standing",
          "stream",
          "style",
          "suggests",
          "suit",
          "surroundings",
          "taken",
          "terrain",
          "total",
          "tracking",
          "tracks",
          "various",
          "varten",
          "video",
          "viewers",
          "visible",
          "vlog",
          "waders",
          "walking",
          "walks",
          "wall",
          "water",
          "way",
          "wearing",
          "white",
          "wide",
          "within",
          "yeah",
          "yep",
          "yes",
          "young"
        ],
        "keyword_count": 173,
        "children": [
          "node_1_14",
          "node_1_15"
        ],
        "level": 2,
        "parent": "node_3_3"
      },
      "node_2_8": {
        "node_id": "node_2_8",
        "time_range": [
          160.0,
          180.0
        ],
        "duration": 20.0,
        "keywords": [
          "1k",
          "2k",
          "30",
          "360",
          "3d",
          "3rd",
          "above",
          "action",
          "ahead",
          "angle",
          "another",
          "appears",
          "area",
          "art",
          "artifacts",
          "barton",
          "beach",
          "black",
          "blur",
          "blurred",
          "blurry",
          "body",
          "boy",
          "boys",
          "brown",
          "bucket",
          "buddy",
          "camera",
          "captured",
          "capturing",
          "cell",
          "char",
          "child",
          "clothes",
          "clothing",
          "coat",
          "compression",
          "context",
          "deep",
          "degree",
          "depicting",
          "detected",
          "dinner",
          "dolly",
          "down",
          "edge",
          "emphasize",
          "enjoying",
          "experience",
          "experiencing",
          "family",
          "featuring",
          "fish",
          "fisherman",
          "fisheye",
          "fishing",
          "flare",
          "flies",
          "footage",
          "frame",
          "frames",
          "giving",
          "grab",
          "grainy",
          "gravel",
          "ground",
          "hands",
          "holding",
          "image",
          "immersive",
          "indicating",
          "isn",
          "jacket",
          "jackets",
          "jumpsuit",
          "knee",
          "lake",
          "laying",
          "lens",
          "location",
          "long",
          "looking",
          "lovely",
          "making",
          "man",
          "member",
          "men",
          "model",
          "molding",
          "moment",
          "motion",
          "near",
          "nearby",
          "nice",
          "offering",
          "oh",
          "okay",
          "orange",
          "out",
          "outdoor",
          "outdoors",
          "outside",
          "people",
          "per",
          "person",
          "perspective",
          "phone",
          "pink",
          "playing",
          "point",
          "pole",
          "positioned",
          "possibly",
          "present",
          "probably",
          "raincoats",
          "reaching",
          "recorded",
          "red",
          "reeling",
          "resolution",
          "river",
          "rocks",
          "rod",
          "rods",
          "sand",
          "scene",
          "seconds",
          "seen",
          "sense",
          "sensor",
          "sharon",
          "shirt",
          "shoulder",
          "showing",
          "shows",
          "slightly",
          "snowsuit",
          "something",
          "spot",
          "standing",
          "stream",
          "talking",
          "technical",
          "toddler",
          "tom",
          "unsteady",
          "video",
          "view",
          "viewer",
          "watches",
          "water",
          "wearing",
          "weird",
          "white",
          "wide",
          "within",
          "wooded",
          "yeah",
          "young"
        ],
        "keyword_count": 160,
        "children": [
          "node_1_16",
          "node_1_17"
        ],
        "level": 2,
        "parent": "node_3_4"
      },
      "node_2_9": {
        "node_id": "node_2_9",
        "time_range": [
          180.0,
          200.0
        ],
        "duration": 20.0,
        "keywords": [
          "10",
          "2d",
          "365",
          "3rd",
          "action",
          "activities",
          "along",
          "alright",
          "angle",
          "another",
          "appears",
          "appropriate",
          "around",
          "attire",
          "available",
          "back",
          "background",
          "backpack",
          "bank",
          "beach",
          "bend",
          "bending",
          "between",
          "black",
          "blur",
          "boat",
          "body",
          "book",
          "bottle",
          "camera",
          "captured",
          "capturing",
          "casts",
          "cell",
          "creating",
          "days",
          "definitely",
          "distortion",
          "dolly",
          "down",
          "dressed",
          "dropped",
          "edge",
          "effect",
          "ey",
          "features",
          "featuring",
          "field",
          "fish",
          "fisherman",
          "fisheye",
          "fishing",
          "floor",
          "focused",
          "further",
          "goes",
          "gonna",
          "gopro",
          "gravel",
          "green",
          "ground",
          "hand",
          "head",
          "hey",
          "holding",
          "image",
          "interacting",
          "jacket",
          "lake",
          "large",
          "lens",
          "line",
          "ll",
          "location",
          "long",
          "lovely",
          "lunch",
          "man",
          "men",
          "mind",
          "moment",
          "motion",
          "mountain",
          "mounted",
          "near",
          "nearby",
          "never",
          "next",
          "nice",
          "object",
          "oh",
          "outdoor",
          "over",
          "overhead",
          "panoramic",
          "pebbly",
          "people",
          "person",
          "perspective",
          "phone",
          "photography",
          "pick",
          "picking",
          "pole",
          "positioned",
          "providing",
          "rain",
          "raincoat",
          "red",
          "resulting",
          "retrieve",
          "river",
          "rocks",
          "rod",
          "scene",
          "seen",
          "sharon",
          "shore",
          "shoreline",
          "showing",
          "shows",
          "side",
          "single",
          "slight",
          "stable",
          "standing",
          "stands",
          "stream",
          "subjects",
          "surface",
          "surroundings",
          "talking",
          "techniques",
          "tips",
          "tom",
          "tommy",
          "trees",
          "tricks",
          "tripod",
          "using",
          "video",
          "view",
          "walking",
          "wanna",
          "water",
          "wearing",
          "weather",
          "weird",
          "wet",
          "wide",
          "young",
          "yup"
        ],
        "keyword_count": 152,
        "children": [
          "node_1_18",
          "node_1_19"
        ],
        "level": 2,
        "parent": "node_3_4"
      },
      "node_2_10": {
        "node_id": "node_2_10",
        "time_range": [
          200.0,
          220.0
        ],
        "duration": 20.0,
        "keywords": [
          "01",
          "10",
          "30",
          "360",
          "3d",
          "3rd",
          "4k",
          "across",
          "action",
          "activity",
          "adventure",
          "alright",
          "angle",
          "angler",
          "animal",
          "appears",
          "area",
          "back",
          "backpack",
          "bait",
          "beside",
          "black",
          "body",
          "boy",
          "bugs",
          "camera",
          "captured",
          "captures",
          "cast",
          "catching",
          "clearer",
          "close",
          "coat",
          "dead",
          "debris",
          "degree",
          "dirty",
          "distance",
          "done",
          "eating",
          "edge",
          "either",
          "enjoys",
          "entire",
          "environment",
          "essence",
          "experience",
          "filled",
          "film",
          "fish",
          "fisheye",
          "fishing",
          "flies",
          "focused",
          "footage",
          "full",
          "gear",
          "gonna",
          "green",
          "ground",
          "guy",
          "hand",
          "hands",
          "head",
          "hey",
          "higher",
          "hiking",
          "holding",
          "hooded",
          "image",
          "immersive",
          "includes",
          "indicating",
          "individual",
          "jacket",
          "lake",
          "leaves",
          "lens",
          "likely",
          "line",
          "little",
          "long",
          "looking",
          "lunch",
          "man",
          "mosquitoes",
          "mountains",
          "mounted",
          "multiple",
          "natural",
          "near",
          "next",
          "object",
          "objects",
          "orange",
          "outdoor",
          "over",
          "people",
          "person",
          "perspective",
          "pole",
          "positioned",
          "positions",
          "possibly",
          "provides",
          "providing",
          "rain",
          "raincoat",
          "raw",
          "recommended",
          "red",
          "releasing",
          "resolution",
          "retrieve",
          "river",
          "rocks",
          "rod",
          "rods",
          "scattered",
          "scene",
          "seconds",
          "seems",
          "setting",
          "setup",
          "shore",
          "shot",
          "showing",
          "shows",
          "sky",
          "small",
          "someone",
          "something",
          "sort",
          "standing",
          "stands",
          "stomachs",
          "suggests",
          "surrounding",
          "taken",
          "thousands",
          "time",
          "tommy",
          "toward",
          "trail",
          "trees",
          "twigs",
          "using",
          "various",
          "video",
          "view",
          "viewers",
          "visible",
          "visuals",
          "walking",
          "wanna",
          "water",
          "way",
          "wearing",
          "wide",
          "within",
          "witness",
          "wooded",
          "young",
          "yup"
        ],
        "keyword_count": 164,
        "children": [
          "node_1_20",
          "node_1_21"
        ],
        "level": 2,
        "parent": "node_3_5"
      },
      "node_2_11": {
        "node_id": "node_2_11",
        "time_range": [
          220.0,
          240.0
        ],
        "duration": 20.0,
        "keywords": [
          "00",
          "19",
          "30",
          "3d",
          "56",
          "58",
          "67",
          "79",
          "actions",
          "additionally",
          "adventure",
          "along",
          "aluminum",
          "angle",
          "animals",
          "another",
          "appears",
          "area",
          "around",
          "atmosphere",
          "attract",
          "baby",
          "background",
          "backpack",
          "backpacks",
          "based",
          "bears",
          "beer",
          "behind",
          "between",
          "bit",
          "black",
          "blue",
          "blur",
          "body",
          "boiling",
          "bottle",
          "bottles",
          "boy",
          "camera",
          "camping",
          "campsite",
          "canopy",
          "capture",
          "captured",
          "captures",
          "capturing",
          "chest",
          "child",
          "children",
          "chocolate",
          "closer",
          "coat",
          "coffee",
          "color",
          "companions",
          "compose",
          "contain",
          "contains",
          "conversation",
          "couple",
          "cups",
          "depicting",
          "depicts",
          "descriptions",
          "detected",
          "done",
          "down",
          "dress",
          "drinking",
          "due",
          "edit",
          "effect",
          "either",
          "elements",
          "else",
          "engaging",
          "entire",
          "evidenced",
          "exchange",
          "experience",
          "experiencing",
          "family",
          "fisheye",
          "fishing",
          "focus",
          "food",
          "foreground",
          "forgot",
          "format",
          "frame",
          "front",
          "full",
          "gentleman",
          "god",
          "gopro",
          "grabbing",
          "green",
          "group",
          "gun",
          "guys",
          "hair",
          "hand",
          "handbag",
          "hands",
          "handshake",
          "happy",
          "hi",
          "hold",
          "holding",
          "hoodie",
          "hot",
          "image",
          "includes",
          "indicating",
          "individuals",
          "inside",
          "items",
          "jacket",
          "kettle",
          "lantern",
          "lap",
          "large",
          "leather",
          "letters",
          "lights",
          "like",
          "likely",
          "location",
          "looking",
          "looks",
          "main",
          "makes",
          "making",
          "man",
          "meal",
          "men",
          "mess",
          "moment",
          "motion",
          "mounted",
          "mug",
          "multiple",
          "near",
          "nearby",
          "next",
          "notices",
          "object",
          "objects",
          "occurring",
          "oh",
          "older",
          "out",
          "outdoor",
          "outdoors",
          "people",
          "person",
          "persons",
          "perspective",
          "place",
          "placed",
          "playing",
          "point",
          "pointing",
          "positioned",
          "possibly",
          "pot",
          "preparing",
          "presence",
          "present",
          "primary",
          "providing",
          "re",
          "red",
          "rod",
          "scene",
          "seems",
          "seen",
          "setting",
          "several",
          "shaky",
          "share",
          "shells",
          "showcasing",
          "showing",
          "shown",
          "shows",
          "single",
          "sips",
          "sitting",
          "smiling",
          "someone",
          "something",
          "standing",
          "sticky",
          "stuff",
          "stuffed",
          "subject",
          "suggesting",
          "summary",
          "supplies",
          "takes",
          "tent",
          "tents",
          "together",
          "toys",
          "tree",
          "trees",
          "trip",
          "umbrella",
          "under",
          "various",
          "video",
          "view",
          "viewer",
          "visible",
          "warm",
          "watching",
          "water",
          "wearing",
          "white",
          "wide",
          "within",
          "young"
        ],
        "keyword_count": 224,
        "children": [
          "node_1_22",
          "node_1_23"
        ],
        "level": 2,
        "parent": "node_3_5"
      },
      "node_2_12": {
        "node_id": "node_2_12",
        "time_range": [
          240.0,
          260.0
        ],
        "duration": 20.0,
        "keywords": [
          "30",
          "54",
          "62",
          "activities",
          "activity",
          "adult",
          "adventure",
          "another",
          "appears",
          "around",
          "artifacts",
          "assortment",
          "attract",
          "backpack",
          "backpacks",
          "bags",
          "ball",
          "bears",
          "bite",
          "blow",
          "blue",
          "blur",
          "body",
          "bottles",
          "bowls",
          "boy",
          "boys",
          "camera",
          "campfire",
          "camping",
          "canister",
          "canvas",
          "captures",
          "capturing",
          "chairs",
          "child",
          "children",
          "conditions",
          "conversation",
          "cooking",
          "cups",
          "details",
          "dung",
          "eating",
          "either",
          "elements",
          "engaged",
          "engaging",
          "entire",
          "explaining",
          "family",
          "father",
          "filming",
          "finished",
          "fishing",
          "flare",
          "flying",
          "following",
          "food",
          "foreground",
          "frying",
          "garden",
          "gathered",
          "god",
          "ground",
          "group",
          "guys",
          "hair",
          "hand",
          "handing",
          "handling",
          "hands",
          "hat",
          "helmet",
          "hold",
          "holding",
          "hungry",
          "image",
          "immersive",
          "indicate",
          "indicating",
          "inside",
          "interacting",
          "interactions",
          "interesting",
          "involved",
          "items",
          "kids",
          "kite",
          "knots",
          "leisure",
          "lens",
          "lighting",
          "like",
          "little",
          "located",
          "looking",
          "lures",
          "male",
          "man",
          "meal",
          "meals",
          "men",
          "miscellaneous",
          "moment",
          "motion",
          "mounted",
          "natural",
          "near",
          "next",
          "object",
          "objects",
          "oh",
          "others",
          "out",
          "outdoor",
          "outdoors",
          "overhead",
          "pan",
          "people",
          "person",
          "place",
          "placed",
          "playing",
          "please",
          "positioned",
          "possibly",
          "pot",
          "pots",
          "preparing",
          "present",
          "pretty",
          "providing",
          "red",
          "resting",
          "right",
          "salted",
          "sandwich",
          "scene",
          "seated",
          "seems",
          "seen",
          "setting",
          "several",
          "shells",
          "showing",
          "shown",
          "siting",
          "sitting",
          "situation",
          "sleeping",
          "smartphone",
          "snacks",
          "something",
          "sons",
          "spaghetti",
          "spoons",
          "sports",
          "standing",
          "sticky",
          "structure",
          "stuff",
          "sure",
          "surrounded",
          "surroundings",
          "survival",
          "technical",
          "tent",
          "tents",
          "tie",
          "time",
          "together",
          "tool",
          "trip",
          "type",
          "under",
          "upcoming",
          "using",
          "various",
          "video",
          "view",
          "visible",
          "warm",
          "wearing",
          "white",
          "yeah",
          "young"
        ],
        "keyword_count": 187,
        "children": [
          "node_1_24",
          "node_1_25"
        ],
        "level": 2,
        "parent": "node_3_6"
      },
      "node_2_13": {
        "node_id": "node_2_13",
        "time_range": [
          260.0,
          280.0
        ],
        "duration": 20.0,
        "keywords": [
          "2015",
          "30",
          "360",
          "3d",
          "3rd",
          "above",
          "accurate",
          "activities",
          "additional",
          "adventure",
          "after",
          "along",
          "another",
          "appears",
          "area",
          "around",
          "array",
          "assortment",
          "backpack",
          "backpacking",
          "backpacks",
          "bags",
          "balls",
          "belongings",
          "black",
          "blow",
          "blowing",
          "blue",
          "bottle",
          "bottles",
          "bowl",
          "bowls",
          "boy",
          "broth",
          "camera",
          "cameras",
          "camping",
          "campsite",
          "candle",
          "captures",
          "capturing",
          "cleaning",
          "container",
          "cooking",
          "cup",
          "cups",
          "degree",
          "descriptions",
          "detailed",
          "dolly",
          "dung",
          "enjoying",
          "expedition",
          "family",
          "features",
          "featuring",
          "finger",
          "fire",
          "fish",
          "fishing",
          "flavored",
          "food",
          "footage",
          "foreground",
          "frisbee",
          "front",
          "glasses",
          "good",
          "green",
          "ground",
          "hand",
          "handbag",
          "hat",
          "helmet",
          "hiking",
          "hold",
          "holding",
          "image",
          "includes",
          "indicating",
          "inside",
          "interacts",
          "interesting",
          "item",
          "items",
          "knife",
          "knives",
          "lid",
          "like",
          "likely",
          "lot",
          "main",
          "man",
          "men",
          "methods",
          "military",
          "mounted",
          "multiple",
          "nearby",
          "next",
          "object",
          "objects",
          "oiling",
          "older",
          "out",
          "outdoors",
          "outside",
          "over",
          "overhead",
          "pan",
          "people",
          "person",
          "personal",
          "perspective",
          "place",
          "placed",
          "placing",
          "pointing",
          "positioned",
          "possibly",
          "pot",
          "pots",
          "pouring",
          "present",
          "provide",
          "providing",
          "ramen",
          "ready",
          "red",
          "rod",
          "salted",
          "scattered",
          "scene",
          "seconds",
          "seen",
          "showing",
          "shows",
          "site",
          "sitting",
          "small",
          "someone",
          "something",
          "spoons",
          "sports",
          "stabilization",
          "stable",
          "standing",
          "takes",
          "tastes",
          "tent",
          "tents",
          "time",
          "together",
          "top",
          "tracking",
          "trip",
          "tripod",
          "trowel",
          "uniform",
          "various",
          "video",
          "view",
          "visible",
          "watching",
          "water",
          "way",
          "wearing",
          "well",
          "white",
          "wing",
          "yeah",
          "yellow"
        ],
        "keyword_count": 172,
        "children": [
          "node_1_26",
          "node_1_27"
        ],
        "level": 2,
        "parent": "node_3_6"
      },
      "node_2_14": {
        "node_id": "node_2_14",
        "time_range": [
          280.0,
          299.999
        ],
        "duration": 19.999000000000024,
        "keywords": [
          "30",
          "31",
          "32",
          "360",
          "3d",
          "3rd",
          "accurate",
          "adding",
          "adult",
          "aged",
          "alright",
          "angle",
          "another",
          "appears",
          "area",
          "around",
          "atmosphere",
          "away",
          "background",
          "backpack",
          "backpacks",
          "bags",
          "baseball",
          "behind",
          "between",
          "bivou",
          "blue",
          "body",
          "book",
          "bottle",
          "bottles",
          "bowl",
          "bowls",
          "boy",
          "camera",
          "camper",
          "camping",
          "campsite",
          "cap",
          "capture",
          "captures",
          "capturing",
          "casual",
          "cell",
          "center",
          "clearly",
          "close",
          "closer",
          "company",
          "conversation",
          "cooking",
          "cozy",
          "cup",
          "cups",
          "daily",
          "degree",
          "depicts",
          "discussing",
          "dishes",
          "dog",
          "dolly",
          "down",
          "eating",
          "enjoy",
          "enjoying",
          "entire",
          "father",
          "features",
          "featuring",
          "flavored",
          "food",
          "footage",
          "foreground",
          "frames",
          "front",
          "further",
          "gear",
          "glasses",
          "good",
          "green",
          "ground",
          "groups",
          "haired",
          "hand",
          "handbag",
          "hands",
          "hat",
          "holding",
          "holds",
          "image",
          "includes",
          "indicating",
          "input",
          "inside",
          "interaction",
          "item",
          "items",
          "knife",
          "lap",
          "lens",
          "letters",
          "life",
          "like",
          "likely",
          "little",
          "ll",
          "located",
          "looking",
          "lot",
          "male",
          "man",
          "meal",
          "men",
          "mess",
          "messy",
          "middle",
          "model",
          "moment",
          "mounted",
          "mouth",
          "multi",
          "multiple",
          "near",
          "nearby",
          "next",
          "numerous",
          "object",
          "objects",
          "oh",
          "older",
          "out",
          "outdoor",
          "oven",
          "overall",
          "pen",
          "people",
          "pepper",
          "person",
          "perspective",
          "phone",
          "place",
          "placed",
          "plates",
          "possibly",
          "pot",
          "pots",
          "present",
          "process",
          "providing",
          "proximity",
          "ramen",
          "ready",
          "recorded",
          "relaxed",
          "representation",
          "right",
          "round",
          "salmon",
          "salt",
          "sandwiches",
          "scattered",
          "scene",
          "seated",
          "seconds",
          "seems",
          "seen",
          "setting",
          "settled",
          "several",
          "shaky",
          "share",
          "shared",
          "sharing",
          "shot",
          "showing",
          "shown",
          "side",
          "site",
          "sitting",
          "soldier",
          "someone",
          "something",
          "son",
          "spoons",
          "table",
          "takes",
          "talking",
          "tastes",
          "tent",
          "together",
          "tool",
          "tripod",
          "trout",
          "trowel",
          "under",
          "unique",
          "various",
          "video",
          "view",
          "visible",
          "wall",
          "watches",
          "wearing",
          "white",
          "wide",
          "wing",
          "winter",
          "yeah",
          "young"
        ],
        "keyword_count": 209,
        "children": [
          "node_1_28",
          "node_1_29"
        ],
        "level": 2,
        "parent": "node_3_7"
      },
      "node_3_0": {
        "node_id": "node_3_0",
        "time_range": [
          0.0,
          40.0
        ],
        "duration": 40.0,
        "keywords": [
          "08",
          "10",
          "12345",
          "27",
          "30",
          "32",
          "35",
          "360",
          "3d",
          "3rd",
          "above",
          "action",
          "adding",
          "additionally",
          "aerial",
          "aid",
          "air",
          "aircraft",
          "airplane",
          "alaska",
          "along",
          "altitude",
          "angle",
          "another",
          "appears",
          "arctic",
          "area",
          "around",
          "away",
          "axe",
          "back",
          "background",
          "backpack",
          "bags",
          "ball",
          "beautiful",
          "behind",
          "below",
          "beside",
          "birds",
          "black",
          "blue",
          "board",
          "boat",
          "boats",
          "body",
          "bottle",
          "boy",
          "boys",
          "building",
          "bus",
          "bush",
          "buttons",
          "cabin",
          "camera",
          "camp",
          "cap",
          "captured",
          "captures",
          "capturing",
          "car",
          "carrying",
          "cars",
          "casting",
          "cause",
          "center",
          "chairs",
          "channel",
          "characteristics",
          "child",
          "close",
          "closer",
          "cockpit",
          "coffee",
          "context",
          "control",
          "controls",
          "crafting",
          "crucial",
          "cup",
          "dashcam",
          "day",
          "days",
          "degree",
          "description",
          "detected",
          "detection",
          "dick",
          "distance",
          "distortion",
          "dolly",
          "driver",
          "drivers",
          "driving",
          "dropped",
          "dynamic",
          "edge",
          "edges",
          "elements",
          "engaging",
          "enjoying",
          "environment",
          "everyday",
          "excitement",
          "experience",
          "exploring",
          "expression",
          "eye",
          "facial",
          "fair",
          "features",
          "featuring",
          "field",
          "fiji",
          "filled",
          "filming",
          "fish",
          "fishing",
          "flies",
          "flight",
          "float",
          "flying",
          "footage",
          "forest",
          "frame",
          "front",
          "frying",
          "further",
          "glasses",
          "going",
          "gonna",
          "gopro",
          "grailing",
          "green",
          "grey",
          "ground",
          "group",
          "guys",
          "hand",
          "hat",
          "head",
          "helicopter",
          "helmet",
          "hiking",
          "hillside",
          "himself",
          "holding",
          "hole",
          "homestead",
          "hoodie",
          "house",
          "image",
          "immersive",
          "includes",
          "indicating",
          "information",
          "inside",
          "instruments",
          "interesting",
          "interior",
          "island",
          "kaleidoscope",
          "kite",
          "lake",
          "landscape",
          "laptop",
          "large",
          "lens",
          "life",
          "likely",
          "line",
          "located",
          "locations",
          "log",
          "long",
          "looking",
          "looks",
          "lot",
          "low",
          "luke",
          "machinery",
          "making",
          "man",
          "market",
          "meal",
          "men",
          "middle",
          "moment",
          "mountain",
          "mountainous",
          "mountains",
          "mounted",
          "mug",
          "multiple",
          "navigates",
          "near",
          "nearby",
          "next",
          "object",
          "objects",
          "ocean",
          "off",
          "operating",
          "original",
          "out",
          "outdoor",
          "outdoors",
          "outside",
          "over",
          "overcast",
          "overhead",
          "pack",
          "pan",
          "part",
          "people",
          "person",
          "personal",
          "perspective",
          "photo",
          "piece",
          "pilot",
          "plane",
          "pointing",
          "positioned",
          "possibly",
          "pov",
          "prennicky",
          "providing",
          "rafting",
          "rainy",
          "re",
          "red",
          "relatively",
          "repair",
          "respective",
          "right",
          "river",
          "road",
          "rocks",
          "saying",
          "says",
          "scene",
          "screen",
          "seat",
          "seated",
          "seats",
          "seconds",
          "seems",
          "seen",
          "serving",
          "setting",
          "several",
          "shaky",
          "shirt",
          "shore",
          "shoreline",
          "shot",
          "shoulder",
          "showing",
          "shows",
          "side",
          "similar",
          "sits",
          "sitting",
          "situated",
          "slightly",
          "small",
          "someone",
          "something",
          "speedometer",
          "stable",
          "stall",
          "standing",
          "stands",
          "steering",
          "stool",
          "structure",
          "stuck",
          "stump",
          "suggesting",
          "sunglasses",
          "surfaces",
          "surrounding",
          "surroundings",
          "switches",
          "taken",
          "talking",
          "tent",
          "timelapse",
          "together",
          "top",
          "tracks",
          "tree",
          "trees",
          "trip",
          "tripod",
          "trout",
          "turned",
          "under",
          "unique",
          "using",
          "vardin",
          "various",
          "vehicle",
          "video",
          "view",
          "viewers",
          "visible",
          "visual",
          "water",
          "way",
          "wearing",
          "welcome",
          "well",
          "wheel",
          "white",
          "wide",
          "window",
          "wing",
          "within",
          "wooden",
          "works",
          "writing",
          "young",
          "youtube",
          "youtuber"
        ],
        "keyword_count": 326,
        "children": [
          "node_2_0",
          "node_2_1"
        ],
        "level": 3,
        "parent": "node_4_0"
      },
      "node_3_1": {
        "node_id": "node_3_1",
        "time_range": [
          40.0,
          80.0
        ],
        "duration": 40.0,
        "keywords": [
          "10",
          "15",
          "30",
          "360",
          "3rd",
          "45",
          "48",
          "7373",
          "above",
          "activity",
          "admiring",
          "aerial",
          "aircraft",
          "airplane",
          "altitude",
          "amazing",
          "angle",
          "another",
          "appears",
          "appreciate",
          "area",
          "aviation",
          "back",
          "background",
          "backpack",
          "beach",
          "beautiful",
          "beauty",
          "before",
          "behind",
          "below",
          "beside",
          "bicycles",
          "blue",
          "blurry",
          "boat",
          "body",
          "boy",
          "boys",
          "calm",
          "camera",
          "canister",
          "captured",
          "captures",
          "capturing",
          "car",
          "center",
          "channels",
          "clear",
          "cloudy",
          "cockpit",
          "colors",
          "communication",
          "conditions",
          "connected",
          "controls",
          "corner",
          "countryside",
          "craft",
          "creates",
          "dark",
          "dashboard",
          "daughter",
          "day",
          "days",
          "degree",
          "departure",
          "description",
          "descriptions",
          "device",
          "disembark",
          "distortion",
          "documentation",
          "door",
          "dressed",
          "driving",
          "due",
          "earth",
          "edge",
          "effect",
          "excited",
          "expansive",
          "experience",
          "family",
          "father",
          "features",
          "featuring",
          "filled",
          "filming",
          "fisheye",
          "fishing",
          "fly",
          "flying",
          "focus",
          "focused",
          "footage",
          "frame",
          "front",
          "gauges",
          "girl",
          "giving",
          "glasses",
          "glimpse",
          "going",
          "gopro",
          "gravel",
          "green",
          "grey",
          "guys",
          "hand",
          "hands",
          "hanging",
          "hat",
          "head",
          "headphones",
          "helicopter",
          "holding",
          "hook",
          "hour",
          "identified",
          "image",
          "immersive",
          "includes",
          "indicates",
          "indicating",
          "inside",
          "interesting",
          "jacket",
          "jackets",
          "lake",
          "lakes",
          "landscape",
          "lapse",
          "large",
          "lens",
          "life",
          "light",
          "likely",
          "located",
          "location",
          "long",
          "looking",
          "low",
          "making",
          "man",
          "marshy",
          "men",
          "moment",
          "mountain",
          "mountainous",
          "mountains",
          "mounted",
          "movement",
          "muted",
          "natural",
          "navigating",
          "near",
          "next",
          "noticeable",
          "number",
          "objects",
          "ocean",
          "orange",
          "ourselves",
          "out",
          "outdoor",
          "outdoors",
          "outside",
          "over",
          "overcast",
          "passenger",
          "people",
          "person",
          "persons",
          "perspective",
          "picturesque",
          "pilot",
          "placed",
          "plane",
          "plants",
          "pockets",
          "point",
          "pontoon",
          "positioned",
          "possibly",
          "potentially",
          "pov",
          "preparing",
          "providing",
          "purposes",
          "radio",
          "raft",
          "range",
          "re",
          "ready",
          "rear",
          "recreational",
          "red",
          "right",
          "river",
          "rivers",
          "rod",
          "rope",
          "scene",
          "scenery",
          "scenic",
          "seaplane",
          "seats",
          "seconds",
          "seems",
          "seen",
          "sense",
          "setting",
          "shaky",
          "shore",
          "shoreline",
          "shot",
          "showcasing",
          "showing",
          "shows",
          "shutter",
          "side",
          "sitting",
          "ski",
          "skies",
          "sky",
          "slightly",
          "slow",
          "small",
          "smiling",
          "snowy",
          "soars",
          "somewhat",
          "son",
          "specific",
          "speed",
          "stability",
          "stable",
          "standing",
          "stands",
          "structures",
          "stunning",
          "style",
          "suggesting",
          "suggests",
          "surrounding",
          "system",
          "taken",
          "tank",
          "time",
          "timelapse",
          "top",
          "travel",
          "trees",
          "tripod",
          "turbulence",
          "twin",
          "twins",
          "unfolds",
          "unique",
          "upper",
          "using",
          "valley",
          "valleys",
          "vantage",
          "vastness",
          "vehicle",
          "video",
          "view",
          "viewed",
          "viewer",
          "viewers",
          "views",
          "visible",
          "visual",
          "water",
          "wearing",
          "welcome",
          "well",
          "wetlands",
          "white",
          "wide",
          "wider",
          "wildlife",
          "window",
          "wing",
          "wings",
          "within",
          "young"
        ],
        "keyword_count": 289,
        "children": [
          "node_2_2",
          "node_2_3"
        ],
        "level": 3,
        "parent": "node_4_0"
      },
      "node_3_2": {
        "node_id": "node_3_2",
        "time_range": [
          80.0,
          120.0
        ],
        "duration": 40.0,
        "keywords": [
          "00",
          "01",
          "03",
          "10",
          "2nd",
          "30",
          "31",
          "360",
          "365",
          "3rd",
          "4k",
          "57",
          "59",
          "64",
          "above",
          "across",
          "action",
          "adult",
          "adventure",
          "aged",
          "ago",
          "alaska",
          "alaskan",
          "along",
          "angle",
          "another",
          "appears",
          "area",
          "areas",
          "arm",
          "back",
          "background",
          "backpack",
          "backpacks",
          "bag",
          "bear",
          "beard",
          "beautiful",
          "behind",
          "black",
          "blanket",
          "blankets",
          "blue",
          "boat",
          "body",
          "brightest",
          "brown",
          "bu",
          "camera",
          "camping",
          "canopy",
          "captured",
          "capturing",
          "carrying",
          "causing",
          "characteristics",
          "children",
          "clip",
          "cloudy",
          "coat",
          "coats",
          "contains",
          "context",
          "contribute",
          "day",
          "days",
          "degree",
          "detail",
          "details",
          "detections",
          "distortion",
          "down",
          "drop",
          "edge",
          "elements",
          "enjoying",
          "face",
          "family",
          "field",
          "fisherman",
          "fishing",
          "float",
          "fly",
          "footage",
          "forecast",
          "forest",
          "forward",
          "frame",
          "front",
          "gear",
          "glasses",
          "going",
          "gonna",
          "grab",
          "grassy",
          "gravel",
          "green",
          "grey",
          "guys",
          "half",
          "hat",
          "helmet",
          "hiking",
          "hood",
          "hour",
          "hugged",
          "huh",
          "image",
          "immersive",
          "indicate",
          "inside",
          "jacket",
          "jackets",
          "jeans",
          "jumpsuits",
          "km",
          "lake",
          "lakes",
          "landscape",
          "large",
          "lens",
          "like",
          "long",
          "looking",
          "looks",
          "loss",
          "male",
          "man",
          "men",
          "middle",
          "mountain",
          "mounted",
          "mouth",
          "much",
          "multiple",
          "near",
          "nearby",
          "next",
          "nh",
          "object",
          "objects",
          "ocean",
          "off",
          "okay",
          "older",
          "orange",
          "ourselves",
          "outdoor",
          "outdoors",
          "overall",
          "overexposed",
          "panoramic",
          "pants",
          "part",
          "patch",
          "path",
          "people",
          "person",
          "perspective",
          "photo",
          "picture",
          "place",
          "plane",
          "pole",
          "positioned",
          "positioning",
          "possibly",
          "pov",
          "presence",
          "present",
          "presented",
          "production",
          "providing",
          "rain",
          "raincoat",
          "raining",
          "re",
          "red",
          "remote",
          "resolution",
          "right",
          "rightind",
          "river",
          "riverbank",
          "rocky",
          "room",
          "says",
          "scene",
          "seconds",
          "seen",
          "setting",
          "sheet",
          "shelter",
          "shore",
          "shoreline",
          "shot",
          "shoulder",
          "showing",
          "sitting",
          "slightly",
          "someone",
          "something",
          "spot",
          "spray",
          "stable",
          "standing",
          "stands",
          "strapped",
          "stream",
          "stuff",
          "style",
          "subject",
          "suggesting",
          "sunglasses",
          "surrounding",
          "taken",
          "taking",
          "talking",
          "tan",
          "technical",
          "tent",
          "tents",
          "time",
          "tommy",
          "toward",
          "travel",
          "tree",
          "trees",
          "trip",
          "twin",
          "twins",
          "umbrella",
          "under",
          "understanding",
          "unique",
          "using",
          "various",
          "video",
          "view",
          "viewer",
          "vlog",
          "walking",
          "water",
          "wearing",
          "welcome",
          "white",
          "wide",
          "wilderness",
          "within",
          "wooded",
          "woods",
          "working",
          "yes"
        ],
        "keyword_count": 253,
        "children": [
          "node_2_4",
          "node_2_5"
        ],
        "level": 3,
        "parent": "node_4_1"
      },
      "node_3_3": {
        "node_id": "node_3_3",
        "time_range": [
          120.0,
          160.0
        ],
        "duration": 40.0,
        "keywords": [
          "00",
          "01",
          "20",
          "34",
          "360",
          "3d",
          "48",
          "4k",
          "action",
          "actions",
          "activities",
          "activity",
          "addition",
          "additional",
          "adventure",
          "allowing",
          "allows",
          "along",
          "angle",
          "angles",
          "another",
          "appears",
          "area",
          "arm",
          "around",
          "attached",
          "background",
          "backpack",
          "backpacks",
          "bait",
          "barton",
          "beach",
          "bear",
          "behavior",
          "behind",
          "bent",
          "beside",
          "between",
          "bird",
          "black",
          "blancher",
          "blue",
          "body",
          "bonk",
          "bottle",
          "boy",
          "broader",
          "bu",
          "bump",
          "camera",
          "cameras",
          "captured",
          "captures",
          "capturing",
          "char",
          "chart",
          "chest",
          "child",
          "close",
          "closely",
          "clothing",
          "colored",
          "container",
          "conversation",
          "covering",
          "daily",
          "daytime",
          "definition",
          "degree",
          "deli",
          "depicting",
          "description",
          "detail",
          "detected",
          "different",
          "dinner",
          "distance",
          "distinct",
          "distortion",
          "documentation",
          "dog",
          "dollar",
          "dolly",
          "down",
          "editing",
          "enjoying",
          "environment",
          "etc",
          "excitement",
          "family",
          "features",
          "featuring",
          "file",
          "filled",
          "fish",
          "fishermen",
          "fishing",
          "fly",
          "focal",
          "focus",
          "focusing",
          "following",
          "footage",
          "forest",
          "frames",
          "front",
          "gear",
          "giving",
          "going",
          "grab",
          "gravel",
          "gravelly",
          "gray",
          "green",
          "ground",
          "groups",
          "gun",
          "hand",
          "harness",
          "hat",
          "held",
          "helmet",
          "high",
          "holding",
          "hook",
          "hurry",
          "image",
          "immersive",
          "includes",
          "indicates",
          "indicating",
          "individual",
          "interest",
          "jacket",
          "kneeling",
          "lake",
          "large",
          "length",
          "lens",
          "life",
          "line",
          "long",
          "looks",
          "lot",
          "lure",
          "main",
          "man",
          "mean",
          "member",
          "men",
          "moment",
          "motion",
          "mountain",
          "mountains",
          "mounted",
          "movements",
          "multiple",
          "near",
          "nearby",
          "nearer",
          "next",
          "nothing",
          "object",
          "objects",
          "observe",
          "observer",
          "observing",
          "ocean",
          "oh",
          "okay",
          "orange",
          "out",
          "outdoor",
          "outdoors",
          "outfit",
          "over",
          "part",
          "pebble",
          "people",
          "person",
          "perspective",
          "perspectives",
          "pieces",
          "pink",
          "placed",
          "point",
          "pole",
          "positioned",
          "positioning",
          "possibly",
          "present",
          "purposes",
          "rain",
          "raincoat",
          "range",
          "raw",
          "re",
          "ready",
          "red",
          "right",
          "river",
          "riverbank",
          "road",
          "rock",
          "rocks",
          "rocky",
          "rod",
          "rods",
          "scattered",
          "scene",
          "scenes",
          "seconds",
          "seen",
          "several",
          "shore",
          "shot",
          "shots",
          "showcases",
          "showing",
          "simply",
          "sitting",
          "six",
          "sky",
          "small",
          "snowsuit",
          "someone",
          "sports",
          "spot",
          "spray",
          "stable",
          "standing",
          "stands",
          "stream",
          "style",
          "subjects",
          "suggesting",
          "suggests",
          "suit",
          "supplies",
          "surrounding",
          "surroundings",
          "taken",
          "tent",
          "terrain",
          "tommy",
          "toob",
          "total",
          "tracking",
          "tracks",
          "ultra",
          "using",
          "various",
          "varten",
          "video",
          "videos",
          "view",
          "viewers",
          "visible",
          "vlog",
          "waders",
          "walking",
          "walks",
          "wall",
          "water",
          "way",
          "wearing",
          "white",
          "wide",
          "within",
          "woman",
          "wow",
          "yeah",
          "yee",
          "yeee",
          "yep",
          "yes",
          "young"
        ],
        "keyword_count": 277,
        "children": [
          "node_2_6",
          "node_2_7"
        ],
        "level": 3,
        "parent": "node_4_1"
      },
      "node_3_4": {
        "node_id": "node_3_4",
        "time_range": [
          160.0,
          200.0
        ],
        "duration": 40.0,
        "keywords": [
          "10",
          "1k",
          "2d",
          "2k",
          "30",
          "360",
          "365",
          "3d",
          "3rd",
          "above",
          "action",
          "activities",
          "ahead",
          "along",
          "alright",
          "angle",
          "another",
          "appears",
          "appropriate",
          "area",
          "around",
          "art",
          "artifacts",
          "attire",
          "available",
          "back",
          "background",
          "backpack",
          "bank",
          "barton",
          "beach",
          "bend",
          "bending",
          "between",
          "black",
          "blur",
          "blurred",
          "blurry",
          "boat",
          "body",
          "book",
          "bottle",
          "boy",
          "boys",
          "brown",
          "bucket",
          "buddy",
          "camera",
          "captured",
          "capturing",
          "casts",
          "cell",
          "char",
          "child",
          "clothes",
          "clothing",
          "coat",
          "compression",
          "context",
          "creating",
          "days",
          "deep",
          "definitely",
          "degree",
          "depicting",
          "detected",
          "dinner",
          "distortion",
          "dolly",
          "down",
          "dressed",
          "dropped",
          "edge",
          "effect",
          "emphasize",
          "enjoying",
          "experience",
          "experiencing",
          "ey",
          "family",
          "features",
          "featuring",
          "field",
          "fish",
          "fisherman",
          "fisheye",
          "fishing",
          "flare",
          "flies",
          "floor",
          "focused",
          "footage",
          "frame",
          "frames",
          "further",
          "giving",
          "goes",
          "gonna",
          "gopro",
          "grab",
          "grainy",
          "gravel",
          "green",
          "ground",
          "hand",
          "hands",
          "head",
          "hey",
          "holding",
          "image",
          "immersive",
          "indicating",
          "interacting",
          "isn",
          "jacket",
          "jackets",
          "jumpsuit",
          "knee",
          "lake",
          "large",
          "laying",
          "lens",
          "line",
          "ll",
          "location",
          "long",
          "looking",
          "lovely",
          "lunch",
          "making",
          "man",
          "member",
          "men",
          "mind",
          "model",
          "molding",
          "moment",
          "motion",
          "mountain",
          "mounted",
          "near",
          "nearby",
          "never",
          "next",
          "nice",
          "object",
          "offering",
          "oh",
          "okay",
          "orange",
          "out",
          "outdoor",
          "outdoors",
          "outside",
          "over",
          "overhead",
          "panoramic",
          "pebbly",
          "people",
          "per",
          "person",
          "perspective",
          "phone",
          "photography",
          "pick",
          "picking",
          "pink",
          "playing",
          "point",
          "pole",
          "positioned",
          "possibly",
          "present",
          "probably",
          "providing",
          "rain",
          "raincoat",
          "raincoats",
          "reaching",
          "recorded",
          "red",
          "reeling",
          "resolution",
          "resulting",
          "retrieve",
          "river",
          "rocks",
          "rod",
          "rods",
          "sand",
          "scene",
          "seconds",
          "seen",
          "sense",
          "sensor",
          "sharon",
          "shirt",
          "shore",
          "shoreline",
          "shoulder",
          "showing",
          "shows",
          "side",
          "single",
          "slight",
          "slightly",
          "snowsuit",
          "something",
          "spot",
          "stable",
          "standing",
          "stands",
          "stream",
          "subjects",
          "surface",
          "surroundings",
          "talking",
          "technical",
          "techniques",
          "tips",
          "toddler",
          "tom",
          "tommy",
          "trees",
          "tricks",
          "tripod",
          "unsteady",
          "using",
          "video",
          "view",
          "viewer",
          "walking",
          "wanna",
          "watches",
          "water",
          "wearing",
          "weather",
          "weird",
          "wet",
          "white",
          "wide",
          "within",
          "wooded",
          "yeah",
          "young",
          "yup"
        ],
        "keyword_count": 246,
        "children": [
          "node_2_8",
          "node_2_9"
        ],
        "level": 3,
        "parent": "node_4_2"
      },
      "node_3_5": {
        "node_id": "node_3_5",
        "time_range": [
          200.0,
          240.0
        ],
        "duration": 40.0,
        "keywords": [
          "00",
          "01",
          "10",
          "19",
          "30",
          "360",
          "3d",
          "3rd",
          "4k",
          "56",
          "58",
          "67",
          "79",
          "across",
          "action",
          "actions",
          "activity",
          "additionally",
          "adventure",
          "along",
          "alright",
          "aluminum",
          "angle",
          "angler",
          "animal",
          "animals",
          "another",
          "appears",
          "area",
          "around",
          "atmosphere",
          "attract",
          "baby",
          "back",
          "background",
          "backpack",
          "backpacks",
          "bait",
          "based",
          "bears",
          "beer",
          "behind",
          "beside",
          "between",
          "bit",
          "black",
          "blue",
          "blur",
          "body",
          "boiling",
          "bottle",
          "bottles",
          "boy",
          "bugs",
          "camera",
          "camping",
          "campsite",
          "canopy",
          "capture",
          "captured",
          "captures",
          "capturing",
          "cast",
          "catching",
          "chest",
          "child",
          "children",
          "chocolate",
          "clearer",
          "close",
          "closer",
          "coat",
          "coffee",
          "color",
          "companions",
          "compose",
          "contain",
          "contains",
          "conversation",
          "couple",
          "cups",
          "dead",
          "debris",
          "degree",
          "depicting",
          "depicts",
          "descriptions",
          "detected",
          "dirty",
          "distance",
          "done",
          "down",
          "dress",
          "drinking",
          "due",
          "eating",
          "edge",
          "edit",
          "effect",
          "either",
          "elements",
          "else",
          "engaging",
          "enjoys",
          "entire",
          "environment",
          "essence",
          "evidenced",
          "exchange",
          "experience",
          "experiencing",
          "family",
          "filled",
          "film",
          "fish",
          "fisheye",
          "fishing",
          "flies",
          "focus",
          "focused",
          "food",
          "footage",
          "foreground",
          "forgot",
          "format",
          "frame",
          "front",
          "full",
          "gear",
          "gentleman",
          "god",
          "gonna",
          "gopro",
          "grabbing",
          "green",
          "ground",
          "group",
          "gun",
          "guy",
          "guys",
          "hair",
          "hand",
          "handbag",
          "hands",
          "handshake",
          "happy",
          "head",
          "hey",
          "hi",
          "higher",
          "hiking",
          "hold",
          "holding",
          "hooded",
          "hoodie",
          "hot",
          "image",
          "immersive",
          "includes",
          "indicating",
          "individual",
          "individuals",
          "inside",
          "items",
          "jacket",
          "kettle",
          "lake",
          "lantern",
          "lap",
          "large",
          "leather",
          "leaves",
          "lens",
          "letters",
          "lights",
          "like",
          "likely",
          "line",
          "little",
          "location",
          "long",
          "looking",
          "looks",
          "lunch",
          "main",
          "makes",
          "making",
          "man",
          "meal",
          "men",
          "mess",
          "moment",
          "mosquitoes",
          "motion",
          "mountains",
          "mounted",
          "mug",
          "multiple",
          "natural",
          "near",
          "nearby",
          "next",
          "notices",
          "object",
          "objects",
          "occurring",
          "oh",
          "older",
          "orange",
          "out",
          "outdoor",
          "outdoors",
          "over",
          "people",
          "person",
          "persons",
          "perspective",
          "place",
          "placed",
          "playing",
          "point",
          "pointing",
          "pole",
          "positioned",
          "positions",
          "possibly",
          "pot",
          "preparing",
          "presence",
          "present",
          "primary",
          "provides",
          "providing",
          "rain",
          "raincoat",
          "raw",
          "re",
          "recommended",
          "red",
          "releasing",
          "resolution",
          "retrieve",
          "river",
          "rocks",
          "rod",
          "rods",
          "scattered",
          "scene",
          "seconds",
          "seems",
          "seen",
          "setting",
          "setup",
          "several",
          "shaky",
          "share",
          "shells",
          "shore",
          "shot",
          "showcasing",
          "showing",
          "shown",
          "shows",
          "single",
          "sips",
          "sitting",
          "sky",
          "small",
          "smiling",
          "someone",
          "something",
          "sort",
          "standing",
          "stands",
          "sticky",
          "stomachs",
          "stuff",
          "stuffed",
          "subject",
          "suggesting",
          "suggests",
          "summary",
          "supplies",
          "surrounding",
          "taken",
          "takes",
          "tent",
          "tents",
          "thousands",
          "time",
          "together",
          "tommy",
          "toward",
          "toys",
          "trail",
          "tree",
          "trees",
          "trip",
          "twigs",
          "umbrella",
          "under",
          "using",
          "various",
          "video",
          "view",
          "viewer",
          "viewers",
          "visible",
          "visuals",
          "walking",
          "wanna",
          "warm",
          "watching",
          "water",
          "way",
          "wearing",
          "white",
          "wide",
          "within",
          "witness",
          "wooded",
          "young",
          "yup"
        ],
        "keyword_count": 323,
        "children": [
          "node_2_10",
          "node_2_11"
        ],
        "level": 3,
        "parent": "node_4_2"
      },
      "node_3_6": {
        "node_id": "node_3_6",
        "time_range": [
          240.0,
          280.0
        ],
        "duration": 40.0,
        "keywords": [
          "2015",
          "30",
          "360",
          "3d",
          "3rd",
          "54",
          "62",
          "above",
          "accurate",
          "activities",
          "activity",
          "additional",
          "adult",
          "adventure",
          "after",
          "along",
          "another",
          "appears",
          "area",
          "around",
          "array",
          "artifacts",
          "assortment",
          "attract",
          "backpack",
          "backpacking",
          "backpacks",
          "bags",
          "ball",
          "balls",
          "bears",
          "belongings",
          "bite",
          "black",
          "blow",
          "blowing",
          "blue",
          "blur",
          "body",
          "bottle",
          "bottles",
          "bowl",
          "bowls",
          "boy",
          "boys",
          "broth",
          "camera",
          "cameras",
          "campfire",
          "camping",
          "campsite",
          "candle",
          "canister",
          "canvas",
          "captures",
          "capturing",
          "chairs",
          "child",
          "children",
          "cleaning",
          "conditions",
          "container",
          "conversation",
          "cooking",
          "cup",
          "cups",
          "degree",
          "descriptions",
          "detailed",
          "details",
          "dolly",
          "dung",
          "eating",
          "either",
          "elements",
          "engaged",
          "engaging",
          "enjoying",
          "entire",
          "expedition",
          "explaining",
          "family",
          "father",
          "features",
          "featuring",
          "filming",
          "finger",
          "finished",
          "fire",
          "fish",
          "fishing",
          "flare",
          "flavored",
          "flying",
          "following",
          "food",
          "footage",
          "foreground",
          "frisbee",
          "front",
          "frying",
          "garden",
          "gathered",
          "glasses",
          "god",
          "good",
          "green",
          "ground",
          "group",
          "guys",
          "hair",
          "hand",
          "handbag",
          "handing",
          "handling",
          "hands",
          "hat",
          "helmet",
          "hiking",
          "hold",
          "holding",
          "hungry",
          "image",
          "immersive",
          "includes",
          "indicate",
          "indicating",
          "inside",
          "interacting",
          "interactions",
          "interacts",
          "interesting",
          "involved",
          "item",
          "items",
          "kids",
          "kite",
          "knife",
          "knives",
          "knots",
          "leisure",
          "lens",
          "lid",
          "lighting",
          "like",
          "likely",
          "little",
          "located",
          "looking",
          "lot",
          "lures",
          "main",
          "male",
          "man",
          "meal",
          "meals",
          "men",
          "methods",
          "military",
          "miscellaneous",
          "moment",
          "motion",
          "mounted",
          "multiple",
          "natural",
          "near",
          "nearby",
          "next",
          "object",
          "objects",
          "oh",
          "oiling",
          "older",
          "others",
          "out",
          "outdoor",
          "outdoors",
          "outside",
          "over",
          "overhead",
          "pan",
          "people",
          "person",
          "personal",
          "perspective",
          "place",
          "placed",
          "placing",
          "playing",
          "please",
          "pointing",
          "positioned",
          "possibly",
          "pot",
          "pots",
          "pouring",
          "preparing",
          "present",
          "pretty",
          "provide",
          "providing",
          "ramen",
          "ready",
          "red",
          "resting",
          "right",
          "rod",
          "salted",
          "sandwich",
          "scattered",
          "scene",
          "seated",
          "seconds",
          "seems",
          "seen",
          "setting",
          "several",
          "shells",
          "showing",
          "shown",
          "shows",
          "site",
          "siting",
          "sitting",
          "situation",
          "sleeping",
          "small",
          "smartphone",
          "snacks",
          "someone",
          "something",
          "sons",
          "spaghetti",
          "spoons",
          "sports",
          "stabilization",
          "stable",
          "standing",
          "sticky",
          "structure",
          "stuff",
          "sure",
          "surrounded",
          "surroundings",
          "survival",
          "takes",
          "tastes",
          "technical",
          "tent",
          "tents",
          "tie",
          "time",
          "together",
          "tool",
          "top",
          "tracking",
          "trip",
          "tripod",
          "trowel",
          "type",
          "under",
          "uniform",
          "upcoming",
          "using",
          "various",
          "video",
          "view",
          "visible",
          "warm",
          "watching",
          "water",
          "way",
          "wearing",
          "well",
          "white",
          "wing",
          "yeah",
          "yellow",
          "young"
        ],
        "keyword_count": 279,
        "children": [
          "node_2_12",
          "node_2_13"
        ],
        "level": 3,
        "parent": "node_4_3"
      },
      "node_3_7": {
        "node_id": "node_3_7",
        "time_range": [
          280.0,
          299.999
        ],
        "duration": 19.999000000000024,
        "keywords": [
          "30",
          "31",
          "32",
          "360",
          "3d",
          "3rd",
          "accurate",
          "adding",
          "adult",
          "aged",
          "alright",
          "angle",
          "another",
          "appears",
          "area",
          "around",
          "atmosphere",
          "away",
          "background",
          "backpack",
          "backpacks",
          "bags",
          "baseball",
          "behind",
          "between",
          "bivou",
          "blue",
          "body",
          "book",
          "bottle",
          "bottles",
          "bowl",
          "bowls",
          "boy",
          "camera",
          "camper",
          "camping",
          "campsite",
          "cap",
          "capture",
          "captures",
          "capturing",
          "casual",
          "cell",
          "center",
          "clearly",
          "close",
          "closer",
          "company",
          "conversation",
          "cooking",
          "cozy",
          "cup",
          "cups",
          "daily",
          "degree",
          "depicts",
          "discussing",
          "dishes",
          "dog",
          "dolly",
          "down",
          "eating",
          "enjoy",
          "enjoying",
          "entire",
          "father",
          "features",
          "featuring",
          "flavored",
          "food",
          "footage",
          "foreground",
          "frames",
          "front",
          "further",
          "gear",
          "glasses",
          "good",
          "green",
          "ground",
          "groups",
          "haired",
          "hand",
          "handbag",
          "hands",
          "hat",
          "holding",
          "holds",
          "image",
          "includes",
          "indicating",
          "input",
          "inside",
          "interaction",
          "item",
          "items",
          "knife",
          "lap",
          "lens",
          "letters",
          "life",
          "like",
          "likely",
          "little",
          "ll",
          "located",
          "looking",
          "lot",
          "male",
          "man",
          "meal",
          "men",
          "mess",
          "messy",
          "middle",
          "model",
          "moment",
          "mounted",
          "mouth",
          "multi",
          "multiple",
          "near",
          "nearby",
          "next",
          "numerous",
          "object",
          "objects",
          "oh",
          "older",
          "out",
          "outdoor",
          "oven",
          "overall",
          "pen",
          "people",
          "pepper",
          "person",
          "perspective",
          "phone",
          "place",
          "placed",
          "plates",
          "possibly",
          "pot",
          "pots",
          "present",
          "process",
          "providing",
          "proximity",
          "ramen",
          "ready",
          "recorded",
          "relaxed",
          "representation",
          "right",
          "round",
          "salmon",
          "salt",
          "sandwiches",
          "scattered",
          "scene",
          "seated",
          "seconds",
          "seems",
          "seen",
          "setting",
          "settled",
          "several",
          "shaky",
          "share",
          "shared",
          "sharing",
          "shot",
          "showing",
          "shown",
          "side",
          "site",
          "sitting",
          "soldier",
          "someone",
          "something",
          "son",
          "spoons",
          "table",
          "takes",
          "talking",
          "tastes",
          "tent",
          "together",
          "tool",
          "tripod",
          "trout",
          "trowel",
          "under",
          "unique",
          "various",
          "video",
          "view",
          "visible",
          "wall",
          "watches",
          "wearing",
          "white",
          "wide",
          "wing",
          "winter",
          "yeah",
          "young"
        ],
        "keyword_count": 209,
        "children": [
          "node_2_14"
        ],
        "level": 3,
        "parent": "node_4_3"
      },
      "node_4_0": {
        "node_id": "node_4_0",
        "time_range": [
          0.0,
          80.0
        ],
        "duration": 80.0,
        "keywords": [
          "08",
          "10",
          "12345",
          "15",
          "27",
          "30",
          "32",
          "35",
          "360",
          "3d",
          "3rd",
          "45",
          "48",
          "7373",
          "above",
          "action",
          "activity",
          "adding",
          "additionally",
          "admiring",
          "aerial",
          "aid",
          "air",
          "aircraft",
          "airplane",
          "alaska",
          "along",
          "altitude",
          "amazing",
          "angle",
          "another",
          "appears",
          "appreciate",
          "arctic",
          "area",
          "around",
          "aviation",
          "away",
          "axe",
          "back",
          "background",
          "backpack",
          "bags",
          "ball",
          "beach",
          "beautiful",
          "beauty",
          "before",
          "behind",
          "below",
          "beside",
          "bicycles",
          "birds",
          "black",
          "blue",
          "blurry",
          "board",
          "boat",
          "boats",
          "body",
          "bottle",
          "boy",
          "boys",
          "building",
          "bus",
          "bush",
          "buttons",
          "cabin",
          "calm",
          "camera",
          "camp",
          "canister",
          "cap",
          "captured",
          "captures",
          "capturing",
          "car",
          "carrying",
          "cars",
          "casting",
          "cause",
          "center",
          "chairs",
          "channel",
          "channels",
          "characteristics",
          "child",
          "clear",
          "close",
          "closer",
          "cloudy",
          "cockpit",
          "coffee",
          "colors",
          "communication",
          "conditions",
          "connected",
          "context",
          "control",
          "controls",
          "corner",
          "countryside",
          "craft",
          "crafting",
          "creates",
          "crucial",
          "cup",
          "dark",
          "dashboard",
          "dashcam",
          "daughter",
          "day",
          "days",
          "degree",
          "departure",
          "description",
          "descriptions",
          "detected",
          "detection",
          "device",
          "dick",
          "disembark",
          "distance",
          "distortion",
          "documentation",
          "dolly",
          "door",
          "dressed",
          "driver",
          "drivers",
          "driving",
          "dropped",
          "due",
          "dynamic",
          "earth",
          "edge",
          "edges",
          "effect",
          "elements",
          "engaging",
          "enjoying",
          "environment",
          "everyday",
          "excited",
          "excitement",
          "expansive",
          "experience",
          "exploring",
          "expression",
          "eye",
          "facial",
          "fair",
          "family",
          "father",
          "features",
          "featuring",
          "field",
          "fiji",
          "filled",
          "filming",
          "fish",
          "fisheye",
          "fishing",
          "flies",
          "flight",
          "float",
          "fly",
          "flying",
          "focus",
          "focused",
          "footage",
          "forest",
          "frame",
          "front",
          "frying",
          "further",
          "gauges",
          "girl",
          "giving",
          "glasses",
          "glimpse",
          "going",
          "gonna",
          "gopro",
          "grailing",
          "gravel",
          "green",
          "grey",
          "ground",
          "group",
          "guys",
          "hand",
          "hands",
          "hanging",
          "hat",
          "head",
          "headphones",
          "helicopter",
          "helmet",
          "hiking",
          "hillside",
          "himself",
          "holding",
          "hole",
          "homestead",
          "hoodie",
          "hook",
          "hour",
          "house",
          "identified",
          "image",
          "immersive",
          "includes",
          "indicates",
          "indicating",
          "information",
          "inside",
          "instruments",
          "interesting",
          "interior",
          "island",
          "jacket",
          "jackets",
          "kaleidoscope",
          "kite",
          "lake",
          "lakes",
          "landscape",
          "lapse",
          "laptop",
          "large",
          "lens",
          "life",
          "light",
          "likely",
          "line",
          "located",
          "location",
          "locations",
          "log",
          "long",
          "looking",
          "looks",
          "lot",
          "low",
          "luke",
          "machinery",
          "making",
          "man",
          "market",
          "marshy",
          "meal",
          "men",
          "middle",
          "moment",
          "mountain",
          "mountainous",
          "mountains",
          "mounted",
          "movement",
          "mug",
          "multiple",
          "muted",
          "natural",
          "navigates",
          "navigating",
          "near",
          "nearby",
          "next",
          "noticeable",
          "number",
          "object",
          "objects",
          "ocean",
          "off",
          "operating",
          "orange",
          "original",
          "ourselves",
          "out",
          "outdoor",
          "outdoors",
          "outside",
          "over",
          "overcast",
          "overhead",
          "pack",
          "pan",
          "part",
          "passenger",
          "people",
          "person",
          "personal",
          "persons",
          "perspective",
          "photo",
          "picturesque",
          "piece",
          "pilot",
          "placed",
          "plane",
          "plants",
          "pockets",
          "point",
          "pointing",
          "pontoon",
          "positioned",
          "possibly",
          "potentially",
          "pov",
          "prennicky",
          "preparing",
          "providing",
          "purposes",
          "radio",
          "raft",
          "rafting",
          "rainy",
          "range",
          "re",
          "ready",
          "rear",
          "recreational",
          "red",
          "relatively",
          "repair",
          "respective",
          "right",
          "river",
          "rivers",
          "road",
          "rocks",
          "rod",
          "rope",
          "saying",
          "says",
          "scene",
          "scenery",
          "scenic",
          "screen",
          "seaplane",
          "seat",
          "seated",
          "seats",
          "seconds",
          "seems",
          "seen",
          "sense",
          "serving",
          "setting",
          "several",
          "shaky",
          "shirt",
          "shore",
          "shoreline",
          "shot",
          "shoulder",
          "showcasing",
          "showing",
          "shows",
          "shutter",
          "side",
          "similar",
          "sits",
          "sitting",
          "situated",
          "ski",
          "skies",
          "sky",
          "slightly",
          "slow",
          "small",
          "smiling",
          "snowy",
          "soars",
          "someone",
          "something",
          "somewhat",
          "son",
          "specific",
          "speed",
          "speedometer",
          "stability",
          "stable",
          "stall",
          "standing",
          "stands",
          "steering",
          "stool",
          "structure",
          "structures",
          "stuck",
          "stump",
          "stunning",
          "style",
          "suggesting",
          "suggests",
          "sunglasses",
          "surfaces",
          "surrounding",
          "surroundings",
          "switches",
          "system",
          "taken",
          "talking",
          "tank",
          "tent",
          "time",
          "timelapse",
          "together",
          "top",
          "tracks",
          "travel",
          "tree",
          "trees",
          "trip",
          "tripod",
          "trout",
          "turbulence",
          "turned",
          "twin",
          "twins",
          "under",
          "unfolds",
          "unique",
          "upper",
          "using",
          "valley",
          "valleys",
          "vantage",
          "vardin",
          "various",
          "vastness",
          "vehicle",
          "video",
          "view",
          "viewed",
          "viewer",
          "viewers",
          "views",
          "visible",
          "visual",
          "water",
          "way",
          "wearing",
          "welcome",
          "well",
          "wetlands",
          "wheel",
          "white",
          "wide",
          "wider",
          "wildlife",
          "window",
          "wing",
          "wings",
          "within",
          "wooden",
          "works",
          "writing",
          "young",
          "youtube",
          "youtuber"
        ],
        "keyword_count": 463,
        "children": [
          "node_3_0",
          "node_3_1"
        ],
        "level": 4,
        "parent": "node_5_0"
      },
      "node_4_1": {
        "node_id": "node_4_1",
        "time_range": [
          80.0,
          160.0
        ],
        "duration": 80.0,
        "keywords": [
          "00",
          "01",
          "03",
          "10",
          "20",
          "2nd",
          "30",
          "31",
          "34",
          "360",
          "365",
          "3d",
          "3rd",
          "48",
          "4k",
          "57",
          "59",
          "64",
          "above",
          "across",
          "action",
          "actions",
          "activities",
          "activity",
          "addition",
          "additional",
          "adult",
          "adventure",
          "aged",
          "ago",
          "alaska",
          "alaskan",
          "allowing",
          "allows",
          "along",
          "angle",
          "angles",
          "another",
          "appears",
          "area",
          "areas",
          "arm",
          "around",
          "attached",
          "back",
          "background",
          "backpack",
          "backpacks",
          "bag",
          "bait",
          "barton",
          "beach",
          "bear",
          "beard",
          "beautiful",
          "behavior",
          "behind",
          "bent",
          "beside",
          "between",
          "bird",
          "black",
          "blancher",
          "blanket",
          "blankets",
          "blue",
          "boat",
          "body",
          "bonk",
          "bottle",
          "boy",
          "brightest",
          "broader",
          "brown",
          "bu",
          "bump",
          "camera",
          "cameras",
          "camping",
          "canopy",
          "captured",
          "captures",
          "capturing",
          "carrying",
          "causing",
          "char",
          "characteristics",
          "chart",
          "chest",
          "child",
          "children",
          "clip",
          "close",
          "closely",
          "clothing",
          "cloudy",
          "coat",
          "coats",
          "colored",
          "container",
          "contains",
          "context",
          "contribute",
          "conversation",
          "covering",
          "daily",
          "day",
          "days",
          "daytime",
          "definition",
          "degree",
          "deli",
          "depicting",
          "description",
          "detail",
          "details",
          "detected",
          "detections",
          "different",
          "dinner",
          "distance",
          "distinct",
          "distortion",
          "documentation",
          "dog",
          "dollar",
          "dolly",
          "down",
          "drop",
          "edge",
          "editing",
          "elements",
          "enjoying",
          "environment",
          "etc",
          "excitement",
          "face",
          "family",
          "features",
          "featuring",
          "field",
          "file",
          "filled",
          "fish",
          "fisherman",
          "fishermen",
          "fishing",
          "float",
          "fly",
          "focal",
          "focus",
          "focusing",
          "following",
          "footage",
          "forecast",
          "forest",
          "forward",
          "frame",
          "frames",
          "front",
          "gear",
          "giving",
          "glasses",
          "going",
          "gonna",
          "grab",
          "grassy",
          "gravel",
          "gravelly",
          "gray",
          "green",
          "grey",
          "ground",
          "groups",
          "gun",
          "guys",
          "half",
          "hand",
          "harness",
          "hat",
          "held",
          "helmet",
          "high",
          "hiking",
          "holding",
          "hood",
          "hook",
          "hour",
          "hugged",
          "huh",
          "hurry",
          "image",
          "immersive",
          "includes",
          "indicate",
          "indicates",
          "indicating",
          "individual",
          "inside",
          "interest",
          "jacket",
          "jackets",
          "jeans",
          "jumpsuits",
          "km",
          "kneeling",
          "lake",
          "lakes",
          "landscape",
          "large",
          "length",
          "lens",
          "life",
          "like",
          "line",
          "long",
          "looking",
          "looks",
          "loss",
          "lot",
          "lure",
          "main",
          "male",
          "man",
          "mean",
          "member",
          "men",
          "middle",
          "moment",
          "motion",
          "mountain",
          "mountains",
          "mounted",
          "mouth",
          "movements",
          "much",
          "multiple",
          "near",
          "nearby",
          "nearer",
          "next",
          "nh",
          "nothing",
          "object",
          "objects",
          "observe",
          "observer",
          "observing",
          "ocean",
          "off",
          "oh",
          "okay",
          "older",
          "orange",
          "ourselves",
          "out",
          "outdoor",
          "outdoors",
          "outfit",
          "over",
          "overall",
          "overexposed",
          "panoramic",
          "pants",
          "part",
          "patch",
          "path",
          "pebble",
          "people",
          "person",
          "perspective",
          "perspectives",
          "photo",
          "picture",
          "pieces",
          "pink",
          "place",
          "placed",
          "plane",
          "point",
          "pole",
          "positioned",
          "positioning",
          "possibly",
          "pov",
          "presence",
          "present",
          "presented",
          "production",
          "providing",
          "purposes",
          "rain",
          "raincoat",
          "raining",
          "range",
          "raw",
          "re",
          "ready",
          "red",
          "remote",
          "resolution",
          "right",
          "rightind",
          "river",
          "riverbank",
          "road",
          "rock",
          "rocks",
          "rocky",
          "rod",
          "rods",
          "room",
          "says",
          "scattered",
          "scene",
          "scenes",
          "seconds",
          "seen",
          "setting",
          "several",
          "sheet",
          "shelter",
          "shore",
          "shoreline",
          "shot",
          "shots",
          "shoulder",
          "showcases",
          "showing",
          "simply",
          "sitting",
          "six",
          "sky",
          "slightly",
          "small",
          "snowsuit",
          "someone",
          "something",
          "sports",
          "spot",
          "spray",
          "stable",
          "standing",
          "stands",
          "strapped",
          "stream",
          "stuff",
          "style",
          "subject",
          "subjects",
          "suggesting",
          "suggests",
          "suit",
          "sunglasses",
          "supplies",
          "surrounding",
          "surroundings",
          "taken",
          "taking",
          "talking",
          "tan",
          "technical",
          "tent",
          "tents",
          "terrain",
          "time",
          "tommy",
          "toob",
          "total",
          "toward",
          "tracking",
          "tracks",
          "travel",
          "tree",
          "trees",
          "trip",
          "twin",
          "twins",
          "ultra",
          "umbrella",
          "under",
          "understanding",
          "unique",
          "using",
          "various",
          "varten",
          "video",
          "videos",
          "view",
          "viewer",
          "viewers",
          "visible",
          "vlog",
          "waders",
          "walking",
          "walks",
          "wall",
          "water",
          "way",
          "wearing",
          "welcome",
          "white",
          "wide",
          "wilderness",
          "within",
          "woman",
          "wooded",
          "woods",
          "working",
          "wow",
          "yeah",
          "yee",
          "yeee",
          "yep",
          "yes",
          "young"
        ],
        "keyword_count": 416,
        "children": [
          "node_3_2",
          "node_3_3"
        ],
        "level": 4,
        "parent": "node_5_0"
      },
      "node_4_2": {
        "node_id": "node_4_2",
        "time_range": [
          160.0,
          240.0
        ],
        "duration": 80.0,
        "keywords": [
          "00",
          "01",
          "10",
          "19",
          "1k",
          "2d",
          "2k",
          "30",
          "360",
          "365",
          "3d",
          "3rd",
          "4k",
          "56",
          "58",
          "67",
          "79",
          "above",
          "across",
          "action",
          "actions",
          "activities",
          "activity",
          "additionally",
          "adventure",
          "ahead",
          "along",
          "alright",
          "aluminum",
          "angle",
          "angler",
          "animal",
          "animals",
          "another",
          "appears",
          "appropriate",
          "area",
          "around",
          "art",
          "artifacts",
          "atmosphere",
          "attire",
          "attract",
          "available",
          "baby",
          "back",
          "background",
          "backpack",
          "backpacks",
          "bait",
          "bank",
          "barton",
          "based",
          "beach",
          "bears",
          "beer",
          "behind",
          "bend",
          "bending",
          "beside",
          "between",
          "bit",
          "black",
          "blue",
          "blur",
          "blurred",
          "blurry",
          "boat",
          "body",
          "boiling",
          "book",
          "bottle",
          "bottles",
          "boy",
          "boys",
          "brown",
          "bucket",
          "buddy",
          "bugs",
          "camera",
          "camping",
          "campsite",
          "canopy",
          "capture",
          "captured",
          "captures",
          "capturing",
          "cast",
          "casts",
          "catching",
          "cell",
          "char",
          "chest",
          "child",
          "children",
          "chocolate",
          "clearer",
          "close",
          "closer",
          "clothes",
          "clothing",
          "coat",
          "coffee",
          "color",
          "companions",
          "compose",
          "compression",
          "contain",
          "contains",
          "context",
          "conversation",
          "couple",
          "creating",
          "cups",
          "days",
          "dead",
          "debris",
          "deep",
          "definitely",
          "degree",
          "depicting",
          "depicts",
          "descriptions",
          "detected",
          "dinner",
          "dirty",
          "distance",
          "distortion",
          "dolly",
          "done",
          "down",
          "dress",
          "dressed",
          "drinking",
          "dropped",
          "due",
          "eating",
          "edge",
          "edit",
          "effect",
          "either",
          "elements",
          "else",
          "emphasize",
          "engaging",
          "enjoying",
          "enjoys",
          "entire",
          "environment",
          "essence",
          "evidenced",
          "exchange",
          "experience",
          "experiencing",
          "ey",
          "family",
          "features",
          "featuring",
          "field",
          "filled",
          "film",
          "fish",
          "fisherman",
          "fisheye",
          "fishing",
          "flare",
          "flies",
          "floor",
          "focus",
          "focused",
          "food",
          "footage",
          "foreground",
          "forgot",
          "format",
          "frame",
          "frames",
          "front",
          "full",
          "further",
          "gear",
          "gentleman",
          "giving",
          "god",
          "goes",
          "gonna",
          "gopro",
          "grab",
          "grabbing",
          "grainy",
          "gravel",
          "green",
          "ground",
          "group",
          "gun",
          "guy",
          "guys",
          "hair",
          "hand",
          "handbag",
          "hands",
          "handshake",
          "happy",
          "head",
          "hey",
          "hi",
          "higher",
          "hiking",
          "hold",
          "holding",
          "hooded",
          "hoodie",
          "hot",
          "image",
          "immersive",
          "includes",
          "indicating",
          "individual",
          "individuals",
          "inside",
          "interacting",
          "isn",
          "items",
          "jacket",
          "jackets",
          "jumpsuit",
          "kettle",
          "knee",
          "lake",
          "lantern",
          "lap",
          "large",
          "laying",
          "leather",
          "leaves",
          "lens",
          "letters",
          "lights",
          "like",
          "likely",
          "line",
          "little",
          "ll",
          "location",
          "long",
          "looking",
          "looks",
          "lovely",
          "lunch",
          "main",
          "makes",
          "making",
          "man",
          "meal",
          "member",
          "men",
          "mess",
          "mind",
          "model",
          "molding",
          "moment",
          "mosquitoes",
          "motion",
          "mountain",
          "mountains",
          "mounted",
          "mug",
          "multiple",
          "natural",
          "near",
          "nearby",
          "never",
          "next",
          "nice",
          "notices",
          "object",
          "objects",
          "occurring",
          "offering",
          "oh",
          "okay",
          "older",
          "orange",
          "out",
          "outdoor",
          "outdoors",
          "outside",
          "over",
          "overhead",
          "panoramic",
          "pebbly",
          "people",
          "per",
          "person",
          "persons",
          "perspective",
          "phone",
          "photography",
          "pick",
          "picking",
          "pink",
          "place",
          "placed",
          "playing",
          "point",
          "pointing",
          "pole",
          "positioned",
          "positions",
          "possibly",
          "pot",
          "preparing",
          "presence",
          "present",
          "primary",
          "probably",
          "provides",
          "providing",
          "rain",
          "raincoat",
          "raincoats",
          "raw",
          "re",
          "reaching",
          "recommended",
          "recorded",
          "red",
          "reeling",
          "releasing",
          "resolution",
          "resulting",
          "retrieve",
          "river",
          "rocks",
          "rod",
          "rods",
          "sand",
          "scattered",
          "scene",
          "seconds",
          "seems",
          "seen",
          "sense",
          "sensor",
          "setting",
          "setup",
          "several",
          "shaky",
          "share",
          "sharon",
          "shells",
          "shirt",
          "shore",
          "shoreline",
          "shot",
          "shoulder",
          "showcasing",
          "showing",
          "shown",
          "shows",
          "side",
          "single",
          "sips",
          "sitting",
          "sky",
          "slight",
          "slightly",
          "small",
          "smiling",
          "snowsuit",
          "someone",
          "something",
          "sort",
          "spot",
          "stable",
          "standing",
          "stands",
          "sticky",
          "stomachs",
          "stream",
          "stuff",
          "stuffed",
          "subject",
          "subjects",
          "suggesting",
          "suggests",
          "summary",
          "supplies",
          "surface",
          "surrounding",
          "surroundings",
          "taken",
          "takes",
          "talking",
          "technical",
          "techniques",
          "tent",
          "tents",
          "thousands",
          "time",
          "tips",
          "toddler",
          "together",
          "tom",
          "tommy",
          "toward",
          "toys",
          "trail",
          "tree",
          "trees",
          "tricks",
          "trip",
          "tripod",
          "twigs",
          "umbrella",
          "under",
          "unsteady",
          "using",
          "various",
          "video",
          "view",
          "viewer",
          "viewers",
          "visible",
          "visuals",
          "walking",
          "wanna",
          "warm",
          "watches",
          "watching",
          "water",
          "way",
          "wearing",
          "weather",
          "weird",
          "wet",
          "white",
          "wide",
          "within",
          "witness",
          "wooded",
          "yeah",
          "young",
          "yup"
        ],
        "keyword_count": 444,
        "children": [
          "node_3_4",
          "node_3_5"
        ],
        "level": 4,
        "parent": "node_5_1"
      },
      "node_4_3": {
        "node_id": "node_4_3",
        "time_range": [
          240.0,
          299.999
        ],
        "duration": 59.999000000000024,
        "keywords": [
          "2015",
          "30",
          "31",
          "32",
          "360",
          "3d",
          "3rd",
          "54",
          "62",
          "above",
          "accurate",
          "activities",
          "activity",
          "adding",
          "additional",
          "adult",
          "adventure",
          "after",
          "aged",
          "along",
          "alright",
          "angle",
          "another",
          "appears",
          "area",
          "around",
          "array",
          "artifacts",
          "assortment",
          "atmosphere",
          "attract",
          "away",
          "background",
          "backpack",
          "backpacking",
          "backpacks",
          "bags",
          "ball",
          "balls",
          "baseball",
          "bears",
          "behind",
          "belongings",
          "between",
          "bite",
          "bivou",
          "black",
          "blow",
          "blowing",
          "blue",
          "blur",
          "body",
          "book",
          "bottle",
          "bottles",
          "bowl",
          "bowls",
          "boy",
          "boys",
          "broth",
          "camera",
          "cameras",
          "camper",
          "campfire",
          "camping",
          "campsite",
          "candle",
          "canister",
          "canvas",
          "cap",
          "capture",
          "captures",
          "capturing",
          "casual",
          "cell",
          "center",
          "chairs",
          "child",
          "children",
          "cleaning",
          "clearly",
          "close",
          "closer",
          "company",
          "conditions",
          "container",
          "conversation",
          "cooking",
          "cozy",
          "cup",
          "cups",
          "daily",
          "degree",
          "depicts",
          "descriptions",
          "detailed",
          "details",
          "discussing",
          "dishes",
          "dog",
          "dolly",
          "down",
          "dung",
          "eating",
          "either",
          "elements",
          "engaged",
          "engaging",
          "enjoy",
          "enjoying",
          "entire",
          "expedition",
          "explaining",
          "family",
          "father",
          "features",
          "featuring",
          "filming",
          "finger",
          "finished",
          "fire",
          "fish",
          "fishing",
          "flare",
          "flavored",
          "flying",
          "following",
          "food",
          "footage",
          "foreground",
          "frames",
          "frisbee",
          "front",
          "frying",
          "further",
          "garden",
          "gathered",
          "gear",
          "glasses",
          "god",
          "good",
          "green",
          "ground",
          "group",
          "groups",
          "guys",
          "hair",
          "haired",
          "hand",
          "handbag",
          "handing",
          "handling",
          "hands",
          "hat",
          "helmet",
          "hiking",
          "hold",
          "holding",
          "holds",
          "hungry",
          "image",
          "immersive",
          "includes",
          "indicate",
          "indicating",
          "input",
          "inside",
          "interacting",
          "interaction",
          "interactions",
          "interacts",
          "interesting",
          "involved",
          "item",
          "items",
          "kids",
          "kite",
          "knife",
          "knives",
          "knots",
          "lap",
          "leisure",
          "lens",
          "letters",
          "lid",
          "life",
          "lighting",
          "like",
          "likely",
          "little",
          "ll",
          "located",
          "looking",
          "lot",
          "lures",
          "main",
          "male",
          "man",
          "meal",
          "meals",
          "men",
          "mess",
          "messy",
          "methods",
          "middle",
          "military",
          "miscellaneous",
          "model",
          "moment",
          "motion",
          "mounted",
          "mouth",
          "multi",
          "multiple",
          "natural",
          "near",
          "nearby",
          "next",
          "numerous",
          "object",
          "objects",
          "oh",
          "oiling",
          "older",
          "others",
          "out",
          "outdoor",
          "outdoors",
          "outside",
          "oven",
          "over",
          "overall",
          "overhead",
          "pan",
          "pen",
          "people",
          "pepper",
          "person",
          "personal",
          "perspective",
          "phone",
          "place",
          "placed",
          "placing",
          "plates",
          "playing",
          "please",
          "pointing",
          "positioned",
          "possibly",
          "pot",
          "pots",
          "pouring",
          "preparing",
          "present",
          "pretty",
          "process",
          "provide",
          "providing",
          "proximity",
          "ramen",
          "ready",
          "recorded",
          "red",
          "relaxed",
          "representation",
          "resting",
          "right",
          "rod",
          "round",
          "salmon",
          "salt",
          "salted",
          "sandwich",
          "sandwiches",
          "scattered",
          "scene",
          "seated",
          "seconds",
          "seems",
          "seen",
          "setting",
          "settled",
          "several",
          "shaky",
          "share",
          "shared",
          "sharing",
          "shells",
          "shot",
          "showing",
          "shown",
          "shows",
          "side",
          "site",
          "siting",
          "sitting",
          "situation",
          "sleeping",
          "small",
          "smartphone",
          "snacks",
          "soldier",
          "someone",
          "something",
          "son",
          "sons",
          "spaghetti",
          "spoons",
          "sports",
          "stabilization",
          "stable",
          "standing",
          "sticky",
          "structure",
          "stuff",
          "sure",
          "surrounded",
          "surroundings",
          "survival",
          "table",
          "takes",
          "talking",
          "tastes",
          "technical",
          "tent",
          "tents",
          "tie",
          "time",
          "together",
          "tool",
          "top",
          "tracking",
          "trip",
          "tripod",
          "trout",
          "trowel",
          "type",
          "under",
          "uniform",
          "unique",
          "upcoming",
          "using",
          "various",
          "video",
          "view",
          "visible",
          "wall",
          "warm",
          "watches",
          "watching",
          "water",
          "way",
          "wearing",
          "well",
          "white",
          "wide",
          "wing",
          "winter",
          "yeah",
          "yellow",
          "young"
        ],
        "keyword_count": 362,
        "children": [
          "node_3_6",
          "node_3_7"
        ],
        "level": 4,
        "parent": "node_5_1"
      },
      "node_5_0": {
        "node_id": "node_5_0",
        "time_range": [
          0.0,
          160.0
        ],
        "duration": 160.0,
        "keywords": [
          "00",
          "01",
          "03",
          "08",
          "10",
          "12345",
          "15",
          "20",
          "27",
          "2nd",
          "30",
          "31",
          "32",
          "34",
          "35",
          "360",
          "365",
          "3d",
          "3rd",
          "45",
          "48",
          "4k",
          "57",
          "59",
          "64",
          "7373",
          "above",
          "across",
          "action",
          "actions",
          "activities",
          "activity",
          "adding",
          "addition",
          "additional",
          "additionally",
          "admiring",
          "adult",
          "adventure",
          "aerial",
          "aged",
          "ago",
          "aid",
          "air",
          "aircraft",
          "airplane",
          "alaska",
          "alaskan",
          "allowing",
          "allows",
          "along",
          "altitude",
          "amazing",
          "angle",
          "angles",
          "another",
          "appears",
          "appreciate",
          "arctic",
          "area",
          "areas",
          "arm",
          "around",
          "attached",
          "aviation",
          "away",
          "axe",
          "back",
          "background",
          "backpack",
          "backpacks",
          "bag",
          "bags",
          "bait",
          "ball",
          "barton",
          "beach",
          "bear",
          "beard",
          "beautiful",
          "beauty",
          "before",
          "behavior",
          "behind",
          "below",
          "bent",
          "beside",
          "between",
          "bicycles",
          "bird",
          "birds",
          "black",
          "blancher",
          "blanket",
          "blankets",
          "blue",
          "blurry",
          "board",
          "boat",
          "boats",
          "body",
          "bonk",
          "bottle",
          "boy",
          "boys",
          "brightest",
          "broader",
          "brown",
          "bu",
          "building",
          "bump",
          "bus",
          "bush",
          "buttons",
          "cabin",
          "calm",
          "camera",
          "cameras",
          "camp",
          "camping",
          "canister",
          "canopy",
          "cap",
          "captured",
          "captures",
          "capturing",
          "car",
          "carrying",
          "cars",
          "casting",
          "cause",
          "causing",
          "center",
          "chairs",
          "channel",
          "channels",
          "char",
          "characteristics",
          "chart",
          "chest",
          "child",
          "children",
          "clear",
          "clip",
          "close",
          "closely",
          "closer",
          "clothing",
          "cloudy",
          "coat",
          "coats",
          "cockpit",
          "coffee",
          "colored",
          "colors",
          "communication",
          "conditions",
          "connected",
          "container",
          "contains",
          "context",
          "contribute",
          "control",
          "controls",
          "conversation",
          "corner",
          "countryside",
          "covering",
          "craft",
          "crafting",
          "creates",
          "crucial",
          "cup",
          "daily",
          "dark",
          "dashboard",
          "dashcam",
          "daughter",
          "day",
          "days",
          "daytime",
          "definition",
          "degree",
          "deli",
          "departure",
          "depicting",
          "description",
          "descriptions",
          "detail",
          "details",
          "detected",
          "detection",
          "detections",
          "device",
          "dick",
          "different",
          "dinner",
          "disembark",
          "distance",
          "distinct",
          "distortion",
          "documentation",
          "dog",
          "dollar",
          "dolly",
          "door",
          "down",
          "dressed",
          "driver",
          "drivers",
          "driving",
          "drop",
          "dropped",
          "due",
          "dynamic",
          "earth",
          "edge",
          "edges",
          "editing",
          "effect",
          "elements",
          "engaging",
          "enjoying",
          "environment",
          "etc",
          "everyday",
          "excited",
          "excitement",
          "expansive",
          "experience",
          "exploring",
          "expression",
          "eye",
          "face",
          "facial",
          "fair",
          "family",
          "father",
          "features",
          "featuring",
          "field",
          "fiji",
          "file",
          "filled",
          "filming",
          "fish",
          "fisherman",
          "fishermen",
          "fisheye",
          "fishing",
          "flies",
          "flight",
          "float",
          "fly",
          "flying",
          "focal",
          "focus",
          "focused",
          "focusing",
          "following",
          "footage",
          "forecast",
          "forest",
          "forward",
          "frame",
          "frames",
          "front",
          "frying",
          "further",
          "gauges",
          "gear",
          "girl",
          "giving",
          "glasses",
          "glimpse",
          "going",
          "gonna",
          "gopro",
          "grab",
          "grailing",
          "grassy",
          "gravel",
          "gravelly",
          "gray",
          "green",
          "grey",
          "ground",
          "group",
          "groups",
          "gun",
          "guys",
          "half",
          "hand",
          "hands",
          "hanging",
          "harness",
          "hat",
          "head",
          "headphones",
          "held",
          "helicopter",
          "helmet",
          "high",
          "hiking",
          "hillside",
          "himself",
          "holding",
          "hole",
          "homestead",
          "hood",
          "hoodie",
          "hook",
          "hour",
          "house",
          "hugged",
          "huh",
          "hurry",
          "identified",
          "image",
          "immersive",
          "includes",
          "indicate",
          "indicates",
          "indicating",
          "individual",
          "information",
          "inside",
          "instruments",
          "interest",
          "interesting",
          "interior",
          "island",
          "jacket",
          "jackets",
          "jeans",
          "jumpsuits",
          "kaleidoscope",
          "kite",
          "km",
          "kneeling",
          "lake",
          "lakes",
          "landscape",
          "lapse",
          "laptop",
          "large",
          "length",
          "lens",
          "life",
          "light",
          "like",
          "likely",
          "line",
          "located",
          "location",
          "locations",
          "log",
          "long",
          "looking",
          "looks",
          "loss",
          "lot",
          "low",
          "luke",
          "lure",
          "machinery",
          "main",
          "making",
          "male",
          "man",
          "market",
          "marshy",
          "meal",
          "mean",
          "member",
          "men",
          "middle",
          "moment",
          "motion",
          "mountain",
          "mountainous",
          "mountains",
          "mounted",
          "mouth",
          "movement",
          "movements",
          "much",
          "mug",
          "multiple",
          "muted",
          "natural",
          "navigates",
          "navigating",
          "near",
          "nearby",
          "nearer",
          "next",
          "nh",
          "nothing",
          "noticeable",
          "number",
          "object",
          "objects",
          "observe",
          "observer",
          "observing",
          "ocean",
          "off",
          "oh",
          "okay",
          "older",
          "operating",
          "orange",
          "original",
          "ourselves",
          "out",
          "outdoor",
          "outdoors",
          "outfit",
          "outside",
          "over",
          "overall",
          "overcast",
          "overexposed",
          "overhead",
          "pack",
          "pan",
          "panoramic",
          "pants",
          "part",
          "passenger",
          "patch",
          "path",
          "pebble",
          "people",
          "person",
          "personal",
          "persons",
          "perspective",
          "perspectives",
          "photo",
          "picture",
          "picturesque",
          "piece",
          "pieces",
          "pilot",
          "pink",
          "place",
          "placed",
          "plane",
          "plants",
          "pockets",
          "point",
          "pointing",
          "pole",
          "pontoon",
          "positioned",
          "positioning",
          "possibly",
          "potentially",
          "pov",
          "prennicky",
          "preparing",
          "presence",
          "present",
          "presented",
          "production",
          "providing",
          "purposes",
          "radio",
          "raft",
          "rafting",
          "rain",
          "raincoat",
          "raining",
          "rainy",
          "range",
          "raw",
          "re",
          "ready",
          "rear",
          "recreational",
          "red",
          "relatively",
          "remote",
          "repair",
          "resolution",
          "respective",
          "right",
          "rightind",
          "river",
          "riverbank",
          "rivers",
          "road",
          "rock",
          "rocks",
          "rocky",
          "rod",
          "rods",
          "room",
          "rope",
          "saying",
          "says",
          "scattered",
          "scene",
          "scenery",
          "scenes",
          "scenic",
          "screen",
          "seaplane",
          "seat",
          "seated",
          "seats",
          "seconds",
          "seems",
          "seen",
          "sense",
          "serving",
          "setting",
          "several",
          "shaky",
          "sheet",
          "shelter",
          "shirt",
          "shore",
          "shoreline",
          "shot",
          "shots",
          "shoulder",
          "showcases",
          "showcasing",
          "showing",
          "shows",
          "shutter",
          "side",
          "similar",
          "simply",
          "sits",
          "sitting",
          "situated",
          "six",
          "ski",
          "skies",
          "sky",
          "slightly",
          "slow",
          "small",
          "smiling",
          "snowsuit",
          "snowy",
          "soars",
          "someone",
          "something",
          "somewhat",
          "son",
          "specific",
          "speed",
          "speedometer",
          "sports",
          "spot",
          "spray",
          "stability",
          "stable",
          "stall",
          "standing",
          "stands",
          "steering",
          "stool",
          "strapped",
          "stream",
          "structure",
          "structures",
          "stuck",
          "stuff",
          "stump",
          "stunning",
          "style",
          "subject",
          "subjects",
          "suggesting",
          "suggests",
          "suit",
          "sunglasses",
          "supplies",
          "surfaces",
          "surrounding",
          "surroundings",
          "switches",
          "system",
          "taken",
          "taking",
          "talking",
          "tan",
          "tank",
          "technical",
          "tent",
          "tents",
          "terrain",
          "time",
          "timelapse",
          "together",
          "tommy",
          "toob",
          "top",
          "total",
          "toward",
          "tracking",
          "tracks",
          "travel",
          "tree",
          "trees",
          "trip",
          "tripod",
          "trout",
          "turbulence",
          "turned",
          "twin",
          "twins",
          "ultra",
          "umbrella",
          "under",
          "understanding",
          "unfolds",
          "unique",
          "upper",
          "using",
          "valley",
          "valleys",
          "vantage",
          "vardin",
          "various",
          "varten",
          "vastness",
          "vehicle",
          "video",
          "videos",
          "view",
          "viewed",
          "viewer",
          "viewers",
          "views",
          "visible",
          "visual",
          "vlog",
          "waders",
          "walking",
          "walks",
          "wall",
          "water",
          "way",
          "wearing",
          "welcome",
          "well",
          "wetlands",
          "wheel",
          "white",
          "wide",
          "wider",
          "wilderness",
          "wildlife",
          "window",
          "wing",
          "wings",
          "within",
          "woman",
          "wooded",
          "wooden",
          "woods",
          "working",
          "works",
          "wow",
          "writing",
          "yeah",
          "yee",
          "yeee",
          "yep",
          "yes",
          "young",
          "youtube",
          "youtuber"
        ],
        "keyword_count": 680,
        "children": [
          "node_4_0",
          "node_4_1"
        ],
        "level": 5,
        "parent": "node_6_0"
      },
      "node_5_1": {
        "node_id": "node_5_1",
        "time_range": [
          160.0,
          299.999
        ],
        "duration": 139.99900000000002,
        "keywords": [
          "00",
          "01",
          "10",
          "19",
          "1k",
          "2015",
          "2d",
          "2k",
          "30",
          "31",
          "32",
          "360",
          "365",
          "3d",
          "3rd",
          "4k",
          "54",
          "56",
          "58",
          "62",
          "67",
          "79",
          "above",
          "accurate",
          "across",
          "action",
          "actions",
          "activities",
          "activity",
          "adding",
          "additional",
          "additionally",
          "adult",
          "adventure",
          "after",
          "aged",
          "ahead",
          "along",
          "alright",
          "aluminum",
          "angle",
          "angler",
          "animal",
          "animals",
          "another",
          "appears",
          "appropriate",
          "area",
          "around",
          "array",
          "art",
          "artifacts",
          "assortment",
          "atmosphere",
          "attire",
          "attract",
          "available",
          "away",
          "baby",
          "back",
          "background",
          "backpack",
          "backpacking",
          "backpacks",
          "bags",
          "bait",
          "ball",
          "balls",
          "bank",
          "barton",
          "baseball",
          "based",
          "beach",
          "bears",
          "beer",
          "behind",
          "belongings",
          "bend",
          "bending",
          "beside",
          "between",
          "bit",
          "bite",
          "bivou",
          "black",
          "blow",
          "blowing",
          "blue",
          "blur",
          "blurred",
          "blurry",
          "boat",
          "body",
          "boiling",
          "book",
          "bottle",
          "bottles",
          "bowl",
          "bowls",
          "boy",
          "boys",
          "broth",
          "brown",
          "bucket",
          "buddy",
          "bugs",
          "camera",
          "cameras",
          "camper",
          "campfire",
          "camping",
          "campsite",
          "candle",
          "canister",
          "canopy",
          "canvas",
          "cap",
          "capture",
          "captured",
          "captures",
          "capturing",
          "cast",
          "casts",
          "casual",
          "catching",
          "cell",
          "center",
          "chairs",
          "char",
          "chest",
          "child",
          "children",
          "chocolate",
          "cleaning",
          "clearer",
          "clearly",
          "close",
          "closer",
          "clothes",
          "clothing",
          "coat",
          "coffee",
          "color",
          "companions",
          "company",
          "compose",
          "compression",
          "conditions",
          "contain",
          "container",
          "contains",
          "context",
          "conversation",
          "cooking",
          "couple",
          "cozy",
          "creating",
          "cup",
          "cups",
          "daily",
          "days",
          "dead",
          "debris",
          "deep",
          "definitely",
          "degree",
          "depicting",
          "depicts",
          "descriptions",
          "detailed",
          "details",
          "detected",
          "dinner",
          "dirty",
          "discussing",
          "dishes",
          "distance",
          "distortion",
          "dog",
          "dolly",
          "done",
          "down",
          "dress",
          "dressed",
          "drinking",
          "dropped",
          "due",
          "dung",
          "eating",
          "edge",
          "edit",
          "effect",
          "either",
          "elements",
          "else",
          "emphasize",
          "engaged",
          "engaging",
          "enjoy",
          "enjoying",
          "enjoys",
          "entire",
          "environment",
          "essence",
          "evidenced",
          "exchange",
          "expedition",
          "experience",
          "experiencing",
          "explaining",
          "ey",
          "family",
          "father",
          "features",
          "featuring",
          "field",
          "filled",
          "film",
          "filming",
          "finger",
          "finished",
          "fire",
          "fish",
          "fisherman",
          "fisheye",
          "fishing",
          "flare",
          "flavored",
          "flies",
          "floor",
          "flying",
          "focus",
          "focused",
          "following",
          "food",
          "footage",
          "foreground",
          "forgot",
          "format",
          "frame",
          "frames",
          "frisbee",
          "front",
          "frying",
          "full",
          "further",
          "garden",
          "gathered",
          "gear",
          "gentleman",
          "giving",
          "glasses",
          "god",
          "goes",
          "gonna",
          "good",
          "gopro",
          "grab",
          "grabbing",
          "grainy",
          "gravel",
          "green",
          "ground",
          "group",
          "groups",
          "gun",
          "guy",
          "guys",
          "hair",
          "haired",
          "hand",
          "handbag",
          "handing",
          "handling",
          "hands",
          "handshake",
          "happy",
          "hat",
          "head",
          "helmet",
          "hey",
          "hi",
          "higher",
          "hiking",
          "hold",
          "holding",
          "holds",
          "hooded",
          "hoodie",
          "hot",
          "hungry",
          "image",
          "immersive",
          "includes",
          "indicate",
          "indicating",
          "individual",
          "individuals",
          "input",
          "inside",
          "interacting",
          "interaction",
          "interactions",
          "interacts",
          "interesting",
          "involved",
          "isn",
          "item",
          "items",
          "jacket",
          "jackets",
          "jumpsuit",
          "kettle",
          "kids",
          "kite",
          "knee",
          "knife",
          "knives",
          "knots",
          "lake",
          "lantern",
          "lap",
          "large",
          "laying",
          "leather",
          "leaves",
          "leisure",
          "lens",
          "letters",
          "lid",
          "life",
          "lighting",
          "lights",
          "like",
          "likely",
          "line",
          "little",
          "ll",
          "located",
          "location",
          "long",
          "looking",
          "looks",
          "lot",
          "lovely",
          "lunch",
          "lures",
          "main",
          "makes",
          "making",
          "male",
          "man",
          "meal",
          "meals",
          "member",
          "men",
          "mess",
          "messy",
          "methods",
          "middle",
          "military",
          "mind",
          "miscellaneous",
          "model",
          "molding",
          "moment",
          "mosquitoes",
          "motion",
          "mountain",
          "mountains",
          "mounted",
          "mouth",
          "mug",
          "multi",
          "multiple",
          "natural",
          "near",
          "nearby",
          "never",
          "next",
          "nice",
          "notices",
          "numerous",
          "object",
          "objects",
          "occurring",
          "offering",
          "oh",
          "oiling",
          "okay",
          "older",
          "orange",
          "others",
          "out",
          "outdoor",
          "outdoors",
          "outside",
          "oven",
          "over",
          "overall",
          "overhead",
          "pan",
          "panoramic",
          "pebbly",
          "pen",
          "people",
          "pepper",
          "per",
          "person",
          "personal",
          "persons",
          "perspective",
          "phone",
          "photography",
          "pick",
          "picking",
          "pink",
          "place",
          "placed",
          "placing",
          "plates",
          "playing",
          "please",
          "point",
          "pointing",
          "pole",
          "positioned",
          "positions",
          "possibly",
          "pot",
          "pots",
          "pouring",
          "preparing",
          "presence",
          "present",
          "pretty",
          "primary",
          "probably",
          "process",
          "provide",
          "provides",
          "providing",
          "proximity",
          "rain",
          "raincoat",
          "raincoats",
          "ramen",
          "raw",
          "re",
          "reaching",
          "ready",
          "recommended",
          "recorded",
          "red",
          "reeling",
          "relaxed",
          "releasing",
          "representation",
          "resolution",
          "resting",
          "resulting",
          "retrieve",
          "right",
          "river",
          "rocks",
          "rod",
          "rods",
          "round",
          "salmon",
          "salt",
          "salted",
          "sand",
          "sandwich",
          "sandwiches",
          "scattered",
          "scene",
          "seated",
          "seconds",
          "seems",
          "seen",
          "sense",
          "sensor",
          "setting",
          "settled",
          "setup",
          "several",
          "shaky",
          "share",
          "shared",
          "sharing",
          "sharon",
          "shells",
          "shirt",
          "shore",
          "shoreline",
          "shot",
          "shoulder",
          "showcasing",
          "showing",
          "shown",
          "shows",
          "side",
          "single",
          "sips",
          "site",
          "siting",
          "sitting",
          "situation",
          "sky",
          "sleeping",
          "slight",
          "slightly",
          "small",
          "smartphone",
          "smiling",
          "snacks",
          "snowsuit",
          "soldier",
          "someone",
          "something",
          "son",
          "sons",
          "sort",
          "spaghetti",
          "spoons",
          "sports",
          "spot",
          "stabilization",
          "stable",
          "standing",
          "stands",
          "sticky",
          "stomachs",
          "stream",
          "structure",
          "stuff",
          "stuffed",
          "subject",
          "subjects",
          "suggesting",
          "suggests",
          "summary",
          "supplies",
          "sure",
          "surface",
          "surrounded",
          "surrounding",
          "surroundings",
          "survival",
          "table",
          "taken",
          "takes",
          "talking",
          "tastes",
          "technical",
          "techniques",
          "tent",
          "tents",
          "thousands",
          "tie",
          "time",
          "tips",
          "toddler",
          "together",
          "tom",
          "tommy",
          "tool",
          "top",
          "toward",
          "toys",
          "tracking",
          "trail",
          "tree",
          "trees",
          "tricks",
          "trip",
          "tripod",
          "trout",
          "trowel",
          "twigs",
          "type",
          "umbrella",
          "under",
          "uniform",
          "unique",
          "unsteady",
          "upcoming",
          "using",
          "various",
          "video",
          "view",
          "viewer",
          "viewers",
          "visible",
          "visuals",
          "walking",
          "wall",
          "wanna",
          "warm",
          "watches",
          "watching",
          "water",
          "way",
          "wearing",
          "weather",
          "weird",
          "well",
          "wet",
          "white",
          "wide",
          "wing",
          "winter",
          "within",
          "witness",
          "wooded",
          "yeah",
          "yellow",
          "young",
          "yup"
        ],
        "keyword_count": 619,
        "children": [
          "node_4_2",
          "node_4_3"
        ],
        "level": 5,
        "parent": "node_6_0"
      },
      "node_6_0": {
        "node_id": "node_6_0",
        "time_range": [
          0.0,
          299.999
        ],
        "duration": 299.999,
        "keywords": [
          "00",
          "01",
          "03",
          "08",
          "10",
          "12345",
          "15",
          "19",
          "1k",
          "20",
          "2015",
          "27",
          "2d",
          "2k",
          "2nd",
          "30",
          "31",
          "32",
          "34",
          "35",
          "360",
          "365",
          "3d",
          "3rd",
          "45",
          "48",
          "4k",
          "54",
          "56",
          "57",
          "58",
          "59",
          "62",
          "64",
          "67",
          "7373",
          "79",
          "above",
          "accurate",
          "across",
          "action",
          "actions",
          "activities",
          "activity",
          "adding",
          "addition",
          "additional",
          "additionally",
          "admiring",
          "adult",
          "adventure",
          "aerial",
          "after",
          "aged",
          "ago",
          "ahead",
          "aid",
          "air",
          "aircraft",
          "airplane",
          "alaska",
          "alaskan",
          "allowing",
          "allows",
          "along",
          "alright",
          "altitude",
          "aluminum",
          "amazing",
          "angle",
          "angler",
          "angles",
          "animal",
          "animals",
          "another",
          "appears",
          "appreciate",
          "appropriate",
          "arctic",
          "area",
          "areas",
          "arm",
          "around",
          "array",
          "art",
          "artifacts",
          "assortment",
          "atmosphere",
          "attached",
          "attire",
          "attract",
          "available",
          "aviation",
          "away",
          "axe",
          "baby",
          "back",
          "background",
          "backpack",
          "backpacking",
          "backpacks",
          "bag",
          "bags",
          "bait",
          "ball",
          "balls",
          "bank",
          "barton",
          "baseball",
          "based",
          "beach",
          "bear",
          "beard",
          "bears",
          "beautiful",
          "beauty",
          "beer",
          "before",
          "behavior",
          "behind",
          "belongings",
          "below",
          "bend",
          "bending",
          "bent",
          "beside",
          "between",
          "bicycles",
          "bird",
          "birds",
          "bit",
          "bite",
          "bivou",
          "black",
          "blancher",
          "blanket",
          "blankets",
          "blow",
          "blowing",
          "blue",
          "blur",
          "blurred",
          "blurry",
          "board",
          "boat",
          "boats",
          "body",
          "boiling",
          "bonk",
          "book",
          "bottle",
          "bottles",
          "bowl",
          "bowls",
          "boy",
          "boys",
          "brightest",
          "broader",
          "broth",
          "brown",
          "bu",
          "bucket",
          "buddy",
          "bugs",
          "building",
          "bump",
          "bus",
          "bush",
          "buttons",
          "cabin",
          "calm",
          "camera",
          "cameras",
          "camp",
          "camper",
          "campfire",
          "camping",
          "campsite",
          "candle",
          "canister",
          "canopy",
          "canvas",
          "cap",
          "capture",
          "captured",
          "captures",
          "capturing",
          "car",
          "carrying",
          "cars",
          "cast",
          "casting",
          "casts",
          "casual",
          "catching",
          "cause",
          "causing",
          "cell",
          "center",
          "chairs",
          "channel",
          "channels",
          "char",
          "characteristics",
          "chart",
          "chest",
          "child",
          "children",
          "chocolate",
          "cleaning",
          "clear",
          "clearer",
          "clearly",
          "clip",
          "close",
          "closely",
          "closer",
          "clothes",
          "clothing",
          "cloudy",
          "coat",
          "coats",
          "cockpit",
          "coffee",
          "color",
          "colored",
          "colors",
          "communication",
          "companions",
          "company",
          "compose",
          "compression",
          "conditions",
          "connected",
          "contain",
          "container",
          "contains",
          "context",
          "contribute",
          "control",
          "controls",
          "conversation",
          "cooking",
          "corner",
          "countryside",
          "couple",
          "covering",
          "cozy",
          "craft",
          "crafting",
          "creates",
          "creating",
          "crucial",
          "cup",
          "cups",
          "daily",
          "dark",
          "dashboard",
          "dashcam",
          "daughter",
          "day",
          "days",
          "daytime",
          "dead",
          "debris",
          "deep",
          "definitely",
          "definition",
          "degree",
          "deli",
          "departure",
          "depicting",
          "depicts",
          "description",
          "descriptions",
          "detail",
          "detailed",
          "details",
          "detected",
          "detection",
          "detections",
          "device",
          "dick",
          "different",
          "dinner",
          "dirty",
          "discussing",
          "disembark",
          "dishes",
          "distance",
          "distinct",
          "distortion",
          "documentation",
          "dog",
          "dollar",
          "dolly",
          "done",
          "door",
          "down",
          "dress",
          "dressed",
          "drinking",
          "driver",
          "drivers",
          "driving",
          "drop",
          "dropped",
          "due",
          "dung",
          "dynamic",
          "earth",
          "eating",
          "edge",
          "edges",
          "edit",
          "editing",
          "effect",
          "either",
          "elements",
          "else",
          "emphasize",
          "engaged",
          "engaging",
          "enjoy",
          "enjoying",
          "enjoys",
          "entire",
          "environment",
          "essence",
          "etc",
          "everyday",
          "evidenced",
          "exchange",
          "excited",
          "excitement",
          "expansive",
          "expedition",
          "experience",
          "experiencing",
          "explaining",
          "exploring",
          "expression",
          "ey",
          "eye",
          "face",
          "facial",
          "fair",
          "family",
          "father",
          "features",
          "featuring",
          "field",
          "fiji",
          "file",
          "filled",
          "film",
          "filming",
          "finger",
          "finished",
          "fire",
          "fish",
          "fisherman",
          "fishermen",
          "fisheye",
          "fishing",
          "flare",
          "flavored",
          "flies",
          "flight",
          "float",
          "floor",
          "fly",
          "flying",
          "focal",
          "focus",
          "focused",
          "focusing",
          "following",
          "food",
          "footage",
          "forecast",
          "foreground",
          "forest",
          "forgot",
          "format",
          "forward",
          "frame",
          "frames",
          "frisbee",
          "front",
          "frying",
          "full",
          "further",
          "garden",
          "gathered",
          "gauges",
          "gear",
          "gentleman",
          "girl",
          "giving",
          "glasses",
          "glimpse",
          "god",
          "goes",
          "going",
          "gonna",
          "good",
          "gopro",
          "grab",
          "grabbing",
          "grailing",
          "grainy",
          "grassy",
          "gravel",
          "gravelly",
          "gray",
          "green",
          "grey",
          "ground",
          "group",
          "groups",
          "gun",
          "guy",
          "guys",
          "hair",
          "haired",
          "half",
          "hand",
          "handbag",
          "handing",
          "handling",
          "hands",
          "handshake",
          "hanging",
          "happy",
          "harness",
          "hat",
          "head",
          "headphones",
          "held",
          "helicopter",
          "helmet",
          "hey",
          "hi",
          "high",
          "higher",
          "hiking",
          "hillside",
          "himself",
          "hold",
          "holding",
          "holds",
          "hole",
          "homestead",
          "hood",
          "hooded",
          "hoodie",
          "hook",
          "hot",
          "hour",
          "house",
          "hugged",
          "huh",
          "hungry",
          "hurry",
          "identified",
          "image",
          "immersive",
          "includes",
          "indicate",
          "indicates",
          "indicating",
          "individual",
          "individuals",
          "information",
          "input",
          "inside",
          "instruments",
          "interacting",
          "interaction",
          "interactions",
          "interacts",
          "interest",
          "interesting",
          "interior",
          "involved",
          "island",
          "isn",
          "item",
          "items",
          "jacket",
          "jackets",
          "jeans",
          "jumpsuit",
          "jumpsuits",
          "kaleidoscope",
          "kettle",
          "kids",
          "kite",
          "km",
          "knee",
          "kneeling",
          "knife",
          "knives",
          "knots",
          "lake",
          "lakes",
          "landscape",
          "lantern",
          "lap",
          "lapse",
          "laptop",
          "large",
          "laying",
          "leather",
          "leaves",
          "leisure",
          "length",
          "lens",
          "letters",
          "lid",
          "life",
          "light",
          "lighting",
          "lights",
          "like",
          "likely",
          "line",
          "little",
          "ll",
          "located",
          "location",
          "locations",
          "log",
          "long",
          "looking",
          "looks",
          "loss",
          "lot",
          "lovely",
          "low",
          "luke",
          "lunch",
          "lure",
          "lures",
          "machinery",
          "main",
          "makes",
          "making",
          "male",
          "man",
          "market",
          "marshy",
          "meal",
          "meals",
          "mean",
          "member",
          "men",
          "mess",
          "messy",
          "methods",
          "middle",
          "military",
          "mind",
          "miscellaneous",
          "model",
          "molding",
          "moment",
          "mosquitoes",
          "motion",
          "mountain",
          "mountainous",
          "mountains",
          "mounted",
          "mouth",
          "movement",
          "movements",
          "much",
          "mug",
          "multi",
          "multiple",
          "muted",
          "natural",
          "navigates",
          "navigating",
          "near",
          "nearby",
          "nearer",
          "never",
          "next",
          "nh",
          "nice",
          "nothing",
          "noticeable",
          "notices",
          "number",
          "numerous",
          "object",
          "objects",
          "observe",
          "observer",
          "observing",
          "occurring",
          "ocean",
          "off",
          "offering",
          "oh",
          "oiling",
          "okay",
          "older",
          "operating",
          "orange",
          "original",
          "others",
          "ourselves",
          "out",
          "outdoor",
          "outdoors",
          "outfit",
          "outside",
          "oven",
          "over",
          "overall",
          "overcast",
          "overexposed",
          "overhead",
          "pack",
          "pan",
          "panoramic",
          "pants",
          "part",
          "passenger",
          "patch",
          "path",
          "pebble",
          "pebbly",
          "pen",
          "people",
          "pepper",
          "per",
          "person",
          "personal",
          "persons",
          "perspective",
          "perspectives",
          "phone",
          "photo",
          "photography",
          "pick",
          "picking",
          "picture",
          "picturesque",
          "piece",
          "pieces",
          "pilot",
          "pink",
          "place",
          "placed",
          "placing",
          "plane",
          "plants",
          "plates",
          "playing",
          "please",
          "pockets",
          "point",
          "pointing",
          "pole",
          "pontoon",
          "positioned",
          "positioning",
          "positions",
          "possibly",
          "pot",
          "potentially",
          "pots",
          "pouring",
          "pov",
          "prennicky",
          "preparing",
          "presence",
          "present",
          "presented",
          "pretty",
          "primary",
          "probably",
          "process",
          "production",
          "provide",
          "provides",
          "providing",
          "proximity",
          "purposes",
          "radio",
          "raft",
          "rafting",
          "rain",
          "raincoat",
          "raincoats",
          "raining",
          "rainy",
          "ramen",
          "range",
          "raw",
          "re",
          "reaching",
          "ready",
          "rear",
          "recommended",
          "recorded",
          "recreational",
          "red",
          "reeling",
          "relatively",
          "relaxed",
          "releasing",
          "remote",
          "repair",
          "representation",
          "resolution",
          "respective",
          "resting",
          "resulting",
          "retrieve",
          "right",
          "rightind",
          "river",
          "riverbank",
          "rivers",
          "road",
          "rock",
          "rocks",
          "rocky",
          "rod",
          "rods",
          "room",
          "rope",
          "round",
          "salmon",
          "salt",
          "salted",
          "sand",
          "sandwich",
          "sandwiches",
          "saying",
          "says",
          "scattered",
          "scene",
          "scenery",
          "scenes",
          "scenic",
          "screen",
          "seaplane",
          "seat",
          "seated",
          "seats",
          "seconds",
          "seems",
          "seen",
          "sense",
          "sensor",
          "serving",
          "setting",
          "settled",
          "setup",
          "several",
          "shaky",
          "share",
          "shared",
          "sharing",
          "sharon",
          "sheet",
          "shells",
          "shelter",
          "shirt",
          "shore",
          "shoreline",
          "shot",
          "shots",
          "shoulder",
          "showcases",
          "showcasing",
          "showing",
          "shown",
          "shows",
          "shutter",
          "side",
          "similar",
          "simply",
          "single",
          "sips",
          "site",
          "siting",
          "sits",
          "sitting",
          "situated",
          "situation",
          "six",
          "ski",
          "skies",
          "sky",
          "sleeping",
          "slight",
          "slightly",
          "slow",
          "small",
          "smartphone",
          "smiling",
          "snacks",
          "snowsuit",
          "snowy",
          "soars",
          "soldier",
          "someone",
          "something",
          "somewhat",
          "son",
          "sons",
          "sort",
          "spaghetti",
          "specific",
          "speed",
          "speedometer",
          "spoons",
          "sports",
          "spot",
          "spray",
          "stability",
          "stabilization",
          "stable",
          "stall",
          "standing",
          "stands",
          "steering",
          "sticky",
          "stomachs",
          "stool",
          "strapped",
          "stream",
          "structure",
          "structures",
          "stuck",
          "stuff",
          "stuffed",
          "stump",
          "stunning",
          "style",
          "subject",
          "subjects",
          "suggesting",
          "suggests",
          "suit",
          "summary",
          "sunglasses",
          "supplies",
          "sure",
          "surface",
          "surfaces",
          "surrounded",
          "surrounding",
          "surroundings",
          "survival",
          "switches",
          "system",
          "table",
          "taken",
          "takes",
          "taking",
          "talking",
          "tan",
          "tank",
          "tastes",
          "technical",
          "techniques",
          "tent",
          "tents",
          "terrain",
          "thousands",
          "tie",
          "time",
          "timelapse",
          "tips",
          "toddler",
          "together",
          "tom",
          "tommy",
          "toob",
          "tool",
          "top",
          "total",
          "toward",
          "toys",
          "tracking",
          "tracks",
          "trail",
          "travel",
          "tree",
          "trees",
          "tricks",
          "trip",
          "tripod",
          "trout",
          "trowel",
          "turbulence",
          "turned",
          "twigs",
          "twin",
          "twins",
          "type",
          "ultra",
          "umbrella",
          "under",
          "understanding",
          "unfolds",
          "uniform",
          "unique",
          "unsteady",
          "upcoming",
          "upper",
          "using",
          "valley",
          "valleys",
          "vantage",
          "vardin",
          "various",
          "varten",
          "vastness",
          "vehicle",
          "video",
          "videos",
          "view",
          "viewed",
          "viewer",
          "viewers",
          "views",
          "visible",
          "visual",
          "visuals",
          "vlog",
          "waders",
          "walking",
          "walks",
          "wall",
          "wanna",
          "warm",
          "watches",
          "watching",
          "water",
          "way",
          "wearing",
          "weather",
          "weird",
          "welcome",
          "well",
          "wet",
          "wetlands",
          "wheel",
          "white",
          "wide",
          "wider",
          "wilderness",
          "wildlife",
          "window",
          "wing",
          "wings",
          "winter",
          "within",
          "witness",
          "woman",
          "wooded",
          "wooden",
          "woods",
          "working",
          "works",
          "wow",
          "writing",
          "yeah",
          "yee",
          "yeee",
          "yellow",
          "yep",
          "yes",
          "young",
          "youtube",
          "youtuber",
          "yup"
        ],
        "keyword_count": 986,
        "children": [
          "node_5_0",
          "node_5_1"
        ],
        "level": 6,
        "parent": null
      }
    },
    "indexes": {
      "by_time": {
        "0.0-5.0": "leaf_0",
        "5.0-10.0": "leaf_1",
        "10.0-15.0": "leaf_2",
        "15.0-20.0": "leaf_3",
        "20.0-25.0": "leaf_4",
        "25.0-30.0": "leaf_5",
        "30.0-35.0": "leaf_6",
        "35.0-40.0": "leaf_7",
        "40.0-45.0": "leaf_8",
        "45.0-50.0": "leaf_9",
        "50.0-55.0": "leaf_10",
        "55.0-60.0": "leaf_11",
        "60.0-65.0": "leaf_12",
        "65.0-70.0": "leaf_13",
        "70.0-75.0": "leaf_14",
        "75.0-80.0": "leaf_15",
        "80.0-85.0": "leaf_16",
        "85.0-90.0": "leaf_17",
        "90.0-95.0": "leaf_18",
        "95.0-100.0": "leaf_19",
        "100.0-105.0": "leaf_20",
        "105.0-110.0": "leaf_21",
        "110.0-115.0": "leaf_22",
        "115.0-120.0": "leaf_23",
        "120.0-125.0": "leaf_24",
        "125.0-130.0": "leaf_25",
        "130.0-135.0": "leaf_26",
        "135.0-140.0": "leaf_27",
        "140.0-145.0": "leaf_28",
        "145.0-150.0": "leaf_29",
        "150.0-155.0": "leaf_30",
        "155.0-160.0": "leaf_31",
        "160.0-165.0": "leaf_32",
        "165.0-170.0": "leaf_33",
        "170.0-175.0": "leaf_34",
        "175.0-180.0": "leaf_35",
        "180.0-185.0": "leaf_36",
        "185.0-190.0": "leaf_37",
        "190.0-195.0": "leaf_38",
        "195.0-200.0": "leaf_39",
        "200.0-205.0": "leaf_40",
        "205.0-210.0": "leaf_41",
        "210.0-215.0": "leaf_42",
        "215.0-220.0": "leaf_43",
        "220.0-225.0": "leaf_44",
        "225.0-230.0": "leaf_45",
        "230.0-235.0": "leaf_46",
        "235.0-240.0": "leaf_47",
        "240.0-245.0": "leaf_48",
        "245.0-250.0": "leaf_49",
        "250.0-255.0": "leaf_50",
        "255.0-260.0": "leaf_51",
        "260.0-265.0": "leaf_52",
        "265.0-270.0": "leaf_53",
        "270.0-275.0": "leaf_54",
        "275.0-280.0": "leaf_55",
        "280.0-285.0": "leaf_56",
        "285.0-290.0": "leaf_57",
        "290.0-295.0": "leaf_58",
        "295.0-300.0": "leaf_59",
        "0.0-10.0": "node_1_0",
        "10.0-20.0": "node_1_1",
        "20.0-30.0": "node_1_2",
        "30.0-40.0": "node_1_3",
        "40.0-50.0": "node_1_4",
        "50.0-60.0": "node_1_5",
        "60.0-70.0": "node_1_6",
        "70.0-80.0": "node_1_7",
        "80.0-90.0": "node_1_8",
        "90.0-100.0": "node_1_9",
        "100.0-110.0": "node_1_10",
        "110.0-120.0": "node_1_11",
        "120.0-130.0": "node_1_12",
        "130.0-140.0": "node_1_13",
        "140.0-150.0": "node_1_14",
        "150.0-160.0": "node_1_15",
        "160.0-170.0": "node_1_16",
        "170.0-180.0": "node_1_17",
        "180.0-190.0": "node_1_18",
        "190.0-200.0": "node_1_19",
        "200.0-210.0": "node_1_20",
        "210.0-220.0": "node_1_21",
        "220.0-230.0": "node_1_22",
        "230.0-240.0": "node_1_23",
        "240.0-250.0": "node_1_24",
        "250.0-260.0": "node_1_25",
        "260.0-270.0": "node_1_26",
        "270.0-280.0": "node_1_27",
        "280.0-290.0": "node_1_28",
        "290.0-300.0": "node_1_29",
        "0.0-20.0": "node_2_0",
        "20.0-40.0": "node_2_1",
        "40.0-60.0": "node_2_2",
        "60.0-80.0": "node_2_3",
        "80.0-100.0": "node_2_4",
        "100.0-120.0": "node_2_5",
        "120.0-140.0": "node_2_6",
        "140.0-160.0": "node_2_7",
        "160.0-180.0": "node_2_8",
        "180.0-200.0": "node_2_9",
        "200.0-220.0": "node_2_10",
        "220.0-240.0": "node_2_11",
        "240.0-260.0": "node_2_12",
        "260.0-280.0": "node_2_13",
        "280.0-300.0": "node_3_7",
        "0.0-40.0": "node_3_0",
        "40.0-80.0": "node_3_1",
        "80.0-120.0": "node_3_2",
        "120.0-160.0": "node_3_3",
        "160.0-200.0": "node_3_4",
        "200.0-240.0": "node_3_5",
        "240.0-280.0": "node_3_6",
        "0.0-80.0": "node_4_0",
        "80.0-160.0": "node_4_1",
        "160.0-240.0": "node_4_2",
        "240.0-300.0": "node_4_3",
        "0.0-160.0": "node_5_0",
        "160.0-300.0": "node_5_1",
        "0.0-300.0": "node_6_0"
      },
      "by_keyword": {
        "360": [
          "leaf_0",
          "leaf_2",
          "leaf_5",
          "leaf_10",
          "leaf_16",
          "leaf_20",
          "leaf_27",
          "leaf_28",
          "leaf_34",
          "leaf_40",
          "leaf_54",
          "leaf_55",
          "leaf_57",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_5",
          "node_1_8",
          "node_1_10",
          "node_1_13",
          "node_1_14",
          "node_1_17",
          "node_1_20",
          "node_1_27",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_10",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "action": [
          "leaf_0",
          "leaf_17",
          "leaf_29",
          "leaf_31",
          "leaf_35",
          "leaf_37",
          "leaf_38",
          "leaf_41",
          "leaf_42",
          "leaf_43",
          "node_1_0",
          "node_1_8",
          "node_1_14",
          "node_1_15",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_2_0",
          "node_2_4",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_3_0",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "air": [
          "leaf_0",
          "node_1_0",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "airplane": [
          "leaf_0",
          "leaf_6",
          "leaf_7",
          "leaf_8",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_13",
          "node_1_0",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "alaska": [
          "leaf_0",
          "leaf_1",
          "leaf_16",
          "node_1_0",
          "node_1_8",
          "node_2_0",
          "node_2_4",
          "node_3_0",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "appears": [
          "leaf_0",
          "leaf_4",
          "leaf_5",
          "leaf_6",
          "leaf_10",
          "leaf_12",
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "leaf_21",
          "leaf_25",
          "leaf_27",
          "leaf_32",
          "leaf_35",
          "leaf_38",
          "leaf_40",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_51",
          "leaf_55",
          "leaf_56",
          "leaf_58",
          "node_1_0",
          "node_1_2",
          "node_1_3",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_10",
          "node_1_12",
          "node_1_13",
          "node_1_16",
          "node_1_17",
          "node_1_19",
          "node_1_20",
          "node_1_22",
          "node_1_23",
          "node_1_25",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "area": [
          "leaf_0",
          "leaf_7",
          "leaf_8",
          "leaf_9",
          "leaf_10",
          "leaf_12",
          "leaf_16",
          "leaf_20",
          "leaf_21",
          "leaf_25",
          "leaf_28",
          "leaf_29",
          "leaf_32",
          "leaf_41",
          "leaf_44",
          "leaf_46",
          "leaf_47",
          "leaf_55",
          "leaf_58",
          "node_1_0",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_8",
          "node_1_10",
          "node_1_12",
          "node_1_14",
          "node_1_16",
          "node_1_20",
          "node_1_22",
          "node_1_23",
          "node_1_27",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_10",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "back": [
          "leaf_0",
          "leaf_2",
          "leaf_5",
          "leaf_10",
          "leaf_17",
          "leaf_20",
          "leaf_21",
          "leaf_37",
          "leaf_41",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_5",
          "node_1_8",
          "node_1_10",
          "node_1_18",
          "node_1_20",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_4",
          "node_2_5",
          "node_2_9",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "background": [
          "leaf_0",
          "leaf_6",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_15",
          "leaf_17",
          "leaf_23",
          "leaf_24",
          "leaf_27",
          "leaf_31",
          "leaf_38",
          "leaf_44",
          "leaf_47",
          "leaf_59",
          "node_1_0",
          "node_1_3",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_15",
          "node_1_19",
          "node_1_22",
          "node_1_23",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_9",
          "node_2_11",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "beautiful": [
          "leaf_0",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_16",
          "node_1_0",
          "node_1_4",
          "node_1_5",
          "node_1_8",
          "node_2_0",
          "node_2_2",
          "node_2_4",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "behind": [
          "leaf_0",
          "leaf_5",
          "leaf_12",
          "leaf_23",
          "leaf_25",
          "leaf_28",
          "leaf_30",
          "leaf_31",
          "leaf_45",
          "leaf_59",
          "node_1_0",
          "node_1_2",
          "node_1_6",
          "node_1_11",
          "node_1_12",
          "node_1_14",
          "node_1_15",
          "node_1_22",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_3",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_11",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "blue": [
          "leaf_0",
          "leaf_10",
          "leaf_12",
          "leaf_13",
          "leaf_20",
          "leaf_25",
          "leaf_46",
          "leaf_50",
          "leaf_52",
          "leaf_53",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "leaf_58",
          "leaf_59",
          "node_1_0",
          "node_1_5",
          "node_1_6",
          "node_1_10",
          "node_1_12",
          "node_1_23",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_2",
          "node_2_3",
          "node_2_5",
          "node_2_6",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "boys": [
          "leaf_0",
          "leaf_1",
          "leaf_4",
          "leaf_8",
          "leaf_34",
          "leaf_48",
          "leaf_49",
          "node_1_0",
          "node_1_2",
          "node_1_4",
          "node_1_17",
          "node_1_24",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_8",
          "node_2_12",
          "node_3_0",
          "node_3_1",
          "node_3_4",
          "node_3_6",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "camera": [
          "leaf_0",
          "leaf_1",
          "leaf_2",
          "leaf_4",
          "leaf_5",
          "leaf_6",
          "leaf_7",
          "leaf_8",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_14",
          "leaf_16",
          "leaf_17",
          "leaf_18",
          "leaf_20",
          "leaf_21",
          "leaf_22",
          "leaf_23",
          "leaf_24",
          "leaf_27",
          "leaf_28",
          "leaf_29",
          "leaf_30",
          "leaf_31",
          "leaf_32",
          "leaf_34",
          "leaf_35",
          "leaf_36",
          "leaf_37",
          "leaf_38",
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "leaf_43",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_48",
          "leaf_49",
          "leaf_50",
          "leaf_52",
          "leaf_55",
          "leaf_56",
          "leaf_59",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "camp": [
          "leaf_0",
          "leaf_1",
          "node_1_0",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "captures": [
          "leaf_0",
          "leaf_1",
          "leaf_4",
          "leaf_8",
          "leaf_9",
          "leaf_10",
          "leaf_12",
          "leaf_27",
          "leaf_40",
          "leaf_41",
          "leaf_43",
          "leaf_45",
          "leaf_50",
          "leaf_51",
          "leaf_52",
          "leaf_56",
          "node_1_0",
          "node_1_2",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_13",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_25",
          "node_1_26",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_6",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "channel": [
          "leaf_0",
          "leaf_1",
          "node_1_0",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "days": [
          "leaf_0",
          "leaf_1",
          "leaf_15",
          "leaf_16",
          "leaf_37",
          "leaf_39",
          "node_1_0",
          "node_1_7",
          "node_1_8",
          "node_1_18",
          "node_1_19",
          "node_2_0",
          "node_2_3",
          "node_2_4",
          "node_2_9",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "degree": [
          "leaf_0",
          "leaf_5",
          "leaf_10",
          "leaf_16",
          "leaf_27",
          "leaf_28",
          "leaf_34",
          "leaf_40",
          "leaf_55",
          "leaf_57",
          "node_1_0",
          "node_1_2",
          "node_1_5",
          "node_1_8",
          "node_1_13",
          "node_1_14",
          "node_1_17",
          "node_1_20",
          "node_1_27",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_4",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_10",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "dropped": [
          "leaf_0",
          "leaf_1",
          "leaf_36",
          "node_1_0",
          "node_1_18",
          "node_2_0",
          "node_2_9",
          "node_3_0",
          "node_3_4",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "environment": [
          "leaf_0",
          "leaf_2",
          "leaf_27",
          "leaf_29",
          "leaf_42",
          "node_1_0",
          "node_1_1",
          "node_1_13",
          "node_1_14",
          "node_1_21",
          "node_2_0",
          "node_2_6",
          "node_2_7",
          "node_2_10",
          "node_3_0",
          "node_3_3",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "excitement": [
          "leaf_0",
          "leaf_31",
          "node_1_0",
          "node_1_15",
          "node_2_0",
          "node_2_7",
          "node_3_0",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "experience": [
          "leaf_0",
          "leaf_6",
          "leaf_9",
          "leaf_35",
          "leaf_42",
          "leaf_46",
          "node_1_0",
          "node_1_3",
          "node_1_4",
          "node_1_17",
          "node_1_21",
          "node_1_23",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_8",
          "node_2_10",
          "node_2_11",
          "node_3_0",
          "node_3_1",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "fiji": [
          "leaf_0",
          "node_1_0",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "flight": [
          "leaf_0",
          "leaf_6",
          "node_1_0",
          "node_1_3",
          "node_2_0",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "float": [
          "leaf_0",
          "leaf_1",
          "leaf_16",
          "leaf_17",
          "node_1_0",
          "node_1_8",
          "node_2_0",
          "node_2_4",
          "node_3_0",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "flying": [
          "leaf_0",
          "leaf_3",
          "leaf_6",
          "leaf_7",
          "leaf_8",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_51",
          "node_1_0",
          "node_1_1",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_25",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_12",
          "node_3_0",
          "node_3_1",
          "node_3_6",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "going": [
          "leaf_0",
          "leaf_1",
          "leaf_15",
          "leaf_16",
          "leaf_18",
          "leaf_19",
          "leaf_23",
          "leaf_24",
          "leaf_25",
          "node_1_0",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_11",
          "node_1_12",
          "node_2_0",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "gonna": [
          "leaf_0",
          "leaf_1",
          "leaf_2",
          "leaf_17",
          "leaf_18",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "node_1_0",
          "node_1_1",
          "node_1_8",
          "node_1_9",
          "node_1_19",
          "node_1_20",
          "node_2_0",
          "node_2_4",
          "node_2_9",
          "node_2_10",
          "node_3_0",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "gopro": [
          "leaf_0",
          "leaf_4",
          "leaf_10",
          "leaf_37",
          "leaf_45",
          "node_1_0",
          "node_1_2",
          "node_1_5",
          "node_1_18",
          "node_1_22",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_9",
          "node_2_11",
          "node_3_0",
          "node_3_1",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "green": [
          "leaf_0",
          "leaf_1",
          "leaf_9",
          "leaf_10",
          "leaf_16",
          "leaf_29",
          "leaf_36",
          "leaf_42",
          "leaf_46",
          "leaf_47",
          "leaf_54",
          "leaf_55",
          "leaf_59",
          "node_1_0",
          "node_1_4",
          "node_1_5",
          "node_1_8",
          "node_1_14",
          "node_1_18",
          "node_1_21",
          "node_1_23",
          "node_1_27",
          "node_1_29",
          "node_2_0",
          "node_2_2",
          "node_2_4",
          "node_2_7",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "hat": [
          "leaf_0",
          "leaf_2",
          "leaf_11",
          "leaf_12",
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "leaf_18",
          "leaf_19",
          "leaf_21",
          "leaf_25",
          "leaf_28",
          "leaf_49",
          "leaf_53",
          "leaf_54",
          "leaf_55",
          "leaf_57",
          "node_1_0",
          "node_1_1",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_10",
          "node_1_12",
          "node_1_14",
          "node_1_24",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_2_0",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "helicopter": [
          "leaf_0",
          "leaf_5",
          "leaf_6",
          "leaf_7",
          "leaf_8",
          "leaf_12",
          "node_1_0",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_6",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "hillside": [
          "leaf_0",
          "node_1_0",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "image": [
          "leaf_0",
          "leaf_1",
          "leaf_4",
          "leaf_5",
          "leaf_6",
          "leaf_7",
          "leaf_8",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_13",
          "leaf_14",
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "leaf_20",
          "leaf_23",
          "leaf_25",
          "leaf_27",
          "leaf_31",
          "leaf_32",
          "leaf_35",
          "leaf_37",
          "leaf_38",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_51",
          "leaf_52",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "leaf_59",
          "node_1_0",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_22",
          "node_1_23",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "indicating": [
          "leaf_0",
          "leaf_11",
          "leaf_26",
          "leaf_35",
          "leaf_41",
          "leaf_45",
          "leaf_50",
          "leaf_53",
          "leaf_55",
          "leaf_59",
          "node_1_0",
          "node_1_5",
          "node_1_13",
          "node_1_17",
          "node_1_20",
          "node_1_22",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_29",
          "node_2_0",
          "node_2_2",
          "node_2_6",
          "node_2_8",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "lake": [
          "leaf_0",
          "leaf_1",
          "leaf_2",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_13",
          "leaf_14",
          "leaf_15",
          "leaf_17",
          "leaf_18",
          "leaf_19",
          "leaf_24",
          "leaf_26",
          "leaf_27",
          "leaf_34",
          "leaf_35",
          "leaf_37",
          "leaf_38",
          "leaf_40",
          "leaf_41",
          "node_1_0",
          "node_1_1",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_12",
          "node_1_13",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_2_0",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_6",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "likely": [
          "leaf_0",
          "leaf_4",
          "leaf_12",
          "leaf_14",
          "leaf_41",
          "leaf_47",
          "leaf_55",
          "leaf_56",
          "node_1_0",
          "node_1_2",
          "node_1_6",
          "node_1_7",
          "node_1_20",
          "node_1_23",
          "node_1_27",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_3",
          "node_2_10",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "luke": [
          "leaf_0",
          "leaf_1",
          "node_1_0",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "man": [
          "leaf_0",
          "leaf_1",
          "leaf_2",
          "leaf_3",
          "leaf_4",
          "leaf_5",
          "leaf_6",
          "leaf_11",
          "leaf_12",
          "leaf_13",
          "leaf_14",
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "leaf_18",
          "leaf_19",
          "leaf_20",
          "leaf_21",
          "leaf_22",
          "leaf_23",
          "leaf_25",
          "leaf_26",
          "leaf_27",
          "leaf_28",
          "leaf_29",
          "leaf_31",
          "leaf_32",
          "leaf_34",
          "leaf_35",
          "leaf_37",
          "leaf_38",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "leaf_43",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "leaf_50",
          "leaf_51",
          "leaf_52",
          "leaf_53",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "leaf_59",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_3",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "mountain": [
          "leaf_0",
          "leaf_3",
          "leaf_9",
          "leaf_11",
          "leaf_18",
          "leaf_24",
          "leaf_27",
          "leaf_38",
          "node_1_0",
          "node_1_1",
          "node_1_4",
          "node_1_5",
          "node_1_9",
          "node_1_12",
          "node_1_13",
          "node_1_19",
          "node_2_0",
          "node_2_2",
          "node_2_4",
          "node_2_6",
          "node_2_9",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "mountainous": [
          "leaf_0",
          "leaf_10",
          "node_1_0",
          "node_1_5",
          "node_2_0",
          "node_2_2",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "mountains": [
          "leaf_0",
          "leaf_2",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_24",
          "leaf_27",
          "leaf_40",
          "node_1_0",
          "node_1_1",
          "node_1_4",
          "node_1_5",
          "node_1_12",
          "node_1_13",
          "node_1_20",
          "node_2_0",
          "node_2_2",
          "node_2_6",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "next": [
          "leaf_0",
          "leaf_1",
          "leaf_2",
          "leaf_3",
          "leaf_5",
          "leaf_12",
          "leaf_13",
          "leaf_16",
          "leaf_17",
          "leaf_18",
          "leaf_21",
          "leaf_24",
          "leaf_26",
          "leaf_27",
          "leaf_29",
          "leaf_37",
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "leaf_44",
          "leaf_45",
          "leaf_49",
          "leaf_52",
          "leaf_53",
          "leaf_54",
          "leaf_57",
          "leaf_59",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_6",
          "node_1_8",
          "node_1_9",
          "node_1_10",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_18",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_24",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "off": [
          "leaf_0",
          "leaf_1",
          "leaf_18",
          "leaf_19",
          "leaf_21",
          "node_1_0",
          "node_1_9",
          "node_1_10",
          "node_2_0",
          "node_2_4",
          "node_2_5",
          "node_3_0",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "outdoor": [
          "leaf_0",
          "leaf_1",
          "leaf_4",
          "leaf_12",
          "leaf_18",
          "leaf_26",
          "leaf_29",
          "leaf_35",
          "leaf_36",
          "leaf_40",
          "leaf_41",
          "leaf_44",
          "leaf_45",
          "leaf_48",
          "leaf_50",
          "leaf_51",
          "leaf_56",
          "node_1_0",
          "node_1_2",
          "node_1_6",
          "node_1_9",
          "node_1_13",
          "node_1_14",
          "node_1_17",
          "node_1_18",
          "node_1_20",
          "node_1_22",
          "node_1_24",
          "node_1_25",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_3",
          "node_2_4",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "over": [
          "leaf_0",
          "leaf_3",
          "leaf_7",
          "leaf_8",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_14",
          "leaf_30",
          "leaf_38",
          "leaf_43",
          "leaf_52",
          "node_1_0",
          "node_1_1",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_7",
          "node_1_15",
          "node_1_19",
          "node_1_21",
          "node_1_26",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_7",
          "node_2_9",
          "node_2_10",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "person": [
          "leaf_0",
          "leaf_1",
          "leaf_2",
          "leaf_3",
          "leaf_4",
          "leaf_5",
          "leaf_6",
          "leaf_7",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_13",
          "leaf_16",
          "leaf_17",
          "leaf_18",
          "leaf_20",
          "leaf_21",
          "leaf_22",
          "leaf_24",
          "leaf_25",
          "leaf_26",
          "leaf_27",
          "leaf_28",
          "leaf_29",
          "leaf_30",
          "leaf_31",
          "leaf_32",
          "leaf_33",
          "leaf_34",
          "leaf_35",
          "leaf_36",
          "leaf_37",
          "leaf_38",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "leaf_43",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_48",
          "leaf_52",
          "leaf_53",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "leaf_58",
          "leaf_59",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_8",
          "node_1_9",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "perspective": [
          "leaf_0",
          "leaf_1",
          "leaf_2",
          "leaf_3",
          "leaf_4",
          "leaf_5",
          "leaf_7",
          "leaf_8",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_14",
          "leaf_15",
          "leaf_16",
          "leaf_20",
          "leaf_21",
          "leaf_22",
          "leaf_23",
          "leaf_24",
          "leaf_27",
          "leaf_28",
          "leaf_29",
          "leaf_30",
          "leaf_31",
          "leaf_32",
          "leaf_33",
          "leaf_34",
          "leaf_35",
          "leaf_36",
          "leaf_37",
          "leaf_38",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "leaf_43",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "leaf_59",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "plane": [
          "leaf_0",
          "leaf_1",
          "leaf_3",
          "leaf_4",
          "leaf_5",
          "leaf_6",
          "leaf_7",
          "leaf_8",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_16",
          "leaf_17",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_8",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "pointing": [
          "leaf_0",
          "leaf_44",
          "leaf_53",
          "node_1_0",
          "node_1_22",
          "node_1_26",
          "node_2_0",
          "node_2_11",
          "node_2_13",
          "node_3_0",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "pov": [
          "leaf_0",
          "leaf_11",
          "leaf_18",
          "node_1_0",
          "node_1_5",
          "node_1_9",
          "node_2_0",
          "node_2_2",
          "node_2_4",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "providing": [
          "leaf_0",
          "leaf_1",
          "leaf_6",
          "leaf_7",
          "leaf_8",
          "leaf_9",
          "leaf_10",
          "leaf_12",
          "leaf_16",
          "leaf_22",
          "leaf_23",
          "leaf_38",
          "leaf_41",
          "leaf_46",
          "leaf_49",
          "leaf_52",
          "leaf_56",
          "node_1_0",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_8",
          "node_1_11",
          "node_1_19",
          "node_1_20",
          "node_1_23",
          "node_1_24",
          "node_1_26",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "re": [
          "leaf_0",
          "leaf_1",
          "leaf_2",
          "leaf_14",
          "leaf_15",
          "leaf_16",
          "leaf_23",
          "leaf_24",
          "leaf_25",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "node_1_0",
          "node_1_1",
          "node_1_7",
          "node_1_8",
          "node_1_11",
          "node_1_12",
          "node_1_22",
          "node_1_23",
          "node_2_0",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_11",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "saying": [
          "leaf_0",
          "node_1_0",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "scene": [
          "leaf_0",
          "leaf_1",
          "leaf_2",
          "leaf_3",
          "leaf_5",
          "leaf_6",
          "leaf_7",
          "leaf_8",
          "leaf_9",
          "leaf_11",
          "leaf_12",
          "leaf_13",
          "leaf_14",
          "leaf_16",
          "leaf_17",
          "leaf_21",
          "leaf_22",
          "leaf_23",
          "leaf_25",
          "leaf_26",
          "leaf_27",
          "leaf_28",
          "leaf_29",
          "leaf_30",
          "leaf_31",
          "leaf_32",
          "leaf_34",
          "leaf_35",
          "leaf_37",
          "leaf_38",
          "leaf_39",
          "leaf_40",
          "leaf_42",
          "leaf_43",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "leaf_50",
          "leaf_51",
          "leaf_52",
          "leaf_53",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "leaf_58",
          "leaf_59",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "seems": [
          "leaf_0",
          "leaf_1",
          "leaf_5",
          "leaf_9",
          "leaf_15",
          "leaf_42",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_50",
          "leaf_58",
          "node_1_0",
          "node_1_2",
          "node_1_4",
          "node_1_7",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_25",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "shaky": [
          "leaf_0",
          "leaf_8",
          "leaf_46",
          "leaf_59",
          "node_1_0",
          "node_1_4",
          "node_1_23",
          "node_1_29",
          "node_2_0",
          "node_2_2",
          "node_2_11",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_5",
          "node_3_7",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "shirt": [
          "leaf_0",
          "leaf_1",
          "leaf_32",
          "node_1_0",
          "node_1_16",
          "node_2_0",
          "node_2_8",
          "node_3_0",
          "node_3_4",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "shot": [
          "leaf_0",
          "leaf_1",
          "leaf_6",
          "leaf_7",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_13",
          "leaf_15",
          "leaf_18",
          "leaf_31",
          "leaf_40",
          "leaf_43",
          "leaf_59",
          "node_1_0",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_9",
          "node_1_15",
          "node_1_20",
          "node_1_21",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_7",
          "node_2_10",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "showing": [
          "leaf_0",
          "leaf_1",
          "leaf_2",
          "leaf_3",
          "leaf_4",
          "leaf_5",
          "leaf_6",
          "leaf_7",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_13",
          "leaf_14",
          "leaf_17",
          "leaf_20",
          "leaf_21",
          "leaf_22",
          "leaf_23",
          "leaf_24",
          "leaf_25",
          "leaf_26",
          "leaf_28",
          "leaf_29",
          "leaf_30",
          "leaf_32",
          "leaf_34",
          "leaf_36",
          "leaf_37",
          "leaf_39",
          "leaf_40",
          "leaf_42",
          "leaf_43",
          "leaf_44",
          "leaf_48",
          "leaf_49",
          "leaf_50",
          "leaf_51",
          "leaf_53",
          "leaf_55",
          "leaf_59",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "similar": [
          "leaf_0",
          "node_1_0",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "slightly": [
          "leaf_0",
          "leaf_8",
          "leaf_17",
          "leaf_35",
          "node_1_0",
          "node_1_4",
          "node_1_8",
          "node_1_17",
          "node_2_0",
          "node_2_2",
          "node_2_4",
          "node_2_8",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "small": [
          "leaf_0",
          "leaf_2",
          "leaf_5",
          "leaf_6",
          "leaf_7",
          "leaf_9",
          "leaf_10",
          "leaf_12",
          "leaf_13",
          "leaf_29",
          "leaf_42",
          "leaf_52",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_14",
          "node_1_21",
          "node_1_26",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_7",
          "node_2_10",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "something": [
          "leaf_0",
          "leaf_5",
          "leaf_21",
          "leaf_22",
          "leaf_32",
          "leaf_42",
          "leaf_44",
          "leaf_47",
          "leaf_48",
          "leaf_50",
          "leaf_53",
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "node_1_0",
          "node_1_2",
          "node_1_10",
          "node_1_11",
          "node_1_16",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_5",
          "node_2_8",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "standing": [
          "leaf_0",
          "leaf_1",
          "leaf_2",
          "leaf_3",
          "leaf_12",
          "leaf_14",
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "leaf_18",
          "leaf_21",
          "leaf_22",
          "leaf_23",
          "leaf_24",
          "leaf_25",
          "leaf_26",
          "leaf_27",
          "leaf_28",
          "leaf_29",
          "leaf_30",
          "leaf_32",
          "leaf_33",
          "leaf_34",
          "leaf_35",
          "leaf_36",
          "leaf_37",
          "leaf_38",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "leaf_43",
          "leaf_45",
          "leaf_49",
          "leaf_53",
          "node_1_0",
          "node_1_1",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_24",
          "node_1_26",
          "node_2_0",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "stands": [
          "leaf_0",
          "leaf_5",
          "leaf_12",
          "leaf_13",
          "leaf_15",
          "leaf_18",
          "leaf_19",
          "leaf_27",
          "leaf_37",
          "leaf_38",
          "leaf_40",
          "node_1_0",
          "node_1_2",
          "node_1_6",
          "node_1_7",
          "node_1_9",
          "node_1_13",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_2_0",
          "node_2_1",
          "node_2_3",
          "node_2_4",
          "node_2_6",
          "node_2_9",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "sunglasses": [
          "leaf_0",
          "leaf_5",
          "leaf_18",
          "node_1_0",
          "node_1_2",
          "node_1_9",
          "node_2_0",
          "node_2_1",
          "node_2_4",
          "node_3_0",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "taken": [
          "leaf_0",
          "leaf_8",
          "leaf_10",
          "leaf_14",
          "leaf_17",
          "leaf_24",
          "leaf_29",
          "leaf_40",
          "leaf_41",
          "leaf_43",
          "node_1_0",
          "node_1_4",
          "node_1_5",
          "node_1_7",
          "node_1_8",
          "node_1_12",
          "node_1_14",
          "node_1_20",
          "node_1_21",
          "node_2_0",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_6",
          "node_2_7",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "top": [
          "leaf_0",
          "leaf_4",
          "leaf_10",
          "leaf_12",
          "leaf_54",
          "node_1_0",
          "node_1_2",
          "node_1_5",
          "node_1_6",
          "node_1_27",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_6",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "video": [
          "leaf_0",
          "leaf_1",
          "leaf_2",
          "leaf_3",
          "leaf_4",
          "leaf_5",
          "leaf_7",
          "leaf_8",
          "leaf_9",
          "leaf_11",
          "leaf_13",
          "leaf_14",
          "leaf_15",
          "leaf_17",
          "leaf_20",
          "leaf_22",
          "leaf_23",
          "leaf_24",
          "leaf_25",
          "leaf_26",
          "leaf_27",
          "leaf_28",
          "leaf_29",
          "leaf_30",
          "leaf_31",
          "leaf_33",
          "leaf_34",
          "leaf_35",
          "leaf_36",
          "leaf_37",
          "leaf_38",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "leaf_44",
          "leaf_45",
          "leaf_47",
          "leaf_48",
          "leaf_50",
          "leaf_51",
          "leaf_53",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "leaf_59",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "view": [
          "leaf_0",
          "leaf_1",
          "leaf_3",
          "leaf_5",
          "leaf_6",
          "leaf_7",
          "leaf_8",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_16",
          "leaf_20",
          "leaf_22",
          "leaf_24",
          "leaf_27",
          "leaf_34",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "leaf_44",
          "leaf_46",
          "leaf_49",
          "leaf_55",
          "leaf_56",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_8",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_17",
          "node_1_19",
          "node_1_20",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_27",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "water": [
          "leaf_0",
          "leaf_1",
          "leaf_6",
          "leaf_7",
          "leaf_8",
          "leaf_10",
          "leaf_12",
          "leaf_13",
          "leaf_14",
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "leaf_18",
          "leaf_19",
          "leaf_23",
          "leaf_24",
          "leaf_26",
          "leaf_27",
          "leaf_28",
          "leaf_31",
          "leaf_32",
          "leaf_33",
          "leaf_34",
          "leaf_35",
          "leaf_37",
          "leaf_38",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "leaf_43",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_52",
          "node_1_0",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_26",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "welcome": [
          "leaf_0",
          "leaf_1",
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "node_1_0",
          "node_1_7",
          "node_1_8",
          "node_2_0",
          "node_2_3",
          "node_2_4",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "within": [
          "leaf_0",
          "leaf_5",
          "leaf_6",
          "leaf_9",
          "leaf_22",
          "leaf_26",
          "leaf_29",
          "leaf_34",
          "leaf_42",
          "leaf_47",
          "node_1_0",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_11",
          "node_1_13",
          "node_1_14",
          "node_1_17",
          "node_1_21",
          "node_1_23",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_10",
          "node_2_11",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "writing": [
          "leaf_0",
          "leaf_4",
          "node_1_0",
          "node_1_2",
          "node_2_0",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "youtube": [
          "leaf_0",
          "leaf_1",
          "node_1_0",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "30": [
          "leaf_1",
          "leaf_4",
          "leaf_13",
          "leaf_22",
          "leaf_23",
          "leaf_33",
          "leaf_40",
          "leaf_41",
          "leaf_44",
          "leaf_51",
          "leaf_53",
          "leaf_56",
          "node_1_0",
          "node_1_2",
          "node_1_6",
          "node_1_11",
          "node_1_16",
          "node_1_20",
          "node_1_22",
          "node_1_25",
          "node_1_26",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_3",
          "node_2_5",
          "node_2_8",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "angle": [
          "leaf_1",
          "leaf_2",
          "leaf_3",
          "leaf_8",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_14",
          "leaf_15",
          "leaf_16",
          "leaf_20",
          "leaf_29",
          "leaf_30",
          "leaf_31",
          "leaf_32",
          "leaf_37",
          "leaf_41",
          "leaf_46",
          "leaf_56",
          "node_1_0",
          "node_1_1",
          "node_1_4",
          "node_1_5",
          "node_1_7",
          "node_1_8",
          "node_1_10",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_18",
          "node_1_20",
          "node_1_23",
          "node_1_28",
          "node_2_0",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "another": [
          "leaf_1",
          "leaf_5",
          "leaf_12",
          "leaf_16",
          "leaf_17",
          "leaf_25",
          "leaf_26",
          "leaf_27",
          "leaf_31",
          "leaf_35",
          "leaf_36",
          "leaf_37",
          "leaf_38",
          "leaf_39",
          "leaf_46",
          "leaf_47",
          "leaf_48",
          "leaf_54",
          "leaf_58",
          "leaf_59",
          "node_1_0",
          "node_1_2",
          "node_1_6",
          "node_1_8",
          "node_1_12",
          "node_1_13",
          "node_1_15",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_23",
          "node_1_24",
          "node_1_27",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_3",
          "node_2_4",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "arctic": [
          "leaf_1",
          "leaf_2",
          "node_1_0",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "away": [
          "leaf_1",
          "leaf_58",
          "leaf_59",
          "node_1_0",
          "node_1_29",
          "node_2_0",
          "node_2_14",
          "node_3_0",
          "node_3_7",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "backpack": [
          "leaf_1",
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "leaf_18",
          "leaf_19",
          "leaf_20",
          "leaf_21",
          "leaf_26",
          "leaf_29",
          "leaf_36",
          "leaf_38",
          "leaf_41",
          "leaf_43",
          "leaf_44",
          "leaf_45",
          "leaf_47",
          "leaf_49",
          "leaf_52",
          "leaf_53",
          "leaf_54",
          "leaf_56",
          "leaf_58",
          "leaf_59",
          "node_1_0",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_10",
          "node_1_13",
          "node_1_14",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "black": [
          "leaf_1",
          "leaf_4",
          "leaf_22",
          "leaf_23",
          "leaf_25",
          "leaf_27",
          "leaf_29",
          "leaf_34",
          "leaf_38",
          "leaf_41",
          "leaf_44",
          "leaf_46",
          "leaf_47",
          "leaf_54",
          "leaf_55",
          "node_1_0",
          "node_1_2",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_17",
          "node_1_19",
          "node_1_20",
          "node_1_22",
          "node_1_23",
          "node_1_27",
          "node_2_0",
          "node_2_1",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_13",
          "node_3_0",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "boat": [
          "leaf_1",
          "leaf_6",
          "leaf_11",
          "leaf_12",
          "leaf_13",
          "leaf_17",
          "leaf_37",
          "leaf_39",
          "node_1_0",
          "node_1_3",
          "node_1_5",
          "node_1_6",
          "node_1_8",
          "node_1_18",
          "node_1_19",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_9",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "boats": [
          "leaf_1",
          "node_1_0",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "cap": [
          "leaf_1",
          "leaf_6",
          "leaf_56",
          "node_1_0",
          "node_1_3",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_14",
          "node_3_0",
          "node_3_7",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "casting": [
          "leaf_1",
          "node_1_0",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "cause": [
          "leaf_1",
          "node_1_0",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "close": [
          "leaf_1",
          "leaf_26",
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "leaf_56",
          "leaf_59",
          "node_1_0",
          "node_1_13",
          "node_1_20",
          "node_1_21",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_6",
          "node_2_10",
          "node_2_14",
          "node_3_0",
          "node_3_3",
          "node_3_5",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "distance": [
          "leaf_1",
          "leaf_24",
          "leaf_27",
          "leaf_40",
          "node_1_0",
          "node_1_12",
          "node_1_13",
          "node_1_20",
          "node_2_0",
          "node_2_6",
          "node_2_10",
          "node_3_0",
          "node_3_3",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "distortion": [
          "leaf_1",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_20",
          "leaf_31",
          "leaf_38",
          "node_1_0",
          "node_1_4",
          "node_1_5",
          "node_1_10",
          "node_1_15",
          "node_1_19",
          "node_2_0",
          "node_2_2",
          "node_2_5",
          "node_2_7",
          "node_2_9",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "dolly": [
          "leaf_1",
          "leaf_2",
          "leaf_29",
          "leaf_30",
          "leaf_31",
          "leaf_32",
          "leaf_33",
          "leaf_34",
          "leaf_35",
          "leaf_36",
          "leaf_37",
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "node_1_0",
          "node_1_1",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_27",
          "node_1_28",
          "node_2_0",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_3",
          "node_3_4",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "edges": [
          "leaf_1",
          "node_1_0",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "enjoying": [
          "leaf_1",
          "leaf_19",
          "leaf_27",
          "leaf_33",
          "leaf_52",
          "leaf_57",
          "node_1_0",
          "node_1_9",
          "node_1_13",
          "node_1_16",
          "node_1_26",
          "node_1_28",
          "node_2_0",
          "node_2_4",
          "node_2_6",
          "node_2_8",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "featuring": [
          "leaf_1",
          "leaf_2",
          "leaf_8",
          "leaf_11",
          "leaf_12",
          "leaf_13",
          "leaf_28",
          "leaf_31",
          "leaf_32",
          "leaf_35",
          "leaf_37",
          "leaf_38",
          "leaf_53",
          "leaf_56",
          "leaf_59",
          "node_1_0",
          "node_1_1",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_26",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_2",
          "node_2_3",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_4",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "fish": [
          "leaf_1",
          "leaf_2",
          "leaf_26",
          "leaf_27",
          "leaf_30",
          "leaf_31",
          "leaf_32",
          "leaf_34",
          "leaf_36",
          "leaf_37",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "leaf_43",
          "leaf_52",
          "leaf_53",
          "leaf_54",
          "node_1_0",
          "node_1_1",
          "node_1_13",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_26",
          "node_1_27",
          "node_2_0",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_13",
          "node_3_0",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "fishing": [
          "leaf_1",
          "leaf_2",
          "leaf_14",
          "leaf_23",
          "leaf_24",
          "leaf_25",
          "leaf_26",
          "leaf_27",
          "leaf_28",
          "leaf_29",
          "leaf_30",
          "leaf_31",
          "leaf_32",
          "leaf_33",
          "leaf_34",
          "leaf_35",
          "leaf_37",
          "leaf_38",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "leaf_43",
          "leaf_46",
          "leaf_51",
          "leaf_53",
          "node_1_0",
          "node_1_1",
          "node_1_7",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_23",
          "node_1_25",
          "node_1_26",
          "node_2_0",
          "node_2_3",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "frame": [
          "leaf_1",
          "leaf_2",
          "leaf_5",
          "leaf_15",
          "leaf_17",
          "leaf_23",
          "leaf_32",
          "leaf_44",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_7",
          "node_1_8",
          "node_1_11",
          "node_1_16",
          "node_1_22",
          "node_2_0",
          "node_2_1",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_8",
          "node_2_11",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "further": [
          "leaf_1",
          "leaf_37",
          "leaf_58",
          "leaf_59",
          "node_1_0",
          "node_1_18",
          "node_1_29",
          "node_2_0",
          "node_2_9",
          "node_2_14",
          "node_3_0",
          "node_3_4",
          "node_3_7",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "glasses": [
          "leaf_1",
          "leaf_5",
          "leaf_12",
          "leaf_16",
          "leaf_19",
          "leaf_22",
          "leaf_53",
          "leaf_54",
          "leaf_56",
          "node_1_0",
          "node_1_2",
          "node_1_6",
          "node_1_8",
          "node_1_9",
          "node_1_11",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "grailing": [
          "leaf_1",
          "leaf_2",
          "node_1_0",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "grey": [
          "leaf_1",
          "leaf_14",
          "leaf_18",
          "leaf_19",
          "leaf_23",
          "node_1_0",
          "node_1_7",
          "node_1_9",
          "node_1_11",
          "node_2_0",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "hand": [
          "leaf_1",
          "leaf_14",
          "leaf_25",
          "leaf_26",
          "leaf_31",
          "leaf_36",
          "leaf_41",
          "leaf_42",
          "leaf_43",
          "leaf_46",
          "leaf_50",
          "leaf_53",
          "leaf_59",
          "node_1_0",
          "node_1_7",
          "node_1_12",
          "node_1_13",
          "node_1_15",
          "node_1_18",
          "node_1_20",
          "node_1_21",
          "node_1_23",
          "node_1_25",
          "node_1_26",
          "node_1_29",
          "node_2_0",
          "node_2_3",
          "node_2_6",
          "node_2_7",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "hiking": [
          "leaf_1",
          "leaf_2",
          "leaf_3",
          "leaf_16",
          "leaf_17",
          "leaf_20",
          "leaf_41",
          "leaf_55",
          "node_1_0",
          "node_1_1",
          "node_1_8",
          "node_1_10",
          "node_1_20",
          "node_1_27",
          "node_2_0",
          "node_2_4",
          "node_2_5",
          "node_2_10",
          "node_2_13",
          "node_3_0",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "holding": [
          "leaf_1",
          "leaf_2",
          "leaf_3",
          "leaf_6",
          "leaf_13",
          "leaf_24",
          "leaf_25",
          "leaf_26",
          "leaf_27",
          "leaf_28",
          "leaf_30",
          "leaf_31",
          "leaf_32",
          "leaf_34",
          "leaf_37",
          "leaf_38",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "leaf_43",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "leaf_50",
          "leaf_52",
          "leaf_53",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "leaf_58",
          "leaf_59",
          "node_1_0",
          "node_1_1",
          "node_1_3",
          "node_1_6",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_3",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "hoodie": [
          "leaf_1",
          "leaf_44",
          "node_1_0",
          "node_1_22",
          "node_2_0",
          "node_2_11",
          "node_3_0",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "immersive": [
          "leaf_1",
          "leaf_9",
          "leaf_16",
          "leaf_29",
          "leaf_35",
          "leaf_41",
          "leaf_42",
          "leaf_49",
          "node_1_0",
          "node_1_4",
          "node_1_8",
          "node_1_14",
          "node_1_17",
          "node_1_20",
          "node_1_21",
          "node_1_24",
          "node_2_0",
          "node_2_2",
          "node_2_4",
          "node_2_7",
          "node_2_8",
          "node_2_10",
          "node_2_12",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "includes": [
          "leaf_1",
          "leaf_10",
          "leaf_11",
          "leaf_27",
          "leaf_41",
          "leaf_43",
          "leaf_44",
          "leaf_47",
          "leaf_53",
          "leaf_56",
          "node_1_0",
          "node_1_5",
          "node_1_13",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_26",
          "node_1_28",
          "node_2_0",
          "node_2_2",
          "node_2_6",
          "node_2_10",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "line": [
          "leaf_1",
          "leaf_28",
          "leaf_29",
          "leaf_30",
          "leaf_31",
          "leaf_37",
          "leaf_43",
          "node_1_0",
          "node_1_14",
          "node_1_15",
          "node_1_18",
          "node_1_21",
          "node_2_0",
          "node_2_7",
          "node_2_9",
          "node_2_10",
          "node_3_0",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "looking": [
          "leaf_1",
          "leaf_2",
          "leaf_4",
          "leaf_11",
          "leaf_14",
          "leaf_17",
          "leaf_18",
          "leaf_21",
          "leaf_23",
          "leaf_33",
          "leaf_40",
          "leaf_41",
          "leaf_44",
          "leaf_47",
          "leaf_48",
          "leaf_58",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_5",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_10",
          "node_1_11",
          "node_1_16",
          "node_1_20",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_8",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "meal": [
          "leaf_1",
          "leaf_45",
          "leaf_50",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "node_1_0",
          "node_1_22",
          "node_1_25",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "men": [
          "leaf_1",
          "leaf_8",
          "leaf_12",
          "leaf_15",
          "leaf_19",
          "leaf_21",
          "leaf_22",
          "leaf_25",
          "leaf_30",
          "leaf_35",
          "leaf_37",
          "leaf_45",
          "leaf_51",
          "leaf_52",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "node_1_0",
          "node_1_4",
          "node_1_6",
          "node_1_7",
          "node_1_9",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_15",
          "node_1_17",
          "node_1_18",
          "node_1_22",
          "node_1_25",
          "node_1_26",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "near": [
          "leaf_1",
          "leaf_3",
          "leaf_5",
          "leaf_6",
          "leaf_7",
          "leaf_12",
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "leaf_18",
          "leaf_21",
          "leaf_22",
          "leaf_23",
          "leaf_24",
          "leaf_29",
          "leaf_31",
          "leaf_32",
          "leaf_34",
          "leaf_35",
          "leaf_37",
          "leaf_38",
          "leaf_43",
          "leaf_45",
          "leaf_48",
          "leaf_58",
          "leaf_59",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_3",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_21",
          "node_1_22",
          "node_1_24",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "nearby": [
          "leaf_1",
          "leaf_16",
          "leaf_18",
          "leaf_26",
          "leaf_34",
          "leaf_38",
          "leaf_46",
          "leaf_47",
          "leaf_53",
          "leaf_54",
          "leaf_56",
          "leaf_58",
          "leaf_59",
          "node_1_0",
          "node_1_8",
          "node_1_9",
          "node_1_13",
          "node_1_17",
          "node_1_19",
          "node_1_23",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_4",
          "node_2_6",
          "node_2_8",
          "node_2_9",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "objects": [
          "leaf_1",
          "leaf_5",
          "leaf_10",
          "leaf_23",
          "leaf_26",
          "leaf_27",
          "leaf_31",
          "leaf_40",
          "leaf_41",
          "leaf_44",
          "leaf_46",
          "leaf_49",
          "leaf_50",
          "leaf_52",
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "leaf_59",
          "node_1_0",
          "node_1_2",
          "node_1_5",
          "node_1_11",
          "node_1_13",
          "node_1_15",
          "node_1_20",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "out": [
          "leaf_1",
          "leaf_2",
          "leaf_4",
          "leaf_5",
          "leaf_11",
          "leaf_14",
          "leaf_28",
          "leaf_29",
          "leaf_32",
          "leaf_47",
          "leaf_51",
          "leaf_52",
          "leaf_57",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_5",
          "node_1_7",
          "node_1_14",
          "node_1_16",
          "node_1_23",
          "node_1_25",
          "node_1_26",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_7",
          "node_2_8",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "outdoors": [
          "leaf_1",
          "leaf_3",
          "leaf_4",
          "leaf_15",
          "leaf_19",
          "leaf_22",
          "leaf_23",
          "leaf_25",
          "leaf_27",
          "leaf_29",
          "leaf_31",
          "leaf_33",
          "leaf_35",
          "leaf_47",
          "leaf_51",
          "leaf_52",
          "leaf_53",
          "leaf_54",
          "leaf_55",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_7",
          "node_1_9",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_23",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_2_0",
          "node_2_1",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "people": [
          "leaf_1",
          "leaf_5",
          "leaf_10",
          "leaf_12",
          "leaf_13",
          "leaf_14",
          "leaf_17",
          "leaf_19",
          "leaf_20",
          "leaf_21",
          "leaf_22",
          "leaf_23",
          "leaf_26",
          "leaf_28",
          "leaf_30",
          "leaf_32",
          "leaf_33",
          "leaf_36",
          "leaf_37",
          "leaf_38",
          "leaf_40",
          "leaf_43",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "leaf_50",
          "leaf_51",
          "leaf_52",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "leaf_58",
          "node_1_0",
          "node_1_2",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_10",
          "node_1_11",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "positioned": [
          "leaf_1",
          "leaf_2",
          "leaf_15",
          "leaf_18",
          "leaf_29",
          "leaf_32",
          "leaf_37",
          "leaf_38",
          "leaf_40",
          "leaf_43",
          "leaf_44",
          "leaf_48",
          "leaf_55",
          "node_1_0",
          "node_1_1",
          "node_1_7",
          "node_1_9",
          "node_1_14",
          "node_1_16",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_24",
          "node_1_27",
          "node_2_0",
          "node_2_3",
          "node_2_4",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "right": [
          "leaf_1",
          "leaf_5",
          "leaf_8",
          "leaf_15",
          "leaf_19",
          "leaf_20",
          "leaf_22",
          "leaf_30",
          "leaf_31",
          "leaf_49",
          "leaf_50",
          "leaf_58",
          "node_1_0",
          "node_1_2",
          "node_1_4",
          "node_1_7",
          "node_1_9",
          "node_1_10",
          "node_1_11",
          "node_1_15",
          "node_1_24",
          "node_1_25",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_7",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "rocks": [
          "leaf_1",
          "leaf_2",
          "leaf_26",
          "leaf_27",
          "leaf_29",
          "leaf_30",
          "leaf_31",
          "leaf_32",
          "leaf_33",
          "leaf_37",
          "leaf_41",
          "node_1_0",
          "node_1_1",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_18",
          "node_1_20",
          "node_2_0",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_3_0",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "setting": [
          "leaf_1",
          "leaf_12",
          "leaf_22",
          "leaf_41",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_50",
          "leaf_56",
          "node_1_0",
          "node_1_6",
          "node_1_11",
          "node_1_20",
          "node_1_22",
          "node_1_23",
          "node_1_25",
          "node_1_28",
          "node_2_0",
          "node_2_3",
          "node_2_5",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "several": [
          "leaf_1",
          "leaf_5",
          "leaf_6",
          "leaf_26",
          "leaf_30",
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "leaf_58",
          "leaf_59",
          "node_1_0",
          "node_1_2",
          "node_1_3",
          "node_1_13",
          "node_1_15",
          "node_1_23",
          "node_1_24",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_6",
          "node_2_7",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "shore": [
          "leaf_1",
          "leaf_12",
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "leaf_18",
          "leaf_30",
          "leaf_37",
          "leaf_38",
          "leaf_40",
          "leaf_41",
          "node_1_0",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_15",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_2_0",
          "node_2_3",
          "node_2_4",
          "node_2_7",
          "node_2_9",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "side": [
          "leaf_1",
          "leaf_5",
          "leaf_8",
          "leaf_12",
          "leaf_13",
          "leaf_14",
          "leaf_15",
          "leaf_36",
          "leaf_38",
          "leaf_58",
          "node_1_0",
          "node_1_2",
          "node_1_4",
          "node_1_6",
          "node_1_7",
          "node_1_18",
          "node_1_19",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_9",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_4",
          "node_3_7",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "tent": [
          "leaf_1",
          "leaf_21",
          "leaf_22",
          "leaf_23",
          "leaf_25",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "leaf_50",
          "leaf_51",
          "leaf_52",
          "leaf_53",
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "leaf_59",
          "node_1_0",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_5",
          "node_2_6",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "timelapse": [
          "leaf_1",
          "leaf_15",
          "node_1_0",
          "node_1_7",
          "node_2_0",
          "node_2_3",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "together": [
          "leaf_1",
          "leaf_45",
          "leaf_48",
          "leaf_52",
          "leaf_57",
          "leaf_58",
          "node_1_0",
          "node_1_22",
          "node_1_24",
          "node_1_26",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "tree": [
          "leaf_1",
          "leaf_3",
          "leaf_4",
          "leaf_21",
          "leaf_22",
          "leaf_44",
          "node_1_0",
          "node_1_1",
          "node_1_2",
          "node_1_10",
          "node_1_11",
          "node_1_22",
          "node_2_0",
          "node_2_1",
          "node_2_5",
          "node_2_11",
          "node_3_0",
          "node_3_2",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "trout": [
          "leaf_1",
          "leaf_2",
          "leaf_56",
          "leaf_57",
          "node_1_0",
          "node_1_1",
          "node_1_28",
          "node_2_0",
          "node_2_14",
          "node_3_0",
          "node_3_7",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "vardin": [
          "leaf_1",
          "leaf_2",
          "node_1_0",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "way": [
          "leaf_1",
          "leaf_29",
          "leaf_43",
          "leaf_52",
          "node_1_0",
          "node_1_14",
          "node_1_21",
          "node_1_26",
          "node_2_0",
          "node_2_7",
          "node_2_10",
          "node_2_13",
          "node_3_0",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "wearing": [
          "leaf_1",
          "leaf_5",
          "leaf_6",
          "leaf_8",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "leaf_18",
          "leaf_19",
          "leaf_20",
          "leaf_21",
          "leaf_22",
          "leaf_23",
          "leaf_24",
          "leaf_25",
          "leaf_26",
          "leaf_27",
          "leaf_28",
          "leaf_30",
          "leaf_34",
          "leaf_38",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_49",
          "leaf_53",
          "leaf_54",
          "leaf_56",
          "leaf_57",
          "leaf_59",
          "node_1_0",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_17",
          "node_1_19",
          "node_1_20",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "wide": [
          "leaf_1",
          "leaf_2",
          "leaf_3",
          "leaf_8",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_14",
          "leaf_15",
          "leaf_16",
          "leaf_20",
          "leaf_29",
          "leaf_30",
          "leaf_31",
          "leaf_32",
          "leaf_37",
          "leaf_39",
          "leaf_41",
          "leaf_46",
          "leaf_56",
          "node_1_0",
          "node_1_1",
          "node_1_4",
          "node_1_5",
          "node_1_7",
          "node_1_8",
          "node_1_10",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_23",
          "node_1_28",
          "node_2_0",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "08": [
          "leaf_2",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "3rd": [
          "leaf_2",
          "leaf_3",
          "leaf_4",
          "leaf_9",
          "leaf_11",
          "leaf_12",
          "leaf_18",
          "leaf_20",
          "leaf_21",
          "leaf_32",
          "leaf_33",
          "leaf_35",
          "leaf_36",
          "leaf_38",
          "leaf_42",
          "leaf_54",
          "leaf_55",
          "leaf_59",
          "node_1_1",
          "node_1_2",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_9",
          "node_1_10",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_21",
          "node_1_27",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "boy": [
          "leaf_2",
          "leaf_4",
          "leaf_5",
          "leaf_15",
          "leaf_28",
          "leaf_31",
          "leaf_33",
          "leaf_34",
          "leaf_35",
          "leaf_40",
          "leaf_44",
          "leaf_45",
          "leaf_48",
          "leaf_49",
          "leaf_52",
          "leaf_56",
          "leaf_57",
          "node_1_1",
          "node_1_2",
          "node_1_7",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_20",
          "node_1_22",
          "node_1_24",
          "node_1_26",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_3",
          "node_2_7",
          "node_2_8",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "bush": [
          "leaf_2",
          "leaf_3",
          "leaf_4",
          "node_1_1",
          "node_1_2",
          "node_2_0",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "capturing": [
          "leaf_2",
          "leaf_6",
          "leaf_8",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_14",
          "leaf_16",
          "leaf_18",
          "leaf_24",
          "leaf_26",
          "leaf_29",
          "leaf_31",
          "leaf_32",
          "leaf_35",
          "leaf_36",
          "leaf_37",
          "leaf_38",
          "leaf_44",
          "leaf_48",
          "leaf_49",
          "leaf_52",
          "leaf_55",
          "leaf_56",
          "node_1_1",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_22",
          "node_1_24",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "description": [
          "leaf_2",
          "leaf_10",
          "leaf_30",
          "node_1_1",
          "node_1_5",
          "node_1_15",
          "node_2_0",
          "node_2_2",
          "node_2_7",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "detection": [
          "leaf_2",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "dick": [
          "leaf_2",
          "leaf_3",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "exploring": [
          "leaf_2",
          "leaf_3",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "expression": [
          "leaf_2",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "facial": [
          "leaf_2",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "ground": [
          "leaf_2",
          "leaf_25",
          "leaf_26",
          "leaf_29",
          "leaf_33",
          "leaf_36",
          "leaf_38",
          "leaf_43",
          "leaf_48",
          "leaf_52",
          "leaf_59",
          "node_1_1",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_16",
          "node_1_18",
          "node_1_19",
          "node_1_21",
          "node_1_24",
          "node_1_26",
          "node_1_29",
          "node_2_0",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "guys": [
          "leaf_2",
          "leaf_14",
          "leaf_15",
          "leaf_19",
          "leaf_20",
          "leaf_21",
          "leaf_47",
          "leaf_49",
          "leaf_50",
          "node_1_1",
          "node_1_7",
          "node_1_9",
          "node_1_10",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_2_0",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_11",
          "node_2_12",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "hole": [
          "leaf_2",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "homestead": [
          "leaf_2",
          "leaf_3",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "inside": [
          "leaf_2",
          "leaf_3",
          "leaf_5",
          "leaf_6",
          "leaf_7",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "leaf_22",
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "leaf_51",
          "leaf_52",
          "leaf_53",
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "node_1_1",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_11",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_5",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "lens": [
          "leaf_2",
          "leaf_3",
          "leaf_8",
          "leaf_9",
          "leaf_11",
          "leaf_16",
          "leaf_20",
          "leaf_22",
          "leaf_29",
          "leaf_32",
          "leaf_35",
          "leaf_37",
          "leaf_42",
          "leaf_48",
          "leaf_56",
          "node_1_1",
          "node_1_4",
          "node_1_5",
          "node_1_8",
          "node_1_10",
          "node_1_11",
          "node_1_14",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_21",
          "node_1_24",
          "node_1_28",
          "node_2_0",
          "node_2_2",
          "node_2_4",
          "node_2_5",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "object": [
          "leaf_2",
          "leaf_22",
          "leaf_25",
          "leaf_30",
          "leaf_36",
          "leaf_38",
          "leaf_43",
          "leaf_45",
          "leaf_47",
          "leaf_50",
          "leaf_52",
          "leaf_54",
          "leaf_58",
          "node_1_1",
          "node_1_11",
          "node_1_12",
          "node_1_15",
          "node_1_18",
          "node_1_19",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_29",
          "node_2_0",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "original": [
          "leaf_2",
          "leaf_3",
          "leaf_4",
          "node_1_1",
          "node_1_2",
          "node_2_0",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "overhead": [
          "leaf_2",
          "leaf_37",
          "leaf_48",
          "leaf_55",
          "node_1_1",
          "node_1_18",
          "node_1_24",
          "node_1_27",
          "node_2_0",
          "node_2_9",
          "node_2_12",
          "node_2_13",
          "node_3_0",
          "node_3_4",
          "node_3_6",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "pack": [
          "leaf_2",
          "leaf_3",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "prennicky": [
          "leaf_2",
          "leaf_3",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "rafting": [
          "leaf_2",
          "leaf_3",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "relatively": [
          "leaf_2",
          "leaf_6",
          "node_1_1",
          "node_1_3",
          "node_2_0",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "river": [
          "leaf_2",
          "leaf_3",
          "leaf_6",
          "leaf_8",
          "leaf_11",
          "leaf_18",
          "leaf_28",
          "leaf_30",
          "leaf_32",
          "leaf_34",
          "leaf_35",
          "leaf_36",
          "leaf_37",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "node_1_1",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_9",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_4",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "seconds": [
          "leaf_2",
          "leaf_4",
          "leaf_10",
          "leaf_12",
          "leaf_16",
          "leaf_29",
          "leaf_30",
          "leaf_33",
          "leaf_40",
          "leaf_53",
          "leaf_56",
          "node_1_1",
          "node_1_2",
          "node_1_5",
          "node_1_6",
          "node_1_8",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_20",
          "node_1_26",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_7",
          "node_2_8",
          "node_2_10",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "sitting": [
          "leaf_2",
          "leaf_3",
          "leaf_5",
          "leaf_6",
          "leaf_8",
          "leaf_10",
          "leaf_13",
          "leaf_22",
          "leaf_23",
          "leaf_25",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_48",
          "leaf_50",
          "leaf_52",
          "leaf_53",
          "leaf_54",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "leaf_59",
          "node_1_1",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_11",
          "node_1_12",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_5",
          "node_2_6",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "stable": [
          "leaf_2",
          "leaf_6",
          "leaf_10",
          "leaf_16",
          "leaf_28",
          "leaf_38",
          "leaf_52",
          "node_1_1",
          "node_1_3",
          "node_1_5",
          "node_1_8",
          "node_1_14",
          "node_1_19",
          "node_1_26",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_4",
          "node_2_7",
          "node_2_9",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "structure": [
          "leaf_2",
          "leaf_51",
          "node_1_1",
          "node_1_25",
          "node_2_0",
          "node_2_12",
          "node_3_0",
          "node_3_6",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "surrounding": [
          "leaf_2",
          "leaf_12",
          "leaf_16",
          "leaf_27",
          "leaf_41",
          "leaf_42",
          "node_1_1",
          "node_1_6",
          "node_1_8",
          "node_1_13",
          "node_1_20",
          "node_1_21",
          "node_2_0",
          "node_2_3",
          "node_2_4",
          "node_2_6",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "wooden": [
          "leaf_2",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "young": [
          "leaf_2",
          "leaf_4",
          "leaf_5",
          "leaf_8",
          "leaf_15",
          "leaf_28",
          "leaf_31",
          "leaf_33",
          "leaf_34",
          "leaf_38",
          "leaf_40",
          "leaf_45",
          "leaf_46",
          "leaf_49",
          "leaf_56",
          "leaf_57",
          "node_1_1",
          "node_1_2",
          "node_1_4",
          "node_1_7",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_19",
          "node_1_20",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_28",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "3d": [
          "leaf_3",
          "leaf_30",
          "leaf_33",
          "leaf_42",
          "leaf_45",
          "leaf_54",
          "leaf_57",
          "node_1_1",
          "node_1_15",
          "node_1_16",
          "node_1_21",
          "node_1_22",
          "node_1_27",
          "node_1_28",
          "node_2_0",
          "node_2_7",
          "node_2_8",
          "node_2_10",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "axe": [
          "leaf_3",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "cabin": [
          "leaf_3",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "coffee": [
          "leaf_3",
          "leaf_46",
          "node_1_1",
          "node_1_23",
          "node_2_0",
          "node_2_11",
          "node_3_0",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "crafting": [
          "leaf_3",
          "leaf_4",
          "node_1_1",
          "node_1_2",
          "node_2_0",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "cup": [
          "leaf_3",
          "leaf_53",
          "leaf_59",
          "node_1_1",
          "node_1_26",
          "node_1_29",
          "node_2_0",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "filming": [
          "leaf_3",
          "leaf_8",
          "leaf_51",
          "node_1_1",
          "node_1_4",
          "node_1_25",
          "node_2_0",
          "node_2_2",
          "node_2_12",
          "node_3_0",
          "node_3_1",
          "node_3_6",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "forest": [
          "leaf_3",
          "leaf_19",
          "leaf_23",
          "leaf_25",
          "node_1_1",
          "node_1_9",
          "node_1_11",
          "node_1_12",
          "node_2_0",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_3_0",
          "node_3_2",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "front": [
          "leaf_3",
          "leaf_5",
          "leaf_7",
          "leaf_9",
          "leaf_10",
          "leaf_12",
          "leaf_18",
          "leaf_25",
          "leaf_45",
          "leaf_47",
          "leaf_52",
          "leaf_57",
          "leaf_58",
          "node_1_1",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_9",
          "node_1_12",
          "node_1_22",
          "node_1_23",
          "node_1_26",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_6",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "frying": [
          "leaf_3",
          "leaf_49",
          "node_1_1",
          "node_1_24",
          "node_2_0",
          "node_2_12",
          "node_3_0",
          "node_3_6",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "kaleidoscope": [
          "leaf_3",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "kite": [
          "leaf_3",
          "leaf_51",
          "node_1_1",
          "node_1_25",
          "node_2_0",
          "node_2_12",
          "node_3_0",
          "node_3_6",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "large": [
          "leaf_3",
          "leaf_4",
          "leaf_12",
          "leaf_14",
          "leaf_20",
          "leaf_31",
          "leaf_38",
          "leaf_45",
          "leaf_46",
          "node_1_1",
          "node_1_2",
          "node_1_6",
          "node_1_7",
          "node_1_10",
          "node_1_15",
          "node_1_19",
          "node_1_22",
          "node_1_23",
          "node_2_0",
          "node_2_1",
          "node_2_3",
          "node_2_5",
          "node_2_7",
          "node_2_9",
          "node_2_11",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "log": [
          "leaf_3",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "mug": [
          "leaf_3",
          "leaf_46",
          "node_1_1",
          "node_1_23",
          "node_2_0",
          "node_2_11",
          "node_3_0",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "outside": [
          "leaf_3",
          "leaf_9",
          "leaf_33",
          "leaf_35",
          "leaf_53",
          "node_1_1",
          "node_1_4",
          "node_1_16",
          "node_1_17",
          "node_1_26",
          "node_2_0",
          "node_2_2",
          "node_2_8",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_4",
          "node_3_6",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "pan": [
          "leaf_3",
          "leaf_49",
          "leaf_50",
          "leaf_55",
          "node_1_1",
          "node_1_24",
          "node_1_25",
          "node_1_27",
          "node_2_0",
          "node_2_12",
          "node_2_13",
          "node_3_0",
          "node_3_6",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "seen": [
          "leaf_3",
          "leaf_7",
          "leaf_9",
          "leaf_12",
          "leaf_23",
          "leaf_26",
          "leaf_34",
          "leaf_38",
          "leaf_46",
          "leaf_49",
          "leaf_52",
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "leaf_59",
          "node_1_1",
          "node_1_3",
          "node_1_4",
          "node_1_6",
          "node_1_11",
          "node_1_13",
          "node_1_17",
          "node_1_19",
          "node_1_23",
          "node_1_24",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_0",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_5",
          "node_2_6",
          "node_2_8",
          "node_2_9",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "stool": [
          "leaf_3",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "stuck": [
          "leaf_3",
          "node_1_1",
          "node_2_0",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "stump": [
          "leaf_3",
          "leaf_4",
          "node_1_1",
          "node_1_2",
          "node_2_0",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "youtuber": [
          "leaf_3",
          "leaf_4",
          "node_1_1",
          "node_1_2",
          "node_2_0",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "12345": [
          "leaf_4",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "27": [
          "leaf_4",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "beside": [
          "leaf_4",
          "leaf_15",
          "leaf_26",
          "leaf_40",
          "node_1_2",
          "node_1_7",
          "node_1_13",
          "node_1_20",
          "node_2_1",
          "node_2_3",
          "node_2_6",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "car": [
          "leaf_4",
          "leaf_5",
          "leaf_6",
          "leaf_7",
          "leaf_11",
          "node_1_2",
          "node_1_3",
          "node_1_5",
          "node_2_1",
          "node_2_2",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "child": [
          "leaf_4",
          "leaf_26",
          "leaf_28",
          "leaf_32",
          "leaf_33",
          "leaf_44",
          "leaf_49",
          "node_1_2",
          "node_1_13",
          "node_1_14",
          "node_1_16",
          "node_1_22",
          "node_1_24",
          "node_2_1",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_11",
          "node_2_12",
          "node_3_0",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "dashcam": [
          "leaf_4",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "driver": [
          "leaf_4",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "drivers": [
          "leaf_4",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "driving": [
          "leaf_4",
          "leaf_11",
          "node_1_2",
          "node_1_5",
          "node_2_1",
          "node_2_2",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "everyday": [
          "leaf_4",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "fair": [
          "leaf_4",
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "features": [
          "leaf_4",
          "leaf_6",
          "leaf_9",
          "leaf_29",
          "leaf_31",
          "leaf_37",
          "leaf_55",
          "leaf_59",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_14",
          "node_1_15",
          "node_1_18",
          "node_1_27",
          "node_1_29",
          "node_2_1",
          "node_2_2",
          "node_2_7",
          "node_2_9",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_4",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "footage": [
          "leaf_4",
          "leaf_6",
          "leaf_10",
          "leaf_12",
          "leaf_16",
          "leaf_27",
          "leaf_29",
          "leaf_34",
          "leaf_35",
          "leaf_40",
          "leaf_41",
          "leaf_52",
          "leaf_56",
          "node_1_2",
          "node_1_3",
          "node_1_5",
          "node_1_6",
          "node_1_8",
          "node_1_13",
          "node_1_14",
          "node_1_17",
          "node_1_20",
          "node_1_26",
          "node_1_28",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_10",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "group": [
          "leaf_4",
          "leaf_47",
          "leaf_50",
          "node_1_2",
          "node_1_23",
          "node_1_25",
          "node_2_1",
          "node_2_11",
          "node_2_12",
          "node_3_0",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "interior": [
          "leaf_4",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "life": [
          "leaf_4",
          "leaf_12",
          "leaf_29",
          "leaf_56",
          "node_1_2",
          "node_1_6",
          "node_1_14",
          "node_1_28",
          "node_2_1",
          "node_2_3",
          "node_2_7",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "long": [
          "leaf_4",
          "leaf_7",
          "leaf_9",
          "leaf_10",
          "leaf_17",
          "leaf_31",
          "leaf_35",
          "leaf_37",
          "leaf_43",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_8",
          "node_1_15",
          "node_1_17",
          "node_1_18",
          "node_1_21",
          "node_2_1",
          "node_2_2",
          "node_2_4",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "moment": [
          "leaf_4",
          "leaf_8",
          "leaf_31",
          "leaf_34",
          "leaf_37",
          "leaf_45",
          "leaf_49",
          "leaf_50",
          "leaf_58",
          "node_1_2",
          "node_1_4",
          "node_1_15",
          "node_1_17",
          "node_1_18",
          "node_1_22",
          "node_1_24",
          "node_1_25",
          "node_1_29",
          "node_2_1",
          "node_2_2",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "part": [
          "leaf_4",
          "leaf_7",
          "leaf_16",
          "leaf_27",
          "node_1_2",
          "node_1_3",
          "node_1_8",
          "node_1_13",
          "node_2_1",
          "node_2_4",
          "node_2_6",
          "node_3_0",
          "node_3_2",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "photo": [
          "leaf_4",
          "leaf_22",
          "node_1_2",
          "node_1_11",
          "node_2_1",
          "node_2_5",
          "node_3_0",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "red": [
          "leaf_4",
          "leaf_8",
          "leaf_10",
          "leaf_12",
          "leaf_19",
          "leaf_20",
          "leaf_22",
          "leaf_23",
          "leaf_24",
          "leaf_25",
          "leaf_26",
          "leaf_27",
          "leaf_28",
          "leaf_30",
          "leaf_31",
          "leaf_32",
          "leaf_33",
          "leaf_34",
          "leaf_38",
          "leaf_40",
          "leaf_44",
          "leaf_45",
          "leaf_47",
          "leaf_48",
          "leaf_52",
          "leaf_53",
          "leaf_54",
          "node_1_2",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_9",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_19",
          "node_1_20",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_26",
          "node_1_27",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "road": [
          "leaf_4",
          "leaf_24",
          "leaf_29",
          "node_1_2",
          "node_1_12",
          "node_1_14",
          "node_2_1",
          "node_2_6",
          "node_2_7",
          "node_3_0",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "says": [
          "leaf_4",
          "leaf_17",
          "node_1_2",
          "node_1_8",
          "node_2_1",
          "node_2_4",
          "node_3_0",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "seated": [
          "leaf_4",
          "leaf_5",
          "leaf_48",
          "leaf_49",
          "leaf_58",
          "node_1_2",
          "node_1_24",
          "node_1_29",
          "node_2_1",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "surroundings": [
          "leaf_4",
          "leaf_7",
          "leaf_29",
          "leaf_38",
          "leaf_51",
          "node_1_2",
          "node_1_3",
          "node_1_14",
          "node_1_19",
          "node_1_25",
          "node_2_1",
          "node_2_7",
          "node_2_9",
          "node_2_12",
          "node_3_0",
          "node_3_3",
          "node_3_4",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "trip": [
          "leaf_4",
          "leaf_23",
          "leaf_45",
          "leaf_47",
          "leaf_51",
          "leaf_53",
          "leaf_55",
          "node_1_2",
          "node_1_11",
          "node_1_22",
          "node_1_23",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_2_1",
          "node_2_5",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_3_0",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "vehicle": [
          "leaf_4",
          "leaf_5",
          "leaf_11",
          "node_1_2",
          "node_1_5",
          "node_2_1",
          "node_2_2",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "visible": [
          "leaf_4",
          "leaf_5",
          "leaf_6",
          "leaf_7",
          "leaf_8",
          "leaf_10",
          "leaf_13",
          "leaf_26",
          "leaf_29",
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "leaf_44",
          "leaf_45",
          "leaf_47",
          "leaf_50",
          "leaf_52",
          "leaf_56",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_13",
          "node_1_14",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_25",
          "node_1_26",
          "node_1_28",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_6",
          "node_2_7",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "well": [
          "leaf_4",
          "leaf_14",
          "leaf_15",
          "leaf_54",
          "node_1_2",
          "node_1_7",
          "node_1_27",
          "node_2_1",
          "node_2_3",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_6",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "white": [
          "leaf_4",
          "leaf_8",
          "leaf_12",
          "leaf_13",
          "leaf_22",
          "leaf_30",
          "leaf_32",
          "leaf_45",
          "leaf_51",
          "leaf_54",
          "leaf_55",
          "leaf_59",
          "node_1_2",
          "node_1_4",
          "node_1_6",
          "node_1_11",
          "node_1_15",
          "node_1_16",
          "node_1_22",
          "node_1_25",
          "node_1_27",
          "node_1_29",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_5",
          "node_2_7",
          "node_2_8",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "window": [
          "leaf_4",
          "leaf_9",
          "node_1_2",
          "node_1_4",
          "node_2_1",
          "node_2_2",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "32": [
          "leaf_5",
          "leaf_56",
          "node_1_2",
          "node_1_28",
          "node_2_1",
          "node_2_14",
          "node_3_0",
          "node_3_7",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "35": [
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "additionally": [
          "leaf_5",
          "leaf_45",
          "node_1_2",
          "node_1_22",
          "node_2_1",
          "node_2_11",
          "node_3_0",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "aircraft": [
          "leaf_5",
          "leaf_7",
          "leaf_9",
          "leaf_11",
          "leaf_12",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "bags": [
          "leaf_5",
          "leaf_49",
          "leaf_52",
          "leaf_58",
          "leaf_59",
          "node_1_2",
          "node_1_24",
          "node_1_26",
          "node_1_29",
          "node_2_1",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "bottle": [
          "leaf_5",
          "leaf_29",
          "leaf_38",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_52",
          "leaf_53",
          "leaf_58",
          "leaf_59",
          "node_1_2",
          "node_1_14",
          "node_1_19",
          "node_1_22",
          "node_1_23",
          "node_1_26",
          "node_1_29",
          "node_2_1",
          "node_2_7",
          "node_2_9",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "carrying": [
          "leaf_5",
          "leaf_19",
          "leaf_20",
          "leaf_21",
          "node_1_2",
          "node_1_9",
          "node_1_10",
          "node_2_1",
          "node_2_4",
          "node_2_5",
          "node_3_0",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "center": [
          "leaf_5",
          "leaf_15",
          "leaf_58",
          "node_1_2",
          "node_1_7",
          "node_1_29",
          "node_2_1",
          "node_2_3",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_7",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "chairs": [
          "leaf_5",
          "leaf_49",
          "node_1_2",
          "node_1_24",
          "node_2_1",
          "node_2_12",
          "node_3_0",
          "node_3_6",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "characteristics": [
          "leaf_5",
          "leaf_20",
          "leaf_22",
          "node_1_2",
          "node_1_10",
          "node_1_11",
          "node_2_1",
          "node_2_5",
          "node_3_0",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "closer": [
          "leaf_5",
          "leaf_46",
          "leaf_58",
          "node_1_2",
          "node_1_23",
          "node_1_29",
          "node_2_1",
          "node_2_11",
          "node_2_14",
          "node_3_0",
          "node_3_5",
          "node_3_7",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "day": [
          "leaf_5",
          "leaf_7",
          "leaf_13",
          "leaf_14",
          "leaf_18",
          "node_1_2",
          "node_1_3",
          "node_1_6",
          "node_1_7",
          "node_1_9",
          "node_2_1",
          "node_2_3",
          "node_2_4",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "detected": [
          "leaf_5",
          "leaf_31",
          "leaf_32",
          "leaf_45",
          "node_1_2",
          "node_1_15",
          "node_1_16",
          "node_1_22",
          "node_2_1",
          "node_2_7",
          "node_2_8",
          "node_2_11",
          "node_3_0",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "elements": [
          "leaf_5",
          "leaf_6",
          "leaf_22",
          "leaf_44",
          "leaf_51",
          "node_1_2",
          "node_1_3",
          "node_1_11",
          "node_1_22",
          "node_1_25",
          "node_2_1",
          "node_2_5",
          "node_2_11",
          "node_2_12",
          "node_3_0",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "head": [
          "leaf_5",
          "leaf_10",
          "leaf_36",
          "leaf_40",
          "node_1_2",
          "node_1_5",
          "node_1_18",
          "node_1_20",
          "node_2_1",
          "node_2_2",
          "node_2_9",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "himself": [
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "located": [
          "leaf_5",
          "leaf_7",
          "leaf_15",
          "leaf_49",
          "leaf_58",
          "node_1_2",
          "node_1_3",
          "node_1_7",
          "node_1_24",
          "node_1_29",
          "node_2_1",
          "node_2_3",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "locations": [
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "looks": [
          "leaf_5",
          "leaf_18",
          "leaf_26",
          "leaf_44",
          "node_1_2",
          "node_1_9",
          "node_1_13",
          "node_1_22",
          "node_2_1",
          "node_2_4",
          "node_2_6",
          "node_2_11",
          "node_3_0",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "machinery": [
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "market": [
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "operating": [
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "personal": [
          "leaf_5",
          "leaf_55",
          "node_1_2",
          "node_1_27",
          "node_2_1",
          "node_2_13",
          "node_3_0",
          "node_3_6",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "piece": [
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "pilot": [
          "leaf_5",
          "leaf_6",
          "leaf_9",
          "leaf_10",
          "leaf_11",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_2_1",
          "node_2_2",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "possibly": [
          "leaf_5",
          "leaf_6",
          "leaf_8",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_14",
          "leaf_18",
          "leaf_27",
          "leaf_32",
          "leaf_34",
          "leaf_35",
          "leaf_41",
          "leaf_44",
          "leaf_45",
          "leaf_47",
          "leaf_51",
          "leaf_52",
          "leaf_53",
          "leaf_59",
          "node_1_2",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_6",
          "node_1_7",
          "node_1_9",
          "node_1_13",
          "node_1_16",
          "node_1_17",
          "node_1_20",
          "node_1_22",
          "node_1_23",
          "node_1_25",
          "node_1_26",
          "node_1_29",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_6",
          "node_2_8",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "rainy": [
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "repair": [
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "respective": [
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "seat": [
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "seats": [
          "leaf_5",
          "leaf_8",
          "node_1_2",
          "node_1_4",
          "node_2_1",
          "node_2_2",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "situated": [
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "someone": [
          "leaf_5",
          "leaf_16",
          "leaf_22",
          "leaf_24",
          "leaf_31",
          "leaf_42",
          "leaf_45",
          "leaf_54",
          "leaf_59",
          "node_1_2",
          "node_1_8",
          "node_1_11",
          "node_1_12",
          "node_1_15",
          "node_1_21",
          "node_1_22",
          "node_1_27",
          "node_1_29",
          "node_2_1",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_10",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "stall": [
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "suggesting": [
          "leaf_5",
          "leaf_14",
          "leaf_15",
          "leaf_17",
          "leaf_26",
          "leaf_45",
          "node_1_2",
          "node_1_7",
          "node_1_8",
          "node_1_13",
          "node_1_22",
          "node_2_1",
          "node_2_3",
          "node_2_4",
          "node_2_6",
          "node_2_11",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "talking": [
          "leaf_5",
          "leaf_16",
          "leaf_34",
          "leaf_37",
          "leaf_56",
          "node_1_2",
          "node_1_8",
          "node_1_17",
          "node_1_18",
          "node_1_28",
          "node_2_1",
          "node_2_4",
          "node_2_8",
          "node_2_9",
          "node_2_14",
          "node_3_0",
          "node_3_2",
          "node_3_4",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "turned": [
          "leaf_5",
          "node_1_2",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "under": [
          "leaf_5",
          "leaf_22",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_50",
          "leaf_57",
          "node_1_2",
          "node_1_11",
          "node_1_22",
          "node_1_23",
          "node_1_25",
          "node_1_28",
          "node_2_1",
          "node_2_5",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "unique": [
          "leaf_5",
          "leaf_8",
          "leaf_23",
          "leaf_58",
          "node_1_2",
          "node_1_4",
          "node_1_11",
          "node_1_29",
          "node_2_1",
          "node_2_2",
          "node_2_5",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "various": [
          "leaf_5",
          "leaf_22",
          "leaf_26",
          "leaf_30",
          "leaf_41",
          "leaf_42",
          "leaf_46",
          "leaf_47",
          "leaf_49",
          "leaf_51",
          "leaf_52",
          "leaf_55",
          "leaf_57",
          "leaf_58",
          "leaf_59",
          "node_1_2",
          "node_1_11",
          "node_1_13",
          "node_1_15",
          "node_1_20",
          "node_1_21",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_1",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "works": [
          "leaf_5",
          "leaf_6",
          "node_1_2",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "above": [
          "leaf_6",
          "leaf_8",
          "leaf_9",
          "leaf_18",
          "leaf_32",
          "leaf_55",
          "node_1_3",
          "node_1_4",
          "node_1_9",
          "node_1_16",
          "node_1_27",
          "node_2_1",
          "node_2_2",
          "node_2_4",
          "node_2_8",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "adding": [
          "leaf_6",
          "leaf_58",
          "node_1_3",
          "node_1_29",
          "node_2_1",
          "node_2_14",
          "node_3_0",
          "node_3_7",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "aid": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "along": [
          "leaf_6",
          "leaf_17",
          "leaf_19",
          "leaf_23",
          "leaf_24",
          "leaf_26",
          "leaf_28",
          "leaf_38",
          "leaf_46",
          "leaf_55",
          "node_1_3",
          "node_1_8",
          "node_1_9",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_19",
          "node_1_23",
          "node_1_27",
          "node_2_1",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_9",
          "node_2_11",
          "node_2_13",
          "node_3_0",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "altitude": [
          "leaf_6",
          "leaf_8",
          "node_1_3",
          "node_1_4",
          "node_2_1",
          "node_2_2",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "ball": [
          "leaf_6",
          "leaf_48",
          "node_1_3",
          "node_1_24",
          "node_2_1",
          "node_2_12",
          "node_3_0",
          "node_3_6",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "board": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "buttons": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "cockpit": [
          "leaf_6",
          "leaf_7",
          "leaf_8",
          "leaf_10",
          "leaf_11",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_2_1",
          "node_2_2",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "context": [
          "leaf_6",
          "leaf_22",
          "leaf_32",
          "node_1_3",
          "node_1_11",
          "node_1_16",
          "node_2_1",
          "node_2_5",
          "node_2_8",
          "node_3_0",
          "node_3_2",
          "node_3_4",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "control": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "controls": [
          "leaf_6",
          "leaf_11",
          "node_1_3",
          "node_1_5",
          "node_2_1",
          "node_2_2",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "crucial": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "dynamic": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "engaging": [
          "leaf_6",
          "leaf_47",
          "leaf_48",
          "node_1_3",
          "node_1_23",
          "node_1_24",
          "node_2_1",
          "node_2_11",
          "node_2_12",
          "node_3_0",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "filled": [
          "leaf_6",
          "leaf_8",
          "leaf_9",
          "leaf_26",
          "leaf_42",
          "node_1_3",
          "node_1_4",
          "node_1_13",
          "node_1_21",
          "node_2_1",
          "node_2_2",
          "node_2_6",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "flies": [
          "leaf_6",
          "leaf_35",
          "leaf_42",
          "leaf_43",
          "node_1_3",
          "node_1_17",
          "node_1_21",
          "node_2_1",
          "node_2_8",
          "node_2_10",
          "node_3_0",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "helmet": [
          "leaf_6",
          "leaf_22",
          "leaf_27",
          "leaf_29",
          "leaf_48",
          "leaf_55",
          "node_1_3",
          "node_1_11",
          "node_1_13",
          "node_1_14",
          "node_1_24",
          "node_1_27",
          "node_2_1",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_12",
          "node_2_13",
          "node_3_0",
          "node_3_2",
          "node_3_3",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "house": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "information": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "interesting": [
          "leaf_6",
          "leaf_12",
          "leaf_50",
          "leaf_55",
          "node_1_3",
          "node_1_6",
          "node_1_25",
          "node_1_27",
          "node_2_1",
          "node_2_3",
          "node_2_12",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_6",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "laptop": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "low": [
          "leaf_6",
          "leaf_14",
          "node_1_3",
          "node_1_7",
          "node_2_1",
          "node_2_3",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "making": [
          "leaf_6",
          "leaf_9",
          "leaf_34",
          "leaf_44",
          "node_1_3",
          "node_1_4",
          "node_1_17",
          "node_1_22",
          "node_2_1",
          "node_2_2",
          "node_2_8",
          "node_2_11",
          "node_3_0",
          "node_3_1",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "mounted": [
          "leaf_6",
          "leaf_10",
          "leaf_11",
          "leaf_12",
          "leaf_17",
          "leaf_18",
          "leaf_20",
          "leaf_22",
          "leaf_23",
          "leaf_24",
          "leaf_27",
          "leaf_29",
          "leaf_36",
          "leaf_38",
          "leaf_41",
          "leaf_43",
          "leaf_44",
          "leaf_45",
          "leaf_48",
          "leaf_49",
          "leaf_52",
          "leaf_55",
          "leaf_59",
          "node_1_3",
          "node_1_5",
          "node_1_6",
          "node_1_8",
          "node_1_9",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_24",
          "node_1_26",
          "node_1_27",
          "node_1_29",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "multiple": [
          "leaf_6",
          "leaf_22",
          "leaf_26",
          "leaf_42",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_53",
          "leaf_55",
          "leaf_56",
          "node_1_3",
          "node_1_11",
          "node_1_13",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_2_1",
          "node_2_5",
          "node_2_6",
          "node_2_10",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "navigates": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "ocean": [
          "leaf_6",
          "leaf_14",
          "leaf_16",
          "leaf_24",
          "node_1_3",
          "node_1_7",
          "node_1_8",
          "node_1_12",
          "node_2_1",
          "node_2_3",
          "node_2_4",
          "node_2_6",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "screen": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "serving": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "shoulder": [
          "leaf_6",
          "leaf_18",
          "leaf_32",
          "node_1_3",
          "node_1_9",
          "node_1_16",
          "node_2_1",
          "node_2_4",
          "node_2_8",
          "node_3_0",
          "node_3_2",
          "node_3_4",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "sits": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "speedometer": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "steering": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "surfaces": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "switches": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "trees": [
          "leaf_6",
          "leaf_11",
          "leaf_15",
          "leaf_20",
          "leaf_21",
          "leaf_23",
          "leaf_36",
          "leaf_41",
          "leaf_44",
          "node_1_3",
          "node_1_5",
          "node_1_7",
          "node_1_10",
          "node_1_11",
          "node_1_18",
          "node_1_20",
          "node_1_22",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_5",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "tripod": [
          "leaf_6",
          "leaf_14",
          "leaf_37",
          "leaf_52",
          "leaf_56",
          "node_1_3",
          "node_1_7",
          "node_1_18",
          "node_1_26",
          "node_1_28",
          "node_2_1",
          "node_2_3",
          "node_2_9",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_4",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "viewers": [
          "leaf_6",
          "leaf_8",
          "leaf_29",
          "leaf_42",
          "node_1_3",
          "node_1_4",
          "node_1_14",
          "node_1_21",
          "node_2_1",
          "node_2_2",
          "node_2_7",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_3",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "visual": [
          "leaf_6",
          "leaf_9",
          "node_1_3",
          "node_1_4",
          "node_2_1",
          "node_2_2",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "wheel": [
          "leaf_6",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "10": [
          "leaf_7",
          "leaf_11",
          "leaf_14",
          "leaf_23",
          "leaf_36",
          "leaf_40",
          "node_1_3",
          "node_1_5",
          "node_1_7",
          "node_1_11",
          "node_1_18",
          "node_1_20",
          "node_2_1",
          "node_2_2",
          "node_2_3",
          "node_2_5",
          "node_2_9",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "aerial": [
          "leaf_7",
          "leaf_8",
          "node_1_3",
          "node_1_4",
          "node_2_1",
          "node_2_2",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "around": [
          "leaf_7",
          "leaf_26",
          "leaf_29",
          "leaf_37",
          "leaf_45",
          "leaf_46",
          "leaf_48",
          "leaf_49",
          "leaf_50",
          "leaf_52",
          "leaf_53",
          "leaf_55",
          "leaf_57",
          "leaf_58",
          "node_1_3",
          "node_1_13",
          "node_1_14",
          "node_1_18",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_1",
          "node_2_6",
          "node_2_7",
          "node_2_9",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "below": [
          "leaf_7",
          "leaf_8",
          "node_1_3",
          "node_1_4",
          "node_2_1",
          "node_2_2",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "birds": [
          "leaf_7",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "body": [
          "leaf_7",
          "leaf_12",
          "leaf_14",
          "leaf_16",
          "leaf_17",
          "leaf_24",
          "leaf_27",
          "leaf_29",
          "leaf_34",
          "leaf_37",
          "leaf_40",
          "leaf_41",
          "leaf_43",
          "leaf_44",
          "leaf_48",
          "leaf_49",
          "leaf_59",
          "node_1_3",
          "node_1_6",
          "node_1_7",
          "node_1_8",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_17",
          "node_1_18",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_24",
          "node_1_29",
          "node_2_1",
          "node_2_3",
          "node_2_4",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "building": [
          "leaf_7",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "bus": [
          "leaf_7",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "captured": [
          "leaf_7",
          "leaf_11",
          "leaf_16",
          "leaf_22",
          "leaf_27",
          "leaf_29",
          "leaf_30",
          "leaf_32",
          "leaf_35",
          "leaf_38",
          "leaf_39",
          "leaf_41",
          "leaf_43",
          "leaf_45",
          "leaf_46",
          "node_1_3",
          "node_1_5",
          "node_1_8",
          "node_1_11",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_2_1",
          "node_2_2",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "cars": [
          "leaf_7",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "edge": [
          "leaf_7",
          "leaf_14",
          "leaf_17",
          "leaf_34",
          "leaf_37",
          "leaf_38",
          "leaf_41",
          "node_1_3",
          "node_1_7",
          "node_1_8",
          "node_1_17",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_2_1",
          "node_2_3",
          "node_2_4",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "eye": [
          "leaf_7",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "field": [
          "leaf_7",
          "leaf_20",
          "leaf_22",
          "leaf_39",
          "node_1_3",
          "node_1_10",
          "node_1_11",
          "node_1_19",
          "node_2_1",
          "node_2_5",
          "node_2_9",
          "node_3_0",
          "node_3_2",
          "node_3_4",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "instruments": [
          "leaf_7",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "island": [
          "leaf_7",
          "node_1_3",
          "node_2_1",
          "node_3_0",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "landscape": [
          "leaf_7",
          "leaf_8",
          "leaf_9",
          "leaf_10",
          "leaf_16",
          "node_1_3",
          "node_1_4",
          "node_1_5",
          "node_1_8",
          "node_2_1",
          "node_2_2",
          "node_2_4",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "lot": [
          "leaf_7",
          "leaf_26",
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "node_1_3",
          "node_1_13",
          "node_1_27",
          "node_1_28",
          "node_2_1",
          "node_2_6",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_3",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "middle": [
          "leaf_7",
          "leaf_18",
          "leaf_59",
          "node_1_3",
          "node_1_9",
          "node_1_29",
          "node_2_1",
          "node_2_4",
          "node_2_14",
          "node_3_0",
          "node_3_2",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "overcast": [
          "leaf_7",
          "leaf_13",
          "leaf_14",
          "node_1_3",
          "node_1_6",
          "node_1_7",
          "node_2_1",
          "node_2_3",
          "node_3_0",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "shoreline": [
          "leaf_7",
          "leaf_15",
          "leaf_19",
          "leaf_38",
          "node_1_3",
          "node_1_7",
          "node_1_9",
          "node_1_19",
          "node_2_1",
          "node_2_3",
          "node_2_4",
          "node_2_9",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "shows": [
          "leaf_7",
          "leaf_8",
          "leaf_34",
          "leaf_37",
          "leaf_41",
          "leaf_45",
          "leaf_52",
          "node_1_3",
          "node_1_4",
          "node_1_17",
          "node_1_18",
          "node_1_20",
          "node_1_22",
          "node_1_26",
          "node_2_1",
          "node_2_2",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_13",
          "node_3_0",
          "node_3_1",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "tracks": [
          "leaf_7",
          "leaf_31",
          "node_1_3",
          "node_1_15",
          "node_2_1",
          "node_2_7",
          "node_3_0",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "using": [
          "leaf_7",
          "leaf_11",
          "leaf_16",
          "leaf_27",
          "leaf_38",
          "leaf_42",
          "leaf_43",
          "leaf_50",
          "leaf_51",
          "node_1_3",
          "node_1_5",
          "node_1_8",
          "node_1_13",
          "node_1_19",
          "node_1_21",
          "node_1_25",
          "node_2_1",
          "node_2_2",
          "node_2_4",
          "node_2_6",
          "node_2_9",
          "node_2_10",
          "node_2_12",
          "node_3_0",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "wing": [
          "leaf_7",
          "leaf_8",
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "node_1_3",
          "node_1_4",
          "node_1_27",
          "node_1_28",
          "node_2_1",
          "node_2_2",
          "node_2_13",
          "node_2_14",
          "node_3_0",
          "node_3_1",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "appreciate": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "beauty": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "channels": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "communication": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "connected": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "corner": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "documentation": [
          "leaf_8",
          "leaf_29",
          "node_1_4",
          "node_1_14",
          "node_2_2",
          "node_2_7",
          "node_3_1",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "due": [
          "leaf_8",
          "leaf_46",
          "node_1_4",
          "node_1_23",
          "node_2_2",
          "node_2_11",
          "node_3_1",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "earth": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "effect": [
          "leaf_8",
          "leaf_37",
          "leaf_44",
          "node_1_4",
          "node_1_18",
          "node_1_22",
          "node_2_2",
          "node_2_9",
          "node_2_11",
          "node_3_1",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "expansive": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "fisheye": [
          "leaf_8",
          "leaf_9",
          "leaf_35",
          "leaf_38",
          "leaf_42",
          "leaf_44",
          "node_1_4",
          "node_1_17",
          "node_1_19",
          "node_1_21",
          "node_1_22",
          "node_2_2",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_3_1",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "focus": [
          "leaf_8",
          "leaf_29",
          "leaf_47",
          "node_1_4",
          "node_1_14",
          "node_1_23",
          "node_2_2",
          "node_2_7",
          "node_2_11",
          "node_3_1",
          "node_3_3",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "giving": [
          "leaf_8",
          "leaf_9",
          "leaf_31",
          "leaf_32",
          "node_1_4",
          "node_1_15",
          "node_1_16",
          "node_2_2",
          "node_2_7",
          "node_2_8",
          "node_3_1",
          "node_3_3",
          "node_3_4",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "headphones": [
          "leaf_8",
          "leaf_10",
          "node_1_4",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "indicates": [
          "leaf_8",
          "leaf_29",
          "node_1_4",
          "node_1_14",
          "node_2_2",
          "node_2_7",
          "node_3_1",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "jackets": [
          "leaf_8",
          "leaf_19",
          "leaf_22",
          "leaf_32",
          "node_1_4",
          "node_1_9",
          "node_1_11",
          "node_1_16",
          "node_2_2",
          "node_2_4",
          "node_2_5",
          "node_2_8",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "marshy": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "natural": [
          "leaf_8",
          "leaf_41",
          "leaf_51",
          "node_1_4",
          "node_1_20",
          "node_1_25",
          "node_2_2",
          "node_2_10",
          "node_2_12",
          "node_3_1",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "noticeable": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "point": [
          "leaf_8",
          "leaf_12",
          "leaf_24",
          "leaf_27",
          "leaf_34",
          "leaf_44",
          "leaf_46",
          "node_1_4",
          "node_1_6",
          "node_1_12",
          "node_1_13",
          "node_1_17",
          "node_1_22",
          "node_1_23",
          "node_2_2",
          "node_2_3",
          "node_2_6",
          "node_2_8",
          "node_2_11",
          "node_3_1",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "purposes": [
          "leaf_8",
          "leaf_26",
          "node_1_4",
          "node_1_13",
          "node_2_2",
          "node_2_6",
          "node_3_1",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "radio": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "recreational": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "rivers": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "scenic": [
          "leaf_8",
          "leaf_9",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "sense": [
          "leaf_8",
          "leaf_32",
          "node_1_4",
          "node_1_16",
          "node_2_2",
          "node_2_8",
          "node_3_1",
          "node_3_4",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "showcasing": [
          "leaf_8",
          "leaf_46",
          "node_1_4",
          "node_1_23",
          "node_2_2",
          "node_2_11",
          "node_3_1",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "system": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "turbulence": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "upper": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "valley": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "vantage": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "vastness": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "viewed": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "wetlands": [
          "leaf_8",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "amazing": [
          "leaf_9",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "before": [
          "leaf_9",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "countryside": [
          "leaf_9",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "focused": [
          "leaf_9",
          "leaf_38",
          "leaf_42",
          "node_1_4",
          "node_1_19",
          "node_1_21",
          "node_2_2",
          "node_2_9",
          "node_2_10",
          "node_3_1",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "navigating": [
          "leaf_9",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "passenger": [
          "leaf_9",
          "leaf_10",
          "node_1_4",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "plants": [
          "leaf_9",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "range": [
          "leaf_9",
          "leaf_24",
          "node_1_4",
          "node_1_12",
          "node_2_2",
          "node_2_6",
          "node_3_1",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "snowy": [
          "leaf_9",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "stunning": [
          "leaf_9",
          "leaf_10",
          "node_1_4",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "unfolds": [
          "leaf_9",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "valleys": [
          "leaf_9",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "viewer": [
          "leaf_9",
          "leaf_22",
          "leaf_34",
          "leaf_44",
          "node_1_4",
          "node_1_11",
          "node_1_17",
          "node_1_22",
          "node_2_2",
          "node_2_5",
          "node_2_8",
          "node_2_11",
          "node_3_1",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "views": [
          "leaf_9",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "wider": [
          "leaf_9",
          "node_1_4",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "15": [
          "leaf_10",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "clear": [
          "leaf_10",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "identified": [
          "leaf_10",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "jacket": [
          "leaf_10",
          "leaf_12",
          "leaf_16",
          "leaf_17",
          "leaf_20",
          "leaf_22",
          "leaf_23",
          "leaf_24",
          "leaf_25",
          "leaf_27",
          "leaf_28",
          "leaf_31",
          "leaf_33",
          "leaf_38",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "leaf_44",
          "leaf_45",
          "leaf_47",
          "node_1_5",
          "node_1_6",
          "node_1_8",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_19",
          "node_1_20",
          "node_1_22",
          "node_1_23",
          "node_2_2",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "movement": [
          "leaf_10",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "scenery": [
          "leaf_10",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "sky": [
          "leaf_10",
          "leaf_27",
          "leaf_40",
          "leaf_41",
          "node_1_5",
          "node_1_13",
          "node_1_20",
          "node_2_2",
          "node_2_6",
          "node_2_10",
          "node_3_1",
          "node_3_3",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "soars": [
          "leaf_10",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "specific": [
          "leaf_10",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "structures": [
          "leaf_10",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "wildlife": [
          "leaf_10",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "creates": [
          "leaf_11",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "dashboard": [
          "leaf_11",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "descriptions": [
          "leaf_11",
          "leaf_44",
          "leaf_54",
          "node_1_5",
          "node_1_22",
          "node_1_27",
          "node_2_2",
          "node_2_11",
          "node_2_13",
          "node_3_1",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "gauges": [
          "leaf_11",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "potentially": [
          "leaf_11",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "suggests": [
          "leaf_11",
          "leaf_27",
          "leaf_29",
          "leaf_41",
          "node_1_5",
          "node_1_13",
          "node_1_14",
          "node_1_20",
          "node_2_2",
          "node_2_6",
          "node_2_7",
          "node_2_10",
          "node_3_1",
          "node_3_3",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "wings": [
          "leaf_11",
          "node_1_5",
          "node_2_2",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "45": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "7373": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "activity": [
          "leaf_12",
          "leaf_26",
          "leaf_42",
          "leaf_48",
          "leaf_49",
          "node_1_6",
          "node_1_13",
          "node_1_21",
          "node_1_24",
          "node_2_3",
          "node_2_6",
          "node_2_10",
          "node_2_12",
          "node_3_1",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "admiring": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "aviation": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "craft": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "departure": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "device": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "door": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "excited": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "glimpse": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "number": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "persons": [
          "leaf_12",
          "leaf_45",
          "node_1_6",
          "node_1_22",
          "node_2_3",
          "node_2_11",
          "node_3_1",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "pontoon": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "preparing": [
          "leaf_12",
          "leaf_13",
          "leaf_45",
          "leaf_48",
          "leaf_50",
          "node_1_6",
          "node_1_22",
          "node_1_24",
          "node_1_25",
          "node_2_3",
          "node_2_11",
          "node_2_12",
          "node_3_1",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "raft": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "ready": [
          "leaf_12",
          "leaf_29",
          "leaf_30",
          "leaf_55",
          "leaf_56",
          "node_1_6",
          "node_1_14",
          "node_1_15",
          "node_1_27",
          "node_1_28",
          "node_2_3",
          "node_2_7",
          "node_2_13",
          "node_2_14",
          "node_3_1",
          "node_3_3",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "rear": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "ski": [
          "leaf_12",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "smiling": [
          "leaf_12",
          "leaf_45",
          "node_1_6",
          "node_1_22",
          "node_2_3",
          "node_2_11",
          "node_3_1",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "style": [
          "leaf_12",
          "leaf_22",
          "leaf_29",
          "node_1_6",
          "node_1_11",
          "node_1_14",
          "node_2_3",
          "node_2_5",
          "node_2_7",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "canister": [
          "leaf_13",
          "leaf_48",
          "node_1_6",
          "node_1_24",
          "node_2_3",
          "node_2_12",
          "node_3_1",
          "node_3_6",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "disembark": [
          "leaf_13",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "hanging": [
          "leaf_13",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "hook": [
          "leaf_13",
          "leaf_31",
          "node_1_6",
          "node_1_15",
          "node_2_3",
          "node_2_7",
          "node_3_1",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "lapse": [
          "leaf_13",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "orange": [
          "leaf_13",
          "leaf_16",
          "leaf_19",
          "leaf_22",
          "leaf_28",
          "leaf_30",
          "leaf_33",
          "leaf_40",
          "node_1_6",
          "node_1_8",
          "node_1_9",
          "node_1_11",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_20",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_7",
          "node_2_8",
          "node_2_10",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "rope": [
          "leaf_13",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "seaplane": [
          "leaf_13",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "tank": [
          "leaf_13",
          "node_1_6",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "time": [
          "leaf_13",
          "leaf_19",
          "leaf_40",
          "leaf_48",
          "leaf_52",
          "node_1_6",
          "node_1_9",
          "node_1_20",
          "node_1_24",
          "node_1_26",
          "node_2_3",
          "node_2_4",
          "node_2_10",
          "node_2_12",
          "node_2_13",
          "node_3_1",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "blurry": [
          "leaf_14",
          "leaf_35",
          "node_1_7",
          "node_1_17",
          "node_2_3",
          "node_2_8",
          "node_3_1",
          "node_3_4",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "cloudy": [
          "leaf_14",
          "leaf_18",
          "node_1_7",
          "node_1_9",
          "node_2_3",
          "node_2_4",
          "node_3_1",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "colors": [
          "leaf_14",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "conditions": [
          "leaf_14",
          "leaf_51",
          "node_1_7",
          "node_1_25",
          "node_2_3",
          "node_2_12",
          "node_3_1",
          "node_3_6",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "dark": [
          "leaf_14",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "family": [
          "leaf_14",
          "leaf_23",
          "leaf_31",
          "leaf_32",
          "leaf_47",
          "leaf_51",
          "leaf_52",
          "node_1_7",
          "node_1_11",
          "node_1_15",
          "node_1_16",
          "node_1_23",
          "node_1_25",
          "node_1_26",
          "node_2_3",
          "node_2_5",
          "node_2_7",
          "node_2_8",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "light": [
          "leaf_14",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "muted": [
          "leaf_14",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "placed": [
          "leaf_14",
          "leaf_26",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "leaf_55",
          "leaf_56",
          "leaf_58",
          "leaf_59",
          "node_1_7",
          "node_1_13",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_3",
          "node_2_6",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_1",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "rod": [
          "leaf_14",
          "leaf_25",
          "leaf_27",
          "leaf_28",
          "leaf_34",
          "leaf_35",
          "leaf_39",
          "leaf_40",
          "leaf_42",
          "leaf_46",
          "leaf_53",
          "node_1_7",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_17",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_23",
          "node_1_26",
          "node_2_3",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_2_11",
          "node_2_13",
          "node_3_1",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "shutter": [
          "leaf_14",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "skies": [
          "leaf_14",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "slow": [
          "leaf_14",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "somewhat": [
          "leaf_14",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "speed": [
          "leaf_14",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "stability": [
          "leaf_14",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "48": [
          "leaf_15",
          "leaf_30",
          "node_1_7",
          "node_1_15",
          "node_2_3",
          "node_2_7",
          "node_3_1",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "beach": [
          "leaf_15",
          "leaf_24",
          "leaf_30",
          "leaf_34",
          "leaf_38",
          "node_1_7",
          "node_1_12",
          "node_1_15",
          "node_1_17",
          "node_1_19",
          "node_2_3",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_3_1",
          "node_3_3",
          "node_3_4",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "bicycles": [
          "leaf_15",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "calm": [
          "leaf_15",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "daughter": [
          "leaf_15",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "dressed": [
          "leaf_15",
          "leaf_38",
          "node_1_7",
          "node_1_19",
          "node_2_3",
          "node_2_9",
          "node_3_1",
          "node_3_4",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "father": [
          "leaf_15",
          "leaf_48",
          "leaf_57",
          "node_1_7",
          "node_1_24",
          "node_1_28",
          "node_2_3",
          "node_2_12",
          "node_2_14",
          "node_3_1",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "fly": [
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "leaf_27",
          "leaf_28",
          "node_1_7",
          "node_1_8",
          "node_1_13",
          "node_1_14",
          "node_2_3",
          "node_2_4",
          "node_2_6",
          "node_2_7",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "girl": [
          "leaf_15",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "gravel": [
          "leaf_15",
          "leaf_16",
          "leaf_19",
          "leaf_23",
          "leaf_24",
          "leaf_25",
          "leaf_26",
          "leaf_33",
          "leaf_38",
          "node_1_7",
          "node_1_8",
          "node_1_9",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_16",
          "node_1_19",
          "node_2_3",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_8",
          "node_2_9",
          "node_3_1",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_4_0",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "hands": [
          "leaf_15",
          "leaf_35",
          "leaf_42",
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "leaf_59",
          "node_1_7",
          "node_1_17",
          "node_1_21",
          "node_1_23",
          "node_1_24",
          "node_1_29",
          "node_2_3",
          "node_2_8",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_1",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_0",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "hour": [
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "node_1_7",
          "node_1_8",
          "node_2_3",
          "node_2_4",
          "node_3_1",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "lakes": [
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "node_1_7",
          "node_1_8",
          "node_2_3",
          "node_2_4",
          "node_3_1",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "location": [
          "leaf_15",
          "leaf_35",
          "leaf_36",
          "leaf_44",
          "node_1_7",
          "node_1_17",
          "node_1_18",
          "node_1_22",
          "node_2_3",
          "node_2_8",
          "node_2_9",
          "node_2_11",
          "node_3_1",
          "node_3_4",
          "node_3_5",
          "node_4_0",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "ourselves": [
          "leaf_15",
          "leaf_16",
          "node_1_7",
          "node_1_8",
          "node_2_3",
          "node_2_4",
          "node_3_1",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "picturesque": [
          "leaf_15",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "pockets": [
          "leaf_15",
          "node_1_7",
          "node_2_3",
          "node_3_1",
          "node_4_0",
          "node_5_0",
          "node_6_0"
        ],
        "son": [
          "leaf_15",
          "leaf_57",
          "node_1_7",
          "node_1_28",
          "node_2_3",
          "node_2_14",
          "node_3_1",
          "node_3_7",
          "node_4_0",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "travel": [
          "leaf_15",
          "leaf_16",
          "node_1_7",
          "node_1_8",
          "node_2_3",
          "node_2_4",
          "node_3_1",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "twin": [
          "leaf_15",
          "leaf_16",
          "leaf_17",
          "node_1_7",
          "node_1_8",
          "node_2_3",
          "node_2_4",
          "node_3_1",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "twins": [
          "leaf_15",
          "leaf_16",
          "node_1_7",
          "node_1_8",
          "node_2_3",
          "node_2_4",
          "node_3_1",
          "node_3_2",
          "node_4_0",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "31": [
          "leaf_16",
          "leaf_59",
          "node_1_8",
          "node_1_29",
          "node_2_4",
          "node_2_14",
          "node_3_2",
          "node_3_7",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "365": [
          "leaf_16",
          "leaf_37",
          "leaf_39",
          "node_1_8",
          "node_1_18",
          "node_1_19",
          "node_2_4",
          "node_2_9",
          "node_3_2",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "adventure": [
          "leaf_16",
          "leaf_18",
          "leaf_26",
          "leaf_40",
          "leaf_45",
          "leaf_48",
          "leaf_55",
          "node_1_8",
          "node_1_9",
          "node_1_13",
          "node_1_20",
          "node_1_22",
          "node_1_24",
          "node_1_27",
          "node_2_4",
          "node_2_6",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "ago": [
          "leaf_16",
          "node_1_8",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "half": [
          "leaf_16",
          "leaf_17",
          "node_1_8",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "mouth": [
          "leaf_16",
          "leaf_18",
          "leaf_19",
          "leaf_59",
          "node_1_8",
          "node_1_9",
          "node_1_29",
          "node_2_4",
          "node_2_14",
          "node_3_2",
          "node_3_7",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "much": [
          "leaf_16",
          "leaf_17",
          "leaf_18",
          "node_1_8",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "older": [
          "leaf_16",
          "leaf_46",
          "leaf_47",
          "leaf_52",
          "leaf_57",
          "node_1_8",
          "node_1_23",
          "node_1_26",
          "node_1_28",
          "node_2_4",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "panoramic": [
          "leaf_16",
          "leaf_37",
          "node_1_8",
          "node_1_18",
          "node_2_4",
          "node_2_9",
          "node_3_2",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "rocky": [
          "leaf_16",
          "leaf_18",
          "leaf_23",
          "leaf_28",
          "leaf_30",
          "node_1_8",
          "node_1_9",
          "node_1_11",
          "node_1_14",
          "node_1_15",
          "node_2_4",
          "node_2_5",
          "node_2_7",
          "node_3_2",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "room": [
          "leaf_16",
          "leaf_17",
          "node_1_8",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "vlog": [
          "leaf_16",
          "leaf_29",
          "node_1_8",
          "node_1_14",
          "node_2_4",
          "node_2_7",
          "node_3_2",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "4k": [
          "leaf_17",
          "leaf_20",
          "leaf_24",
          "leaf_26",
          "leaf_41",
          "leaf_43",
          "node_1_8",
          "node_1_10",
          "node_1_12",
          "node_1_13",
          "node_1_20",
          "node_1_21",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_10",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "across": [
          "leaf_17",
          "leaf_42",
          "node_1_8",
          "node_1_21",
          "node_2_4",
          "node_2_10",
          "node_3_2",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "alaskan": [
          "leaf_17",
          "leaf_18",
          "node_1_8",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "areas": [
          "leaf_17",
          "leaf_23",
          "node_1_8",
          "node_1_11",
          "node_2_4",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "backpacks": [
          "leaf_17",
          "leaf_19",
          "leaf_26",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_48",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "leaf_58",
          "node_1_8",
          "node_1_9",
          "node_1_13",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_4",
          "node_2_6",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "brightest": [
          "leaf_17",
          "node_1_8",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "camping": [
          "leaf_17",
          "leaf_23",
          "leaf_44",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_51",
          "leaf_52",
          "leaf_53",
          "leaf_54",
          "leaf_55",
          "leaf_57",
          "leaf_58",
          "node_1_8",
          "node_1_11",
          "node_1_22",
          "node_1_23",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_4",
          "node_2_5",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "causing": [
          "leaf_17",
          "node_1_8",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "detail": [
          "leaf_17",
          "leaf_26",
          "node_1_8",
          "node_1_13",
          "node_2_4",
          "node_2_6",
          "node_3_2",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "forecast": [
          "leaf_17",
          "leaf_18",
          "node_1_8",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "km": [
          "leaf_17",
          "node_1_8",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "loss": [
          "leaf_17",
          "node_1_8",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "nh": [
          "leaf_17",
          "node_1_8",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "okay": [
          "leaf_17",
          "leaf_18",
          "leaf_29",
          "leaf_30",
          "leaf_31",
          "leaf_32",
          "leaf_33",
          "node_1_8",
          "node_1_9",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_2_4",
          "node_2_7",
          "node_2_8",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "overexposed": [
          "leaf_17",
          "node_1_8",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "patch": [
          "leaf_17",
          "node_1_8",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "picture": [
          "leaf_17",
          "node_1_8",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "present": [
          "leaf_17",
          "leaf_26",
          "leaf_31",
          "leaf_35",
          "leaf_47",
          "leaf_48",
          "leaf_53",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "leaf_58",
          "node_1_8",
          "node_1_13",
          "node_1_15",
          "node_1_17",
          "node_1_23",
          "node_1_24",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_4",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "raincoat": [
          "leaf_17",
          "leaf_25",
          "leaf_38",
          "leaf_40",
          "leaf_41",
          "node_1_8",
          "node_1_12",
          "node_1_19",
          "node_1_20",
          "node_2_4",
          "node_2_6",
          "node_2_9",
          "node_2_10",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "raining": [
          "leaf_17",
          "leaf_18",
          "leaf_19",
          "node_1_8",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "remote": [
          "leaf_17",
          "leaf_18",
          "node_1_8",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "tents": [
          "leaf_17",
          "leaf_23",
          "leaf_45",
          "leaf_51",
          "leaf_52",
          "node_1_8",
          "node_1_11",
          "node_1_22",
          "node_1_25",
          "node_1_26",
          "node_2_4",
          "node_2_5",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "wilderness": [
          "leaf_17",
          "leaf_18",
          "leaf_21",
          "node_1_8",
          "node_1_9",
          "node_1_10",
          "node_2_4",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "03": [
          "leaf_18",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "2nd": [
          "leaf_18",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "59": [
          "leaf_18",
          "leaf_19",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "64": [
          "leaf_18",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "aged": [
          "leaf_18",
          "leaf_59",
          "node_1_9",
          "node_1_29",
          "node_2_4",
          "node_2_14",
          "node_3_2",
          "node_3_7",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "beard": [
          "leaf_18",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "face": [
          "leaf_18",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "forward": [
          "leaf_18",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "place": [
          "leaf_18",
          "leaf_19",
          "leaf_47",
          "leaf_51",
          "leaf_52",
          "leaf_53",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "node_1_9",
          "node_1_23",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_2_4",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "shelter": [
          "leaf_18",
          "leaf_19",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "strapped": [
          "leaf_18",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "toward": [
          "leaf_18",
          "leaf_40",
          "leaf_41",
          "node_1_9",
          "node_1_20",
          "node_2_4",
          "node_2_10",
          "node_3_2",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "00": [
          "leaf_19",
          "leaf_25",
          "leaf_27",
          "leaf_44",
          "node_1_9",
          "node_1_12",
          "node_1_13",
          "node_1_22",
          "node_2_4",
          "node_2_6",
          "node_2_11",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "01": [
          "leaf_19",
          "leaf_25",
          "leaf_27",
          "leaf_43",
          "node_1_9",
          "node_1_12",
          "node_1_13",
          "node_1_21",
          "node_2_4",
          "node_2_6",
          "node_2_10",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "57": [
          "leaf_19",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "bag": [
          "leaf_19",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "coat": [
          "leaf_19",
          "leaf_20",
          "leaf_32",
          "leaf_40",
          "leaf_45",
          "leaf_47",
          "node_1_9",
          "node_1_10",
          "node_1_16",
          "node_1_20",
          "node_1_22",
          "node_1_23",
          "node_2_4",
          "node_2_5",
          "node_2_8",
          "node_2_10",
          "node_2_11",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "down": [
          "leaf_19",
          "leaf_25",
          "leaf_26",
          "leaf_32",
          "leaf_33",
          "leaf_36",
          "leaf_47",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "leaf_59",
          "node_1_9",
          "node_1_12",
          "node_1_13",
          "node_1_16",
          "node_1_18",
          "node_1_23",
          "node_1_28",
          "node_1_29",
          "node_2_4",
          "node_2_6",
          "node_2_8",
          "node_2_9",
          "node_2_11",
          "node_2_14",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_7",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "drop": [
          "leaf_19",
          "leaf_20",
          "leaf_21",
          "node_1_9",
          "node_1_10",
          "node_2_4",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "grab": [
          "leaf_19",
          "leaf_20",
          "leaf_21",
          "leaf_23",
          "leaf_24",
          "leaf_25",
          "leaf_32",
          "node_1_9",
          "node_1_10",
          "node_1_11",
          "node_1_12",
          "node_1_16",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_8",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "huh": [
          "leaf_19",
          "leaf_20",
          "leaf_21",
          "node_1_9",
          "node_1_10",
          "node_2_4",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "like": [
          "leaf_19",
          "leaf_20",
          "leaf_45",
          "leaf_46",
          "leaf_47",
          "leaf_51",
          "leaf_52",
          "leaf_53",
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "node_1_9",
          "node_1_10",
          "node_1_22",
          "node_1_23",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_2_4",
          "node_2_5",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "path": [
          "leaf_19",
          "node_1_9",
          "node_2_4",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "spot": [
          "leaf_19",
          "leaf_20",
          "leaf_21",
          "leaf_31",
          "leaf_32",
          "node_1_9",
          "node_1_10",
          "node_1_15",
          "node_1_16",
          "node_2_4",
          "node_2_5",
          "node_2_7",
          "node_2_8",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "stuff": [
          "leaf_19",
          "leaf_20",
          "leaf_21",
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "node_1_9",
          "node_1_10",
          "node_1_23",
          "node_1_24",
          "node_2_4",
          "node_2_5",
          "node_2_11",
          "node_2_12",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "walking": [
          "leaf_19",
          "leaf_20",
          "leaf_24",
          "leaf_29",
          "leaf_36",
          "leaf_41",
          "node_1_9",
          "node_1_10",
          "node_1_12",
          "node_1_14",
          "node_1_18",
          "node_1_20",
          "node_2_4",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_9",
          "node_2_10",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "coats": [
          "leaf_20",
          "node_1_10",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "contains": [
          "leaf_20",
          "leaf_46",
          "node_1_10",
          "node_1_23",
          "node_2_5",
          "node_2_11",
          "node_3_2",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "details": [
          "leaf_20",
          "leaf_22",
          "leaf_48",
          "node_1_10",
          "node_1_11",
          "node_1_24",
          "node_2_5",
          "node_2_12",
          "node_3_2",
          "node_3_6",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "grassy": [
          "leaf_20",
          "node_1_10",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "jeans": [
          "leaf_20",
          "node_1_10",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "rain": [
          "leaf_20",
          "leaf_28",
          "leaf_37",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "node_1_10",
          "node_1_14",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_2_5",
          "node_2_7",
          "node_2_9",
          "node_2_10",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "resolution": [
          "leaf_20",
          "leaf_32",
          "leaf_43",
          "node_1_10",
          "node_1_16",
          "node_1_21",
          "node_2_5",
          "node_2_8",
          "node_2_10",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "woods": [
          "leaf_20",
          "leaf_21",
          "node_1_10",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "brown": [
          "leaf_21",
          "leaf_32",
          "node_1_10",
          "node_1_16",
          "node_2_5",
          "node_2_8",
          "node_3_2",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "pants": [
          "leaf_21",
          "node_1_10",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "sheet": [
          "leaf_21",
          "node_1_10",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "tan": [
          "leaf_21",
          "node_1_10",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "umbrella": [
          "leaf_21",
          "leaf_22",
          "leaf_46",
          "node_1_10",
          "node_1_11",
          "node_1_23",
          "node_2_5",
          "node_2_11",
          "node_3_2",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "wooded": [
          "leaf_21",
          "leaf_32",
          "leaf_41",
          "node_1_10",
          "node_1_16",
          "node_1_20",
          "node_2_5",
          "node_2_8",
          "node_2_10",
          "node_3_2",
          "node_3_4",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "yes": [
          "leaf_21",
          "leaf_22",
          "leaf_26",
          "leaf_27",
          "leaf_28",
          "node_1_10",
          "node_1_11",
          "node_1_13",
          "node_1_14",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_3_2",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "adult": [
          "leaf_22",
          "leaf_48",
          "leaf_56",
          "node_1_11",
          "node_1_24",
          "node_1_28",
          "node_2_5",
          "node_2_12",
          "node_2_14",
          "node_3_2",
          "node_3_6",
          "node_3_7",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "blanket": [
          "leaf_22",
          "node_1_11",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "canopy": [
          "leaf_22",
          "leaf_45",
          "node_1_11",
          "node_1_22",
          "node_2_5",
          "node_2_11",
          "node_3_2",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "children": [
          "leaf_22",
          "leaf_47",
          "leaf_48",
          "leaf_50",
          "node_1_11",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_2_5",
          "node_2_11",
          "node_2_12",
          "node_3_2",
          "node_3_5",
          "node_3_6",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "clip": [
          "leaf_22",
          "node_1_11",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "contribute": [
          "leaf_22",
          "node_1_11",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "detections": [
          "leaf_22",
          "node_1_11",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "gear": [
          "leaf_22",
          "leaf_26",
          "leaf_40",
          "leaf_59",
          "node_1_11",
          "node_1_13",
          "node_1_20",
          "node_1_29",
          "node_2_5",
          "node_2_6",
          "node_2_10",
          "node_2_14",
          "node_3_2",
          "node_3_3",
          "node_3_5",
          "node_3_7",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "hugged": [
          "leaf_22",
          "node_1_11",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "indicate": [
          "leaf_22",
          "leaf_48",
          "node_1_11",
          "node_1_24",
          "node_2_5",
          "node_2_12",
          "node_3_2",
          "node_3_6",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "male": [
          "leaf_22",
          "leaf_48",
          "leaf_56",
          "node_1_11",
          "node_1_24",
          "node_1_28",
          "node_2_5",
          "node_2_12",
          "node_2_14",
          "node_3_2",
          "node_3_6",
          "node_3_7",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "overall": [
          "leaf_22",
          "leaf_58",
          "node_1_11",
          "node_1_29",
          "node_2_5",
          "node_2_14",
          "node_3_2",
          "node_3_7",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "positioning": [
          "leaf_22",
          "leaf_28",
          "leaf_29",
          "leaf_30",
          "node_1_11",
          "node_1_14",
          "node_1_15",
          "node_2_5",
          "node_2_7",
          "node_3_2",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "presence": [
          "leaf_22",
          "leaf_47",
          "node_1_11",
          "node_1_23",
          "node_2_5",
          "node_2_11",
          "node_3_2",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "presented": [
          "leaf_22",
          "node_1_11",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "production": [
          "leaf_22",
          "node_1_11",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "rightind": [
          "leaf_22",
          "leaf_23",
          "node_1_11",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "subject": [
          "leaf_22",
          "leaf_47",
          "node_1_11",
          "node_1_23",
          "node_2_5",
          "node_2_11",
          "node_3_2",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "taking": [
          "leaf_22",
          "node_1_11",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "technical": [
          "leaf_22",
          "leaf_35",
          "leaf_48",
          "node_1_11",
          "node_1_17",
          "node_1_24",
          "node_2_5",
          "node_2_8",
          "node_2_12",
          "node_3_2",
          "node_3_4",
          "node_3_6",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "understanding": [
          "leaf_22",
          "node_1_11",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "working": [
          "leaf_22",
          "node_1_11",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "arm": [
          "leaf_23",
          "leaf_24",
          "node_1_11",
          "node_1_12",
          "node_2_5",
          "node_2_6",
          "node_3_2",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "bear": [
          "leaf_23",
          "leaf_24",
          "leaf_25",
          "node_1_11",
          "node_1_12",
          "node_2_5",
          "node_2_6",
          "node_3_2",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "blankets": [
          "leaf_23",
          "node_1_11",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "bu": [
          "leaf_23",
          "leaf_24",
          "node_1_11",
          "node_1_12",
          "node_2_5",
          "node_2_6",
          "node_3_2",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "fisherman": [
          "leaf_23",
          "leaf_35",
          "leaf_38",
          "node_1_11",
          "node_1_17",
          "node_1_19",
          "node_2_5",
          "node_2_8",
          "node_2_9",
          "node_3_2",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "hood": [
          "leaf_23",
          "node_1_11",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "jumpsuits": [
          "leaf_23",
          "node_1_11",
          "node_2_5",
          "node_3_2",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "pole": [
          "leaf_23",
          "leaf_30",
          "leaf_33",
          "leaf_38",
          "leaf_39",
          "leaf_41",
          "node_1_11",
          "node_1_15",
          "node_1_16",
          "node_1_19",
          "node_1_20",
          "node_2_5",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_10",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "riverbank": [
          "leaf_23",
          "leaf_28",
          "node_1_11",
          "node_1_14",
          "node_2_5",
          "node_2_7",
          "node_3_2",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "spray": [
          "leaf_23",
          "leaf_24",
          "leaf_25",
          "node_1_11",
          "node_1_12",
          "node_2_5",
          "node_2_6",
          "node_3_2",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "stream": [
          "leaf_23",
          "leaf_24",
          "leaf_26",
          "leaf_27",
          "leaf_28",
          "leaf_33",
          "leaf_36",
          "leaf_38",
          "node_1_11",
          "node_1_12",
          "node_1_13",
          "node_1_14",
          "node_1_16",
          "node_1_18",
          "node_1_19",
          "node_2_5",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "tommy": [
          "leaf_23",
          "leaf_24",
          "leaf_25",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "node_1_11",
          "node_1_12",
          "node_1_19",
          "node_1_20",
          "node_2_5",
          "node_2_6",
          "node_2_9",
          "node_2_10",
          "node_3_2",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "definition": [
          "leaf_24",
          "node_1_12",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "fishermen": [
          "leaf_24",
          "node_1_12",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "harness": [
          "leaf_24",
          "node_1_12",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "high": [
          "leaf_24",
          "node_1_12",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "pebble": [
          "leaf_24",
          "node_1_12",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "rods": [
          "leaf_24",
          "leaf_28",
          "leaf_32",
          "leaf_35",
          "leaf_43",
          "node_1_12",
          "node_1_14",
          "node_1_16",
          "node_1_17",
          "node_1_21",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_10",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "ultra": [
          "leaf_24",
          "node_1_12",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "waders": [
          "leaf_24",
          "leaf_28",
          "node_1_12",
          "node_1_14",
          "node_2_6",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "woman": [
          "leaf_24",
          "node_1_12",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "conversation": [
          "leaf_25",
          "leaf_47",
          "leaf_48",
          "leaf_56",
          "node_1_12",
          "node_1_23",
          "node_1_24",
          "node_1_28",
          "node_2_6",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "daytime": [
          "leaf_25",
          "node_1_12",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "gun": [
          "leaf_25",
          "leaf_44",
          "node_1_12",
          "node_1_22",
          "node_2_6",
          "node_2_11",
          "node_3_3",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "nothing": [
          "leaf_25",
          "leaf_26",
          "node_1_12",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "suit": [
          "leaf_25",
          "leaf_28",
          "node_1_12",
          "node_1_14",
          "node_2_6",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "toob": [
          "leaf_25",
          "leaf_26",
          "node_1_12",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "activities": [
          "leaf_26",
          "leaf_38",
          "leaf_51",
          "leaf_52",
          "node_1_13",
          "node_1_19",
          "node_1_25",
          "node_1_26",
          "node_2_6",
          "node_2_9",
          "node_2_12",
          "node_2_13",
          "node_3_3",
          "node_3_4",
          "node_3_6",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "addition": [
          "leaf_26",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "additional": [
          "leaf_26",
          "leaf_54",
          "node_1_13",
          "node_1_27",
          "node_2_6",
          "node_2_13",
          "node_3_3",
          "node_3_6",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "bait": [
          "leaf_26",
          "leaf_42",
          "node_1_13",
          "node_1_21",
          "node_2_6",
          "node_2_10",
          "node_3_3",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "between": [
          "leaf_26",
          "leaf_36",
          "leaf_45",
          "leaf_47",
          "leaf_58",
          "node_1_13",
          "node_1_18",
          "node_1_22",
          "node_1_23",
          "node_1_29",
          "node_2_6",
          "node_2_9",
          "node_2_11",
          "node_2_14",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_7",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "cameras": [
          "leaf_26",
          "leaf_55",
          "node_1_13",
          "node_1_27",
          "node_2_6",
          "node_2_13",
          "node_3_3",
          "node_3_6",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "colored": [
          "leaf_26",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "container": [
          "leaf_26",
          "leaf_52",
          "node_1_13",
          "node_1_26",
          "node_2_6",
          "node_2_13",
          "node_3_3",
          "node_3_6",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "covering": [
          "leaf_26",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "different": [
          "leaf_26",
          "leaf_30",
          "node_1_13",
          "node_1_15",
          "node_2_6",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "editing": [
          "leaf_26",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "file": [
          "leaf_26",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "individual": [
          "leaf_26",
          "leaf_41",
          "node_1_13",
          "node_1_20",
          "node_2_6",
          "node_2_10",
          "node_3_3",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "interest": [
          "leaf_26",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "kneeling": [
          "leaf_26",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "lure": [
          "leaf_26",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "main": [
          "leaf_26",
          "leaf_45",
          "leaf_47",
          "leaf_54",
          "node_1_13",
          "node_1_22",
          "node_1_23",
          "node_1_27",
          "node_2_6",
          "node_2_11",
          "node_2_13",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "nearer": [
          "leaf_26",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "observer": [
          "leaf_26",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "observing": [
          "leaf_26",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "pieces": [
          "leaf_26",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "raw": [
          "leaf_26",
          "leaf_41",
          "node_1_13",
          "node_1_20",
          "node_2_6",
          "node_2_10",
          "node_3_3",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "scattered": [
          "leaf_26",
          "leaf_42",
          "leaf_43",
          "leaf_53",
          "leaf_58",
          "node_1_13",
          "node_1_21",
          "node_1_26",
          "node_1_29",
          "node_2_6",
          "node_2_10",
          "node_2_13",
          "node_2_14",
          "node_3_3",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "scenes": [
          "leaf_26",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "snowsuit": [
          "leaf_26",
          "leaf_33",
          "node_1_13",
          "node_1_16",
          "node_2_6",
          "node_2_8",
          "node_3_3",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "sports": [
          "leaf_26",
          "leaf_48",
          "leaf_53",
          "node_1_13",
          "node_1_24",
          "node_1_26",
          "node_2_6",
          "node_2_12",
          "node_2_13",
          "node_3_3",
          "node_3_6",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "subjects": [
          "leaf_26",
          "leaf_38",
          "node_1_13",
          "node_1_19",
          "node_2_6",
          "node_2_9",
          "node_3_3",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "supplies": [
          "leaf_26",
          "leaf_47",
          "node_1_13",
          "node_1_23",
          "node_2_6",
          "node_2_11",
          "node_3_3",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "videos": [
          "leaf_26",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "wow": [
          "leaf_26",
          "leaf_27",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "yee": [
          "leaf_26",
          "leaf_27",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "yeee": [
          "leaf_26",
          "leaf_27",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "actions": [
          "leaf_27",
          "leaf_44",
          "node_1_13",
          "node_1_22",
          "node_2_6",
          "node_2_11",
          "node_3_3",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "chest": [
          "leaf_27",
          "leaf_44",
          "node_1_13",
          "node_1_22",
          "node_2_6",
          "node_2_11",
          "node_3_3",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "following": [
          "leaf_27",
          "leaf_48",
          "node_1_13",
          "node_1_24",
          "node_2_6",
          "node_2_12",
          "node_3_3",
          "node_3_6",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "gray": [
          "leaf_27",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "hurry": [
          "leaf_27",
          "leaf_28",
          "node_1_13",
          "node_1_14",
          "node_2_6",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "mean": [
          "leaf_27",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "oh": [
          "leaf_27",
          "leaf_28",
          "leaf_29",
          "leaf_31",
          "leaf_32",
          "leaf_33",
          "leaf_34",
          "leaf_35",
          "leaf_36",
          "leaf_37",
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "leaf_50",
          "leaf_57",
          "leaf_58",
          "leaf_59",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_18",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_28",
          "node_1_29",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "rock": [
          "leaf_27",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "simply": [
          "leaf_27",
          "node_1_13",
          "node_2_6",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "wall": [
          "leaf_27",
          "leaf_28",
          "leaf_58",
          "node_1_13",
          "node_1_14",
          "node_1_29",
          "node_2_6",
          "node_2_7",
          "node_2_14",
          "node_3_3",
          "node_3_7",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "yeah": [
          "leaf_27",
          "leaf_28",
          "leaf_29",
          "leaf_31",
          "leaf_32",
          "leaf_33",
          "leaf_34",
          "leaf_48",
          "leaf_49",
          "leaf_50",
          "leaf_51",
          "leaf_52",
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "node_1_13",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_1_17",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_6",
          "node_2_7",
          "node_2_8",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_3",
          "node_3_4",
          "node_3_6",
          "node_3_7",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "chart": [
          "leaf_28",
          "leaf_29",
          "node_1_14",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "dollar": [
          "leaf_28",
          "leaf_29",
          "node_1_14",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "outfit": [
          "leaf_28",
          "node_1_14",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "20": [
          "leaf_29",
          "node_1_14",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "allowing": [
          "leaf_29",
          "node_1_14",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "allows": [
          "leaf_29",
          "node_1_14",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "barton": [
          "leaf_29",
          "leaf_30",
          "leaf_31",
          "leaf_32",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_2_7",
          "node_2_8",
          "node_3_3",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "behavior": [
          "leaf_29",
          "node_1_14",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "bird": [
          "leaf_29",
          "node_1_14",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "bonk": [
          "leaf_29",
          "leaf_30",
          "node_1_14",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "closely": [
          "leaf_29",
          "node_1_14",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "daily": [
          "leaf_29",
          "leaf_56",
          "node_1_14",
          "node_1_28",
          "node_2_7",
          "node_2_14",
          "node_3_3",
          "node_3_7",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "dinner": [
          "leaf_29",
          "leaf_30",
          "leaf_32",
          "leaf_33",
          "node_1_14",
          "node_1_15",
          "node_1_16",
          "node_2_7",
          "node_2_8",
          "node_3_3",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "dog": [
          "leaf_29",
          "leaf_58",
          "node_1_14",
          "node_1_29",
          "node_2_7",
          "node_2_14",
          "node_3_3",
          "node_3_7",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "held": [
          "leaf_29",
          "leaf_31",
          "node_1_14",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "movements": [
          "leaf_29",
          "node_1_14",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "observe": [
          "leaf_29",
          "node_1_14",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "showcases": [
          "leaf_29",
          "node_1_14",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "walks": [
          "leaf_29",
          "node_1_14",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "yep": [
          "leaf_29",
          "leaf_30",
          "node_1_14",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "34": [
          "leaf_30",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "angles": [
          "leaf_30",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "bent": [
          "leaf_30",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "blancher": [
          "leaf_30",
          "leaf_31",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "bump": [
          "leaf_30",
          "leaf_31",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "clothing": [
          "leaf_30",
          "leaf_33",
          "node_1_15",
          "node_1_16",
          "node_2_7",
          "node_2_8",
          "node_3_3",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "deli": [
          "leaf_30",
          "leaf_31",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "etc": [
          "leaf_30",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "focal": [
          "leaf_30",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "gravelly": [
          "leaf_30",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "length": [
          "leaf_30",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "motion": [
          "leaf_30",
          "leaf_31",
          "leaf_35",
          "leaf_38",
          "leaf_46",
          "leaf_48",
          "node_1_15",
          "node_1_17",
          "node_1_19",
          "node_1_23",
          "node_1_24",
          "node_2_7",
          "node_2_8",
          "node_2_9",
          "node_2_11",
          "node_2_12",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "perspectives": [
          "leaf_30",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "shots": [
          "leaf_30",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "terrain": [
          "leaf_30",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "tracking": [
          "leaf_30",
          "leaf_54",
          "node_1_15",
          "node_1_27",
          "node_2_7",
          "node_2_13",
          "node_3_3",
          "node_3_6",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "varten": [
          "leaf_30",
          "leaf_31",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "attached": [
          "leaf_31",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "broader": [
          "leaf_31",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "char": [
          "leaf_31",
          "leaf_32",
          "node_1_15",
          "node_1_16",
          "node_2_7",
          "node_2_8",
          "node_3_3",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "depicting": [
          "leaf_31",
          "leaf_35",
          "leaf_47",
          "node_1_15",
          "node_1_17",
          "node_1_23",
          "node_2_7",
          "node_2_8",
          "node_2_11",
          "node_3_3",
          "node_3_4",
          "node_3_5",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "distinct": [
          "leaf_31",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "focusing": [
          "leaf_31",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "frames": [
          "leaf_31",
          "leaf_32",
          "leaf_56",
          "node_1_15",
          "node_1_16",
          "node_1_28",
          "node_2_7",
          "node_2_8",
          "node_2_14",
          "node_3_3",
          "node_3_4",
          "node_3_7",
          "node_4_1",
          "node_4_2",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "groups": [
          "leaf_31",
          "leaf_58",
          "node_1_15",
          "node_1_29",
          "node_2_7",
          "node_2_14",
          "node_3_3",
          "node_3_7",
          "node_4_1",
          "node_4_3",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "member": [
          "leaf_31",
          "leaf_32",
          "node_1_15",
          "node_1_16",
          "node_2_7",
          "node_2_8",
          "node_3_3",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "pink": [
          "leaf_31",
          "leaf_32",
          "node_1_15",
          "node_1_16",
          "node_2_7",
          "node_2_8",
          "node_3_3",
          "node_3_4",
          "node_4_1",
          "node_4_2",
          "node_5_0",
          "node_5_1",
          "node_6_0"
        ],
        "six": [
          "leaf_31",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "total": [
          "leaf_31",
          "node_1_15",
          "node_2_7",
          "node_3_3",
          "node_4_1",
          "node_5_0",
          "node_6_0"
        ],
        "1k": [
          "leaf_32",
          "node_1_16",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "2k": [
          "leaf_32",
          "node_1_16",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "ahead": [
          "leaf_32",
          "node_1_16",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "buddy": [
          "leaf_32",
          "leaf_33",
          "node_1_16",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "grainy": [
          "leaf_32",
          "node_1_16",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "laying": [
          "leaf_32",
          "node_1_16",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "per": [
          "leaf_32",
          "node_1_16",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "reaching": [
          "leaf_32",
          "node_1_16",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "reeling": [
          "leaf_32",
          "node_1_16",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "sensor": [
          "leaf_32",
          "node_1_16",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "art": [
          "leaf_33",
          "leaf_34",
          "node_1_16",
          "node_1_17",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "bucket": [
          "leaf_33",
          "node_1_16",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "isn": [
          "leaf_33",
          "leaf_34",
          "node_1_16",
          "node_1_17",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "model": [
          "leaf_33",
          "leaf_57",
          "node_1_16",
          "node_1_28",
          "node_2_8",
          "node_2_14",
          "node_3_4",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "molding": [
          "leaf_33",
          "node_1_16",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "nice": [
          "leaf_33",
          "leaf_34",
          "leaf_38",
          "leaf_39",
          "node_1_16",
          "node_1_17",
          "node_1_19",
          "node_2_8",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "playing": [
          "leaf_33",
          "leaf_34",
          "leaf_47",
          "leaf_51",
          "node_1_16",
          "node_1_17",
          "node_1_23",
          "node_1_25",
          "node_2_8",
          "node_2_11",
          "node_2_12",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "sand": [
          "leaf_33",
          "node_1_16",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "toddler": [
          "leaf_33",
          "node_1_16",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "cell": [
          "leaf_34",
          "leaf_39",
          "leaf_58",
          "node_1_17",
          "node_1_19",
          "node_1_29",
          "node_2_8",
          "node_2_9",
          "node_2_14",
          "node_3_4",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "clothes": [
          "leaf_34",
          "node_1_17",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "deep": [
          "leaf_34",
          "node_1_17",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "experiencing": [
          "leaf_34",
          "leaf_44",
          "node_1_17",
          "node_1_22",
          "node_2_8",
          "node_2_11",
          "node_3_4",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "jumpsuit": [
          "leaf_34",
          "node_1_17",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "knee": [
          "leaf_34",
          "node_1_17",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "phone": [
          "leaf_34",
          "leaf_39",
          "leaf_58",
          "node_1_17",
          "node_1_19",
          "node_1_29",
          "node_2_8",
          "node_2_9",
          "node_2_14",
          "node_3_4",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "probably": [
          "leaf_34",
          "leaf_35",
          "node_1_17",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "raincoats": [
          "leaf_34",
          "node_1_17",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "recorded": [
          "leaf_34",
          "leaf_59",
          "node_1_17",
          "node_1_29",
          "node_2_8",
          "node_2_14",
          "node_3_4",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "watches": [
          "leaf_34",
          "leaf_57",
          "node_1_17",
          "node_1_28",
          "node_2_8",
          "node_2_14",
          "node_3_4",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "artifacts": [
          "leaf_35",
          "leaf_48",
          "node_1_17",
          "node_1_24",
          "node_2_8",
          "node_2_12",
          "node_3_4",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "blur": [
          "leaf_35",
          "leaf_38",
          "leaf_46",
          "leaf_48",
          "node_1_17",
          "node_1_19",
          "node_1_23",
          "node_1_24",
          "node_2_8",
          "node_2_9",
          "node_2_11",
          "node_2_12",
          "node_3_4",
          "node_3_5",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "blurred": [
          "leaf_35",
          "node_1_17",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "compression": [
          "leaf_35",
          "node_1_17",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "emphasize": [
          "leaf_35",
          "node_1_17",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "flare": [
          "leaf_35",
          "leaf_48",
          "node_1_17",
          "node_1_24",
          "node_2_8",
          "node_2_12",
          "node_3_4",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "lovely": [
          "leaf_35",
          "leaf_36",
          "leaf_37",
          "node_1_17",
          "node_1_18",
          "node_2_8",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "offering": [
          "leaf_35",
          "node_1_17",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "sharon": [
          "leaf_35",
          "leaf_36",
          "leaf_37",
          "node_1_17",
          "node_1_18",
          "node_2_8",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "tom": [
          "leaf_35",
          "leaf_36",
          "node_1_17",
          "node_1_18",
          "node_2_8",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "unsteady": [
          "leaf_35",
          "node_1_17",
          "node_2_8",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "weird": [
          "leaf_35",
          "leaf_36",
          "leaf_37",
          "node_1_17",
          "node_1_18",
          "node_2_8",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "bend": [
          "leaf_36",
          "node_1_18",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "book": [
          "leaf_36",
          "leaf_39",
          "leaf_59",
          "node_1_18",
          "node_1_19",
          "node_1_29",
          "node_2_9",
          "node_2_14",
          "node_3_4",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "floor": [
          "leaf_36",
          "node_1_18",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "goes": [
          "leaf_36",
          "leaf_37",
          "node_1_18",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "picking": [
          "leaf_36",
          "node_1_18",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "retrieve": [
          "leaf_36",
          "leaf_42",
          "node_1_18",
          "node_1_21",
          "node_2_9",
          "node_2_10",
          "node_3_4",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "surface": [
          "leaf_36",
          "node_1_18",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "wet": [
          "leaf_36",
          "node_1_18",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "casts": [
          "leaf_37",
          "node_1_18",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "creating": [
          "leaf_37",
          "node_1_18",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "definitely": [
          "leaf_37",
          "leaf_38",
          "node_1_18",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "ey": [
          "leaf_37",
          "leaf_38",
          "node_1_18",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "hey": [
          "leaf_37",
          "leaf_38",
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "node_1_18",
          "node_1_19",
          "node_1_20",
          "node_2_9",
          "node_2_10",
          "node_3_4",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "mind": [
          "leaf_37",
          "leaf_38",
          "node_1_18",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "never": [
          "leaf_37",
          "leaf_38",
          "node_1_18",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "single": [
          "leaf_37",
          "leaf_44",
          "node_1_18",
          "node_1_22",
          "node_2_9",
          "node_2_11",
          "node_3_4",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "alright": [
          "leaf_38",
          "leaf_39",
          "leaf_41",
          "leaf_42",
          "leaf_58",
          "leaf_59",
          "node_1_19",
          "node_1_20",
          "node_1_21",
          "node_1_29",
          "node_2_9",
          "node_2_10",
          "node_2_14",
          "node_3_4",
          "node_3_5",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "appropriate": [
          "leaf_38",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "attire": [
          "leaf_38",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "bending": [
          "leaf_38",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "interacting": [
          "leaf_38",
          "leaf_50",
          "node_1_19",
          "node_1_25",
          "node_2_9",
          "node_2_12",
          "node_3_4",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "ll": [
          "leaf_38",
          "leaf_39",
          "leaf_59",
          "node_1_19",
          "node_1_29",
          "node_2_9",
          "node_2_14",
          "node_3_4",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "pebbly": [
          "leaf_38",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "pick": [
          "leaf_38",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "resulting": [
          "leaf_38",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "slight": [
          "leaf_38",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "weather": [
          "leaf_38",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "2d": [
          "leaf_39",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "available": [
          "leaf_39",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "bank": [
          "leaf_39",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "lunch": [
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "node_1_19",
          "node_1_20",
          "node_2_9",
          "node_2_10",
          "node_3_4",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "photography": [
          "leaf_39",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "techniques": [
          "leaf_39",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "tips": [
          "leaf_39",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "tricks": [
          "leaf_39",
          "node_1_19",
          "node_2_9",
          "node_3_4",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "wanna": [
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "node_1_19",
          "node_1_20",
          "node_2_9",
          "node_2_10",
          "node_3_4",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "yup": [
          "leaf_39",
          "leaf_40",
          "leaf_41",
          "node_1_19",
          "node_1_20",
          "node_2_9",
          "node_2_10",
          "node_3_4",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "angler": [
          "leaf_40",
          "node_1_20",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "enjoys": [
          "leaf_40",
          "node_1_20",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "essence": [
          "leaf_40",
          "node_1_20",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "hooded": [
          "leaf_40",
          "leaf_41",
          "node_1_20",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "little": [
          "leaf_40",
          "leaf_41",
          "leaf_42",
          "leaf_43",
          "leaf_48",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "leaf_59",
          "node_1_20",
          "node_1_21",
          "node_1_24",
          "node_1_28",
          "node_1_29",
          "node_2_10",
          "node_2_12",
          "node_2_14",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "eating": [
          "leaf_41",
          "leaf_42",
          "leaf_49",
          "leaf_50",
          "leaf_51",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "node_1_20",
          "node_1_21",
          "node_1_24",
          "node_1_25",
          "node_1_28",
          "node_1_29",
          "node_2_10",
          "node_2_12",
          "node_2_14",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "either": [
          "leaf_41",
          "leaf_42",
          "leaf_44",
          "leaf_49",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_24",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_3_5",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "full": [
          "leaf_41",
          "leaf_42",
          "leaf_45",
          "leaf_46",
          "node_1_20",
          "node_1_21",
          "node_1_22",
          "node_1_23",
          "node_2_10",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "guy": [
          "leaf_41",
          "leaf_42",
          "node_1_20",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "releasing": [
          "leaf_41",
          "node_1_20",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "stomachs": [
          "leaf_41",
          "leaf_42",
          "node_1_20",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "trail": [
          "leaf_41",
          "node_1_20",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "bugs": [
          "leaf_42",
          "leaf_43",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "cast": [
          "leaf_42",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "catching": [
          "leaf_42",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "dead": [
          "leaf_42",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "film": [
          "leaf_42",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "mosquitoes": [
          "leaf_42",
          "leaf_43",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "positions": [
          "leaf_42",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "provides": [
          "leaf_42",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "thousands": [
          "leaf_42",
          "leaf_43",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "witness": [
          "leaf_42",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "animal": [
          "leaf_43",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "clearer": [
          "leaf_43",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "debris": [
          "leaf_43",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "dirty": [
          "leaf_43",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "done": [
          "leaf_43",
          "leaf_44",
          "leaf_45",
          "node_1_21",
          "node_1_22",
          "node_2_10",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "entire": [
          "leaf_43",
          "leaf_46",
          "leaf_48",
          "leaf_56",
          "node_1_21",
          "node_1_23",
          "node_1_24",
          "node_1_28",
          "node_2_10",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "higher": [
          "leaf_43",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "leaves": [
          "leaf_43",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "recommended": [
          "leaf_43",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "setup": [
          "leaf_43",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "sort": [
          "leaf_43",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "twigs": [
          "leaf_43",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "visuals": [
          "leaf_43",
          "node_1_21",
          "node_2_10",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "19": [
          "leaf_44",
          "node_1_22",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "based": [
          "leaf_44",
          "node_1_22",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "campsite": [
          "leaf_44",
          "leaf_46",
          "leaf_47",
          "leaf_52",
          "leaf_58",
          "node_1_22",
          "node_1_23",
          "node_1_26",
          "node_1_29",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "compose": [
          "leaf_44",
          "node_1_22",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "edit": [
          "leaf_44",
          "node_1_22",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "foreground": [
          "leaf_44",
          "leaf_45",
          "leaf_47",
          "leaf_48",
          "leaf_54",
          "leaf_58",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_27",
          "node_1_29",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "forgot": [
          "leaf_44",
          "leaf_45",
          "node_1_22",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "hi": [
          "leaf_44",
          "leaf_45",
          "node_1_22",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "aluminum": [
          "leaf_45",
          "node_1_22",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "atmosphere": [
          "leaf_45",
          "leaf_58",
          "node_1_22",
          "node_1_29",
          "node_2_11",
          "node_2_14",
          "node_3_5",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "bit": [
          "leaf_45",
          "leaf_46",
          "node_1_22",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "bottles": [
          "leaf_45",
          "leaf_47",
          "leaf_49",
          "leaf_54",
          "leaf_56",
          "leaf_58",
          "leaf_59",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "chocolate": [
          "leaf_45",
          "leaf_46",
          "node_1_22",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "else": [
          "leaf_45",
          "node_1_22",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "food": [
          "leaf_45",
          "leaf_47",
          "leaf_48",
          "leaf_50",
          "leaf_52",
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "grabbing": [
          "leaf_45",
          "node_1_22",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "happy": [
          "leaf_45",
          "node_1_22",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "individuals": [
          "leaf_45",
          "leaf_47",
          "node_1_22",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "makes": [
          "leaf_45",
          "leaf_46",
          "node_1_22",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "pot": [
          "leaf_45",
          "leaf_48",
          "leaf_55",
          "leaf_57",
          "node_1_22",
          "node_1_24",
          "node_1_27",
          "node_1_28",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "share": [
          "leaf_45",
          "leaf_58",
          "node_1_22",
          "node_1_29",
          "node_2_11",
          "node_2_14",
          "node_3_5",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "shown": [
          "leaf_45",
          "leaf_51",
          "leaf_58",
          "node_1_22",
          "node_1_25",
          "node_1_29",
          "node_2_11",
          "node_2_12",
          "node_2_14",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "warm": [
          "leaf_45",
          "leaf_47",
          "leaf_48",
          "node_1_22",
          "node_1_23",
          "node_1_24",
          "node_2_11",
          "node_2_12",
          "node_3_5",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "watching": [
          "leaf_45",
          "leaf_52",
          "node_1_22",
          "node_1_26",
          "node_2_11",
          "node_2_13",
          "node_3_5",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "56": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "58": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "67": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "79": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "boiling": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "capture": [
          "leaf_46",
          "leaf_58",
          "node_1_23",
          "node_1_29",
          "node_2_11",
          "node_2_14",
          "node_3_5",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "color": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "companions": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "cups": [
          "leaf_46",
          "leaf_47",
          "leaf_49",
          "leaf_50",
          "leaf_52",
          "leaf_58",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_29",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "dress": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "drinking": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "format": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "gentleman": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "hold": [
          "leaf_46",
          "leaf_47",
          "leaf_48",
          "leaf_51",
          "leaf_52",
          "leaf_53",
          "node_1_23",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_3_5",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "hot": [
          "leaf_46",
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "items": [
          "leaf_46",
          "leaf_48",
          "leaf_49",
          "leaf_52",
          "leaf_54",
          "leaf_55",
          "leaf_58",
          "leaf_59",
          "node_1_23",
          "node_1_24",
          "node_1_26",
          "node_1_27",
          "node_1_29",
          "node_2_11",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "kettle": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "lantern": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "lights": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "sips": [
          "leaf_46",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "animals": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "attract": [
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "node_1_23",
          "node_1_24",
          "node_2_11",
          "node_2_12",
          "node_3_5",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "baby": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "bears": [
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "node_1_23",
          "node_1_24",
          "node_2_11",
          "node_2_12",
          "node_3_5",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "beer": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "contain": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "couple": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "depicts": [
          "leaf_47",
          "leaf_58",
          "node_1_23",
          "node_1_29",
          "node_2_11",
          "node_2_14",
          "node_3_5",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "evidenced": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "exchange": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "god": [
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "node_1_23",
          "node_1_24",
          "node_2_11",
          "node_2_12",
          "node_3_5",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "hair": [
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "node_1_23",
          "node_1_24",
          "node_2_11",
          "node_2_12",
          "node_3_5",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "handbag": [
          "leaf_47",
          "leaf_52",
          "leaf_58",
          "node_1_23",
          "node_1_26",
          "node_1_29",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "handshake": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "lap": [
          "leaf_47",
          "leaf_59",
          "node_1_23",
          "node_1_29",
          "node_2_11",
          "node_2_14",
          "node_3_5",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "leather": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "letters": [
          "leaf_47",
          "leaf_57",
          "node_1_23",
          "node_1_28",
          "node_2_11",
          "node_2_14",
          "node_3_5",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "mess": [
          "leaf_47",
          "leaf_56",
          "leaf_58",
          "node_1_23",
          "node_1_28",
          "node_1_29",
          "node_2_11",
          "node_2_14",
          "node_3_5",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "notices": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "occurring": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "primary": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "shells": [
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "node_1_23",
          "node_1_24",
          "node_2_11",
          "node_2_12",
          "node_3_5",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "sticky": [
          "leaf_47",
          "leaf_48",
          "leaf_49",
          "node_1_23",
          "node_1_24",
          "node_2_11",
          "node_2_12",
          "node_3_5",
          "node_3_6",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "stuffed": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "summary": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "takes": [
          "leaf_47",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "node_1_23",
          "node_1_27",
          "node_1_28",
          "node_2_11",
          "node_2_13",
          "node_2_14",
          "node_3_5",
          "node_3_6",
          "node_3_7",
          "node_4_2",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "toys": [
          "leaf_47",
          "node_1_23",
          "node_2_11",
          "node_3_5",
          "node_4_2",
          "node_5_1",
          "node_6_0"
        ],
        "cooking": [
          "leaf_48",
          "leaf_50",
          "leaf_52",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "garden": [
          "leaf_48",
          "leaf_49",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "handing": [
          "leaf_48",
          "leaf_50",
          "node_1_24",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "involved": [
          "leaf_48",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "leisure": [
          "leaf_48",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "situation": [
          "leaf_48",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "sons": [
          "leaf_48",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "surrounded": [
          "leaf_48",
          "leaf_49",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "survival": [
          "leaf_48",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "tool": [
          "leaf_48",
          "leaf_59",
          "node_1_24",
          "node_1_29",
          "node_2_12",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "type": [
          "leaf_48",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "upcoming": [
          "leaf_48",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "54": [
          "leaf_49",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "62": [
          "leaf_49",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "assortment": [
          "leaf_49",
          "leaf_54",
          "node_1_24",
          "node_1_27",
          "node_2_12",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "bowls": [
          "leaf_49",
          "leaf_50",
          "leaf_51",
          "leaf_52",
          "leaf_53",
          "leaf_54",
          "leaf_55",
          "leaf_56",
          "leaf_59",
          "node_1_24",
          "node_1_25",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "hungry": [
          "leaf_49",
          "leaf_50",
          "node_1_24",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "knots": [
          "leaf_49",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "miscellaneous": [
          "leaf_49",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "please": [
          "leaf_49",
          "leaf_50",
          "leaf_51",
          "node_1_24",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "pots": [
          "leaf_49",
          "leaf_54",
          "leaf_56",
          "node_1_24",
          "node_1_27",
          "node_1_28",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "pretty": [
          "leaf_49",
          "leaf_50",
          "node_1_24",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "siting": [
          "leaf_49",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "snacks": [
          "leaf_49",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "sure": [
          "leaf_49",
          "leaf_50",
          "node_1_24",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "tie": [
          "leaf_49",
          "node_1_24",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "bite": [
          "leaf_50",
          "leaf_51",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "campfire": [
          "leaf_50",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "explaining": [
          "leaf_50",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "finished": [
          "leaf_50",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "gathered": [
          "leaf_50",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "handling": [
          "leaf_50",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "kids": [
          "leaf_50",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "sandwich": [
          "leaf_50",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "spaghetti": [
          "leaf_50",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "spoons": [
          "leaf_50",
          "leaf_52",
          "leaf_56",
          "node_1_25",
          "node_1_26",
          "node_1_28",
          "node_2_12",
          "node_2_13",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "blow": [
          "leaf_51",
          "leaf_52",
          "leaf_53",
          "node_1_25",
          "node_1_26",
          "node_2_12",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "canvas": [
          "leaf_51",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "dung": [
          "leaf_51",
          "leaf_52",
          "node_1_25",
          "node_1_26",
          "node_2_12",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "engaged": [
          "leaf_51",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "interactions": [
          "leaf_51",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "lighting": [
          "leaf_51",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "lures": [
          "leaf_51",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "meals": [
          "leaf_51",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "others": [
          "leaf_51",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "resting": [
          "leaf_51",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "salted": [
          "leaf_51",
          "leaf_52",
          "node_1_25",
          "node_1_26",
          "node_2_12",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "sleeping": [
          "leaf_51",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "smartphone": [
          "leaf_51",
          "node_1_25",
          "node_2_12",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "blowing": [
          "leaf_52",
          "node_1_26",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "bowl": [
          "leaf_52",
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "leaf_59",
          "node_1_26",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_13",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "candle": [
          "leaf_52",
          "node_1_26",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "fire": [
          "leaf_52",
          "node_1_26",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "interacts": [
          "leaf_52",
          "node_1_26",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "pouring": [
          "leaf_52",
          "node_1_26",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "2015": [
          "leaf_53",
          "node_1_26",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "balls": [
          "leaf_53",
          "node_1_26",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "broth": [
          "leaf_53",
          "leaf_54",
          "node_1_26",
          "node_1_27",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "cleaning": [
          "leaf_53",
          "node_1_26",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "expedition": [
          "leaf_53",
          "node_1_26",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "finger": [
          "leaf_53",
          "node_1_26",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "item": [
          "leaf_53",
          "leaf_59",
          "node_1_26",
          "node_1_29",
          "node_2_13",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "lid": [
          "leaf_53",
          "node_1_26",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "military": [
          "leaf_53",
          "node_1_26",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "oiling": [
          "leaf_53",
          "leaf_54",
          "node_1_26",
          "node_1_27",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "uniform": [
          "leaf_53",
          "node_1_26",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "accurate": [
          "leaf_54",
          "leaf_56",
          "node_1_27",
          "node_1_28",
          "node_2_13",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "after": [
          "leaf_54",
          "leaf_55",
          "node_1_27",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "detailed": [
          "leaf_54",
          "node_1_27",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "frisbee": [
          "leaf_54",
          "leaf_55",
          "node_1_27",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "methods": [
          "leaf_54",
          "node_1_27",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "placing": [
          "leaf_54",
          "node_1_27",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "provide": [
          "leaf_54",
          "node_1_27",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "site": [
          "leaf_54",
          "leaf_58",
          "node_1_27",
          "node_1_29",
          "node_2_13",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "stabilization": [
          "leaf_54",
          "node_1_27",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "array": [
          "leaf_55",
          "node_1_27",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "backpacking": [
          "leaf_55",
          "node_1_27",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "belongings": [
          "leaf_55",
          "node_1_27",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "flavored": [
          "leaf_55",
          "leaf_56",
          "node_1_27",
          "node_1_28",
          "node_2_13",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "good": [
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "leaf_59",
          "node_1_27",
          "node_1_28",
          "node_1_29",
          "node_2_13",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "knife": [
          "leaf_55",
          "leaf_58",
          "node_1_27",
          "node_1_29",
          "node_2_13",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "knives": [
          "leaf_55",
          "node_1_27",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "ramen": [
          "leaf_55",
          "leaf_56",
          "node_1_27",
          "node_1_28",
          "node_2_13",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "tastes": [
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "node_1_27",
          "node_1_28",
          "node_2_13",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "trowel": [
          "leaf_55",
          "leaf_56",
          "leaf_57",
          "node_1_27",
          "node_1_28",
          "node_2_13",
          "node_2_14",
          "node_3_6",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "yellow": [
          "leaf_55",
          "node_1_27",
          "node_2_13",
          "node_3_6",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "baseball": [
          "leaf_56",
          "node_1_28",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "clearly": [
          "leaf_56",
          "node_1_28",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "discussing": [
          "leaf_56",
          "node_1_28",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "input": [
          "leaf_56",
          "node_1_28",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "interaction": [
          "leaf_56",
          "node_1_28",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "numerous": [
          "leaf_56",
          "node_1_28",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "oven": [
          "leaf_56",
          "node_1_28",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "plates": [
          "leaf_56",
          "node_1_28",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "process": [
          "leaf_56",
          "node_1_28",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "representation": [
          "leaf_56",
          "node_1_28",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "salmon": [
          "leaf_56",
          "leaf_57",
          "node_1_28",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "salt": [
          "leaf_56",
          "leaf_57",
          "leaf_58",
          "leaf_59",
          "node_1_28",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "sharing": [
          "leaf_56",
          "node_1_28",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "pepper": [
          "leaf_57",
          "leaf_58",
          "leaf_59",
          "node_1_28",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "bivou": [
          "leaf_58",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "casual": [
          "leaf_58",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "company": [
          "leaf_58",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "cozy": [
          "leaf_58",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "enjoy": [
          "leaf_58",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "messy": [
          "leaf_58",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "relaxed": [
          "leaf_58",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "sandwiches": [
          "leaf_58",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "settled": [
          "leaf_58",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "shared": [
          "leaf_58",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "table": [
          "leaf_58",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "camper": [
          "leaf_59",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "dishes": [
          "leaf_59",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "haired": [
          "leaf_59",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "holds": [
          "leaf_59",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "multi": [
          "leaf_59",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "pen": [
          "leaf_59",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "proximity": [
          "leaf_59",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "round": [
          "leaf_59",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "soldier": [
          "leaf_59",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ],
        "winter": [
          "leaf_59",
          "node_1_29",
          "node_2_14",
          "node_3_7",
          "node_4_3",
          "node_5_1",
          "node_6_0"
        ]
      }
    },
    "tree_metadata": {
      "leaf_duration": 5.0,
      "branching_factor": 2,
      "total_levels": 7,
      "total_nodes": 120,
      "total_keywords": 986,
      "stop_words_removed": [
        "a",
        "about",
        "add",
        "added",
        "against",
        "agree",
        "agreed",
        "all",
        "allow",
        "allowed",
        "already",
        "also",
        "although",
        "among",
        "an",
        "and",
        "any",
        "appear",
        "appeared",
        "are",
        "as",
        "ask",
        "asked",
        "at",
        "ate",
        "be",
        "became",
        "because",
        "become",
        "been",
        "being",
        "believe",
        "believed",
        "both",
        "bought",
        "break",
        "bring",
        "broke",
        "brought",
        "build",
        "built",
        "but",
        "buy",
        "by",
        "call",
        "called",
        "came",
        "can",
        "carried",
        "carry",
        "catch",
        "caught",
        "change",
        "changed",
        "choose",
        "chose",
        "come",
        "concerning",
        "consider",
        "considered",
        "continue",
        "continued",
        "could",
        "cover",
        "covered",
        "create",
        "created",
        "cut",
        "decide",
        "decided",
        "despite",
        "develop",
        "developed",
        "did",
        "die",
        "died",
        "do",
        "does",
        "doing",
        "don",
        "draw",
        "drew",
        "during",
        "each",
        "eat",
        "even",
        "every",
        "explain",
        "explained",
        "fall",
        "feel",
        "fell",
        "felt",
        "few",
        "find",
        "first",
        "follow",
        "followed",
        "for",
        "found",
        "from",
        "gave",
        "get",
        "give",
        "go",
        "got",
        "grew",
        "grow",
        "had",
        "happen",
        "happened",
        "has",
        "have",
        "having",
        "he",
        "help",
        "helped",
        "her",
        "here",
        "him",
        "his",
        "hit",
        "how",
        "i",
        "if",
        "in",
        "include",
        "included",
        "including",
        "into",
        "is",
        "it",
        "its",
        "just",
        "kill",
        "killed",
        "knew",
        "know",
        "lead",
        "learn",
        "learned",
        "leave",
        "led",
        "left",
        "let",
        "live",
        "lived",
        "look",
        "looked",
        "lose",
        "lost",
        "love",
        "loved",
        "made",
        "make",
        "many",
        "may",
        "me",
        "meet",
        "met",
        "might",
        "more",
        "most",
        "move",
        "moved",
        "must",
        "my",
        "need",
        "needed",
        "no",
        "nor",
        "not",
        "now",
        "of",
        "offer",
        "offered",
        "on",
        "one",
        "only",
        "open",
        "opened",
        "or",
        "other",
        "ought",
        "our",
        "paid",
        "pass",
        "passed",
        "pay",
        "produce",
        "produced",
        "put",
        "raise",
        "raised",
        "reach",
        "reached",
        "read",
        "receive",
        "received",
        "remember",
        "remembered",
        "return",
        "returned",
        "said",
        "same",
        "sat",
        "saw",
        "say",
        "second",
        "see",
        "seem",
        "seemed",
        "sell",
        "send",
        "sent",
        "serve",
        "served",
        "set",
        "shall",
        "she",
        "should",
        "show",
        "showed",
        "since",
        "sit",
        "so",
        "sold",
        "some",
        "speak",
        "spend",
        "spent",
        "spoke",
        "stand",
        "stay",
        "stayed",
        "still",
        "stood",
        "stop",
        "stopped",
        "such",
        "support",
        "supported",
        "take",
        "tell",
        "than",
        "that",
        "the",
        "their",
        "them",
        "then",
        "there",
        "these",
        "they",
        "think",
        "third",
        "this",
        "those",
        "though",
        "thought",
        "three",
        "through",
        "throughout",
        "to",
        "told",
        "too",
        "took",
        "towards",
        "tried",
        "try",
        "two",
        "understand",
        "understood",
        "unless",
        "until",
        "up",
        "upon",
        "us",
        "use",
        "used",
        "very",
        "wait",
        "waited",
        "walk",
        "walked",
        "want",
        "wanted",
        "was",
        "watch",
        "watched",
        "we",
        "went",
        "were",
        "what",
        "when",
        "where",
        "whether",
        "which",
        "while",
        "who",
        "whom",
        "why",
        "will",
        "win",
        "with",
        "won",
        "work",
        "worked",
        "would",
        "write",
        "wrote",
        "yet",
        "you",
        "your"
      ]
    }
  }
}